2023-08-15 09:23:33,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 09:23:33,994:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 09:23:33,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 09:23:33,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 09:24:30,685:INFO:PyCaret ClassificationExperiment
2023-08-15 09:24:30,686:INFO:Logging name: clf-default-name
2023-08-15 09:24:30,686:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 09:24:30,686:INFO:version 3.0.4
2023-08-15 09:24:30,686:INFO:Initializing setup()
2023-08-15 09:24:30,686:INFO:self.USI: 6848
2023-08-15 09:24:30,686:INFO:self._variable_keys: {'fix_imbalance', '_available_plots', 'exp_id', '_ml_usecase', 'pipeline', 'logging_param', 'X_test', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_groups_param', 'log_plots_param', 'y', 'data', 'seed', 'html_param', 'exp_name_log', 'n_jobs_param', 'USI', 'is_multiclass', 'X', 'idx', 'gpu_param', 'X_train', 'y_test', 'y_train', 'fold_generator', 'memory', 'target_param'}
2023-08-15 09:24:30,686:INFO:Checking environment
2023-08-15 09:24:30,686:INFO:python_version: 3.10.12
2023-08-15 09:24:30,686:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 09:24:30,686:INFO:machine: AMD64
2023-08-15 09:24:30,686:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 09:24:30,690:INFO:Memory: svmem(total=68448301056, available=55091912704, percent=19.5, used=13356388352, free=55091912704)
2023-08-15 09:24:30,690:INFO:Physical Core: 12
2023-08-15 09:24:30,690:INFO:Logical Core: 20
2023-08-15 09:24:30,690:INFO:Checking libraries
2023-08-15 09:24:30,690:INFO:System:
2023-08-15 09:24:30,690:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 09:24:30,690:INFO:executable: c:\Users\Ramon\anaconda3\envs\PycaretEnv\python.exe
2023-08-15 09:24:30,690:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 09:24:30,690:INFO:PyCaret required dependencies:
2023-08-15 09:24:31,199:INFO:                 pip: 23.2.1
2023-08-15 09:24:31,199:INFO:          setuptools: 68.0.0
2023-08-15 09:24:31,199:INFO:             pycaret: 3.0.4
2023-08-15 09:24:31,199:INFO:             IPython: 8.14.0
2023-08-15 09:24:31,199:INFO:          ipywidgets: 8.1.0
2023-08-15 09:24:31,199:INFO:                tqdm: 4.66.1
2023-08-15 09:24:31,199:INFO:               numpy: 1.25.2
2023-08-15 09:24:31,199:INFO:              pandas: 2.0.3
2023-08-15 09:24:31,199:INFO:              jinja2: 3.1.2
2023-08-15 09:24:31,199:INFO:               scipy: 1.11.1
2023-08-15 09:24:31,199:INFO:              joblib: 1.3.2
2023-08-15 09:24:31,199:INFO:             sklearn: 1.3.0
2023-08-15 09:24:31,199:INFO:                pyod: 1.1.0
2023-08-15 09:24:31,199:INFO:            imblearn: 0.11.0
2023-08-15 09:24:31,199:INFO:   category_encoders: 2.6.1
2023-08-15 09:24:31,199:INFO:            lightgbm: 4.0.0
2023-08-15 09:24:31,199:INFO:               numba: 0.57.1
2023-08-15 09:24:31,199:INFO:            requests: 2.31.0
2023-08-15 09:24:31,199:INFO:          matplotlib: 3.7.2
2023-08-15 09:24:31,199:INFO:          scikitplot: 0.3.7
2023-08-15 09:24:31,199:INFO:         yellowbrick: 1.5
2023-08-15 09:24:31,200:INFO:              plotly: 5.16.0
2023-08-15 09:24:31,200:INFO:    plotly-resampler: Not installed
2023-08-15 09:24:31,200:INFO:             kaleido: 0.2.1
2023-08-15 09:24:31,200:INFO:           schemdraw: 0.15
2023-08-15 09:24:31,200:INFO:         statsmodels: 0.14.0
2023-08-15 09:24:31,200:INFO:              sktime: 0.21.0
2023-08-15 09:24:31,200:INFO:               tbats: 1.1.3
2023-08-15 09:24:31,200:INFO:            pmdarima: 2.0.3
2023-08-15 09:24:31,200:INFO:              psutil: 5.9.5
2023-08-15 09:24:31,200:INFO:          markupsafe: 2.1.3
2023-08-15 09:24:31,200:INFO:             pickle5: Not installed
2023-08-15 09:24:31,200:INFO:         cloudpickle: 2.2.1
2023-08-15 09:24:31,200:INFO:         deprecation: 2.1.0
2023-08-15 09:24:31,200:INFO:              xxhash: 3.2.0
2023-08-15 09:24:31,200:INFO:           wurlitzer: Not installed
2023-08-15 09:24:31,200:INFO:PyCaret optional dependencies:
2023-08-15 09:24:31,335:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
2023-08-15 09:24:31,335:WARNING:  warnings.warn(
2023-08-15 09:24:32,560:INFO:                shap: 0.42.1
2023-08-15 09:24:32,561:INFO:           interpret: 0.4.3
2023-08-15 09:24:32,561:INFO:                umap: 0.5.3
2023-08-15 09:24:32,561:INFO:    pandas_profiling: 4.4.0
2023-08-15 09:24:32,561:INFO:  explainerdashboard: 0.4.3
2023-08-15 09:24:32,561:INFO:             autoviz: 0.1.730
2023-08-15 09:24:32,561:INFO:           fairlearn: 0.7.0
2023-08-15 09:24:32,561:INFO:          deepchecks: 0.17.4
2023-08-15 09:24:32,561:INFO:             xgboost: 1.7.6
2023-08-15 09:24:32,561:INFO:            catboost: 1.2
2023-08-15 09:24:32,561:INFO:              kmodes: 0.12.2
2023-08-15 09:24:32,561:INFO:             mlxtend: 0.22.0
2023-08-15 09:24:32,561:INFO:       statsforecast: 1.5.0
2023-08-15 09:24:32,561:INFO:        tune_sklearn: 0.4.6
2023-08-15 09:24:32,561:INFO:                 ray: 2.6.1
2023-08-15 09:24:32,561:INFO:            hyperopt: 0.2.7
2023-08-15 09:24:32,561:INFO:              optuna: 3.3.0
2023-08-15 09:24:32,561:INFO:               skopt: 0.9.0
2023-08-15 09:24:32,561:INFO:              mlflow: 1.30.1
2023-08-15 09:24:32,561:INFO:              gradio: 3.39.0
2023-08-15 09:24:32,561:INFO:             fastapi: 0.101.0
2023-08-15 09:24:32,561:INFO:             uvicorn: 0.23.2
2023-08-15 09:24:32,561:INFO:              m2cgen: 0.10.0
2023-08-15 09:24:32,561:INFO:           evidently: 0.2.8
2023-08-15 09:24:32,561:INFO:               fugue: 0.8.6
2023-08-15 09:24:32,561:INFO:           streamlit: Not installed
2023-08-15 09:24:32,561:INFO:             prophet: Not installed
2023-08-15 09:24:32,561:INFO:None
2023-08-15 09:24:32,561:INFO:Set up data.
2023-08-15 09:24:32,744:INFO:Set up train/test split.
2023-08-15 09:24:32,902:INFO:Set up index.
2023-08-15 09:24:32,906:INFO:Set up folding strategy.
2023-08-15 09:24:32,907:INFO:Assigning column types.
2023-08-15 09:24:32,941:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 09:24:32,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 09:24:32,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 09:24:32,987:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:24:33,020:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:24:33,131:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 09:24:33,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 09:24:33,147:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:24:33,148:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:24:33,149:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 09:24:33,174:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 09:24:33,189:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:24:33,190:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:24:33,216:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 09:24:33,232:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:24:33,233:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:24:33,234:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 09:24:33,271:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:24:33,273:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:24:33,313:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:24:33,314:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:24:33,315:INFO:Preparing preprocessing pipeline...
2023-08-15 09:24:33,322:INFO:Set up label encoding.
2023-08-15 09:24:33,322:INFO:Set up simple imputation.
2023-08-15 09:24:33,361:INFO:Set up encoding of ordinal features.
2023-08-15 09:24:33,435:INFO:Set up encoding of categorical features.
2023-08-15 09:24:33,440:INFO:Set up column name cleaning.
2023-08-15 09:24:36,017:INFO:Finished creating preprocessing pipeline.
2023-08-15 09:24:36,053:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 09:24:36,054:INFO:Creating final display dataframe.
2023-08-15 09:24:37,904:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              6848
2023-08-15 09:24:37,947:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:24:37,949:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:24:37,990:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:24:37,992:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:24:37,993:INFO:setup() successfully completed in 7.34s...............
2023-08-15 09:28:59,970:INFO:Soft dependency imported: autoviz: 0.1.730
2023-08-15 09:46:05,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 09:46:05,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 09:46:05,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 09:46:05,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 09:46:06,619:INFO:PyCaret ClassificationExperiment
2023-08-15 09:46:06,619:INFO:Logging name: clf-default-name
2023-08-15 09:46:06,619:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 09:46:06,619:INFO:version 3.0.4
2023-08-15 09:46:06,619:INFO:Initializing setup()
2023-08-15 09:46:06,619:INFO:self.USI: 1801
2023-08-15 09:46:06,619:INFO:self._variable_keys: {'html_param', 'data', 'is_multiclass', 'memory', 'logging_param', 'y_test', 'y', 'fold_generator', 'X', 'log_plots_param', 'pipeline', '_available_plots', 'gpu_param', 'y_train', 'X_train', 'USI', 'target_param', 'idx', 'gpu_n_jobs_param', 'fold_groups_param', 'fold_shuffle_param', 'X_test', 'exp_id', '_ml_usecase', 'n_jobs_param', 'seed', 'fix_imbalance', 'exp_name_log'}
2023-08-15 09:46:06,619:INFO:Checking environment
2023-08-15 09:46:06,619:INFO:python_version: 3.10.12
2023-08-15 09:46:06,619:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 09:46:06,619:INFO:machine: AMD64
2023-08-15 09:46:06,619:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 09:46:06,623:INFO:Memory: svmem(total=68448301056, available=54344826880, percent=20.6, used=14103474176, free=54344826880)
2023-08-15 09:46:06,623:INFO:Physical Core: 12
2023-08-15 09:46:06,623:INFO:Logical Core: 20
2023-08-15 09:46:06,623:INFO:Checking libraries
2023-08-15 09:46:06,623:INFO:System:
2023-08-15 09:46:06,623:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 09:46:06,623:INFO:executable: c:\Users\Ramon\anaconda3\envs\PycaretEnv\python.exe
2023-08-15 09:46:06,623:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 09:46:06,623:INFO:PyCaret required dependencies:
2023-08-15 09:46:06,996:INFO:                 pip: 23.2.1
2023-08-15 09:46:06,996:INFO:          setuptools: 68.0.0
2023-08-15 09:46:06,996:INFO:             pycaret: 3.0.4
2023-08-15 09:46:06,996:INFO:             IPython: 8.14.0
2023-08-15 09:46:06,996:INFO:          ipywidgets: 8.1.0
2023-08-15 09:46:06,996:INFO:                tqdm: 4.66.1
2023-08-15 09:46:06,996:INFO:               numpy: 1.25.2
2023-08-15 09:46:06,996:INFO:              pandas: 2.0.3
2023-08-15 09:46:06,996:INFO:              jinja2: 3.1.2
2023-08-15 09:46:06,996:INFO:               scipy: 1.11.1
2023-08-15 09:46:06,996:INFO:              joblib: 1.3.2
2023-08-15 09:46:06,996:INFO:             sklearn: 1.3.0
2023-08-15 09:46:06,996:INFO:                pyod: 1.1.0
2023-08-15 09:46:06,996:INFO:            imblearn: 0.11.0
2023-08-15 09:46:06,996:INFO:   category_encoders: 2.6.1
2023-08-15 09:46:06,996:INFO:            lightgbm: 4.0.0
2023-08-15 09:46:06,996:INFO:               numba: 0.57.1
2023-08-15 09:46:06,996:INFO:            requests: 2.31.0
2023-08-15 09:46:06,996:INFO:          matplotlib: 3.7.2
2023-08-15 09:46:06,996:INFO:          scikitplot: 0.3.7
2023-08-15 09:46:06,996:INFO:         yellowbrick: 1.5
2023-08-15 09:46:06,996:INFO:              plotly: 5.16.0
2023-08-15 09:46:06,996:INFO:    plotly-resampler: Not installed
2023-08-15 09:46:06,996:INFO:             kaleido: 0.2.1
2023-08-15 09:46:06,996:INFO:           schemdraw: 0.15
2023-08-15 09:46:06,996:INFO:         statsmodels: 0.14.0
2023-08-15 09:46:06,996:INFO:              sktime: 0.21.0
2023-08-15 09:46:06,997:INFO:               tbats: 1.1.3
2023-08-15 09:46:06,997:INFO:            pmdarima: 2.0.3
2023-08-15 09:46:06,997:INFO:              psutil: 5.9.5
2023-08-15 09:46:06,997:INFO:          markupsafe: 2.1.3
2023-08-15 09:46:06,997:INFO:             pickle5: Not installed
2023-08-15 09:46:06,997:INFO:         cloudpickle: 2.2.1
2023-08-15 09:46:06,997:INFO:         deprecation: 2.1.0
2023-08-15 09:46:06,997:INFO:              xxhash: 3.2.0
2023-08-15 09:46:06,997:INFO:           wurlitzer: Not installed
2023-08-15 09:46:06,997:INFO:PyCaret optional dependencies:
2023-08-15 09:46:07,169:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
  warnings.warn(

2023-08-15 09:46:08,228:INFO:                shap: 0.42.1
2023-08-15 09:46:08,229:INFO:           interpret: 0.4.3
2023-08-15 09:46:08,229:INFO:                umap: 0.5.3
2023-08-15 09:46:08,229:INFO:    pandas_profiling: 4.4.0
2023-08-15 09:46:08,229:INFO:  explainerdashboard: 0.4.3
2023-08-15 09:46:08,229:INFO:             autoviz: 0.1.730
2023-08-15 09:46:08,229:INFO:           fairlearn: 0.7.0
2023-08-15 09:46:08,229:INFO:          deepchecks: 0.17.4
2023-08-15 09:46:08,229:INFO:             xgboost: 1.7.6
2023-08-15 09:46:08,229:INFO:            catboost: 1.2
2023-08-15 09:46:08,229:INFO:              kmodes: 0.12.2
2023-08-15 09:46:08,229:INFO:             mlxtend: 0.22.0
2023-08-15 09:46:08,229:INFO:       statsforecast: 1.5.0
2023-08-15 09:46:08,229:INFO:        tune_sklearn: 0.4.6
2023-08-15 09:46:08,229:INFO:                 ray: 2.6.1
2023-08-15 09:46:08,229:INFO:            hyperopt: 0.2.7
2023-08-15 09:46:08,229:INFO:              optuna: 3.3.0
2023-08-15 09:46:08,229:INFO:               skopt: 0.9.0
2023-08-15 09:46:08,229:INFO:              mlflow: 1.30.1
2023-08-15 09:46:08,229:INFO:              gradio: 3.39.0
2023-08-15 09:46:08,229:INFO:             fastapi: 0.101.0
2023-08-15 09:46:08,229:INFO:             uvicorn: 0.23.2
2023-08-15 09:46:08,229:INFO:              m2cgen: 0.10.0
2023-08-15 09:46:08,229:INFO:           evidently: 0.2.8
2023-08-15 09:46:08,229:INFO:               fugue: 0.8.6
2023-08-15 09:46:08,229:INFO:           streamlit: Not installed
2023-08-15 09:46:08,229:INFO:             prophet: Not installed
2023-08-15 09:46:08,229:INFO:None
2023-08-15 09:46:08,229:INFO:Set up data.
2023-08-15 09:46:08,415:INFO:Set up train/test split.
2023-08-15 09:46:08,576:INFO:Set up index.
2023-08-15 09:46:08,581:INFO:Set up folding strategy.
2023-08-15 09:46:08,581:INFO:Assigning column types.
2023-08-15 09:46:08,616:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 09:46:08,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 09:46:08,641:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 09:46:08,660:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:46:08,679:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:46:08,716:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 09:46:08,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 09:46:08,731:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:46:08,733:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:46:08,733:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 09:46:08,755:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 09:46:08,770:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:46:08,771:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:46:08,795:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 09:46:08,809:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:46:08,812:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:46:08,812:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 09:46:08,849:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:46:08,851:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:46:08,889:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:46:08,890:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:46:08,892:INFO:Preparing preprocessing pipeline...
2023-08-15 09:46:08,899:INFO:Set up label encoding.
2023-08-15 09:46:08,899:INFO:Set up simple imputation.
2023-08-15 09:46:08,937:INFO:Set up encoding of ordinal features.
2023-08-15 09:46:09,017:INFO:Set up encoding of categorical features.
2023-08-15 09:46:09,022:INFO:Set up column name cleaning.
2023-08-15 09:46:10,476:INFO:Finished creating preprocessing pipeline.
2023-08-15 09:46:10,511:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 09:46:10,511:INFO:Creating final display dataframe.
2023-08-15 09:46:11,896:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              1801
2023-08-15 09:46:11,941:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:46:11,943:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:46:11,986:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 09:46:11,987:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 09:46:11,988:INFO:setup() successfully completed in 5.4s...............
2023-08-15 09:47:09,680:INFO:Soft dependency imported: autoviz: 0.1.730
2023-08-15 09:50:38,173:INFO:Soft dependency imported: autoviz: 0.1.730
2023-08-15 10:14:43,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:14:43,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:14:43,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:14:43,279:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:14:44,233:INFO:PyCaret ClassificationExperiment
2023-08-15 10:14:44,233:INFO:Logging name: clf-default-name
2023-08-15 10:14:44,233:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 10:14:44,233:INFO:version 3.0.4
2023-08-15 10:14:44,233:INFO:Initializing setup()
2023-08-15 10:14:44,233:INFO:self.USI: 8805
2023-08-15 10:14:44,233:INFO:self._variable_keys: {'idx', 'fix_imbalance', 'logging_param', 'gpu_n_jobs_param', 'y_test', 'data', 'exp_name_log', 'n_jobs_param', 'target_param', 'y_train', '_ml_usecase', 'pipeline', 'seed', 'is_multiclass', 'X_test', 'memory', 'fold_shuffle_param', 'exp_id', 'fold_groups_param', 'y', 'X', 'gpu_param', 'X_train', 'USI', 'log_plots_param', 'fold_generator', '_available_plots', 'html_param'}
2023-08-15 10:14:44,233:INFO:Checking environment
2023-08-15 10:14:44,233:INFO:python_version: 3.10.12
2023-08-15 10:14:44,233:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 10:14:44,233:INFO:machine: AMD64
2023-08-15 10:14:44,233:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 10:14:44,237:INFO:Memory: svmem(total=68448301056, available=51769655296, percent=24.4, used=16678645760, free=51769655296)
2023-08-15 10:14:44,237:INFO:Physical Core: 12
2023-08-15 10:14:44,237:INFO:Logical Core: 20
2023-08-15 10:14:44,237:INFO:Checking libraries
2023-08-15 10:14:44,237:INFO:System:
2023-08-15 10:14:44,237:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 10:14:44,237:INFO:executable: C:\Users\Ramon\anaconda3\envs\pycaretenv\python.exe
2023-08-15 10:14:44,237:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 10:14:44,237:INFO:PyCaret required dependencies:
2023-08-15 10:14:44,605:INFO:                 pip: 23.2.1
2023-08-15 10:14:44,605:INFO:          setuptools: 68.0.0
2023-08-15 10:14:44,605:INFO:             pycaret: 3.0.4
2023-08-15 10:14:44,605:INFO:             IPython: 8.14.0
2023-08-15 10:14:44,605:INFO:          ipywidgets: 8.1.0
2023-08-15 10:14:44,605:INFO:                tqdm: 4.66.1
2023-08-15 10:14:44,605:INFO:               numpy: 1.25.2
2023-08-15 10:14:44,605:INFO:              pandas: 2.0.3
2023-08-15 10:14:44,605:INFO:              jinja2: 3.1.2
2023-08-15 10:14:44,605:INFO:               scipy: 1.11.1
2023-08-15 10:14:44,605:INFO:              joblib: 1.3.2
2023-08-15 10:14:44,605:INFO:             sklearn: 1.3.0
2023-08-15 10:14:44,605:INFO:                pyod: 1.1.0
2023-08-15 10:14:44,605:INFO:            imblearn: 0.11.0
2023-08-15 10:14:44,605:INFO:   category_encoders: 2.6.1
2023-08-15 10:14:44,605:INFO:            lightgbm: 4.0.0
2023-08-15 10:14:44,605:INFO:               numba: 0.57.1
2023-08-15 10:14:44,605:INFO:            requests: 2.31.0
2023-08-15 10:14:44,605:INFO:          matplotlib: 3.7.2
2023-08-15 10:14:44,605:INFO:          scikitplot: 0.3.7
2023-08-15 10:14:44,605:INFO:         yellowbrick: 1.5
2023-08-15 10:14:44,605:INFO:              plotly: 5.16.0
2023-08-15 10:14:44,605:INFO:    plotly-resampler: Not installed
2023-08-15 10:14:44,605:INFO:             kaleido: 0.2.1
2023-08-15 10:14:44,605:INFO:           schemdraw: 0.15
2023-08-15 10:14:44,606:INFO:         statsmodels: 0.14.0
2023-08-15 10:14:44,606:INFO:              sktime: 0.21.0
2023-08-15 10:14:44,606:INFO:               tbats: 1.1.3
2023-08-15 10:14:44,606:INFO:            pmdarima: 2.0.3
2023-08-15 10:14:44,606:INFO:              psutil: 5.9.5
2023-08-15 10:14:44,606:INFO:          markupsafe: 2.1.3
2023-08-15 10:14:44,606:INFO:             pickle5: Not installed
2023-08-15 10:14:44,606:INFO:         cloudpickle: 2.2.1
2023-08-15 10:14:44,606:INFO:         deprecation: 2.1.0
2023-08-15 10:14:44,606:INFO:              xxhash: 3.2.0
2023-08-15 10:14:44,606:INFO:           wurlitzer: Not installed
2023-08-15 10:14:44,606:INFO:PyCaret optional dependencies:
2023-08-15 10:14:44,773:WARNING:C:\Users\Ramon\anaconda3\envs\pycaretenv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
  warnings.warn(

2023-08-15 10:14:45,781:INFO:                shap: 0.42.1
2023-08-15 10:14:45,782:INFO:           interpret: 0.4.3
2023-08-15 10:14:45,782:INFO:                umap: 0.5.3
2023-08-15 10:14:45,782:INFO:    pandas_profiling: 4.4.0
2023-08-15 10:14:45,782:INFO:  explainerdashboard: 0.4.3
2023-08-15 10:14:45,782:INFO:             autoviz: 0.1.730
2023-08-15 10:14:45,782:INFO:           fairlearn: 0.7.0
2023-08-15 10:14:45,782:INFO:          deepchecks: 0.17.4
2023-08-15 10:14:45,782:INFO:             xgboost: 1.7.6
2023-08-15 10:14:45,782:INFO:            catboost: 1.2
2023-08-15 10:14:45,782:INFO:              kmodes: 0.12.2
2023-08-15 10:14:45,782:INFO:             mlxtend: 0.22.0
2023-08-15 10:14:45,782:INFO:       statsforecast: 1.5.0
2023-08-15 10:14:45,782:INFO:        tune_sklearn: 0.4.6
2023-08-15 10:14:45,782:INFO:                 ray: 2.6.1
2023-08-15 10:14:45,782:INFO:            hyperopt: 0.2.7
2023-08-15 10:14:45,782:INFO:              optuna: 3.3.0
2023-08-15 10:14:45,782:INFO:               skopt: 0.9.0
2023-08-15 10:14:45,782:INFO:              mlflow: 1.30.1
2023-08-15 10:14:45,782:INFO:              gradio: 3.39.0
2023-08-15 10:14:45,782:INFO:             fastapi: 0.101.0
2023-08-15 10:14:45,782:INFO:             uvicorn: 0.23.2
2023-08-15 10:14:45,782:INFO:              m2cgen: 0.10.0
2023-08-15 10:14:45,782:INFO:           evidently: 0.2.8
2023-08-15 10:14:45,782:INFO:               fugue: 0.8.6
2023-08-15 10:14:45,782:INFO:           streamlit: Not installed
2023-08-15 10:14:45,782:INFO:             prophet: Not installed
2023-08-15 10:14:45,782:INFO:None
2023-08-15 10:14:45,782:INFO:Set up data.
2023-08-15 10:14:45,984:INFO:Set up train/test split.
2023-08-15 10:14:46,146:INFO:Set up index.
2023-08-15 10:14:46,151:INFO:Set up folding strategy.
2023-08-15 10:14:46,151:INFO:Assigning column types.
2023-08-15 10:14:46,186:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 10:14:46,209:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 10:14:46,212:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:14:46,230:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:14:46,249:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:14:46,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 10:14:46,285:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:14:46,300:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:14:46,302:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:14:46,302:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 10:14:46,326:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:14:46,341:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:14:46,342:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:14:46,366:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:14:46,380:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:14:46,382:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:14:46,382:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 10:14:46,422:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:14:46,424:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:14:46,464:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:14:46,465:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:14:46,467:INFO:Preparing preprocessing pipeline...
2023-08-15 10:14:46,474:INFO:Set up label encoding.
2023-08-15 10:14:46,474:INFO:Set up simple imputation.
2023-08-15 10:14:46,513:INFO:Set up encoding of ordinal features.
2023-08-15 10:14:46,588:INFO:Set up encoding of categorical features.
2023-08-15 10:14:46,594:INFO:Set up column name cleaning.
2023-08-15 10:14:47,130:INFO:Finished creating preprocessing pipeline.
2023-08-15 10:14:47,176:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 10:14:47,176:INFO:Creating final display dataframe.
2023-08-15 10:14:48,576:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              8805
2023-08-15 10:14:48,619:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:14:48,620:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:14:48,659:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:14:48,660:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:14:48,661:INFO:setup() successfully completed in 4.45s...............
2023-08-15 10:17:18,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:17:18,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:17:18,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:17:18,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:17:18,732:INFO:PyCaret ClassificationExperiment
2023-08-15 10:17:18,732:INFO:Logging name: clf-default-name
2023-08-15 10:17:18,732:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 10:17:18,732:INFO:version 3.0.4
2023-08-15 10:17:18,732:INFO:Initializing setup()
2023-08-15 10:17:18,732:INFO:self.USI: cb0c
2023-08-15 10:17:18,732:INFO:self._variable_keys: {'idx', 'target_param', 'y', 'seed', 'fold_generator', 'memory', 'html_param', 'gpu_param', 'USI', 'n_jobs_param', 'gpu_n_jobs_param', 'X_test', 'fix_imbalance', 'is_multiclass', 'pipeline', 'exp_id', 'logging_param', 'y_test', 'y_train', '_available_plots', 'fold_groups_param', 'X', '_ml_usecase', 'X_train', 'fold_shuffle_param', 'exp_name_log', 'data', 'log_plots_param'}
2023-08-15 10:17:18,732:INFO:Checking environment
2023-08-15 10:17:18,732:INFO:python_version: 3.10.12
2023-08-15 10:17:18,732:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 10:17:18,732:INFO:machine: AMD64
2023-08-15 10:17:18,732:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 10:17:18,736:INFO:Memory: svmem(total=68448301056, available=52512018432, percent=23.3, used=15936282624, free=52512018432)
2023-08-15 10:17:18,736:INFO:Physical Core: 12
2023-08-15 10:17:18,736:INFO:Logical Core: 20
2023-08-15 10:17:18,736:INFO:Checking libraries
2023-08-15 10:17:18,736:INFO:System:
2023-08-15 10:17:18,736:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 10:17:18,736:INFO:executable: c:\Users\Ramon\anaconda3\envs\PycaretEnv\python.exe
2023-08-15 10:17:18,736:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 10:17:18,736:INFO:PyCaret required dependencies:
2023-08-15 10:17:19,089:INFO:                 pip: 23.2.1
2023-08-15 10:17:19,089:INFO:          setuptools: 68.0.0
2023-08-15 10:17:19,089:INFO:             pycaret: 3.0.4
2023-08-15 10:17:19,089:INFO:             IPython: 8.14.0
2023-08-15 10:17:19,089:INFO:          ipywidgets: 8.1.0
2023-08-15 10:17:19,089:INFO:                tqdm: 4.66.1
2023-08-15 10:17:19,089:INFO:               numpy: 1.25.2
2023-08-15 10:17:19,089:INFO:              pandas: 2.0.3
2023-08-15 10:17:19,089:INFO:              jinja2: 3.1.2
2023-08-15 10:17:19,089:INFO:               scipy: 1.11.1
2023-08-15 10:17:19,089:INFO:              joblib: 1.3.2
2023-08-15 10:17:19,089:INFO:             sklearn: 1.3.0
2023-08-15 10:17:19,089:INFO:                pyod: 1.1.0
2023-08-15 10:17:19,089:INFO:            imblearn: 0.11.0
2023-08-15 10:17:19,089:INFO:   category_encoders: 2.6.1
2023-08-15 10:17:19,089:INFO:            lightgbm: 4.0.0
2023-08-15 10:17:19,089:INFO:               numba: 0.57.1
2023-08-15 10:17:19,089:INFO:            requests: 2.31.0
2023-08-15 10:17:19,089:INFO:          matplotlib: 3.7.2
2023-08-15 10:17:19,090:INFO:          scikitplot: 0.3.7
2023-08-15 10:17:19,090:INFO:         yellowbrick: 1.5
2023-08-15 10:17:19,090:INFO:              plotly: 5.16.0
2023-08-15 10:17:19,090:INFO:    plotly-resampler: Not installed
2023-08-15 10:17:19,090:INFO:             kaleido: 0.2.1
2023-08-15 10:17:19,090:INFO:           schemdraw: 0.15
2023-08-15 10:17:19,090:INFO:         statsmodels: 0.14.0
2023-08-15 10:17:19,090:INFO:              sktime: 0.21.0
2023-08-15 10:17:19,090:INFO:               tbats: 1.1.3
2023-08-15 10:17:19,090:INFO:            pmdarima: 2.0.3
2023-08-15 10:17:19,090:INFO:              psutil: 5.9.5
2023-08-15 10:17:19,090:INFO:          markupsafe: 2.1.3
2023-08-15 10:17:19,090:INFO:             pickle5: Not installed
2023-08-15 10:17:19,090:INFO:         cloudpickle: 2.2.1
2023-08-15 10:17:19,090:INFO:         deprecation: 2.1.0
2023-08-15 10:17:19,090:INFO:              xxhash: 3.2.0
2023-08-15 10:17:19,090:INFO:           wurlitzer: Not installed
2023-08-15 10:17:19,090:INFO:PyCaret optional dependencies:
2023-08-15 10:17:19,250:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
  warnings.warn(

2023-08-15 10:17:20,272:INFO:                shap: 0.42.1
2023-08-15 10:17:20,272:INFO:           interpret: 0.4.3
2023-08-15 10:17:20,272:INFO:                umap: 0.5.3
2023-08-15 10:17:20,272:INFO:    pandas_profiling: 4.4.0
2023-08-15 10:17:20,272:INFO:  explainerdashboard: 0.4.3
2023-08-15 10:17:20,272:INFO:             autoviz: 0.1.730
2023-08-15 10:17:20,272:INFO:           fairlearn: 0.7.0
2023-08-15 10:17:20,272:INFO:          deepchecks: 0.17.4
2023-08-15 10:17:20,272:INFO:             xgboost: 1.7.6
2023-08-15 10:17:20,272:INFO:            catboost: 1.2
2023-08-15 10:17:20,272:INFO:              kmodes: 0.12.2
2023-08-15 10:17:20,272:INFO:             mlxtend: 0.22.0
2023-08-15 10:17:20,272:INFO:       statsforecast: 1.5.0
2023-08-15 10:17:20,272:INFO:        tune_sklearn: 0.4.6
2023-08-15 10:17:20,272:INFO:                 ray: 2.6.1
2023-08-15 10:17:20,272:INFO:            hyperopt: 0.2.7
2023-08-15 10:17:20,272:INFO:              optuna: 3.3.0
2023-08-15 10:17:20,272:INFO:               skopt: 0.9.0
2023-08-15 10:17:20,272:INFO:              mlflow: 1.30.1
2023-08-15 10:17:20,272:INFO:              gradio: 3.39.0
2023-08-15 10:17:20,272:INFO:             fastapi: 0.101.0
2023-08-15 10:17:20,272:INFO:             uvicorn: 0.23.2
2023-08-15 10:17:20,272:INFO:              m2cgen: 0.10.0
2023-08-15 10:17:20,272:INFO:           evidently: 0.2.8
2023-08-15 10:17:20,272:INFO:               fugue: 0.8.6
2023-08-15 10:17:20,272:INFO:           streamlit: Not installed
2023-08-15 10:17:20,272:INFO:             prophet: Not installed
2023-08-15 10:17:20,272:INFO:None
2023-08-15 10:17:20,272:INFO:Set up data.
2023-08-15 10:17:20,466:INFO:Set up train/test split.
2023-08-15 10:17:20,629:INFO:Set up index.
2023-08-15 10:17:20,634:INFO:Set up folding strategy.
2023-08-15 10:17:20,634:INFO:Assigning column types.
2023-08-15 10:17:20,667:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 10:17:20,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 10:17:20,693:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:17:20,712:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:17:20,729:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:17:20,765:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 10:17:20,765:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:17:20,779:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:17:20,781:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:17:20,781:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 10:17:20,804:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:17:20,818:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:17:20,820:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:17:20,843:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:17:20,857:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:17:20,859:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:17:20,859:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 10:17:20,897:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:17:20,898:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:17:20,936:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:17:20,938:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:17:20,940:INFO:Preparing preprocessing pipeline...
2023-08-15 10:17:20,945:INFO:Set up label encoding.
2023-08-15 10:17:20,946:INFO:Set up simple imputation.
2023-08-15 10:17:20,983:INFO:Set up encoding of ordinal features.
2023-08-15 10:17:21,057:INFO:Set up encoding of categorical features.
2023-08-15 10:17:21,063:INFO:Set up column name cleaning.
2023-08-15 10:17:21,581:INFO:Finished creating preprocessing pipeline.
2023-08-15 10:17:21,619:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 10:17:21,619:INFO:Creating final display dataframe.
2023-08-15 10:17:22,774:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              cb0c
2023-08-15 10:17:22,817:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:17:22,819:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:17:22,866:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:17:22,868:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:17:22,869:INFO:setup() successfully completed in 4.16s...............
2023-08-15 10:23:58,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:23:58,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:23:58,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:23:58,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 10:23:59,592:INFO:PyCaret ClassificationExperiment
2023-08-15 10:23:59,592:INFO:Logging name: clf-default-name
2023-08-15 10:23:59,592:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 10:23:59,592:INFO:version 3.0.4
2023-08-15 10:23:59,592:INFO:Initializing setup()
2023-08-15 10:23:59,592:INFO:self.USI: 7eca
2023-08-15 10:23:59,592:INFO:self._variable_keys: {'idx', 'memory', 'target_param', 'y_test', 'y_train', 'n_jobs_param', 'fold_generator', 'X_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'y', '_available_plots', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'logging_param', 'X_train', 'is_multiclass', 'exp_name_log', 'html_param', 'seed', 'USI', 'gpu_param', 'pipeline', 'log_plots_param', 'X', 'exp_id'}
2023-08-15 10:23:59,592:INFO:Checking environment
2023-08-15 10:23:59,592:INFO:python_version: 3.10.12
2023-08-15 10:23:59,592:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 10:23:59,592:INFO:machine: AMD64
2023-08-15 10:23:59,592:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 10:23:59,596:INFO:Memory: svmem(total=68448301056, available=51532292096, percent=24.7, used=16916008960, free=51532292096)
2023-08-15 10:23:59,596:INFO:Physical Core: 12
2023-08-15 10:23:59,596:INFO:Logical Core: 20
2023-08-15 10:23:59,597:INFO:Checking libraries
2023-08-15 10:23:59,597:INFO:System:
2023-08-15 10:23:59,597:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 10:23:59,597:INFO:executable: c:\Users\Ramon\anaconda3\envs\PycaretEnv\python.exe
2023-08-15 10:23:59,597:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 10:23:59,597:INFO:PyCaret required dependencies:
2023-08-15 10:23:59,957:INFO:                 pip: 23.2.1
2023-08-15 10:23:59,957:INFO:          setuptools: 68.0.0
2023-08-15 10:23:59,958:INFO:             pycaret: 3.0.4
2023-08-15 10:23:59,958:INFO:             IPython: 8.14.0
2023-08-15 10:23:59,958:INFO:          ipywidgets: 8.1.0
2023-08-15 10:23:59,958:INFO:                tqdm: 4.66.1
2023-08-15 10:23:59,958:INFO:               numpy: 1.25.2
2023-08-15 10:23:59,958:INFO:              pandas: 2.0.3
2023-08-15 10:23:59,958:INFO:              jinja2: 3.1.2
2023-08-15 10:23:59,958:INFO:               scipy: 1.11.1
2023-08-15 10:23:59,958:INFO:              joblib: 1.3.2
2023-08-15 10:23:59,958:INFO:             sklearn: 1.3.0
2023-08-15 10:23:59,958:INFO:                pyod: 1.1.0
2023-08-15 10:23:59,958:INFO:            imblearn: 0.11.0
2023-08-15 10:23:59,958:INFO:   category_encoders: 2.6.1
2023-08-15 10:23:59,958:INFO:            lightgbm: 4.0.0
2023-08-15 10:23:59,958:INFO:               numba: 0.57.1
2023-08-15 10:23:59,958:INFO:            requests: 2.31.0
2023-08-15 10:23:59,958:INFO:          matplotlib: 3.7.2
2023-08-15 10:23:59,958:INFO:          scikitplot: 0.3.7
2023-08-15 10:23:59,958:INFO:         yellowbrick: 1.5
2023-08-15 10:23:59,958:INFO:              plotly: 5.16.0
2023-08-15 10:23:59,958:INFO:    plotly-resampler: Not installed
2023-08-15 10:23:59,958:INFO:             kaleido: 0.2.1
2023-08-15 10:23:59,958:INFO:           schemdraw: 0.15
2023-08-15 10:23:59,958:INFO:         statsmodels: 0.14.0
2023-08-15 10:23:59,958:INFO:              sktime: 0.21.0
2023-08-15 10:23:59,958:INFO:               tbats: 1.1.3
2023-08-15 10:23:59,958:INFO:            pmdarima: 2.0.3
2023-08-15 10:23:59,958:INFO:              psutil: 5.9.5
2023-08-15 10:23:59,958:INFO:          markupsafe: 2.1.3
2023-08-15 10:23:59,958:INFO:             pickle5: Not installed
2023-08-15 10:23:59,958:INFO:         cloudpickle: 2.2.1
2023-08-15 10:23:59,958:INFO:         deprecation: 2.1.0
2023-08-15 10:23:59,958:INFO:              xxhash: 3.2.0
2023-08-15 10:23:59,958:INFO:           wurlitzer: Not installed
2023-08-15 10:23:59,959:INFO:PyCaret optional dependencies:
2023-08-15 10:24:00,068:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning:

IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.


2023-08-15 10:24:01,171:INFO:                shap: 0.42.1
2023-08-15 10:24:01,171:INFO:           interpret: 0.4.3
2023-08-15 10:24:01,171:INFO:                umap: 0.5.3
2023-08-15 10:24:01,171:INFO:    pandas_profiling: 4.4.0
2023-08-15 10:24:01,171:INFO:  explainerdashboard: 0.4.3
2023-08-15 10:24:01,172:INFO:             autoviz: 0.1.730
2023-08-15 10:24:01,172:INFO:           fairlearn: 0.7.0
2023-08-15 10:24:01,172:INFO:          deepchecks: 0.17.4
2023-08-15 10:24:01,172:INFO:             xgboost: 1.7.6
2023-08-15 10:24:01,172:INFO:            catboost: 1.2
2023-08-15 10:24:01,172:INFO:              kmodes: 0.12.2
2023-08-15 10:24:01,172:INFO:             mlxtend: 0.22.0
2023-08-15 10:24:01,172:INFO:       statsforecast: 1.5.0
2023-08-15 10:24:01,172:INFO:        tune_sklearn: 0.4.6
2023-08-15 10:24:01,172:INFO:                 ray: 2.6.1
2023-08-15 10:24:01,172:INFO:            hyperopt: 0.2.7
2023-08-15 10:24:01,172:INFO:              optuna: 3.3.0
2023-08-15 10:24:01,172:INFO:               skopt: 0.9.0
2023-08-15 10:24:01,172:INFO:              mlflow: 1.30.1
2023-08-15 10:24:01,172:INFO:              gradio: 3.39.0
2023-08-15 10:24:01,172:INFO:             fastapi: 0.101.0
2023-08-15 10:24:01,172:INFO:             uvicorn: 0.23.2
2023-08-15 10:24:01,172:INFO:              m2cgen: 0.10.0
2023-08-15 10:24:01,172:INFO:           evidently: 0.2.8
2023-08-15 10:24:01,172:INFO:               fugue: 0.8.6
2023-08-15 10:24:01,172:INFO:           streamlit: Not installed
2023-08-15 10:24:01,172:INFO:             prophet: Not installed
2023-08-15 10:24:01,172:INFO:None
2023-08-15 10:24:01,172:INFO:Set up data.
2023-08-15 10:24:01,362:INFO:Set up train/test split.
2023-08-15 10:24:01,527:INFO:Set up index.
2023-08-15 10:24:01,532:INFO:Set up folding strategy.
2023-08-15 10:24:01,532:INFO:Assigning column types.
2023-08-15 10:24:01,565:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 10:24:01,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 10:24:01,591:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:24:01,609:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:24:01,626:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:24:01,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 10:24:01,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:24:01,677:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:24:01,678:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:24:01,679:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 10:24:01,702:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:24:01,716:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:24:01,717:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:24:01,741:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:24:01,756:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:24:01,757:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:24:01,757:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 10:24:01,795:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:24:01,797:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:24:01,836:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:24:01,838:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:24:01,841:INFO:Preparing preprocessing pipeline...
2023-08-15 10:24:01,847:INFO:Set up label encoding.
2023-08-15 10:24:01,847:INFO:Set up simple imputation.
2023-08-15 10:24:01,886:INFO:Set up encoding of ordinal features.
2023-08-15 10:24:01,958:INFO:Set up encoding of categorical features.
2023-08-15 10:24:01,964:INFO:Set up column name cleaning.
2023-08-15 10:24:02,546:INFO:Finished creating preprocessing pipeline.
2023-08-15 10:24:02,584:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 10:24:02,584:INFO:Creating final display dataframe.
2023-08-15 10:24:02,922:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              7eca
2023-08-15 10:24:02,965:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:24:02,966:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:24:03,005:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:24:03,006:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:24:03,007:INFO:setup() successfully completed in 3.44s...............
2023-08-15 10:27:16,938:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\seaborn\matrix.py:309: UserWarning:

Attempting to set identical low and high xlims makes transformation singular; automatically expanding.


2023-08-15 10:27:16,938:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\seaborn\matrix.py:309: UserWarning:

Attempting to set identical low and high ylims makes transformation singular; automatically expanding.


2023-08-15 10:27:22,715:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\scipy\cluster\hierarchy.py:2847: UserWarning:

Attempting to set identical low and high ylims makes transformation singular; automatically expanding.


2023-08-15 10:27:33,176:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\seaborn\matrix.py:309: UserWarning:

Attempting to set identical low and high xlims makes transformation singular; automatically expanding.


2023-08-15 10:27:33,176:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\seaborn\matrix.py:309: UserWarning:

Attempting to set identical low and high ylims makes transformation singular; automatically expanding.


2023-08-15 10:30:07,661:INFO:PyCaret ClassificationExperiment
2023-08-15 10:30:07,661:INFO:Logging name: clf-default-name
2023-08-15 10:30:07,661:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 10:30:07,661:INFO:version 3.0.4
2023-08-15 10:30:07,661:INFO:Initializing setup()
2023-08-15 10:30:07,661:INFO:self.USI: 4819
2023-08-15 10:30:07,661:INFO:self._variable_keys: {'idx', 'memory', 'target_param', 'y_test', 'y_train', 'n_jobs_param', 'fold_generator', 'X_test', 'fold_shuffle_param', 'fix_imbalance', '_ml_usecase', 'y', '_available_plots', 'gpu_n_jobs_param', 'data', 'fold_groups_param', 'logging_param', 'X_train', 'is_multiclass', 'exp_name_log', 'html_param', 'seed', 'USI', 'gpu_param', 'pipeline', 'log_plots_param', 'X', 'exp_id'}
2023-08-15 10:30:07,661:INFO:Checking environment
2023-08-15 10:30:07,661:INFO:python_version: 3.10.12
2023-08-15 10:30:07,661:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 10:30:07,661:INFO:machine: AMD64
2023-08-15 10:30:07,661:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 10:30:07,665:INFO:Memory: svmem(total=68448301056, available=50963701760, percent=25.5, used=17484599296, free=50963701760)
2023-08-15 10:30:07,665:INFO:Physical Core: 12
2023-08-15 10:30:07,665:INFO:Logical Core: 20
2023-08-15 10:30:07,665:INFO:Checking libraries
2023-08-15 10:30:07,665:INFO:System:
2023-08-15 10:30:07,665:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 10:30:07,665:INFO:executable: c:\Users\Ramon\anaconda3\envs\PycaretEnv\python.exe
2023-08-15 10:30:07,665:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 10:30:07,665:INFO:PyCaret required dependencies:
2023-08-15 10:30:07,666:INFO:                 pip: 23.2.1
2023-08-15 10:30:07,666:INFO:          setuptools: 68.0.0
2023-08-15 10:30:07,666:INFO:             pycaret: 3.0.4
2023-08-15 10:30:07,666:INFO:             IPython: 8.14.0
2023-08-15 10:30:07,666:INFO:          ipywidgets: 8.1.0
2023-08-15 10:30:07,666:INFO:                tqdm: 4.66.1
2023-08-15 10:30:07,666:INFO:               numpy: 1.25.2
2023-08-15 10:30:07,666:INFO:              pandas: 2.0.3
2023-08-15 10:30:07,666:INFO:              jinja2: 3.1.2
2023-08-15 10:30:07,666:INFO:               scipy: 1.11.1
2023-08-15 10:30:07,666:INFO:              joblib: 1.3.2
2023-08-15 10:30:07,666:INFO:             sklearn: 1.3.0
2023-08-15 10:30:07,666:INFO:                pyod: 1.1.0
2023-08-15 10:30:07,666:INFO:            imblearn: 0.11.0
2023-08-15 10:30:07,666:INFO:   category_encoders: 2.6.1
2023-08-15 10:30:07,666:INFO:            lightgbm: 4.0.0
2023-08-15 10:30:07,666:INFO:               numba: 0.57.1
2023-08-15 10:30:07,666:INFO:            requests: 2.31.0
2023-08-15 10:30:07,666:INFO:          matplotlib: 3.7.2
2023-08-15 10:30:07,666:INFO:          scikitplot: 0.3.7
2023-08-15 10:30:07,666:INFO:         yellowbrick: 1.5
2023-08-15 10:30:07,666:INFO:              plotly: 5.16.0
2023-08-15 10:30:07,666:INFO:    plotly-resampler: Not installed
2023-08-15 10:30:07,666:INFO:             kaleido: 0.2.1
2023-08-15 10:30:07,666:INFO:           schemdraw: 0.15
2023-08-15 10:30:07,666:INFO:         statsmodels: 0.14.0
2023-08-15 10:30:07,666:INFO:              sktime: 0.21.0
2023-08-15 10:30:07,666:INFO:               tbats: 1.1.3
2023-08-15 10:30:07,666:INFO:            pmdarima: 2.0.3
2023-08-15 10:30:07,666:INFO:              psutil: 5.9.5
2023-08-15 10:30:07,666:INFO:          markupsafe: 2.1.3
2023-08-15 10:30:07,666:INFO:             pickle5: Not installed
2023-08-15 10:30:07,666:INFO:         cloudpickle: 2.2.1
2023-08-15 10:30:07,666:INFO:         deprecation: 2.1.0
2023-08-15 10:30:07,666:INFO:              xxhash: 3.2.0
2023-08-15 10:30:07,666:INFO:           wurlitzer: Not installed
2023-08-15 10:30:07,666:INFO:PyCaret optional dependencies:
2023-08-15 10:30:07,666:INFO:                shap: 0.42.1
2023-08-15 10:30:07,666:INFO:           interpret: 0.4.3
2023-08-15 10:30:07,666:INFO:                umap: 0.5.3
2023-08-15 10:30:07,666:INFO:    pandas_profiling: 4.4.0
2023-08-15 10:30:07,666:INFO:  explainerdashboard: 0.4.3
2023-08-15 10:30:07,666:INFO:             autoviz: 0.1.730
2023-08-15 10:30:07,666:INFO:           fairlearn: 0.7.0
2023-08-15 10:30:07,666:INFO:          deepchecks: 0.17.4
2023-08-15 10:30:07,666:INFO:             xgboost: 1.7.6
2023-08-15 10:30:07,666:INFO:            catboost: 1.2
2023-08-15 10:30:07,666:INFO:              kmodes: 0.12.2
2023-08-15 10:30:07,666:INFO:             mlxtend: 0.22.0
2023-08-15 10:30:07,666:INFO:       statsforecast: 1.5.0
2023-08-15 10:30:07,666:INFO:        tune_sklearn: 0.4.6
2023-08-15 10:30:07,666:INFO:                 ray: 2.6.1
2023-08-15 10:30:07,666:INFO:            hyperopt: 0.2.7
2023-08-15 10:30:07,667:INFO:              optuna: 3.3.0
2023-08-15 10:30:07,667:INFO:               skopt: 0.9.0
2023-08-15 10:30:07,667:INFO:              mlflow: 1.30.1
2023-08-15 10:30:07,667:INFO:              gradio: 3.39.0
2023-08-15 10:30:07,667:INFO:             fastapi: 0.101.0
2023-08-15 10:30:07,667:INFO:             uvicorn: 0.23.2
2023-08-15 10:30:07,667:INFO:              m2cgen: 0.10.0
2023-08-15 10:30:07,667:INFO:           evidently: 0.2.8
2023-08-15 10:30:07,667:INFO:               fugue: 0.8.6
2023-08-15 10:30:07,667:INFO:           streamlit: Not installed
2023-08-15 10:30:07,667:INFO:             prophet: Not installed
2023-08-15 10:30:07,667:INFO:None
2023-08-15 10:30:07,667:INFO:Set up data.
2023-08-15 10:30:07,854:INFO:Set up train/test split.
2023-08-15 10:30:08,018:INFO:Set up index.
2023-08-15 10:30:08,023:INFO:Set up folding strategy.
2023-08-15 10:30:08,023:INFO:Assigning column types.
2023-08-15 10:30:08,058:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 10:30:08,083:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 10:30:08,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:30:08,099:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:30:08,101:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:30:08,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 10:30:08,126:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:30:08,142:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:30:08,143:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:30:08,144:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 10:30:08,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:30:08,183:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:30:08,185:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:30:08,210:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 10:30:08,224:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:30:08,226:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:30:08,226:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 10:30:08,266:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:30:08,267:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:30:08,308:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:30:08,310:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:30:08,311:INFO:Preparing preprocessing pipeline...
2023-08-15 10:30:08,317:INFO:Set up label encoding.
2023-08-15 10:30:08,317:INFO:Set up simple imputation.
2023-08-15 10:30:08,356:INFO:Set up encoding of ordinal features.
2023-08-15 10:30:08,426:INFO:Set up encoding of categorical features.
2023-08-15 10:30:08,432:INFO:Set up column name cleaning.
2023-08-15 10:30:08,976:INFO:Finished creating preprocessing pipeline.
2023-08-15 10:30:09,013:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 10:30:09,013:INFO:Creating final display dataframe.
2023-08-15 10:30:09,366:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              4819
2023-08-15 10:30:09,409:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:30:09,411:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:30:09,450:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 10:30:09,451:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 10:30:09,452:INFO:setup() successfully completed in 1.82s...............
2023-08-15 10:45:54,455:INFO:Initializing compare_models()
2023-08-15 10:45:54,456:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-15 10:45:54,456:INFO:Checking exceptions
2023-08-15 10:45:54,489:INFO:Preparing display monitor
2023-08-15 10:45:54,506:INFO:Initializing Logistic Regression
2023-08-15 10:45:54,506:INFO:Total runtime is 0.0 minutes
2023-08-15 10:45:54,508:INFO:SubProcess create_model() called ==================================
2023-08-15 10:45:54,508:INFO:Initializing create_model()
2023-08-15 10:45:54,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:45:54,509:INFO:Checking exceptions
2023-08-15 10:45:54,509:INFO:Importing libraries
2023-08-15 10:45:54,509:INFO:Copying training dataset
2023-08-15 10:45:54,574:INFO:Defining folds
2023-08-15 10:45:54,574:INFO:Declaring metric variables
2023-08-15 10:45:54,576:INFO:Importing untrained model
2023-08-15 10:45:54,579:INFO:Logistic Regression Imported successfully
2023-08-15 10:45:54,583:INFO:Starting cross validation
2023-08-15 10:45:54,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:47:00,022:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:00,497:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:00,611:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:00,872:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:01,041:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:01,058:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:01,211:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:01,237:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:01,341:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:01,387:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 10:47:02,308:INFO:Calculating mean and std
2023-08-15 10:47:02,309:INFO:Creating metrics dataframe
2023-08-15 10:47:02,344:INFO:Uploading results into container
2023-08-15 10:47:02,344:INFO:Uploading model into container now
2023-08-15 10:47:02,345:INFO:_master_model_container: 1
2023-08-15 10:47:02,345:INFO:_display_container: 2
2023-08-15 10:47:02,345:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 10:47:02,345:INFO:create_model() successfully completed......................................
2023-08-15 10:47:02,613:INFO:SubProcess create_model() end ==================================
2023-08-15 10:47:02,613:INFO:Creating metrics dataframe
2023-08-15 10:47:02,617:INFO:Initializing K Neighbors Classifier
2023-08-15 10:47:02,617:INFO:Total runtime is 1.1351753989855449 minutes
2023-08-15 10:47:02,619:INFO:SubProcess create_model() called ==================================
2023-08-15 10:47:02,620:INFO:Initializing create_model()
2023-08-15 10:47:02,620:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:47:02,620:INFO:Checking exceptions
2023-08-15 10:47:02,620:INFO:Importing libraries
2023-08-15 10:47:02,620:INFO:Copying training dataset
2023-08-15 10:47:02,679:INFO:Defining folds
2023-08-15 10:47:02,679:INFO:Declaring metric variables
2023-08-15 10:47:02,682:INFO:Importing untrained model
2023-08-15 10:47:02,684:INFO:K Neighbors Classifier Imported successfully
2023-08-15 10:47:02,688:INFO:Starting cross validation
2023-08-15 10:47:02,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:47:13,448:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,475:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,477:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,478:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,543:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,563:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,568:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,568:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,593:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,627:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,634:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,656:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,657:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,665:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,712:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,720:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,743:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,762:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,775:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:13,799:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:14,243:INFO:Calculating mean and std
2023-08-15 10:47:14,244:INFO:Creating metrics dataframe
2023-08-15 10:47:14,291:INFO:Uploading results into container
2023-08-15 10:47:14,291:INFO:Uploading model into container now
2023-08-15 10:47:14,291:INFO:_master_model_container: 2
2023-08-15 10:47:14,291:INFO:_display_container: 2
2023-08-15 10:47:14,292:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-15 10:47:14,292:INFO:create_model() successfully completed......................................
2023-08-15 10:47:14,419:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2023-08-15 10:47:14,420:WARNING:Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2023-08-15 10:47:14,420:INFO:Initializing create_model()
2023-08-15 10:47:14,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:47:14,420:INFO:Checking exceptions
2023-08-15 10:47:14,420:INFO:Importing libraries
2023-08-15 10:47:14,420:INFO:Copying training dataset
2023-08-15 10:47:14,473:INFO:Defining folds
2023-08-15 10:47:14,473:INFO:Declaring metric variables
2023-08-15 10:47:14,476:INFO:Importing untrained model
2023-08-15 10:47:14,479:INFO:K Neighbors Classifier Imported successfully
2023-08-15 10:47:14,484:INFO:Starting cross validation
2023-08-15 10:47:14,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:47:19,272:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,272:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,345:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,408:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,424:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,460:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,479:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,486:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,497:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,549:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,575:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,582:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,599:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,623:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,650:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,669:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,680:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,728:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,738:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:19,804:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 10:47:20,265:INFO:Calculating mean and std
2023-08-15 10:47:20,266:INFO:Creating metrics dataframe
2023-08-15 10:47:20,317:INFO:Uploading results into container
2023-08-15 10:47:20,318:INFO:Uploading model into container now
2023-08-15 10:47:20,318:INFO:_master_model_container: 3
2023-08-15 10:47:20,318:INFO:_display_container: 2
2023-08-15 10:47:20,318:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-15 10:47:20,318:INFO:create_model() successfully completed......................................
2023-08-15 10:47:20,441:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2023-08-15 10:47:20,441:ERROR:Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 813, in compare_models
    np.sum(
AssertionError

2023-08-15 10:47:20,442:INFO:Initializing Naive Bayes
2023-08-15 10:47:20,442:INFO:Total runtime is 1.4322611689567566 minutes
2023-08-15 10:47:20,444:INFO:SubProcess create_model() called ==================================
2023-08-15 10:47:20,444:INFO:Initializing create_model()
2023-08-15 10:47:20,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:47:20,444:INFO:Checking exceptions
2023-08-15 10:47:20,444:INFO:Importing libraries
2023-08-15 10:47:20,444:INFO:Copying training dataset
2023-08-15 10:47:20,511:INFO:Defining folds
2023-08-15 10:47:20,512:INFO:Declaring metric variables
2023-08-15 10:47:20,514:INFO:Importing untrained model
2023-08-15 10:47:20,517:INFO:Naive Bayes Imported successfully
2023-08-15 10:47:20,521:INFO:Starting cross validation
2023-08-15 10:47:20,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:47:23,734:INFO:Calculating mean and std
2023-08-15 10:47:23,735:INFO:Creating metrics dataframe
2023-08-15 10:47:23,790:INFO:Uploading results into container
2023-08-15 10:47:23,791:INFO:Uploading model into container now
2023-08-15 10:47:23,791:INFO:_master_model_container: 4
2023-08-15 10:47:23,791:INFO:_display_container: 2
2023-08-15 10:47:23,791:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 10:47:23,791:INFO:create_model() successfully completed......................................
2023-08-15 10:47:23,912:INFO:SubProcess create_model() end ==================================
2023-08-15 10:47:23,912:INFO:Creating metrics dataframe
2023-08-15 10:47:23,917:INFO:Initializing Decision Tree Classifier
2023-08-15 10:47:23,917:INFO:Total runtime is 1.4901893337567647 minutes
2023-08-15 10:47:23,919:INFO:SubProcess create_model() called ==================================
2023-08-15 10:47:23,920:INFO:Initializing create_model()
2023-08-15 10:47:23,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:47:23,920:INFO:Checking exceptions
2023-08-15 10:47:23,920:INFO:Importing libraries
2023-08-15 10:47:23,920:INFO:Copying training dataset
2023-08-15 10:47:23,977:INFO:Defining folds
2023-08-15 10:47:23,977:INFO:Declaring metric variables
2023-08-15 10:47:23,980:INFO:Importing untrained model
2023-08-15 10:47:23,982:INFO:Decision Tree Classifier Imported successfully
2023-08-15 10:47:23,986:INFO:Starting cross validation
2023-08-15 10:47:23,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:47:28,895:INFO:Calculating mean and std
2023-08-15 10:47:28,896:INFO:Creating metrics dataframe
2023-08-15 10:47:28,950:INFO:Uploading results into container
2023-08-15 10:47:28,951:INFO:Uploading model into container now
2023-08-15 10:47:28,951:INFO:_master_model_container: 5
2023-08-15 10:47:28,951:INFO:_display_container: 2
2023-08-15 10:47:28,951:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-15 10:47:28,952:INFO:create_model() successfully completed......................................
2023-08-15 10:47:29,073:INFO:SubProcess create_model() end ==================================
2023-08-15 10:47:29,073:INFO:Creating metrics dataframe
2023-08-15 10:47:29,079:INFO:Initializing SVM - Linear Kernel
2023-08-15 10:47:29,079:INFO:Total runtime is 1.5762108206748962 minutes
2023-08-15 10:47:29,082:INFO:SubProcess create_model() called ==================================
2023-08-15 10:47:29,082:INFO:Initializing create_model()
2023-08-15 10:47:29,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:47:29,082:INFO:Checking exceptions
2023-08-15 10:47:29,082:INFO:Importing libraries
2023-08-15 10:47:29,082:INFO:Copying training dataset
2023-08-15 10:47:29,140:INFO:Defining folds
2023-08-15 10:47:29,140:INFO:Declaring metric variables
2023-08-15 10:47:29,143:INFO:Importing untrained model
2023-08-15 10:47:29,146:INFO:SVM - Linear Kernel Imported successfully
2023-08-15 10:47:29,150:INFO:Starting cross validation
2023-08-15 10:47:29,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:47:48,982:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:49,855:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:50,126:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:50,324:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:47:50,394:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:51,018:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:51,073:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:51,211:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:51,293:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:51,704:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:52,120:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:52,556:INFO:Calculating mean and std
2023-08-15 10:47:52,557:INFO:Creating metrics dataframe
2023-08-15 10:47:52,613:INFO:Uploading results into container
2023-08-15 10:47:52,614:INFO:Uploading model into container now
2023-08-15 10:47:52,614:INFO:_master_model_container: 6
2023-08-15 10:47:52,614:INFO:_display_container: 2
2023-08-15 10:47:52,614:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-15 10:47:52,614:INFO:create_model() successfully completed......................................
2023-08-15 10:47:52,735:INFO:SubProcess create_model() end ==================================
2023-08-15 10:47:52,735:INFO:Creating metrics dataframe
2023-08-15 10:47:52,740:INFO:Initializing Ridge Classifier
2023-08-15 10:47:52,740:INFO:Total runtime is 1.9705686688423156 minutes
2023-08-15 10:47:52,742:INFO:SubProcess create_model() called ==================================
2023-08-15 10:47:52,743:INFO:Initializing create_model()
2023-08-15 10:47:52,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:47:52,743:INFO:Checking exceptions
2023-08-15 10:47:52,743:INFO:Importing libraries
2023-08-15 10:47:52,743:INFO:Copying training dataset
2023-08-15 10:47:52,800:INFO:Defining folds
2023-08-15 10:47:52,800:INFO:Declaring metric variables
2023-08-15 10:47:52,803:INFO:Importing untrained model
2023-08-15 10:47:52,806:INFO:Ridge Classifier Imported successfully
2023-08-15 10:47:52,810:INFO:Starting cross validation
2023-08-15 10:47:52,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:47:54,774:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:54,848:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:54,891:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:54,953:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:54,959:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:54,992:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:55,004:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:55,039:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:55,064:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:55,118:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 10:47:55,938:INFO:Calculating mean and std
2023-08-15 10:47:55,938:INFO:Creating metrics dataframe
2023-08-15 10:47:55,999:INFO:Uploading results into container
2023-08-15 10:47:55,999:INFO:Uploading model into container now
2023-08-15 10:47:55,999:INFO:_master_model_container: 7
2023-08-15 10:47:55,999:INFO:_display_container: 2
2023-08-15 10:47:56,000:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-15 10:47:56,000:INFO:create_model() successfully completed......................................
2023-08-15 10:47:56,127:INFO:SubProcess create_model() end ==================================
2023-08-15 10:47:56,127:INFO:Creating metrics dataframe
2023-08-15 10:47:56,133:INFO:Initializing Random Forest Classifier
2023-08-15 10:47:56,133:INFO:Total runtime is 2.0271194497744243 minutes
2023-08-15 10:47:56,135:INFO:SubProcess create_model() called ==================================
2023-08-15 10:47:56,135:INFO:Initializing create_model()
2023-08-15 10:47:56,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:47:56,135:INFO:Checking exceptions
2023-08-15 10:47:56,135:INFO:Importing libraries
2023-08-15 10:47:56,135:INFO:Copying training dataset
2023-08-15 10:47:56,194:INFO:Defining folds
2023-08-15 10:47:56,195:INFO:Declaring metric variables
2023-08-15 10:47:56,197:INFO:Importing untrained model
2023-08-15 10:47:56,200:INFO:Random Forest Classifier Imported successfully
2023-08-15 10:47:56,204:INFO:Starting cross validation
2023-08-15 10:47:56,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:48:25,332:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.03s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 10:48:25,571:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.38s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 10:48:30,311:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 10:48:32,471:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 10:48:32,634:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 10:48:35,894:INFO:Calculating mean and std
2023-08-15 10:48:35,895:INFO:Creating metrics dataframe
2023-08-15 10:48:35,969:INFO:Uploading results into container
2023-08-15 10:48:35,970:INFO:Uploading model into container now
2023-08-15 10:48:35,970:INFO:_master_model_container: 8
2023-08-15 10:48:35,970:INFO:_display_container: 2
2023-08-15 10:48:35,970:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-15 10:48:35,970:INFO:create_model() successfully completed......................................
2023-08-15 10:48:36,109:INFO:SubProcess create_model() end ==================================
2023-08-15 10:48:36,110:INFO:Creating metrics dataframe
2023-08-15 10:48:36,117:INFO:Initializing Quadratic Discriminant Analysis
2023-08-15 10:48:36,117:INFO:Total runtime is 2.6935147404670716 minutes
2023-08-15 10:48:36,120:INFO:SubProcess create_model() called ==================================
2023-08-15 10:48:36,120:INFO:Initializing create_model()
2023-08-15 10:48:36,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:48:36,120:INFO:Checking exceptions
2023-08-15 10:48:36,120:INFO:Importing libraries
2023-08-15 10:48:36,120:INFO:Copying training dataset
2023-08-15 10:48:36,206:INFO:Defining folds
2023-08-15 10:48:36,206:INFO:Declaring metric variables
2023-08-15 10:48:36,208:INFO:Importing untrained model
2023-08-15 10:48:36,211:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 10:48:36,216:INFO:Starting cross validation
2023-08-15 10:48:36,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:48:39,355:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,366:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,381:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,483:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,488:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,530:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,557:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,708:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,722:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:39,738:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 10:48:41,263:INFO:Calculating mean and std
2023-08-15 10:48:41,264:INFO:Creating metrics dataframe
2023-08-15 10:48:41,331:INFO:Uploading results into container
2023-08-15 10:48:41,331:INFO:Uploading model into container now
2023-08-15 10:48:41,332:INFO:_master_model_container: 9
2023-08-15 10:48:41,332:INFO:_display_container: 2
2023-08-15 10:48:41,332:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 10:48:41,332:INFO:create_model() successfully completed......................................
2023-08-15 10:48:41,452:INFO:SubProcess create_model() end ==================================
2023-08-15 10:48:41,452:INFO:Creating metrics dataframe
2023-08-15 10:48:41,458:INFO:Initializing Ada Boost Classifier
2023-08-15 10:48:41,458:INFO:Total runtime is 2.7825343012809753 minutes
2023-08-15 10:48:41,460:INFO:SubProcess create_model() called ==================================
2023-08-15 10:48:41,460:INFO:Initializing create_model()
2023-08-15 10:48:41,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:48:41,460:INFO:Checking exceptions
2023-08-15 10:48:41,460:INFO:Importing libraries
2023-08-15 10:48:41,460:INFO:Copying training dataset
2023-08-15 10:48:41,518:INFO:Defining folds
2023-08-15 10:48:41,518:INFO:Declaring metric variables
2023-08-15 10:48:41,521:INFO:Importing untrained model
2023-08-15 10:48:41,524:INFO:Ada Boost Classifier Imported successfully
2023-08-15 10:48:41,528:INFO:Starting cross validation
2023-08-15 10:48:41,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:48:59,404:INFO:Calculating mean and std
2023-08-15 10:48:59,405:INFO:Creating metrics dataframe
2023-08-15 10:48:59,474:INFO:Uploading results into container
2023-08-15 10:48:59,474:INFO:Uploading model into container now
2023-08-15 10:48:59,474:INFO:_master_model_container: 10
2023-08-15 10:48:59,474:INFO:_display_container: 2
2023-08-15 10:48:59,475:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-15 10:48:59,475:INFO:create_model() successfully completed......................................
2023-08-15 10:48:59,597:INFO:SubProcess create_model() end ==================================
2023-08-15 10:48:59,597:INFO:Creating metrics dataframe
2023-08-15 10:48:59,603:INFO:Initializing Gradient Boosting Classifier
2023-08-15 10:48:59,603:INFO:Total runtime is 3.0849538683891295 minutes
2023-08-15 10:48:59,605:INFO:SubProcess create_model() called ==================================
2023-08-15 10:48:59,605:INFO:Initializing create_model()
2023-08-15 10:48:59,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:48:59,605:INFO:Checking exceptions
2023-08-15 10:48:59,605:INFO:Importing libraries
2023-08-15 10:48:59,605:INFO:Copying training dataset
2023-08-15 10:48:59,663:INFO:Defining folds
2023-08-15 10:48:59,663:INFO:Declaring metric variables
2023-08-15 10:48:59,666:INFO:Importing untrained model
2023-08-15 10:48:59,668:INFO:Gradient Boosting Classifier Imported successfully
2023-08-15 10:48:59,672:INFO:Starting cross validation
2023-08-15 10:48:59,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:49:46,926:INFO:Calculating mean and std
2023-08-15 10:49:46,927:INFO:Creating metrics dataframe
2023-08-15 10:49:46,998:INFO:Uploading results into container
2023-08-15 10:49:46,999:INFO:Uploading model into container now
2023-08-15 10:49:46,999:INFO:_master_model_container: 11
2023-08-15 10:49:46,999:INFO:_display_container: 2
2023-08-15 10:49:46,999:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-15 10:49:47,000:INFO:create_model() successfully completed......................................
2023-08-15 10:49:47,134:INFO:SubProcess create_model() end ==================================
2023-08-15 10:49:47,134:INFO:Creating metrics dataframe
2023-08-15 10:49:47,139:INFO:Initializing Linear Discriminant Analysis
2023-08-15 10:49:47,140:INFO:Total runtime is 3.8772355397542317 minutes
2023-08-15 10:49:47,142:INFO:SubProcess create_model() called ==================================
2023-08-15 10:49:47,142:INFO:Initializing create_model()
2023-08-15 10:49:47,142:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:49:47,142:INFO:Checking exceptions
2023-08-15 10:49:47,142:INFO:Importing libraries
2023-08-15 10:49:47,142:INFO:Copying training dataset
2023-08-15 10:49:47,199:INFO:Defining folds
2023-08-15 10:49:47,199:INFO:Declaring metric variables
2023-08-15 10:49:47,202:INFO:Importing untrained model
2023-08-15 10:49:47,205:INFO:Linear Discriminant Analysis Imported successfully
2023-08-15 10:49:47,209:INFO:Starting cross validation
2023-08-15 10:49:47,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:49:52,367:INFO:Calculating mean and std
2023-08-15 10:49:52,368:INFO:Creating metrics dataframe
2023-08-15 10:49:52,443:INFO:Uploading results into container
2023-08-15 10:49:52,443:INFO:Uploading model into container now
2023-08-15 10:49:52,444:INFO:_master_model_container: 12
2023-08-15 10:49:52,444:INFO:_display_container: 2
2023-08-15 10:49:52,444:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-15 10:49:52,444:INFO:create_model() successfully completed......................................
2023-08-15 10:49:52,568:INFO:SubProcess create_model() end ==================================
2023-08-15 10:49:52,568:INFO:Creating metrics dataframe
2023-08-15 10:49:52,576:INFO:Initializing Extra Trees Classifier
2023-08-15 10:49:52,576:INFO:Total runtime is 3.9678399324417115 minutes
2023-08-15 10:49:52,579:INFO:SubProcess create_model() called ==================================
2023-08-15 10:49:52,579:INFO:Initializing create_model()
2023-08-15 10:49:52,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:49:52,580:INFO:Checking exceptions
2023-08-15 10:49:52,580:INFO:Importing libraries
2023-08-15 10:49:52,580:INFO:Copying training dataset
2023-08-15 10:49:52,640:INFO:Defining folds
2023-08-15 10:49:52,640:INFO:Declaring metric variables
2023-08-15 10:49:52,642:INFO:Importing untrained model
2023-08-15 10:49:52,645:INFO:Extra Trees Classifier Imported successfully
2023-08-15 10:49:52,649:INFO:Starting cross validation
2023-08-15 10:49:52,651:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:50:36,606:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 10:50:38,029:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 10:50:41,183:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 10:50:41,219:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 10:50:41,585:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 10:50:41,596:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 10:50:41,852:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 10:50:42,986:INFO:Calculating mean and std
2023-08-15 10:50:42,987:INFO:Creating metrics dataframe
2023-08-15 10:50:43,045:INFO:Uploading results into container
2023-08-15 10:50:43,045:INFO:Uploading model into container now
2023-08-15 10:50:43,046:INFO:_master_model_container: 13
2023-08-15 10:50:43,046:INFO:_display_container: 2
2023-08-15 10:50:43,046:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-15 10:50:43,046:INFO:create_model() successfully completed......................................
2023-08-15 10:50:43,281:INFO:SubProcess create_model() end ==================================
2023-08-15 10:50:43,281:INFO:Creating metrics dataframe
2023-08-15 10:50:43,290:INFO:Initializing Extreme Gradient Boosting
2023-08-15 10:50:43,291:INFO:Total runtime is 4.813079949220022 minutes
2023-08-15 10:50:43,294:INFO:SubProcess create_model() called ==================================
2023-08-15 10:50:43,294:INFO:Initializing create_model()
2023-08-15 10:50:43,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:50:43,294:INFO:Checking exceptions
2023-08-15 10:50:43,294:INFO:Importing libraries
2023-08-15 10:50:43,294:INFO:Copying training dataset
2023-08-15 10:50:43,392:INFO:Defining folds
2023-08-15 10:50:43,393:INFO:Declaring metric variables
2023-08-15 10:50:43,397:INFO:Importing untrained model
2023-08-15 10:50:43,400:INFO:Extreme Gradient Boosting Imported successfully
2023-08-15 10:50:43,407:INFO:Starting cross validation
2023-08-15 10:50:43,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:51:09,951:INFO:Calculating mean and std
2023-08-15 10:51:09,952:INFO:Creating metrics dataframe
2023-08-15 10:51:10,010:INFO:Uploading results into container
2023-08-15 10:51:10,010:INFO:Uploading model into container now
2023-08-15 10:51:10,011:INFO:_master_model_container: 14
2023-08-15 10:51:10,011:INFO:_display_container: 2
2023-08-15 10:51:10,011:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-15 10:51:10,011:INFO:create_model() successfully completed......................................
2023-08-15 10:51:10,140:INFO:SubProcess create_model() end ==================================
2023-08-15 10:51:10,140:INFO:Creating metrics dataframe
2023-08-15 10:51:10,147:INFO:Initializing Light Gradient Boosting Machine
2023-08-15 10:51:10,147:INFO:Total runtime is 5.260683178901672 minutes
2023-08-15 10:51:10,149:INFO:SubProcess create_model() called ==================================
2023-08-15 10:51:10,150:INFO:Initializing create_model()
2023-08-15 10:51:10,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:51:10,150:INFO:Checking exceptions
2023-08-15 10:51:10,150:INFO:Importing libraries
2023-08-15 10:51:10,150:INFO:Copying training dataset
2023-08-15 10:51:10,206:INFO:Defining folds
2023-08-15 10:51:10,206:INFO:Declaring metric variables
2023-08-15 10:51:10,210:INFO:Importing untrained model
2023-08-15 10:51:10,212:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 10:51:10,217:INFO:Starting cross validation
2023-08-15 10:51:10,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:51:16,339:INFO:Calculating mean and std
2023-08-15 10:51:16,340:INFO:Creating metrics dataframe
2023-08-15 10:51:16,400:INFO:Uploading results into container
2023-08-15 10:51:16,400:INFO:Uploading model into container now
2023-08-15 10:51:16,401:INFO:_master_model_container: 15
2023-08-15 10:51:16,401:INFO:_display_container: 2
2023-08-15 10:51:16,401:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 10:51:16,401:INFO:create_model() successfully completed......................................
2023-08-15 10:51:16,526:INFO:SubProcess create_model() end ==================================
2023-08-15 10:51:16,526:INFO:Creating metrics dataframe
2023-08-15 10:51:16,532:INFO:Initializing CatBoost Classifier
2023-08-15 10:51:16,533:INFO:Total runtime is 5.36712117989858 minutes
2023-08-15 10:51:16,535:INFO:SubProcess create_model() called ==================================
2023-08-15 10:51:16,535:INFO:Initializing create_model()
2023-08-15 10:51:16,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:51:16,535:INFO:Checking exceptions
2023-08-15 10:51:16,535:INFO:Importing libraries
2023-08-15 10:51:16,535:INFO:Copying training dataset
2023-08-15 10:51:16,588:INFO:Defining folds
2023-08-15 10:51:16,588:INFO:Declaring metric variables
2023-08-15 10:51:16,590:INFO:Importing untrained model
2023-08-15 10:51:16,593:INFO:CatBoost Classifier Imported successfully
2023-08-15 10:51:16,597:INFO:Starting cross validation
2023-08-15 10:51:16,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:52:58,224:INFO:Calculating mean and std
2023-08-15 10:52:58,225:INFO:Creating metrics dataframe
2023-08-15 10:52:58,288:INFO:Uploading results into container
2023-08-15 10:52:58,289:INFO:Uploading model into container now
2023-08-15 10:52:58,289:INFO:_master_model_container: 16
2023-08-15 10:52:58,289:INFO:_display_container: 2
2023-08-15 10:52:58,289:INFO:<catboost.core.CatBoostClassifier object at 0x00000253DA1707F0>
2023-08-15 10:52:58,289:INFO:create_model() successfully completed......................................
2023-08-15 10:52:58,432:INFO:SubProcess create_model() end ==================================
2023-08-15 10:52:58,432:INFO:Creating metrics dataframe
2023-08-15 10:52:58,438:INFO:Initializing Dummy Classifier
2023-08-15 10:52:58,438:INFO:Total runtime is 7.065539960066477 minutes
2023-08-15 10:52:58,441:INFO:SubProcess create_model() called ==================================
2023-08-15 10:52:58,441:INFO:Initializing create_model()
2023-08-15 10:52:58,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253D9CE5D80>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:52:58,441:INFO:Checking exceptions
2023-08-15 10:52:58,441:INFO:Importing libraries
2023-08-15 10:52:58,441:INFO:Copying training dataset
2023-08-15 10:52:58,497:INFO:Defining folds
2023-08-15 10:52:58,497:INFO:Declaring metric variables
2023-08-15 10:52:58,500:INFO:Importing untrained model
2023-08-15 10:52:58,503:INFO:Dummy Classifier Imported successfully
2023-08-15 10:52:58,507:INFO:Starting cross validation
2023-08-15 10:52:58,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 10:53:00,189:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,305:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,376:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,378:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,390:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,403:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,450:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,490:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,512:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:00,526:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 10:53:01,180:INFO:Calculating mean and std
2023-08-15 10:53:01,183:INFO:Creating metrics dataframe
2023-08-15 10:53:01,249:INFO:Uploading results into container
2023-08-15 10:53:01,250:INFO:Uploading model into container now
2023-08-15 10:53:01,250:INFO:_master_model_container: 17
2023-08-15 10:53:01,250:INFO:_display_container: 2
2023-08-15 10:53:01,250:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-15 10:53:01,250:INFO:create_model() successfully completed......................................
2023-08-15 10:53:01,381:INFO:SubProcess create_model() end ==================================
2023-08-15 10:53:01,382:INFO:Creating metrics dataframe
2023-08-15 10:53:01,395:INFO:Initializing create_model()
2023-08-15 10:53:01,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 10:53:01,395:INFO:Checking exceptions
2023-08-15 10:53:01,396:INFO:Importing libraries
2023-08-15 10:53:01,397:INFO:Copying training dataset
2023-08-15 10:53:01,450:INFO:Defining folds
2023-08-15 10:53:01,450:INFO:Declaring metric variables
2023-08-15 10:53:01,451:INFO:Importing untrained model
2023-08-15 10:53:01,451:INFO:Declaring custom model
2023-08-15 10:53:01,451:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 10:53:01,453:INFO:Cross validation set to False
2023-08-15 10:53:01,453:INFO:Fitting Model
2023-08-15 10:53:04,153:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 10:53:04,153:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 10:53:04,172:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006466 seconds.
2023-08-15 10:53:04,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 10:53:04,172:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 10:53:04,173:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 10:53:04,173:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-15 10:53:04,174:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 10:53:04,174:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 10:53:04,577:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 10:53:04,577:INFO:create_model() successfully completed......................................
2023-08-15 10:53:04,740:INFO:_master_model_container: 17
2023-08-15 10:53:04,740:INFO:_display_container: 2
2023-08-15 10:53:04,741:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 10:53:04,741:INFO:compare_models() successfully completed......................................
2023-08-15 11:40:37,147:INFO:Initializing create_model()
2023-08-15 11:40:37,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 11:40:37,147:INFO:Checking exceptions
2023-08-15 11:40:37,157:INFO:Importing libraries
2023-08-15 11:40:37,158:INFO:Copying training dataset
2023-08-15 11:40:37,217:INFO:Defining folds
2023-08-15 11:40:37,217:INFO:Declaring metric variables
2023-08-15 11:40:37,220:INFO:Importing untrained model
2023-08-15 11:40:37,223:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 11:40:37,227:INFO:Starting cross validation
2023-08-15 11:40:37,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:40:43,776:INFO:Calculating mean and std
2023-08-15 11:40:43,777:INFO:Creating metrics dataframe
2023-08-15 11:40:43,782:INFO:Finalizing model
2023-08-15 11:40:45,826:INFO:Uploading results into container
2023-08-15 11:40:45,827:INFO:Uploading model into container now
2023-08-15 11:40:45,835:INFO:_master_model_container: 18
2023-08-15 11:40:45,835:INFO:_display_container: 3
2023-08-15 11:40:45,836:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 11:40:45,836:INFO:create_model() successfully completed......................................
2023-08-15 11:40:48,019:INFO:Initializing create_model()
2023-08-15 11:40:48,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 11:40:48,020:INFO:Checking exceptions
2023-08-15 11:40:48,029:INFO:Importing libraries
2023-08-15 11:40:48,029:INFO:Copying training dataset
2023-08-15 11:40:48,089:INFO:Defining folds
2023-08-15 11:40:48,089:INFO:Declaring metric variables
2023-08-15 11:40:48,091:INFO:Importing untrained model
2023-08-15 11:40:48,094:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 11:40:48,099:INFO:Starting cross validation
2023-08-15 11:40:48,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:40:53,797:INFO:Calculating mean and std
2023-08-15 11:40:53,798:INFO:Creating metrics dataframe
2023-08-15 11:40:53,801:INFO:Finalizing model
2023-08-15 11:40:54,561:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning:

Variables are collinear


2023-08-15 11:40:54,708:INFO:Uploading results into container
2023-08-15 11:40:54,709:INFO:Uploading model into container now
2023-08-15 11:40:54,715:INFO:_master_model_container: 19
2023-08-15 11:40:54,716:INFO:_display_container: 4
2023-08-15 11:40:54,716:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 11:40:54,716:INFO:create_model() successfully completed......................................
2023-08-15 11:41:55,108:INFO:Initializing tune_model()
2023-08-15 11:41:55,108:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>)
2023-08-15 11:41:55,108:INFO:Checking exceptions
2023-08-15 11:41:55,140:INFO:Copying training dataset
2023-08-15 11:41:55,179:INFO:Checking base model
2023-08-15 11:41:55,179:INFO:Base model : Light Gradient Boosting Machine
2023-08-15 11:41:55,182:INFO:Declaring metric variables
2023-08-15 11:41:55,185:INFO:Defining Hyperparameters
2023-08-15 11:41:55,314:INFO:Tuning with n_jobs=-1
2023-08-15 11:41:55,314:INFO:Initializing RandomizedSearchCV
2023-08-15 11:43:11,642:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.005, 'actual_estimator__num_leaves': 150, 'actual_estimator__n_estimators': 20, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 6, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.9}
2023-08-15 11:43:11,643:INFO:Hyperparameter search completed
2023-08-15 11:43:11,643:INFO:SubProcess create_model() called ==================================
2023-08-15 11:43:11,644:INFO:Initializing create_model()
2023-08-15 11:43:11,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253AF16D8A0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.005, 'num_leaves': 150, 'n_estimators': 20, 'min_split_gain': 0.3, 'min_child_samples': 6, 'learning_rate': 0.4, 'feature_fraction': 0.5, 'bagging_freq': 3, 'bagging_fraction': 0.9})
2023-08-15 11:43:11,644:INFO:Checking exceptions
2023-08-15 11:43:11,645:INFO:Importing libraries
2023-08-15 11:43:11,645:INFO:Copying training dataset
2023-08-15 11:43:11,706:INFO:Defining folds
2023-08-15 11:43:11,706:INFO:Declaring metric variables
2023-08-15 11:43:11,709:INFO:Importing untrained model
2023-08-15 11:43:11,709:INFO:Declaring custom model
2023-08-15 11:43:11,711:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 11:43:11,715:INFO:Starting cross validation
2023-08-15 11:43:11,717:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:43:14,877:INFO:Calculating mean and std
2023-08-15 11:43:14,878:INFO:Creating metrics dataframe
2023-08-15 11:43:14,881:INFO:Finalizing model
2023-08-15 11:43:15,451:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:43:15,451:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:43:15,451:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:43:15,535:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 11:43:15,535:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:43:15,535:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:43:15,535:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:43:15,535:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 11:43:15,557:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005693 seconds.
2023-08-15 11:43:15,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 11:43:15,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 11:43:15,558:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 11:43:15,558:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-15 11:43:15,561:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 11:43:15,561:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 11:43:15,887:INFO:Uploading results into container
2023-08-15 11:43:15,888:INFO:Uploading model into container now
2023-08-15 11:43:15,888:INFO:_master_model_container: 20
2023-08-15 11:43:15,889:INFO:_display_container: 5
2023-08-15 11:43:15,889:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-15 11:43:15,889:INFO:create_model() successfully completed......................................
2023-08-15 11:43:16,054:INFO:SubProcess create_model() end ==================================
2023-08-15 11:43:16,054:INFO:choose_better activated
2023-08-15 11:43:16,057:INFO:SubProcess create_model() called ==================================
2023-08-15 11:43:16,057:INFO:Initializing create_model()
2023-08-15 11:43:16,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 11:43:16,057:INFO:Checking exceptions
2023-08-15 11:43:16,058:INFO:Importing libraries
2023-08-15 11:43:16,059:INFO:Copying training dataset
2023-08-15 11:43:16,108:INFO:Defining folds
2023-08-15 11:43:16,108:INFO:Declaring metric variables
2023-08-15 11:43:16,108:INFO:Importing untrained model
2023-08-15 11:43:16,108:INFO:Declaring custom model
2023-08-15 11:43:16,109:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 11:43:16,109:INFO:Starting cross validation
2023-08-15 11:43:16,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:43:18,875:INFO:Calculating mean and std
2023-08-15 11:43:18,876:INFO:Creating metrics dataframe
2023-08-15 11:43:18,877:INFO:Finalizing model
2023-08-15 11:43:19,559:INFO:Uploading results into container
2023-08-15 11:43:19,560:INFO:Uploading model into container now
2023-08-15 11:43:19,560:INFO:_master_model_container: 21
2023-08-15 11:43:19,560:INFO:_display_container: 6
2023-08-15 11:43:19,561:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 11:43:19,561:INFO:create_model() successfully completed......................................
2023-08-15 11:43:19,688:INFO:SubProcess create_model() end ==================================
2023-08-15 11:43:19,689:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.0343
2023-08-15 11:43:19,689:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.0754
2023-08-15 11:43:19,690:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-15 11:43:19,690:INFO:choose_better completed
2023-08-15 11:43:19,695:INFO:_master_model_container: 21
2023-08-15 11:43:19,696:INFO:_display_container: 5
2023-08-15 11:43:19,696:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-15 11:43:19,696:INFO:tune_model() successfully completed......................................
2023-08-15 11:44:39,821:INFO:Initializing tune_model()
2023-08-15 11:44:39,821:INFO:tune_model(estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>)
2023-08-15 11:44:39,821:INFO:Checking exceptions
2023-08-15 11:44:39,854:INFO:Copying training dataset
2023-08-15 11:44:39,894:INFO:Checking base model
2023-08-15 11:44:39,894:INFO:Base model : Quadratic Discriminant Analysis
2023-08-15 11:44:39,896:INFO:Declaring metric variables
2023-08-15 11:44:39,898:INFO:Defining Hyperparameters
2023-08-15 11:44:40,038:INFO:Tuning with n_jobs=-1
2023-08-15 11:44:40,038:INFO:Initializing RandomizedSearchCV
2023-08-15 11:44:44,826:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:45,195:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:45,253:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:45,328:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:45,609:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:45,856:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:45,924:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:45,961:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:46,246:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:46,407:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:46,505:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:46,718:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:46,896:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:47,013:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:47,247:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:47,341:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:47,364:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:47,429:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:47,492:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:47,651:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:51,609:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:52,412:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:52,781:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:52,939:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:53,044:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:53,644:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:53,904:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:54,038:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:54,120:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:54,643:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:54,727:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:54,898:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:54,919:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:55,165:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:55,194:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:55,257:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:55,627:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:55,647:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:55,668:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:56,095:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:58,332:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:44:59,646:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:00,475:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:00,671:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:01,024:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:01,349:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:01,433:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:01,515:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:01,709:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:01,825:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:01,965:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:02,176:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:02,615:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:03,031:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:03,119:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:03,190:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:03,247:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:03,417:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:03,974:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:04,154:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:05,170:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:06,130:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:07,103:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:07,449:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:07,477:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:07,527:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:07,713:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:07,951:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:08,604:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:08,962:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:09,332:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:09,521:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:09,843:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:10,110:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:10,488:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:10,933:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:11,278:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:11,727:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:12,105:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:12,526:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:12,874:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:13,260:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:13,584:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:13,991:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:14,312:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:14,763:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:15,097:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:15,531:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:15,846:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:16,184:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:16,523:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:16,881:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:17,051:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:17,365:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:17,581:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:17,850:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:18,051:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:18,191:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:18,310:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:18,405:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:45:21,960:INFO:best_params: {'actual_estimator__reg_param': 0.47}
2023-08-15 11:45:21,961:INFO:Hyperparameter search completed
2023-08-15 11:45:21,961:INFO:SubProcess create_model() called ==================================
2023-08-15 11:45:21,961:INFO:Initializing create_model()
2023-08-15 11:45:21,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253AF16D8A0>, model_only=True, return_train_score=False, kwargs={'reg_param': 0.47})
2023-08-15 11:45:21,962:INFO:Checking exceptions
2023-08-15 11:45:21,962:INFO:Importing libraries
2023-08-15 11:45:21,962:INFO:Copying training dataset
2023-08-15 11:45:22,013:INFO:Defining folds
2023-08-15 11:45:22,014:INFO:Declaring metric variables
2023-08-15 11:45:22,016:INFO:Importing untrained model
2023-08-15 11:45:22,016:INFO:Declaring custom model
2023-08-15 11:45:22,018:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 11:45:22,022:INFO:Starting cross validation
2023-08-15 11:45:22,023:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:45:25,098:INFO:Calculating mean and std
2023-08-15 11:45:25,099:INFO:Creating metrics dataframe
2023-08-15 11:45:25,103:INFO:Finalizing model
2023-08-15 11:45:25,831:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning:

Variables are collinear


2023-08-15 11:45:25,998:INFO:Uploading results into container
2023-08-15 11:45:25,999:INFO:Uploading model into container now
2023-08-15 11:45:26,000:INFO:_master_model_container: 22
2023-08-15 11:45:26,000:INFO:_display_container: 6
2023-08-15 11:45:26,000:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001)
2023-08-15 11:45:26,000:INFO:create_model() successfully completed......................................
2023-08-15 11:45:26,136:INFO:SubProcess create_model() end ==================================
2023-08-15 11:45:26,136:INFO:choose_better activated
2023-08-15 11:45:26,138:INFO:SubProcess create_model() called ==================================
2023-08-15 11:45:26,138:INFO:Initializing create_model()
2023-08-15 11:45:26,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 11:45:26,138:INFO:Checking exceptions
2023-08-15 11:45:26,140:INFO:Importing libraries
2023-08-15 11:45:26,140:INFO:Copying training dataset
2023-08-15 11:45:26,190:INFO:Defining folds
2023-08-15 11:45:26,190:INFO:Declaring metric variables
2023-08-15 11:45:26,190:INFO:Importing untrained model
2023-08-15 11:45:26,190:INFO:Declaring custom model
2023-08-15 11:45:26,190:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 11:45:26,190:INFO:Starting cross validation
2023-08-15 11:45:26,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:45:29,053:INFO:Calculating mean and std
2023-08-15 11:45:29,053:INFO:Creating metrics dataframe
2023-08-15 11:45:29,055:INFO:Finalizing model
2023-08-15 11:45:29,727:INFO:Uploading results into container
2023-08-15 11:45:29,728:INFO:Uploading model into container now
2023-08-15 11:45:29,728:INFO:_master_model_container: 23
2023-08-15 11:45:29,728:INFO:_display_container: 7
2023-08-15 11:45:29,728:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 11:45:29,728:INFO:create_model() successfully completed......................................
2023-08-15 11:45:29,854:INFO:SubProcess create_model() end ==================================
2023-08-15 11:45:29,854:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Accuracy is 0.5545
2023-08-15 11:45:29,855:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001) result for Accuracy is 0.9175
2023-08-15 11:45:29,855:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001) is best model
2023-08-15 11:45:29,855:INFO:choose_better completed
2023-08-15 11:45:29,861:INFO:_master_model_container: 23
2023-08-15 11:45:29,861:INFO:_display_container: 6
2023-08-15 11:45:29,862:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001)
2023-08-15 11:45:29,862:INFO:tune_model() successfully completed......................................
2023-08-15 11:46:00,654:INFO:Initializing tune_model()
2023-08-15 11:46:00,654:INFO:tune_model(estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>)
2023-08-15 11:46:00,654:INFO:Checking exceptions
2023-08-15 11:46:00,688:INFO:Copying training dataset
2023-08-15 11:46:00,726:INFO:Checking base model
2023-08-15 11:46:00,727:INFO:Base model : Quadratic Discriminant Analysis
2023-08-15 11:46:00,729:INFO:Declaring metric variables
2023-08-15 11:46:00,731:INFO:Defining Hyperparameters
2023-08-15 11:46:00,862:INFO:Tuning with n_jobs=-1
2023-08-15 11:46:00,862:INFO:Initializing RandomizedSearchCV
2023-08-15 11:46:21,640:INFO:best_params: {'actual_estimator__reg_param': 0.98}
2023-08-15 11:46:21,640:INFO:Hyperparameter search completed
2023-08-15 11:46:21,640:INFO:SubProcess create_model() called ==================================
2023-08-15 11:46:21,641:INFO:Initializing create_model()
2023-08-15 11:46:21,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253B5807EB0>, model_only=True, return_train_score=False, kwargs={'reg_param': 0.98})
2023-08-15 11:46:21,641:INFO:Checking exceptions
2023-08-15 11:46:21,641:INFO:Importing libraries
2023-08-15 11:46:21,641:INFO:Copying training dataset
2023-08-15 11:46:21,689:INFO:Defining folds
2023-08-15 11:46:21,689:INFO:Declaring metric variables
2023-08-15 11:46:21,691:INFO:Importing untrained model
2023-08-15 11:46:21,692:INFO:Declaring custom model
2023-08-15 11:46:21,694:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 11:46:21,698:INFO:Starting cross validation
2023-08-15 11:46:21,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:46:24,819:INFO:Calculating mean and std
2023-08-15 11:46:24,820:INFO:Creating metrics dataframe
2023-08-15 11:46:24,823:INFO:Finalizing model
2023-08-15 11:46:25,568:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning:

Variables are collinear


2023-08-15 11:46:25,734:INFO:Uploading results into container
2023-08-15 11:46:25,735:INFO:Uploading model into container now
2023-08-15 11:46:25,735:INFO:_master_model_container: 24
2023-08-15 11:46:25,735:INFO:_display_container: 7
2023-08-15 11:46:25,735:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.98,
                              store_covariance=False, tol=0.0001)
2023-08-15 11:46:25,735:INFO:create_model() successfully completed......................................
2023-08-15 11:46:25,860:INFO:SubProcess create_model() end ==================================
2023-08-15 11:46:25,860:INFO:choose_better activated
2023-08-15 11:46:25,862:INFO:SubProcess create_model() called ==================================
2023-08-15 11:46:25,862:INFO:Initializing create_model()
2023-08-15 11:46:25,862:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 11:46:25,863:INFO:Checking exceptions
2023-08-15 11:46:25,864:INFO:Importing libraries
2023-08-15 11:46:25,864:INFO:Copying training dataset
2023-08-15 11:46:25,911:INFO:Defining folds
2023-08-15 11:46:25,911:INFO:Declaring metric variables
2023-08-15 11:46:25,912:INFO:Importing untrained model
2023-08-15 11:46:25,912:INFO:Declaring custom model
2023-08-15 11:46:25,912:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 11:46:25,912:INFO:Starting cross validation
2023-08-15 11:46:25,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:46:28,760:INFO:Calculating mean and std
2023-08-15 11:46:28,761:INFO:Creating metrics dataframe
2023-08-15 11:46:28,762:INFO:Finalizing model
2023-08-15 11:46:29,430:INFO:Uploading results into container
2023-08-15 11:46:29,431:INFO:Uploading model into container now
2023-08-15 11:46:29,431:INFO:_master_model_container: 25
2023-08-15 11:46:29,431:INFO:_display_container: 8
2023-08-15 11:46:29,431:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 11:46:29,431:INFO:create_model() successfully completed......................................
2023-08-15 11:46:29,555:INFO:SubProcess create_model() end ==================================
2023-08-15 11:46:29,556:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Recall is 0.8525
2023-08-15 11:46:29,556:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.98,
                              store_covariance=False, tol=0.0001) result for Recall is 0.3845
2023-08-15 11:46:29,556:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2023-08-15 11:46:29,556:INFO:choose_better completed
2023-08-15 11:46:29,557:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-15 11:46:29,563:INFO:_master_model_container: 25
2023-08-15 11:46:29,564:INFO:_display_container: 7
2023-08-15 11:46:29,564:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 11:46:29,564:INFO:tune_model() successfully completed......................................
2023-08-15 11:47:42,968:INFO:Initializing create_model()
2023-08-15 11:47:42,968:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 11:47:42,968:INFO:Checking exceptions
2023-08-15 11:47:42,977:INFO:Importing libraries
2023-08-15 11:47:42,977:INFO:Copying training dataset
2023-08-15 11:47:43,035:INFO:Defining folds
2023-08-15 11:47:43,035:INFO:Declaring metric variables
2023-08-15 11:47:43,037:INFO:Importing untrained model
2023-08-15 11:47:43,039:INFO:Naive Bayes Imported successfully
2023-08-15 11:47:43,043:INFO:Starting cross validation
2023-08-15 11:47:43,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:47:46,716:INFO:Calculating mean and std
2023-08-15 11:47:46,717:INFO:Creating metrics dataframe
2023-08-15 11:47:46,722:INFO:Finalizing model
2023-08-15 11:47:47,492:INFO:Uploading results into container
2023-08-15 11:47:47,492:INFO:Uploading model into container now
2023-08-15 11:47:47,500:INFO:_master_model_container: 26
2023-08-15 11:47:47,500:INFO:_display_container: 8
2023-08-15 11:47:47,500:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 11:47:47,500:INFO:create_model() successfully completed......................................
2023-08-15 11:48:10,582:INFO:Initializing tune_model()
2023-08-15 11:48:10,582:INFO:tune_model(estimator=nb, fold=None, round=4, n_iter=10, custom_grid=None, optimize=recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>)
2023-08-15 11:48:10,582:INFO:Checking exceptions
2023-08-15 11:49:43,058:INFO:Initializing tune_model()
2023-08-15 11:49:43,058:INFO:tune_model(estimator=nb, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>)
2023-08-15 11:49:43,058:INFO:Checking exceptions
2023-08-15 11:51:36,081:INFO:Initializing tune_model()
2023-08-15 11:51:36,081:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>)
2023-08-15 11:51:36,081:INFO:Checking exceptions
2023-08-15 11:51:36,115:INFO:Copying training dataset
2023-08-15 11:51:36,156:INFO:Checking base model
2023-08-15 11:51:36,157:INFO:Base model : Naive Bayes
2023-08-15 11:51:36,160:INFO:Declaring metric variables
2023-08-15 11:51:36,162:INFO:Defining Hyperparameters
2023-08-15 11:51:36,335:INFO:Tuning with n_jobs=-1
2023-08-15 11:51:36,335:INFO:Initializing RandomizedSearchCV
2023-08-15 11:52:04,510:INFO:best_params: {'actual_estimator__var_smoothing': 2e-09}
2023-08-15 11:52:04,510:INFO:Hyperparameter search completed
2023-08-15 11:52:04,510:INFO:SubProcess create_model() called ==================================
2023-08-15 11:52:04,511:INFO:Initializing create_model()
2023-08-15 11:52:04,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253DB249510>, model_only=True, return_train_score=False, kwargs={'var_smoothing': 2e-09})
2023-08-15 11:52:04,511:INFO:Checking exceptions
2023-08-15 11:52:04,511:INFO:Importing libraries
2023-08-15 11:52:04,511:INFO:Copying training dataset
2023-08-15 11:52:04,562:INFO:Defining folds
2023-08-15 11:52:04,563:INFO:Declaring metric variables
2023-08-15 11:52:04,565:INFO:Importing untrained model
2023-08-15 11:52:04,565:INFO:Declaring custom model
2023-08-15 11:52:04,567:INFO:Naive Bayes Imported successfully
2023-08-15 11:52:04,572:INFO:Starting cross validation
2023-08-15 11:52:04,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:52:08,037:INFO:Calculating mean and std
2023-08-15 11:52:08,038:INFO:Creating metrics dataframe
2023-08-15 11:52:08,042:INFO:Finalizing model
2023-08-15 11:52:08,838:INFO:Uploading results into container
2023-08-15 11:52:08,839:INFO:Uploading model into container now
2023-08-15 11:52:08,839:INFO:_master_model_container: 27
2023-08-15 11:52:08,839:INFO:_display_container: 9
2023-08-15 11:52:08,839:INFO:GaussianNB(priors=None, var_smoothing=2e-09)
2023-08-15 11:52:08,840:INFO:create_model() successfully completed......................................
2023-08-15 11:52:08,994:INFO:SubProcess create_model() end ==================================
2023-08-15 11:52:08,994:INFO:choose_better activated
2023-08-15 11:52:08,997:INFO:SubProcess create_model() called ==================================
2023-08-15 11:52:08,997:INFO:Initializing create_model()
2023-08-15 11:52:08,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 11:52:08,997:INFO:Checking exceptions
2023-08-15 11:52:08,998:INFO:Importing libraries
2023-08-15 11:52:08,998:INFO:Copying training dataset
2023-08-15 11:52:09,048:INFO:Defining folds
2023-08-15 11:52:09,049:INFO:Declaring metric variables
2023-08-15 11:52:09,049:INFO:Importing untrained model
2023-08-15 11:52:09,049:INFO:Declaring custom model
2023-08-15 11:52:09,049:INFO:Naive Bayes Imported successfully
2023-08-15 11:52:09,050:INFO:Starting cross validation
2023-08-15 11:52:09,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 11:52:12,214:INFO:Calculating mean and std
2023-08-15 11:52:12,215:INFO:Creating metrics dataframe
2023-08-15 11:52:12,216:INFO:Finalizing model
2023-08-15 11:52:13,015:INFO:Uploading results into container
2023-08-15 11:52:13,015:INFO:Uploading model into container now
2023-08-15 11:52:13,015:INFO:_master_model_container: 28
2023-08-15 11:52:13,015:INFO:_display_container: 10
2023-08-15 11:52:13,016:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 11:52:13,016:INFO:create_model() successfully completed......................................
2023-08-15 11:52:13,160:INFO:SubProcess create_model() end ==================================
2023-08-15 11:52:13,161:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.8498
2023-08-15 11:52:13,161:INFO:GaussianNB(priors=None, var_smoothing=2e-09) result for Recall is 0.8498
2023-08-15 11:52:13,161:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2023-08-15 11:52:13,161:INFO:choose_better completed
2023-08-15 11:52:13,161:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-15 11:52:13,167:INFO:_master_model_container: 28
2023-08-15 11:52:13,167:INFO:_display_container: 9
2023-08-15 11:52:13,167:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 11:52:13,167:INFO:tune_model() successfully completed......................................
2023-08-15 11:53:27,688:INFO:Initializing evaluate_model()
2023-08-15 11:53:27,688:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 11:53:27,715:INFO:Initializing plot_model()
2023-08-15 11:53:27,716:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:53:27,716:INFO:Checking exceptions
2023-08-15 11:53:27,734:INFO:Preloading libraries
2023-08-15 11:53:27,738:INFO:Copying training dataset
2023-08-15 11:53:27,738:INFO:Plot type: pipeline
2023-08-15 11:53:27,895:INFO:Visual Rendered Successfully
2023-08-15 11:53:28,046:INFO:plot_model() successfully completed......................................
2023-08-15 11:53:32,037:INFO:Initializing plot_model()
2023-08-15 11:53:32,037:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:53:32,037:INFO:Checking exceptions
2023-08-15 11:53:32,059:INFO:Preloading libraries
2023-08-15 11:53:32,061:INFO:Copying training dataset
2023-08-15 11:53:32,061:INFO:Plot type: parameter
2023-08-15 11:53:32,064:INFO:Visual Rendered Successfully
2023-08-15 11:53:32,223:INFO:plot_model() successfully completed......................................
2023-08-15 11:53:33,541:INFO:Initializing plot_model()
2023-08-15 11:53:33,541:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:53:33,541:INFO:Checking exceptions
2023-08-15 11:53:33,559:INFO:Preloading libraries
2023-08-15 11:53:33,562:INFO:Copying training dataset
2023-08-15 11:53:33,562:INFO:Plot type: pipeline
2023-08-15 11:53:33,692:INFO:Visual Rendered Successfully
2023-08-15 11:53:33,842:INFO:plot_model() successfully completed......................................
2023-08-15 11:53:35,173:INFO:Initializing plot_model()
2023-08-15 11:53:35,174:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:53:35,174:INFO:Checking exceptions
2023-08-15 11:53:35,193:INFO:Preloading libraries
2023-08-15 11:53:35,195:INFO:Copying training dataset
2023-08-15 11:53:35,195:INFO:Plot type: lift
2023-08-15 11:53:35,196:INFO:Generating predictions / predict_proba on X_test
2023-08-15 11:53:35,944:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:53:35,944:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:53:35,944:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:53:36,253:INFO:Visual Rendered Successfully
2023-08-15 11:53:36,412:INFO:plot_model() successfully completed......................................
2023-08-15 11:53:36,442:INFO:Initializing plot_model()
2023-08-15 11:53:36,442:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:53:36,442:INFO:Checking exceptions
2023-08-15 11:53:36,460:INFO:Preloading libraries
2023-08-15 11:53:36,463:INFO:Copying training dataset
2023-08-15 11:53:36,463:INFO:Plot type: feature_all
2023-08-15 11:53:37,017:WARNING:No coef_ found. Trying feature_importances_
2023-08-15 11:53:37,546:INFO:Visual Rendered Successfully
2023-08-15 11:53:37,695:INFO:plot_model() successfully completed......................................
2023-08-15 11:53:40,505:INFO:Initializing plot_model()
2023-08-15 11:53:40,505:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:53:40,505:INFO:Checking exceptions
2023-08-15 11:53:40,522:INFO:Preloading libraries
2023-08-15 11:53:40,524:INFO:Copying training dataset
2023-08-15 11:53:40,524:INFO:Plot type: pipeline
2023-08-15 11:53:40,661:INFO:Visual Rendered Successfully
2023-08-15 11:53:40,823:INFO:plot_model() successfully completed......................................
2023-08-15 11:53:42,605:INFO:Initializing evaluate_model()
2023-08-15 11:53:42,605:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 11:53:42,628:INFO:Initializing plot_model()
2023-08-15 11:53:42,628:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:53:42,628:INFO:Checking exceptions
2023-08-15 11:53:42,645:INFO:Preloading libraries
2023-08-15 11:53:42,646:INFO:Copying training dataset
2023-08-15 11:53:42,646:INFO:Plot type: pipeline
2023-08-15 11:53:42,753:INFO:Visual Rendered Successfully
2023-08-15 11:53:42,913:INFO:plot_model() successfully completed......................................
2023-08-15 11:53:51,002:INFO:Initializing plot_model()
2023-08-15 11:53:51,003:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:53:51,003:INFO:Checking exceptions
2023-08-15 11:53:51,020:INFO:Preloading libraries
2023-08-15 11:53:51,021:INFO:Copying training dataset
2023-08-15 11:53:51,021:INFO:Plot type: learning
2023-08-15 11:53:51,306:INFO:Fitting Model
2023-08-15 11:53:51,883:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:52,458:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:52,517:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:52,541:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:52,852:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:52,963:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:53,240:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:53,426:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:53,626:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:53,828:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:53,916:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:53,987:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:54,336:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:54,453:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:54,623:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:54,666:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:54,713:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:54,984:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:55,075:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:55,127:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:55,321:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:55,323:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:55,705:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:55,950:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:56,215:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:56,282:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:56,362:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:56,367:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:57,186:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:57,238:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:57,749:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:57,881:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:57,934:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:58,162:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:58,430:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:58,601:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:58,653:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:58,689:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:58,902:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:59,074:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:59,550:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:59,660:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:59,684:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:53:59,772:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:00,171:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:00,288:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:00,493:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:00,741:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:00,825:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:00,965:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:01,170:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:01,421:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:01,438:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:01,774:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:02,227:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:02,268:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:02,354:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:02,740:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:02,786:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:03,028:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:03,186:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:03,351:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:03,405:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:03,466:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:03,583:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:04,077:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:04,324:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:04,415:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:05,039:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:05,052:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:05,084:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:05,266:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:05,632:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:05,653:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:05,744:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:06,022:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:06,057:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:06,329:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:06,405:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:06,720:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:06,827:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:07,395:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:07,405:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:07,661:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:07,733:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:07,790:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:07,943:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:08,237:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:08,335:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:08,574:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:08,728:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:09,045:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:09,173:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:09,244:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:09,426:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:09,662:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:09,678:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:09,756:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:09,976:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:10,135:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:54:10,759:INFO:Visual Rendered Successfully
2023-08-15 11:54:10,928:INFO:plot_model() successfully completed......................................
2023-08-15 11:54:10,936:INFO:Initializing plot_model()
2023-08-15 11:54:10,937:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:54:10,937:INFO:Checking exceptions
2023-08-15 11:54:10,954:INFO:Preloading libraries
2023-08-15 11:54:10,956:INFO:Copying training dataset
2023-08-15 11:54:10,956:INFO:Plot type: learning
2023-08-15 11:54:11,270:INFO:Fitting Model
2023-08-15 11:54:29,411:INFO:Visual Rendered Successfully
2023-08-15 11:54:29,615:INFO:plot_model() successfully completed......................................
2023-08-15 11:54:29,631:INFO:Initializing evaluate_model()
2023-08-15 11:54:29,632:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 11:54:29,658:INFO:Initializing plot_model()
2023-08-15 11:54:29,659:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:54:29,659:INFO:Checking exceptions
2023-08-15 11:54:29,675:INFO:Preloading libraries
2023-08-15 11:54:29,678:INFO:Copying training dataset
2023-08-15 11:54:29,678:INFO:Plot type: pipeline
2023-08-15 11:54:29,811:INFO:Visual Rendered Successfully
2023-08-15 11:54:29,992:INFO:plot_model() successfully completed......................................
2023-08-15 11:54:30,008:INFO:Initializing plot_model()
2023-08-15 11:54:30,008:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:54:30,008:INFO:Checking exceptions
2023-08-15 11:54:30,030:INFO:Preloading libraries
2023-08-15 11:54:30,033:INFO:Copying training dataset
2023-08-15 11:54:30,033:INFO:Plot type: pr
2023-08-15 11:54:30,364:INFO:Fitting Model
2023-08-15 11:54:30,368:INFO:Scoring test/hold-out set
2023-08-15 11:54:30,374:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:54:30,374:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:54:30,374:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:54:30,405:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:54:30,405:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:54:30,406:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:54:30,625:INFO:Visual Rendered Successfully
2023-08-15 11:54:30,789:INFO:plot_model() successfully completed......................................
2023-08-15 11:54:36,372:INFO:Initializing plot_model()
2023-08-15 11:54:36,373:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:54:36,373:INFO:Checking exceptions
2023-08-15 11:54:36,390:INFO:Preloading libraries
2023-08-15 11:54:36,392:INFO:Copying training dataset
2023-08-15 11:54:36,392:INFO:Plot type: confusion_matrix
2023-08-15 11:54:36,713:INFO:Fitting Model
2023-08-15 11:54:36,714:INFO:Scoring test/hold-out set
2023-08-15 11:54:36,721:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:54:36,721:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:54:36,721:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:54:36,748:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:54:36,748:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:54:36,748:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:54:36,896:INFO:Visual Rendered Successfully
2023-08-15 11:54:37,064:INFO:plot_model() successfully completed......................................
2023-08-15 11:56:17,997:INFO:Initializing evaluate_model()
2023-08-15 11:56:17,997:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 11:56:18,021:INFO:Initializing plot_model()
2023-08-15 11:56:18,021:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:56:18,021:INFO:Checking exceptions
2023-08-15 11:56:18,039:INFO:Preloading libraries
2023-08-15 11:56:18,043:INFO:Copying training dataset
2023-08-15 11:56:18,043:INFO:Plot type: pipeline
2023-08-15 11:56:18,175:INFO:Visual Rendered Successfully
2023-08-15 11:56:18,358:INFO:plot_model() successfully completed......................................
2023-08-15 11:56:29,422:INFO:Initializing plot_model()
2023-08-15 11:56:29,422:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:56:29,422:INFO:Checking exceptions
2023-08-15 11:56:29,441:INFO:Preloading libraries
2023-08-15 11:56:29,443:INFO:Copying training dataset
2023-08-15 11:56:29,443:INFO:Plot type: auc
2023-08-15 11:56:29,761:INFO:Fitting Model
2023-08-15 11:56:29,764:INFO:Scoring test/hold-out set
2023-08-15 11:56:29,770:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:56:29,770:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:56:29,771:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:56:29,799:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:56:29,799:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:56:29,799:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:56:30,148:INFO:Visual Rendered Successfully
2023-08-15 11:56:30,321:INFO:plot_model() successfully completed......................................
2023-08-15 11:57:34,701:INFO:Initializing evaluate_model()
2023-08-15 11:57:34,701:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 11:57:34,730:INFO:Initializing plot_model()
2023-08-15 11:57:34,731:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:57:34,731:INFO:Checking exceptions
2023-08-15 11:57:34,751:INFO:Preloading libraries
2023-08-15 11:57:34,753:INFO:Copying training dataset
2023-08-15 11:57:34,753:INFO:Plot type: pipeline
2023-08-15 11:57:34,890:INFO:Visual Rendered Successfully
2023-08-15 11:57:35,082:INFO:plot_model() successfully completed......................................
2023-08-15 11:58:05,003:INFO:Initializing evaluate_model()
2023-08-15 11:58:05,003:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 11:58:05,029:INFO:Initializing plot_model()
2023-08-15 11:58:05,029:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:58:05,029:INFO:Checking exceptions
2023-08-15 11:58:05,056:INFO:Preloading libraries
2023-08-15 11:58:05,059:INFO:Copying training dataset
2023-08-15 11:58:05,059:INFO:Plot type: pipeline
2023-08-15 11:58:05,175:INFO:Visual Rendered Successfully
2023-08-15 11:58:05,360:INFO:plot_model() successfully completed......................................
2023-08-15 11:58:35,867:INFO:Initializing plot_model()
2023-08-15 11:58:35,867:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:58:35,867:INFO:Checking exceptions
2023-08-15 11:58:35,885:INFO:Preloading libraries
2023-08-15 11:58:35,887:INFO:Copying training dataset
2023-08-15 11:58:35,887:INFO:Plot type: parameter
2023-08-15 11:58:35,890:INFO:Visual Rendered Successfully
2023-08-15 11:58:36,081:INFO:plot_model() successfully completed......................................
2023-08-15 11:58:37,493:INFO:Initializing plot_model()
2023-08-15 11:58:37,493:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:58:37,493:INFO:Checking exceptions
2023-08-15 11:58:37,510:INFO:Preloading libraries
2023-08-15 11:58:37,512:INFO:Copying training dataset
2023-08-15 11:58:37,512:INFO:Plot type: auc
2023-08-15 11:58:37,822:INFO:Fitting Model
2023-08-15 11:58:37,824:INFO:Scoring test/hold-out set
2023-08-15 11:58:37,831:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:58:37,831:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:58:37,831:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:58:37,860:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:58:37,860:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:58:37,860:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:58:38,064:INFO:Visual Rendered Successfully
2023-08-15 11:58:38,274:INFO:plot_model() successfully completed......................................
2023-08-15 11:58:49,028:INFO:Initializing plot_model()
2023-08-15 11:58:49,029:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:58:49,029:INFO:Checking exceptions
2023-08-15 11:58:49,046:INFO:Preloading libraries
2023-08-15 11:58:49,049:INFO:Copying training dataset
2023-08-15 11:58:49,049:INFO:Plot type: confusion_matrix
2023-08-15 11:58:49,376:INFO:Fitting Model
2023-08-15 11:58:49,378:INFO:Scoring test/hold-out set
2023-08-15 11:58:49,384:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:58:49,384:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:58:49,384:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:58:49,413:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 11:58:49,413:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 11:58:49,413:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 11:58:49,514:INFO:Visual Rendered Successfully
2023-08-15 11:58:49,690:INFO:plot_model() successfully completed......................................
2023-08-15 11:58:59,438:INFO:Initializing evaluate_model()
2023-08-15 11:58:59,439:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 11:58:59,463:INFO:Initializing plot_model()
2023-08-15 11:58:59,463:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:58:59,463:INFO:Checking exceptions
2023-08-15 11:58:59,481:INFO:Preloading libraries
2023-08-15 11:58:59,481:INFO:Copying training dataset
2023-08-15 11:58:59,481:INFO:Plot type: pipeline
2023-08-15 11:58:59,568:INFO:Visual Rendered Successfully
2023-08-15 11:58:59,735:INFO:plot_model() successfully completed......................................
2023-08-15 11:59:01,728:INFO:Initializing evaluate_model()
2023-08-15 11:59:01,728:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 11:59:01,753:INFO:Initializing plot_model()
2023-08-15 11:59:01,754:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:59:01,754:INFO:Checking exceptions
2023-08-15 11:59:01,771:INFO:Preloading libraries
2023-08-15 11:59:01,771:INFO:Copying training dataset
2023-08-15 11:59:01,771:INFO:Plot type: pipeline
2023-08-15 11:59:01,857:INFO:Visual Rendered Successfully
2023-08-15 11:59:02,040:INFO:plot_model() successfully completed......................................
2023-08-15 11:59:06,154:INFO:Initializing plot_model()
2023-08-15 11:59:06,155:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:59:06,155:INFO:Checking exceptions
2023-08-15 11:59:06,173:INFO:Preloading libraries
2023-08-15 11:59:06,175:INFO:Copying training dataset
2023-08-15 11:59:06,175:INFO:Plot type: learning
2023-08-15 11:59:06,482:INFO:Fitting Model
2023-08-15 11:59:23,958:INFO:Visual Rendered Successfully
2023-08-15 11:59:24,205:INFO:plot_model() successfully completed......................................
2023-08-15 11:59:37,860:INFO:Initializing plot_model()
2023-08-15 11:59:37,860:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 11:59:37,860:INFO:Checking exceptions
2023-08-15 11:59:37,880:INFO:Preloading libraries
2023-08-15 11:59:37,880:INFO:Copying training dataset
2023-08-15 11:59:37,880:INFO:Plot type: learning
2023-08-15 11:59:38,186:INFO:Fitting Model
2023-08-15 11:59:38,898:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:39,161:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:39,213:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:39,453:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:39,634:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:39,923:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:40,125:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:40,244:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:40,705:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:40,804:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:40,873:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:41,005:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:41,096:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:41,492:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:41,545:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:41,612:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:41,685:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:41,752:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:42,001:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:42,205:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:42,512:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:42,650:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:42,772:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:43,012:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:43,022:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:43,316:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:43,462:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:43,468:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:44,065:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:44,274:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:44,579:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:44,762:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:44,976:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:45,153:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:45,202:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:45,335:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:45,665:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:45,832:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:45,914:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:46,226:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:46,566:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:46,592:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:46,645:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:46,771:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:47,008:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:47,148:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:47,311:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:47,636:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:47,888:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:47,980:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:48,201:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:48,410:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:48,438:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:48,646:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:49,403:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:49,406:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:49,618:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:49,696:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:49,761:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:49,905:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:50,181:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:50,516:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:50,553:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:50,719:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:50,811:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:51,248:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:51,517:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:51,528:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:51,578:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:51,906:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:51,926:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:52,357:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:52,381:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:52,758:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:52,814:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:53,037:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:53,208:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:53,249:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:53,682:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:53,858:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:54,145:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:54,456:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:54,542:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:54,597:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:54,730:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:55,215:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:55,241:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:55,338:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:55,475:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:55,887:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:55,921:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:56,352:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:56,436:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:56,564:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:56,817:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:56,957:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:57,065:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:57,370:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:57,553:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:57,585:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 11:59:58,074:INFO:Visual Rendered Successfully
2023-08-15 11:59:58,273:INFO:plot_model() successfully completed......................................
2023-08-15 12:00:07,972:INFO:Initializing plot_model()
2023-08-15 12:00:07,972:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 12:00:07,972:INFO:Checking exceptions
2023-08-15 12:00:07,990:INFO:Preloading libraries
2023-08-15 12:00:07,990:INFO:Copying training dataset
2023-08-15 12:00:07,990:INFO:Plot type: learning
2023-08-15 12:00:08,307:INFO:Fitting Model
2023-08-15 12:00:15,610:INFO:Visual Rendered Successfully
2023-08-15 12:00:15,798:INFO:plot_model() successfully completed......................................
2023-08-15 12:01:48,673:INFO:Initializing interpret_model()
2023-08-15 12:01:48,673:INFO:interpret_model(estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>)
2023-08-15 12:01:48,674:INFO:Checking exceptions
2023-08-15 12:01:48,674:INFO:Soft dependency imported: shap: 0.42.1
2023-08-15 12:02:12,069:INFO:Initializing interpret_model()
2023-08-15 12:02:12,069:INFO:interpret_model(estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>)
2023-08-15 12:02:12,069:INFO:Checking exceptions
2023-08-15 12:02:12,069:INFO:Soft dependency imported: shap: 0.42.1
2023-08-15 12:08:54,076:INFO:Initializing blend_models()
2023-08-15 12:08:54,076:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 12:08:54,076:INFO:Checking exceptions
2023-08-15 12:08:54,108:INFO:Importing libraries
2023-08-15 12:08:54,108:INFO:Copying training dataset
2023-08-15 12:08:54,111:INFO:Getting model names
2023-08-15 12:08:54,113:INFO:SubProcess create_model() called ==================================
2023-08-15 12:08:54,115:INFO:Initializing create_model()
2023-08-15 12:08:54,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253F68DE560>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:08:54,115:INFO:Checking exceptions
2023-08-15 12:08:54,115:INFO:Importing libraries
2023-08-15 12:08:54,115:INFO:Copying training dataset
2023-08-15 12:08:54,172:INFO:Defining folds
2023-08-15 12:08:54,172:INFO:Declaring metric variables
2023-08-15 12:08:54,175:INFO:Importing untrained model
2023-08-15 12:08:54,175:INFO:Declaring custom model
2023-08-15 12:08:54,178:INFO:Voting Classifier Imported successfully
2023-08-15 12:08:54,182:INFO:Starting cross validation
2023-08-15 12:08:54,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:09:01,803:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:01,874:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:02,023:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:02,358:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:02,454:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:02,582:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:02,615:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:02,687:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:02,768:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:02,884:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:08,111:INFO:Calculating mean and std
2023-08-15 12:09:08,112:INFO:Creating metrics dataframe
2023-08-15 12:09:08,117:INFO:Finalizing model
2023-08-15 12:09:11,138:INFO:Uploading results into container
2023-08-15 12:09:11,139:INFO:Uploading model into container now
2023-08-15 12:09:11,139:INFO:_master_model_container: 29
2023-08-15 12:09:11,139:INFO:_display_container: 10
2023-08-15 12:09:11,141:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 12:09:11,141:INFO:create_model() successfully completed......................................
2023-08-15 12:09:11,347:INFO:SubProcess create_model() end ==================================
2023-08-15 12:09:11,353:INFO:_master_model_container: 29
2023-08-15 12:09:11,353:INFO:_display_container: 10
2023-08-15 12:09:11,355:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 12:09:11,355:INFO:blend_models() successfully completed......................................
2023-08-15 12:09:46,057:INFO:Initializing evaluate_model()
2023-08-15 12:09:46,057:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 12:09:46,085:INFO:Initializing plot_model()
2023-08-15 12:09:46,086:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 12:09:46,086:INFO:Checking exceptions
2023-08-15 12:09:46,105:INFO:Preloading libraries
2023-08-15 12:09:46,114:INFO:Copying training dataset
2023-08-15 12:09:46,115:INFO:Plot type: pipeline
2023-08-15 12:09:46,225:INFO:Visual Rendered Successfully
2023-08-15 12:09:46,406:INFO:plot_model() successfully completed......................................
2023-08-15 12:09:49,268:INFO:Initializing plot_model()
2023-08-15 12:09:49,268:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 12:09:49,268:INFO:Checking exceptions
2023-08-15 12:09:49,287:INFO:Preloading libraries
2023-08-15 12:09:49,291:INFO:Copying training dataset
2023-08-15 12:09:49,291:INFO:Plot type: learning
2023-08-15 12:09:49,610:INFO:Fitting Model
2023-08-15 12:09:50,512:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:51,033:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:51,306:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:51,808:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:51,983:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:52,040:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:52,161:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:52,333:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:52,555:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:52,563:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:59,156:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:09:59,693:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:00,064:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:00,176:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:00,609:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:00,880:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:01,331:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:01,600:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:01,809:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:03,471:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:09,891:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:10,173:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:10,549:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:10,839:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:11,110:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:11,649:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:13,709:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:14,585:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:15,490:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:15,720:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:19,246:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:19,521:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:19,706:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:20,434:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:21,008:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:21,773:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:21,940:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:23,033:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:24,281:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:24,900:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:28,489:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:28,625:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:29,124:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:29,613:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:30,478:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:30,994:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:31,617:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:32,475:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:33,508:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:34,484:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:10:41,122:INFO:Visual Rendered Successfully
2023-08-15 12:10:41,336:INFO:plot_model() successfully completed......................................
2023-08-15 12:11:16,352:INFO:Initializing plot_model()
2023-08-15 12:11:16,353:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 12:11:16,353:INFO:Checking exceptions
2023-08-15 12:11:16,373:INFO:Preloading libraries
2023-08-15 12:11:16,376:INFO:Copying training dataset
2023-08-15 12:11:16,376:INFO:Plot type: error
2023-08-15 12:11:16,701:INFO:Fitting Model
2023-08-15 12:11:16,702:INFO:Scoring test/hold-out set
2023-08-15 12:11:17,129:INFO:Visual Rendered Successfully
2023-08-15 12:11:17,307:INFO:plot_model() successfully completed......................................
2023-08-15 12:11:34,651:INFO:Initializing blend_models()
2023-08-15 12:11:34,651:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator_list=[LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 12:11:34,651:INFO:Checking exceptions
2023-08-15 12:11:34,681:INFO:Importing libraries
2023-08-15 12:11:34,681:INFO:Copying training dataset
2023-08-15 12:11:34,683:INFO:Getting model names
2023-08-15 12:11:34,685:INFO:SubProcess create_model() called ==================================
2023-08-15 12:11:34,687:INFO:Initializing create_model()
2023-08-15 12:11:34,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253FCFAC4C0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:11:34,687:INFO:Checking exceptions
2023-08-15 12:11:34,687:INFO:Importing libraries
2023-08-15 12:11:34,687:INFO:Copying training dataset
2023-08-15 12:11:34,740:INFO:Defining folds
2023-08-15 12:11:34,740:INFO:Declaring metric variables
2023-08-15 12:11:34,743:INFO:Importing untrained model
2023-08-15 12:11:34,743:INFO:Declaring custom model
2023-08-15 12:11:34,746:INFO:Voting Classifier Imported successfully
2023-08-15 12:11:34,750:INFO:Starting cross validation
2023-08-15 12:11:34,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:11:37,491:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:37,524:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:37,559:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:37,570:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:37,852:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:37,867:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:40,589:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:40,691:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:40,706:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:40,766:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:11:43,032:INFO:Calculating mean and std
2023-08-15 12:11:43,033:INFO:Creating metrics dataframe
2023-08-15 12:11:43,037:INFO:Finalizing model
2023-08-15 12:11:44,648:INFO:Uploading results into container
2023-08-15 12:11:44,649:INFO:Uploading model into container now
2023-08-15 12:11:44,649:INFO:_master_model_container: 30
2023-08-15 12:11:44,649:INFO:_display_container: 11
2023-08-15 12:11:44,651:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 12:11:44,651:INFO:create_model() successfully completed......................................
2023-08-15 12:11:44,831:INFO:SubProcess create_model() end ==================================
2023-08-15 12:11:44,837:INFO:_master_model_container: 30
2023-08-15 12:11:44,837:INFO:_display_container: 11
2023-08-15 12:11:44,839:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 12:11:44,840:INFO:blend_models() successfully completed......................................
2023-08-15 12:12:02,485:INFO:Initializing evaluate_model()
2023-08-15 12:12:02,485:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 12:12:02,513:INFO:Initializing plot_model()
2023-08-15 12:12:02,513:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 12:12:02,513:INFO:Checking exceptions
2023-08-15 12:12:02,534:INFO:Preloading libraries
2023-08-15 12:12:02,537:INFO:Copying training dataset
2023-08-15 12:12:02,537:INFO:Plot type: pipeline
2023-08-15 12:12:02,665:INFO:Visual Rendered Successfully
2023-08-15 12:12:02,840:INFO:plot_model() successfully completed......................................
2023-08-15 12:12:34,772:INFO:Initializing plot_model()
2023-08-15 12:12:34,772:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 12:12:34,772:INFO:Checking exceptions
2023-08-15 12:12:34,790:INFO:Preloading libraries
2023-08-15 12:12:34,793:INFO:Copying training dataset
2023-08-15 12:12:34,793:INFO:Plot type: error
2023-08-15 12:12:35,109:INFO:Fitting Model
2023-08-15 12:12:35,110:INFO:Scoring test/hold-out set
2023-08-15 12:12:35,118:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 12:12:35,118:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 12:12:35,118:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 12:12:35,261:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 12:12:35,261:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 12:12:35,261:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 12:12:35,517:INFO:Visual Rendered Successfully
2023-08-15 12:12:35,694:INFO:plot_model() successfully completed......................................
2023-08-15 12:13:30,713:INFO:Initializing blend_models()
2023-08-15 12:13:30,713:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=hard, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 12:13:30,713:INFO:Checking exceptions
2023-08-15 12:13:30,741:INFO:Importing libraries
2023-08-15 12:13:30,741:INFO:Copying training dataset
2023-08-15 12:13:30,744:INFO:Getting model names
2023-08-15 12:13:30,746:INFO:SubProcess create_model() called ==================================
2023-08-15 12:13:30,748:INFO:Initializing create_model()
2023-08-15 12:13:30,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253DE4E5750>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:13:30,748:INFO:Checking exceptions
2023-08-15 12:13:30,748:INFO:Importing libraries
2023-08-15 12:13:30,748:INFO:Copying training dataset
2023-08-15 12:13:30,832:INFO:Defining folds
2023-08-15 12:13:30,832:INFO:Declaring metric variables
2023-08-15 12:13:30,835:INFO:Importing untrained model
2023-08-15 12:13:30,835:INFO:Declaring custom model
2023-08-15 12:13:30,838:INFO:Voting Classifier Imported successfully
2023-08-15 12:13:30,842:INFO:Starting cross validation
2023-08-15 12:13:30,845:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:13:32,736:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:33,272:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:33,431:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:33,535:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:33,559:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:36,180:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:36,388:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:36,723:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:36,733:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:36,826:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:38,248:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:38,311:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:38,329:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:38,330:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:38,343:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:38,903:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:39,174:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:39,514:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:39,626:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:39,638:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:40,710:INFO:Calculating mean and std
2023-08-15 12:13:40,711:INFO:Creating metrics dataframe
2023-08-15 12:13:40,715:INFO:Finalizing model
2023-08-15 12:13:41,809:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:42,276:INFO:Uploading results into container
2023-08-15 12:13:42,277:INFO:Uploading model into container now
2023-08-15 12:13:42,277:INFO:_master_model_container: 31
2023-08-15 12:13:42,277:INFO:_display_container: 12
2023-08-15 12:13:42,279:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 12:13:42,279:INFO:create_model() successfully completed......................................
2023-08-15 12:13:42,469:INFO:SubProcess create_model() end ==================================
2023-08-15 12:13:42,475:INFO:_master_model_container: 31
2023-08-15 12:13:42,475:INFO:_display_container: 12
2023-08-15 12:13:42,477:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 12:13:42,477:INFO:blend_models() successfully completed......................................
2023-08-15 12:13:46,614:INFO:Initializing blend_models()
2023-08-15 12:13:46,614:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator_list=[LGBMClassifier(bagging_fraction=0.9, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.4, max_depth=-1,
               min_child_samples=6, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=20, n_jobs=-1, num_leaves=150, objective=None,
               random_state=123, reg_alpha=0.005, reg_lambda=0.0005,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=hard, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 12:13:46,614:INFO:Checking exceptions
2023-08-15 12:13:46,645:INFO:Importing libraries
2023-08-15 12:13:46,645:INFO:Copying training dataset
2023-08-15 12:13:46,648:INFO:Getting model names
2023-08-15 12:13:46,650:INFO:SubProcess create_model() called ==================================
2023-08-15 12:13:46,652:INFO:Initializing create_model()
2023-08-15 12:13:46,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000253F68DC370>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:13:46,652:INFO:Checking exceptions
2023-08-15 12:13:46,652:INFO:Importing libraries
2023-08-15 12:13:46,652:INFO:Copying training dataset
2023-08-15 12:13:46,714:INFO:Defining folds
2023-08-15 12:13:46,714:INFO:Declaring metric variables
2023-08-15 12:13:46,716:INFO:Importing untrained model
2023-08-15 12:13:46,716:INFO:Declaring custom model
2023-08-15 12:13:46,719:INFO:Voting Classifier Imported successfully
2023-08-15 12:13:46,723:INFO:Starting cross validation
2023-08-15 12:13:46,725:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:13:49,344:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:49,941:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:50,201:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:50,226:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:50,249:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:50,430:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:50,568:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:50,595:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:50,648:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:52,480:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:52,482:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:52,523:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:52,525:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:52,537:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:52,543:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:52,543:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:52,939:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:53,049:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:53,777:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:54,090:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:13:54,994:INFO:Calculating mean and std
2023-08-15 12:13:54,995:INFO:Creating metrics dataframe
2023-08-15 12:13:54,999:INFO:Finalizing model
2023-08-15 12:13:56,105:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:13:56,484:INFO:Uploading results into container
2023-08-15 12:13:56,484:INFO:Uploading model into container now
2023-08-15 12:13:56,485:INFO:_master_model_container: 32
2023-08-15 12:13:56,485:INFO:_display_container: 13
2023-08-15 12:13:56,487:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 12:13:56,488:INFO:create_model() successfully completed......................................
2023-08-15 12:13:56,666:INFO:SubProcess create_model() end ==================================
2023-08-15 12:13:56,672:INFO:_master_model_container: 32
2023-08-15 12:13:56,673:INFO:_display_container: 13
2023-08-15 12:13:56,675:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 12:13:56,675:INFO:blend_models() successfully completed......................................
2023-08-15 12:14:15,294:INFO:Initializing plot_model()
2023-08-15 12:14:15,295:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.9,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.5,
                                             importance_type='split',
                                             learning_rate=0.4, max_depth=-1,
                                             min_child_samples=6,
                                             min_child_weight=0.001,
                                             min_split_gain=0.3,
                                             n_estimators=20, n_jobs=-1,
                                             num_leaves=150...
                                             random_state=123, reg_alpha=0.005,
                                             reg_lambda=0.0005, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 12:14:15,295:INFO:Checking exceptions
2023-08-15 12:14:15,314:INFO:Preloading libraries
2023-08-15 12:14:15,316:INFO:Copying training dataset
2023-08-15 12:14:15,316:INFO:Plot type: auc
2023-08-15 12:14:15,632:INFO:Fitting Model
2023-08-15 12:14:15,635:INFO:Scoring test/hold-out set
2023-08-15 12:14:15,641:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 12:14:15,641:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 12:14:15,641:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 12:14:15,786:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2023-08-15 12:14:15,786:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-08-15 12:14:15,786:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-15 12:14:16,100:INFO:Visual Rendered Successfully
2023-08-15 12:14:16,317:INFO:plot_model() successfully completed......................................
2023-08-15 12:14:17,778:INFO:Initializing plot_model()
2023-08-15 12:14:17,778:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000253AF1E85B0>, system=True)
2023-08-15 12:14:17,778:INFO:Checking exceptions
2023-08-15 12:14:17,795:INFO:Preloading libraries
2023-08-15 12:14:17,799:INFO:Copying training dataset
2023-08-15 12:14:17,799:INFO:Plot type: auc
2023-08-15 12:14:18,139:INFO:Fitting Model
2023-08-15 12:14:18,142:INFO:Scoring test/hold-out set
2023-08-15 12:14:18,627:INFO:Visual Rendered Successfully
2023-08-15 12:14:18,826:INFO:plot_model() successfully completed......................................
2023-08-15 12:16:33,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 12:16:33,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 12:16:33,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 12:16:33,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 12:16:34,883:INFO:PyCaret ClassificationExperiment
2023-08-15 12:16:34,883:INFO:Logging name: clf-default-name
2023-08-15 12:16:34,883:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 12:16:34,883:INFO:version 3.0.4
2023-08-15 12:16:34,883:INFO:Initializing setup()
2023-08-15 12:16:34,883:INFO:self.USI: 94c6
2023-08-15 12:16:34,883:INFO:self._variable_keys: {'X_train', 'data', 'fold_groups_param', '_available_plots', 'html_param', 'exp_name_log', 'n_jobs_param', 'idx', 'pipeline', 'seed', 'fold_shuffle_param', 'target_param', 'fix_imbalance', 'y_test', 'y_train', 'X', 'X_test', 'memory', 'gpu_n_jobs_param', 'fold_generator', 'gpu_param', '_ml_usecase', 'y', 'exp_id', 'logging_param', 'USI', 'is_multiclass', 'log_plots_param'}
2023-08-15 12:16:34,883:INFO:Checking environment
2023-08-15 12:16:34,883:INFO:python_version: 3.10.12
2023-08-15 12:16:34,883:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 12:16:34,883:INFO:machine: AMD64
2023-08-15 12:16:34,883:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 12:16:34,887:INFO:Memory: svmem(total=68448301056, available=44600225792, percent=34.8, used=23848075264, free=44600225792)
2023-08-15 12:16:34,888:INFO:Physical Core: 12
2023-08-15 12:16:34,888:INFO:Logical Core: 20
2023-08-15 12:16:34,888:INFO:Checking libraries
2023-08-15 12:16:34,888:INFO:System:
2023-08-15 12:16:34,888:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 12:16:34,888:INFO:executable: c:\Users\Ramon\anaconda3\envs\PycaretEnv\python.exe
2023-08-15 12:16:34,888:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 12:16:34,888:INFO:PyCaret required dependencies:
2023-08-15 12:16:35,278:INFO:                 pip: 23.2.1
2023-08-15 12:16:35,278:INFO:          setuptools: 68.0.0
2023-08-15 12:16:35,278:INFO:             pycaret: 3.0.4
2023-08-15 12:16:35,278:INFO:             IPython: 8.14.0
2023-08-15 12:16:35,278:INFO:          ipywidgets: 8.1.0
2023-08-15 12:16:35,278:INFO:                tqdm: 4.66.1
2023-08-15 12:16:35,278:INFO:               numpy: 1.25.2
2023-08-15 12:16:35,278:INFO:              pandas: 2.0.3
2023-08-15 12:16:35,278:INFO:              jinja2: 3.1.2
2023-08-15 12:16:35,278:INFO:               scipy: 1.11.1
2023-08-15 12:16:35,278:INFO:              joblib: 1.3.2
2023-08-15 12:16:35,278:INFO:             sklearn: 1.3.0
2023-08-15 12:16:35,278:INFO:                pyod: 1.1.0
2023-08-15 12:16:35,278:INFO:            imblearn: 0.11.0
2023-08-15 12:16:35,278:INFO:   category_encoders: 2.6.1
2023-08-15 12:16:35,278:INFO:            lightgbm: 4.0.0
2023-08-15 12:16:35,278:INFO:               numba: 0.57.1
2023-08-15 12:16:35,278:INFO:            requests: 2.31.0
2023-08-15 12:16:35,278:INFO:          matplotlib: 3.7.2
2023-08-15 12:16:35,278:INFO:          scikitplot: 0.3.7
2023-08-15 12:16:35,278:INFO:         yellowbrick: 1.5
2023-08-15 12:16:35,278:INFO:              plotly: 5.16.0
2023-08-15 12:16:35,278:INFO:    plotly-resampler: Not installed
2023-08-15 12:16:35,278:INFO:             kaleido: 0.2.1
2023-08-15 12:16:35,278:INFO:           schemdraw: 0.15
2023-08-15 12:16:35,278:INFO:         statsmodels: 0.14.0
2023-08-15 12:16:35,278:INFO:              sktime: 0.21.0
2023-08-15 12:16:35,278:INFO:               tbats: 1.1.3
2023-08-15 12:16:35,279:INFO:            pmdarima: 2.0.3
2023-08-15 12:16:35,279:INFO:              psutil: 5.9.5
2023-08-15 12:16:35,279:INFO:          markupsafe: 2.1.3
2023-08-15 12:16:35,279:INFO:             pickle5: Not installed
2023-08-15 12:16:35,279:INFO:         cloudpickle: 2.2.1
2023-08-15 12:16:35,279:INFO:         deprecation: 2.1.0
2023-08-15 12:16:35,279:INFO:              xxhash: 3.2.0
2023-08-15 12:16:35,279:INFO:           wurlitzer: Not installed
2023-08-15 12:16:35,279:INFO:PyCaret optional dependencies:
2023-08-15 12:16:35,449:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
  warnings.warn(

2023-08-15 12:16:36,487:INFO:                shap: 0.42.1
2023-08-15 12:16:36,487:INFO:           interpret: 0.4.3
2023-08-15 12:16:36,487:INFO:                umap: 0.5.3
2023-08-15 12:16:36,487:INFO:    pandas_profiling: 4.4.0
2023-08-15 12:16:36,487:INFO:  explainerdashboard: 0.4.3
2023-08-15 12:16:36,487:INFO:             autoviz: 0.1.730
2023-08-15 12:16:36,487:INFO:           fairlearn: 0.7.0
2023-08-15 12:16:36,487:INFO:          deepchecks: 0.17.4
2023-08-15 12:16:36,487:INFO:             xgboost: 1.7.6
2023-08-15 12:16:36,487:INFO:            catboost: 1.2
2023-08-15 12:16:36,487:INFO:              kmodes: 0.12.2
2023-08-15 12:16:36,487:INFO:             mlxtend: 0.22.0
2023-08-15 12:16:36,487:INFO:       statsforecast: 1.5.0
2023-08-15 12:16:36,487:INFO:        tune_sklearn: 0.4.6
2023-08-15 12:16:36,487:INFO:                 ray: 2.6.1
2023-08-15 12:16:36,488:INFO:            hyperopt: 0.2.7
2023-08-15 12:16:36,488:INFO:              optuna: 3.3.0
2023-08-15 12:16:36,488:INFO:               skopt: 0.9.0
2023-08-15 12:16:36,488:INFO:              mlflow: 1.30.1
2023-08-15 12:16:36,488:INFO:              gradio: 3.39.0
2023-08-15 12:16:36,488:INFO:             fastapi: 0.101.0
2023-08-15 12:16:36,488:INFO:             uvicorn: 0.23.2
2023-08-15 12:16:36,488:INFO:              m2cgen: 0.10.0
2023-08-15 12:16:36,488:INFO:           evidently: 0.2.8
2023-08-15 12:16:36,488:INFO:               fugue: 0.8.6
2023-08-15 12:16:36,488:INFO:           streamlit: Not installed
2023-08-15 12:16:36,488:INFO:             prophet: Not installed
2023-08-15 12:16:36,488:INFO:None
2023-08-15 12:16:36,488:INFO:Set up data.
2023-08-15 12:16:36,670:INFO:Set up train/test split.
2023-08-15 12:16:36,830:INFO:Set up index.
2023-08-15 12:16:36,836:INFO:Set up folding strategy.
2023-08-15 12:16:36,836:INFO:Assigning column types.
2023-08-15 12:16:36,869:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 12:16:36,892:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 12:16:36,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 12:16:36,912:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:16:36,928:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:16:36,964:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 12:16:36,965:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 12:16:36,979:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:16:36,980:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:16:36,981:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 12:16:37,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 12:16:37,019:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:16:37,020:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:16:37,044:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 12:16:37,059:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:16:37,060:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:16:37,061:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 12:16:37,099:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:16:37,100:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:16:37,138:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:16:37,139:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:16:37,141:INFO:Preparing preprocessing pipeline...
2023-08-15 12:16:37,146:INFO:Set up label encoding.
2023-08-15 12:16:37,146:INFO:Set up simple imputation.
2023-08-15 12:16:37,185:INFO:Set up encoding of ordinal features.
2023-08-15 12:16:37,260:INFO:Set up encoding of categorical features.
2023-08-15 12:16:37,265:INFO:Set up column name cleaning.
2023-08-15 12:16:37,818:INFO:Finished creating preprocessing pipeline.
2023-08-15 12:16:37,859:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 12:16:37,859:INFO:Creating final display dataframe.
2023-08-15 12:16:38,206:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              94c6
2023-08-15 12:16:38,251:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:16:38,252:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:16:38,292:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:16:38,293:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:16:38,295:INFO:setup() successfully completed in 3.57s...............
2023-08-15 12:16:58,602:INFO:Initializing compare_models()
2023-08-15 12:16:58,602:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-15 12:16:58,603:INFO:Checking exceptions
2023-08-15 12:16:58,636:INFO:Preparing display monitor
2023-08-15 12:16:58,651:INFO:Initializing Logistic Regression
2023-08-15 12:16:58,651:INFO:Total runtime is 0.0 minutes
2023-08-15 12:16:58,653:INFO:SubProcess create_model() called ==================================
2023-08-15 12:16:58,653:INFO:Initializing create_model()
2023-08-15 12:16:58,654:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:16:58,654:INFO:Checking exceptions
2023-08-15 12:16:58,654:INFO:Importing libraries
2023-08-15 12:16:58,654:INFO:Copying training dataset
2023-08-15 12:16:58,717:INFO:Defining folds
2023-08-15 12:16:58,717:INFO:Declaring metric variables
2023-08-15 12:16:58,719:INFO:Importing untrained model
2023-08-15 12:16:58,721:INFO:Logistic Regression Imported successfully
2023-08-15 12:16:58,725:INFO:Starting cross validation
2023-08-15 12:16:58,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:17:58,653:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:58,683:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:58,720:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:58,822:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:58,825:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:58,894:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:58,991:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:59,060:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:59,175:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:17:59,220:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:18:01,138:INFO:Calculating mean and std
2023-08-15 12:18:01,139:INFO:Creating metrics dataframe
2023-08-15 12:18:01,320:INFO:Uploading results into container
2023-08-15 12:18:01,321:INFO:Uploading model into container now
2023-08-15 12:18:01,321:INFO:_master_model_container: 1
2023-08-15 12:18:01,321:INFO:_display_container: 2
2023-08-15 12:18:01,322:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 12:18:01,322:INFO:create_model() successfully completed......................................
2023-08-15 12:18:01,537:INFO:SubProcess create_model() end ==================================
2023-08-15 12:18:01,537:INFO:Creating metrics dataframe
2023-08-15 12:18:01,541:INFO:Initializing K Neighbors Classifier
2023-08-15 12:18:01,542:INFO:Total runtime is 1.048188825448354 minutes
2023-08-15 12:18:01,544:INFO:SubProcess create_model() called ==================================
2023-08-15 12:18:01,544:INFO:Initializing create_model()
2023-08-15 12:18:01,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:18:01,544:INFO:Checking exceptions
2023-08-15 12:18:01,544:INFO:Importing libraries
2023-08-15 12:18:01,544:INFO:Copying training dataset
2023-08-15 12:18:01,598:INFO:Defining folds
2023-08-15 12:18:01,599:INFO:Declaring metric variables
2023-08-15 12:18:01,602:INFO:Importing untrained model
2023-08-15 12:18:01,604:INFO:K Neighbors Classifier Imported successfully
2023-08-15 12:18:01,608:INFO:Starting cross validation
2023-08-15 12:18:01,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:18:07,179:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,224:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,227:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,332:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,337:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,339:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,363:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,378:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,388:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,391:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,426:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,438:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,543:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,567:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,571:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,603:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,626:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,627:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,658:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:07,789:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:09,107:INFO:Calculating mean and std
2023-08-15 12:18:09,108:INFO:Creating metrics dataframe
2023-08-15 12:18:09,289:INFO:Uploading results into container
2023-08-15 12:18:09,289:INFO:Uploading model into container now
2023-08-15 12:18:09,290:INFO:_master_model_container: 2
2023-08-15 12:18:09,290:INFO:_display_container: 2
2023-08-15 12:18:09,290:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-15 12:18:09,290:INFO:create_model() successfully completed......................................
2023-08-15 12:18:09,389:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2023-08-15 12:18:09,390:WARNING:Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2023-08-15 12:18:09,391:INFO:Initializing create_model()
2023-08-15 12:18:09,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:18:09,391:INFO:Checking exceptions
2023-08-15 12:18:09,391:INFO:Importing libraries
2023-08-15 12:18:09,391:INFO:Copying training dataset
2023-08-15 12:18:09,442:INFO:Defining folds
2023-08-15 12:18:09,443:INFO:Declaring metric variables
2023-08-15 12:18:09,446:INFO:Importing untrained model
2023-08-15 12:18:09,449:INFO:K Neighbors Classifier Imported successfully
2023-08-15 12:18:09,454:INFO:Starting cross validation
2023-08-15 12:18:09,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:18:10,615:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,642:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,680:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,728:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,748:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,845:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,852:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,891:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,902:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,914:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,937:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,951:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,965:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,983:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:10,992:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:11,028:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:11,054:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:11,068:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:11,114:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:11,156:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:18:12,566:INFO:Calculating mean and std
2023-08-15 12:18:12,567:INFO:Creating metrics dataframe
2023-08-15 12:18:12,746:INFO:Uploading results into container
2023-08-15 12:18:12,746:INFO:Uploading model into container now
2023-08-15 12:18:12,747:INFO:_master_model_container: 3
2023-08-15 12:18:12,747:INFO:_display_container: 2
2023-08-15 12:18:12,747:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-15 12:18:12,747:INFO:create_model() successfully completed......................................
2023-08-15 12:18:12,853:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2023-08-15 12:18:12,853:ERROR:Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 813, in compare_models
    np.sum(
AssertionError

2023-08-15 12:18:12,853:INFO:Initializing Naive Bayes
2023-08-15 12:18:12,853:INFO:Total runtime is 1.2367152571678162 minutes
2023-08-15 12:18:12,855:INFO:SubProcess create_model() called ==================================
2023-08-15 12:18:12,856:INFO:Initializing create_model()
2023-08-15 12:18:12,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:18:12,856:INFO:Checking exceptions
2023-08-15 12:18:12,856:INFO:Importing libraries
2023-08-15 12:18:12,856:INFO:Copying training dataset
2023-08-15 12:18:12,911:INFO:Defining folds
2023-08-15 12:18:12,911:INFO:Declaring metric variables
2023-08-15 12:18:12,914:INFO:Importing untrained model
2023-08-15 12:18:12,916:INFO:Naive Bayes Imported successfully
2023-08-15 12:18:12,921:INFO:Starting cross validation
2023-08-15 12:18:12,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:18:16,172:INFO:Calculating mean and std
2023-08-15 12:18:16,173:INFO:Creating metrics dataframe
2023-08-15 12:18:16,346:INFO:Uploading results into container
2023-08-15 12:18:16,347:INFO:Uploading model into container now
2023-08-15 12:18:16,347:INFO:_master_model_container: 4
2023-08-15 12:18:16,347:INFO:_display_container: 2
2023-08-15 12:18:16,347:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 12:18:16,348:INFO:create_model() successfully completed......................................
2023-08-15 12:18:16,445:INFO:SubProcess create_model() end ==================================
2023-08-15 12:18:16,445:INFO:Creating metrics dataframe
2023-08-15 12:18:16,450:INFO:Initializing Decision Tree Classifier
2023-08-15 12:18:16,450:INFO:Total runtime is 1.2966562668482462 minutes
2023-08-15 12:18:16,452:INFO:SubProcess create_model() called ==================================
2023-08-15 12:18:16,452:INFO:Initializing create_model()
2023-08-15 12:18:16,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:18:16,453:INFO:Checking exceptions
2023-08-15 12:18:16,453:INFO:Importing libraries
2023-08-15 12:18:16,453:INFO:Copying training dataset
2023-08-15 12:18:16,508:INFO:Defining folds
2023-08-15 12:18:16,509:INFO:Declaring metric variables
2023-08-15 12:18:16,511:INFO:Importing untrained model
2023-08-15 12:18:16,514:INFO:Decision Tree Classifier Imported successfully
2023-08-15 12:18:16,518:INFO:Starting cross validation
2023-08-15 12:18:16,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:18:22,261:INFO:Calculating mean and std
2023-08-15 12:18:22,262:INFO:Creating metrics dataframe
2023-08-15 12:18:22,435:INFO:Uploading results into container
2023-08-15 12:18:22,436:INFO:Uploading model into container now
2023-08-15 12:18:22,436:INFO:_master_model_container: 5
2023-08-15 12:18:22,437:INFO:_display_container: 2
2023-08-15 12:18:22,437:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-15 12:18:22,437:INFO:create_model() successfully completed......................................
2023-08-15 12:18:22,539:INFO:SubProcess create_model() end ==================================
2023-08-15 12:18:22,539:INFO:Creating metrics dataframe
2023-08-15 12:18:22,543:INFO:Initializing SVM - Linear Kernel
2023-08-15 12:18:22,544:INFO:Total runtime is 1.3982280373573304 minutes
2023-08-15 12:18:22,546:INFO:SubProcess create_model() called ==================================
2023-08-15 12:18:22,546:INFO:Initializing create_model()
2023-08-15 12:18:22,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:18:22,546:INFO:Checking exceptions
2023-08-15 12:18:22,546:INFO:Importing libraries
2023-08-15 12:18:22,546:INFO:Copying training dataset
2023-08-15 12:18:22,604:INFO:Defining folds
2023-08-15 12:18:22,604:INFO:Declaring metric variables
2023-08-15 12:18:22,606:INFO:Importing untrained model
2023-08-15 12:18:22,609:INFO:SVM - Linear Kernel Imported successfully
2023-08-15 12:18:22,613:INFO:Starting cross validation
2023-08-15 12:18:22,615:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:18:42,540:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:43,543:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:43,629:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:43,843:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:18:44,036:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:44,829:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:44,862:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:44,967:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:45,005:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:45,565:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:45,868:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:46,311:INFO:Calculating mean and std
2023-08-15 12:18:46,312:INFO:Creating metrics dataframe
2023-08-15 12:18:46,503:INFO:Uploading results into container
2023-08-15 12:18:46,504:INFO:Uploading model into container now
2023-08-15 12:18:46,504:INFO:_master_model_container: 6
2023-08-15 12:18:46,505:INFO:_display_container: 2
2023-08-15 12:18:46,505:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-15 12:18:46,505:INFO:create_model() successfully completed......................................
2023-08-15 12:18:46,603:INFO:SubProcess create_model() end ==================================
2023-08-15 12:18:46,603:INFO:Creating metrics dataframe
2023-08-15 12:18:46,608:INFO:Initializing Ridge Classifier
2023-08-15 12:18:46,608:INFO:Total runtime is 1.7992969075838725 minutes
2023-08-15 12:18:46,610:INFO:SubProcess create_model() called ==================================
2023-08-15 12:18:46,610:INFO:Initializing create_model()
2023-08-15 12:18:46,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:18:46,610:INFO:Checking exceptions
2023-08-15 12:18:46,610:INFO:Importing libraries
2023-08-15 12:18:46,611:INFO:Copying training dataset
2023-08-15 12:18:46,667:INFO:Defining folds
2023-08-15 12:18:46,667:INFO:Declaring metric variables
2023-08-15 12:18:46,670:INFO:Importing untrained model
2023-08-15 12:18:46,672:INFO:Ridge Classifier Imported successfully
2023-08-15 12:18:46,676:INFO:Starting cross validation
2023-08-15 12:18:46,678:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:18:48,391:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,423:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,467:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,473:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,487:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,494:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,501:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,596:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,636:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:48,663:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:18:50,453:INFO:Calculating mean and std
2023-08-15 12:18:50,454:INFO:Creating metrics dataframe
2023-08-15 12:18:50,631:INFO:Uploading results into container
2023-08-15 12:18:50,632:INFO:Uploading model into container now
2023-08-15 12:18:50,632:INFO:_master_model_container: 7
2023-08-15 12:18:50,632:INFO:_display_container: 2
2023-08-15 12:18:50,632:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-15 12:18:50,633:INFO:create_model() successfully completed......................................
2023-08-15 12:18:50,730:INFO:SubProcess create_model() end ==================================
2023-08-15 12:18:50,730:INFO:Creating metrics dataframe
2023-08-15 12:18:50,735:INFO:Initializing Random Forest Classifier
2023-08-15 12:18:50,735:INFO:Total runtime is 1.8680708448092143 minutes
2023-08-15 12:18:50,738:INFO:SubProcess create_model() called ==================================
2023-08-15 12:18:50,738:INFO:Initializing create_model()
2023-08-15 12:18:50,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:18:50,738:INFO:Checking exceptions
2023-08-15 12:18:50,738:INFO:Importing libraries
2023-08-15 12:18:50,738:INFO:Copying training dataset
2023-08-15 12:18:50,794:INFO:Defining folds
2023-08-15 12:18:50,794:INFO:Declaring metric variables
2023-08-15 12:18:50,797:INFO:Importing untrained model
2023-08-15 12:18:50,799:INFO:Random Forest Classifier Imported successfully
2023-08-15 12:18:50,804:INFO:Starting cross validation
2023-08-15 12:18:50,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:19:20,851:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.20s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:19:21,373:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.39s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:19:24,943:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 12:19:26,741:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.26s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:19:27,112:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.15s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:19:31,432:INFO:Calculating mean and std
2023-08-15 12:19:31,432:INFO:Creating metrics dataframe
2023-08-15 12:19:31,642:INFO:Uploading results into container
2023-08-15 12:19:31,642:INFO:Uploading model into container now
2023-08-15 12:19:31,643:INFO:_master_model_container: 8
2023-08-15 12:19:31,643:INFO:_display_container: 2
2023-08-15 12:19:31,643:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-15 12:19:31,643:INFO:create_model() successfully completed......................................
2023-08-15 12:19:31,741:INFO:SubProcess create_model() end ==================================
2023-08-15 12:19:31,741:INFO:Creating metrics dataframe
2023-08-15 12:19:31,747:INFO:Initializing Quadratic Discriminant Analysis
2023-08-15 12:19:31,747:INFO:Total runtime is 2.5516142010688783 minutes
2023-08-15 12:19:31,749:INFO:SubProcess create_model() called ==================================
2023-08-15 12:19:31,749:INFO:Initializing create_model()
2023-08-15 12:19:31,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:19:31,749:INFO:Checking exceptions
2023-08-15 12:19:31,749:INFO:Importing libraries
2023-08-15 12:19:31,749:INFO:Copying training dataset
2023-08-15 12:19:31,807:INFO:Defining folds
2023-08-15 12:19:31,807:INFO:Declaring metric variables
2023-08-15 12:19:31,810:INFO:Importing untrained model
2023-08-15 12:19:31,813:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 12:19:31,817:INFO:Starting cross validation
2023-08-15 12:19:31,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:19:35,203:INFO:Calculating mean and std
2023-08-15 12:19:35,204:INFO:Creating metrics dataframe
2023-08-15 12:19:35,395:INFO:Uploading results into container
2023-08-15 12:19:35,395:INFO:Uploading model into container now
2023-08-15 12:19:35,396:INFO:_master_model_container: 9
2023-08-15 12:19:35,396:INFO:_display_container: 2
2023-08-15 12:19:35,396:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 12:19:35,396:INFO:create_model() successfully completed......................................
2023-08-15 12:19:35,495:INFO:SubProcess create_model() end ==================================
2023-08-15 12:19:35,495:INFO:Creating metrics dataframe
2023-08-15 12:19:35,501:INFO:Initializing Ada Boost Classifier
2023-08-15 12:19:35,501:INFO:Total runtime is 2.6141831318537396 minutes
2023-08-15 12:19:35,503:INFO:SubProcess create_model() called ==================================
2023-08-15 12:19:35,503:INFO:Initializing create_model()
2023-08-15 12:19:35,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:19:35,503:INFO:Checking exceptions
2023-08-15 12:19:35,503:INFO:Importing libraries
2023-08-15 12:19:35,503:INFO:Copying training dataset
2023-08-15 12:19:35,560:INFO:Defining folds
2023-08-15 12:19:35,560:INFO:Declaring metric variables
2023-08-15 12:19:35,563:INFO:Importing untrained model
2023-08-15 12:19:35,566:INFO:Ada Boost Classifier Imported successfully
2023-08-15 12:19:35,570:INFO:Starting cross validation
2023-08-15 12:19:35,572:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:19:54,330:INFO:Calculating mean and std
2023-08-15 12:19:54,331:INFO:Creating metrics dataframe
2023-08-15 12:19:54,526:INFO:Uploading results into container
2023-08-15 12:19:54,526:INFO:Uploading model into container now
2023-08-15 12:19:54,527:INFO:_master_model_container: 10
2023-08-15 12:19:54,527:INFO:_display_container: 2
2023-08-15 12:19:54,527:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-15 12:19:54,527:INFO:create_model() successfully completed......................................
2023-08-15 12:19:54,625:INFO:SubProcess create_model() end ==================================
2023-08-15 12:19:54,626:INFO:Creating metrics dataframe
2023-08-15 12:19:54,631:INFO:Initializing Gradient Boosting Classifier
2023-08-15 12:19:54,632:INFO:Total runtime is 2.93301827510198 minutes
2023-08-15 12:19:54,634:INFO:SubProcess create_model() called ==================================
2023-08-15 12:19:54,634:INFO:Initializing create_model()
2023-08-15 12:19:54,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:19:54,634:INFO:Checking exceptions
2023-08-15 12:19:54,634:INFO:Importing libraries
2023-08-15 12:19:54,634:INFO:Copying training dataset
2023-08-15 12:19:54,689:INFO:Defining folds
2023-08-15 12:19:54,689:INFO:Declaring metric variables
2023-08-15 12:19:54,691:INFO:Importing untrained model
2023-08-15 12:19:54,694:INFO:Gradient Boosting Classifier Imported successfully
2023-08-15 12:19:54,698:INFO:Starting cross validation
2023-08-15 12:19:54,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:20:45,159:INFO:Calculating mean and std
2023-08-15 12:20:45,160:INFO:Creating metrics dataframe
2023-08-15 12:20:45,367:INFO:Uploading results into container
2023-08-15 12:20:45,369:INFO:Uploading model into container now
2023-08-15 12:20:45,369:INFO:_master_model_container: 11
2023-08-15 12:20:45,369:INFO:_display_container: 2
2023-08-15 12:20:45,370:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-15 12:20:45,370:INFO:create_model() successfully completed......................................
2023-08-15 12:20:45,482:INFO:SubProcess create_model() end ==================================
2023-08-15 12:20:45,483:INFO:Creating metrics dataframe
2023-08-15 12:20:45,489:INFO:Initializing Linear Discriminant Analysis
2023-08-15 12:20:45,489:INFO:Total runtime is 3.7806442419687913 minutes
2023-08-15 12:20:45,491:INFO:SubProcess create_model() called ==================================
2023-08-15 12:20:45,492:INFO:Initializing create_model()
2023-08-15 12:20:45,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:20:45,492:INFO:Checking exceptions
2023-08-15 12:20:45,492:INFO:Importing libraries
2023-08-15 12:20:45,492:INFO:Copying training dataset
2023-08-15 12:20:45,551:INFO:Defining folds
2023-08-15 12:20:45,551:INFO:Declaring metric variables
2023-08-15 12:20:45,554:INFO:Importing untrained model
2023-08-15 12:20:45,556:INFO:Linear Discriminant Analysis Imported successfully
2023-08-15 12:20:45,560:INFO:Starting cross validation
2023-08-15 12:20:45,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:20:51,837:INFO:Calculating mean and std
2023-08-15 12:20:51,837:INFO:Creating metrics dataframe
2023-08-15 12:20:52,035:INFO:Uploading results into container
2023-08-15 12:20:52,036:INFO:Uploading model into container now
2023-08-15 12:20:52,036:INFO:_master_model_container: 12
2023-08-15 12:20:52,036:INFO:_display_container: 2
2023-08-15 12:20:52,037:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-15 12:20:52,037:INFO:create_model() successfully completed......................................
2023-08-15 12:20:52,139:INFO:SubProcess create_model() end ==================================
2023-08-15 12:20:52,139:INFO:Creating metrics dataframe
2023-08-15 12:20:52,146:INFO:Initializing Extra Trees Classifier
2023-08-15 12:20:52,146:INFO:Total runtime is 3.8915875355402636 minutes
2023-08-15 12:20:52,148:INFO:SubProcess create_model() called ==================================
2023-08-15 12:20:52,148:INFO:Initializing create_model()
2023-08-15 12:20:52,148:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:20:52,148:INFO:Checking exceptions
2023-08-15 12:20:52,148:INFO:Importing libraries
2023-08-15 12:20:52,149:INFO:Copying training dataset
2023-08-15 12:20:52,205:INFO:Defining folds
2023-08-15 12:20:52,205:INFO:Declaring metric variables
2023-08-15 12:20:52,208:INFO:Importing untrained model
2023-08-15 12:20:52,210:INFO:Extra Trees Classifier Imported successfully
2023-08-15 12:20:52,214:INFO:Starting cross validation
2023-08-15 12:20:52,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:21:11,111:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 12:21:15,816:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.41s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:21:33,501:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:21:34,798:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:21:34,932:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:21:35,244:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:21:35,715:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:21:36,570:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:21:37,602:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:21:38,912:INFO:Calculating mean and std
2023-08-15 12:21:38,913:INFO:Creating metrics dataframe
2023-08-15 12:21:39,011:INFO:Uploading results into container
2023-08-15 12:21:39,012:INFO:Uploading model into container now
2023-08-15 12:21:39,012:INFO:_master_model_container: 13
2023-08-15 12:21:39,013:INFO:_display_container: 2
2023-08-15 12:21:39,013:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-15 12:21:39,013:INFO:create_model() successfully completed......................................
2023-08-15 12:21:39,123:INFO:SubProcess create_model() end ==================================
2023-08-15 12:21:39,123:INFO:Creating metrics dataframe
2023-08-15 12:21:39,129:INFO:Initializing Extreme Gradient Boosting
2023-08-15 12:21:39,130:INFO:Total runtime is 4.674656244119009 minutes
2023-08-15 12:21:39,131:INFO:SubProcess create_model() called ==================================
2023-08-15 12:21:39,131:INFO:Initializing create_model()
2023-08-15 12:21:39,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:21:39,132:INFO:Checking exceptions
2023-08-15 12:21:39,132:INFO:Importing libraries
2023-08-15 12:21:39,132:INFO:Copying training dataset
2023-08-15 12:21:39,192:INFO:Defining folds
2023-08-15 12:21:39,192:INFO:Declaring metric variables
2023-08-15 12:21:39,194:INFO:Importing untrained model
2023-08-15 12:21:39,198:INFO:Extreme Gradient Boosting Imported successfully
2023-08-15 12:21:39,202:INFO:Starting cross validation
2023-08-15 12:21:39,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:22:07,405:INFO:Calculating mean and std
2023-08-15 12:22:07,406:INFO:Creating metrics dataframe
2023-08-15 12:22:07,501:INFO:Uploading results into container
2023-08-15 12:22:07,502:INFO:Uploading model into container now
2023-08-15 12:22:07,502:INFO:_master_model_container: 14
2023-08-15 12:22:07,502:INFO:_display_container: 2
2023-08-15 12:22:07,502:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-15 12:22:07,502:INFO:create_model() successfully completed......................................
2023-08-15 12:22:07,606:INFO:SubProcess create_model() end ==================================
2023-08-15 12:22:07,606:INFO:Creating metrics dataframe
2023-08-15 12:22:07,613:INFO:Initializing Light Gradient Boosting Machine
2023-08-15 12:22:07,613:INFO:Total runtime is 5.149379511674246 minutes
2023-08-15 12:22:07,615:INFO:SubProcess create_model() called ==================================
2023-08-15 12:22:07,616:INFO:Initializing create_model()
2023-08-15 12:22:07,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:22:07,616:INFO:Checking exceptions
2023-08-15 12:22:07,616:INFO:Importing libraries
2023-08-15 12:22:07,616:INFO:Copying training dataset
2023-08-15 12:22:07,673:INFO:Defining folds
2023-08-15 12:22:07,673:INFO:Declaring metric variables
2023-08-15 12:22:07,676:INFO:Importing untrained model
2023-08-15 12:22:07,678:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 12:22:07,682:INFO:Starting cross validation
2023-08-15 12:22:07,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:22:13,976:INFO:Calculating mean and std
2023-08-15 12:22:13,977:INFO:Creating metrics dataframe
2023-08-15 12:22:14,073:INFO:Uploading results into container
2023-08-15 12:22:14,073:INFO:Uploading model into container now
2023-08-15 12:22:14,074:INFO:_master_model_container: 15
2023-08-15 12:22:14,074:INFO:_display_container: 2
2023-08-15 12:22:14,074:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:22:14,074:INFO:create_model() successfully completed......................................
2023-08-15 12:22:14,172:INFO:SubProcess create_model() end ==================================
2023-08-15 12:22:14,173:INFO:Creating metrics dataframe
2023-08-15 12:22:14,179:INFO:Initializing CatBoost Classifier
2023-08-15 12:22:14,179:INFO:Total runtime is 5.258803335825603 minutes
2023-08-15 12:22:14,181:INFO:SubProcess create_model() called ==================================
2023-08-15 12:22:14,181:INFO:Initializing create_model()
2023-08-15 12:22:14,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:22:14,182:INFO:Checking exceptions
2023-08-15 12:22:14,182:INFO:Importing libraries
2023-08-15 12:22:14,182:INFO:Copying training dataset
2023-08-15 12:22:14,238:INFO:Defining folds
2023-08-15 12:22:14,239:INFO:Declaring metric variables
2023-08-15 12:22:14,241:INFO:Importing untrained model
2023-08-15 12:22:14,244:INFO:CatBoost Classifier Imported successfully
2023-08-15 12:22:14,248:INFO:Starting cross validation
2023-08-15 12:22:14,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:23:50,484:INFO:Calculating mean and std
2023-08-15 12:23:50,485:INFO:Creating metrics dataframe
2023-08-15 12:23:50,584:INFO:Uploading results into container
2023-08-15 12:23:50,585:INFO:Uploading model into container now
2023-08-15 12:23:50,585:INFO:_master_model_container: 16
2023-08-15 12:23:50,585:INFO:_display_container: 2
2023-08-15 12:23:50,585:INFO:<catboost.core.CatBoostClassifier object at 0x000002A78EEB91E0>
2023-08-15 12:23:50,585:INFO:create_model() successfully completed......................................
2023-08-15 12:23:50,696:INFO:SubProcess create_model() end ==================================
2023-08-15 12:23:50,696:INFO:Creating metrics dataframe
2023-08-15 12:23:50,703:INFO:Initializing Dummy Classifier
2023-08-15 12:23:50,703:INFO:Total runtime is 6.867540391286215 minutes
2023-08-15 12:23:50,705:INFO:SubProcess create_model() called ==================================
2023-08-15 12:23:50,706:INFO:Initializing create_model()
2023-08-15 12:23:50,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8D4A4D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:23:50,706:INFO:Checking exceptions
2023-08-15 12:23:50,706:INFO:Importing libraries
2023-08-15 12:23:50,706:INFO:Copying training dataset
2023-08-15 12:23:50,767:INFO:Defining folds
2023-08-15 12:23:50,767:INFO:Declaring metric variables
2023-08-15 12:23:50,770:INFO:Importing untrained model
2023-08-15 12:23:50,772:INFO:Dummy Classifier Imported successfully
2023-08-15 12:23:50,776:INFO:Starting cross validation
2023-08-15 12:23:50,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:23:52,350:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,441:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,450:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,498:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,512:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,557:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,594:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,622:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,629:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:52,651:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:23:53,657:INFO:Calculating mean and std
2023-08-15 12:23:53,662:INFO:Creating metrics dataframe
2023-08-15 12:23:53,770:INFO:Uploading results into container
2023-08-15 12:23:53,771:INFO:Uploading model into container now
2023-08-15 12:23:53,771:INFO:_master_model_container: 17
2023-08-15 12:23:53,771:INFO:_display_container: 2
2023-08-15 12:23:53,771:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-15 12:23:53,771:INFO:create_model() successfully completed......................................
2023-08-15 12:23:53,871:INFO:SubProcess create_model() end ==================================
2023-08-15 12:23:53,872:INFO:Creating metrics dataframe
2023-08-15 12:23:53,884:INFO:Initializing create_model()
2023-08-15 12:23:53,884:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:23:53,884:INFO:Checking exceptions
2023-08-15 12:23:53,886:INFO:Importing libraries
2023-08-15 12:23:53,886:INFO:Copying training dataset
2023-08-15 12:23:53,942:INFO:Defining folds
2023-08-15 12:23:53,942:INFO:Declaring metric variables
2023-08-15 12:23:53,942:INFO:Importing untrained model
2023-08-15 12:23:53,942:INFO:Declaring custom model
2023-08-15 12:23:53,943:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 12:23:53,944:INFO:Cross validation set to False
2023-08-15 12:23:53,944:INFO:Fitting Model
2023-08-15 12:23:56,716:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 12:23:56,716:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 12:23:56,736:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006553 seconds.
2023-08-15 12:23:56,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 12:23:56,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 12:23:56,736:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 12:23:56,736:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-15 12:23:56,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 12:23:56,737:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 12:23:57,148:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:23:57,149:INFO:create_model() successfully completed......................................
2023-08-15 12:23:57,267:INFO:_master_model_container: 17
2023-08-15 12:23:57,267:INFO:_display_container: 2
2023-08-15 12:23:57,268:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:23:57,268:INFO:compare_models() successfully completed......................................
2023-08-15 12:23:57,322:INFO:Initializing create_model()
2023-08-15 12:23:57,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:23:57,322:INFO:Checking exceptions
2023-08-15 12:23:57,332:INFO:Importing libraries
2023-08-15 12:23:57,332:INFO:Copying training dataset
2023-08-15 12:23:57,387:INFO:Defining folds
2023-08-15 12:23:57,387:INFO:Declaring metric variables
2023-08-15 12:23:57,390:INFO:Importing untrained model
2023-08-15 12:23:57,392:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 12:23:57,396:INFO:Starting cross validation
2023-08-15 12:23:57,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:24:00,392:INFO:Calculating mean and std
2023-08-15 12:24:00,393:INFO:Creating metrics dataframe
2023-08-15 12:24:00,397:INFO:Finalizing model
2023-08-15 12:24:02,417:INFO:Uploading results into container
2023-08-15 12:24:02,418:INFO:Uploading model into container now
2023-08-15 12:24:02,425:INFO:_master_model_container: 18
2023-08-15 12:24:02,425:INFO:_display_container: 3
2023-08-15 12:24:02,425:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:24:02,425:INFO:create_model() successfully completed......................................
2023-08-15 12:24:02,585:INFO:Initializing tune_model()
2023-08-15 12:24:02,586:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>)
2023-08-15 12:24:02,586:INFO:Checking exceptions
2023-08-15 12:24:02,616:INFO:Copying training dataset
2023-08-15 12:24:02,652:INFO:Checking base model
2023-08-15 12:24:02,652:INFO:Base model : Light Gradient Boosting Machine
2023-08-15 12:24:02,654:INFO:Declaring metric variables
2023-08-15 12:24:02,656:INFO:Defining Hyperparameters
2023-08-15 12:24:02,759:INFO:Tuning with n_jobs=-1
2023-08-15 12:24:02,759:INFO:Initializing RandomizedSearchCV
2023-08-15 12:25:16,356:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-08-15 12:25:16,356:INFO:Hyperparameter search completed
2023-08-15 12:25:16,356:INFO:SubProcess create_model() called ==================================
2023-08-15 12:25:16,357:INFO:Initializing create_model()
2023-08-15 12:25:16,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7E9B53F70>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-08-15 12:25:16,357:INFO:Checking exceptions
2023-08-15 12:25:16,357:INFO:Importing libraries
2023-08-15 12:25:16,357:INFO:Copying training dataset
2023-08-15 12:25:16,413:INFO:Defining folds
2023-08-15 12:25:16,413:INFO:Declaring metric variables
2023-08-15 12:25:16,415:INFO:Importing untrained model
2023-08-15 12:25:16,415:INFO:Declaring custom model
2023-08-15 12:25:16,418:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 12:25:16,422:INFO:Starting cross validation
2023-08-15 12:25:16,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:25:19,926:INFO:Calculating mean and std
2023-08-15 12:25:19,927:INFO:Creating metrics dataframe
2023-08-15 12:25:19,931:INFO:Finalizing model
2023-08-15 12:25:20,499:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-15 12:25:20,499:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-15 12:25:20,499:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-15 12:25:20,579:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 12:25:20,579:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-15 12:25:20,579:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-15 12:25:20,579:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-15 12:25:20,579:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 12:25:20,599:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006136 seconds.
2023-08-15 12:25:20,599:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 12:25:20,599:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 12:25:20,599:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 12:25:20,599:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-15 12:25:20,602:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 12:25:20,602:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 12:25:21,191:INFO:Uploading results into container
2023-08-15 12:25:21,192:INFO:Uploading model into container now
2023-08-15 12:25:21,192:INFO:_master_model_container: 19
2023-08-15 12:25:21,192:INFO:_display_container: 4
2023-08-15 12:25:21,193:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:25:21,193:INFO:create_model() successfully completed......................................
2023-08-15 12:25:21,305:INFO:SubProcess create_model() end ==================================
2023-08-15 12:25:21,305:INFO:choose_better activated
2023-08-15 12:25:21,307:INFO:SubProcess create_model() called ==================================
2023-08-15 12:25:21,307:INFO:Initializing create_model()
2023-08-15 12:25:21,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:25:21,308:INFO:Checking exceptions
2023-08-15 12:25:21,309:INFO:Importing libraries
2023-08-15 12:25:21,309:INFO:Copying training dataset
2023-08-15 12:25:21,359:INFO:Defining folds
2023-08-15 12:25:21,360:INFO:Declaring metric variables
2023-08-15 12:25:21,360:INFO:Importing untrained model
2023-08-15 12:25:21,360:INFO:Declaring custom model
2023-08-15 12:25:21,360:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 12:25:21,360:INFO:Starting cross validation
2023-08-15 12:25:21,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:25:24,301:INFO:Calculating mean and std
2023-08-15 12:25:24,301:INFO:Creating metrics dataframe
2023-08-15 12:25:24,303:INFO:Finalizing model
2023-08-15 12:25:24,964:INFO:Uploading results into container
2023-08-15 12:25:24,964:INFO:Uploading model into container now
2023-08-15 12:25:24,965:INFO:_master_model_container: 20
2023-08-15 12:25:24,965:INFO:_display_container: 5
2023-08-15 12:25:24,965:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:25:24,965:INFO:create_model() successfully completed......................................
2023-08-15 12:25:25,064:INFO:SubProcess create_model() end ==================================
2023-08-15 12:25:25,065:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9194
2023-08-15 12:25:25,065:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9193
2023-08-15 12:25:25,066:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-15 12:25:25,066:INFO:choose_better completed
2023-08-15 12:25:25,066:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-15 12:25:25,072:INFO:_master_model_container: 20
2023-08-15 12:25:25,072:INFO:_display_container: 4
2023-08-15 12:25:25,072:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:25:25,072:INFO:tune_model() successfully completed......................................
2023-08-15 12:25:25,311:INFO:Initializing create_model()
2023-08-15 12:25:25,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:25:25,311:INFO:Checking exceptions
2023-08-15 12:25:25,321:INFO:Importing libraries
2023-08-15 12:25:25,321:INFO:Copying training dataset
2023-08-15 12:25:25,381:INFO:Defining folds
2023-08-15 12:25:25,381:INFO:Declaring metric variables
2023-08-15 12:25:25,383:INFO:Importing untrained model
2023-08-15 12:25:25,385:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 12:25:25,389:INFO:Starting cross validation
2023-08-15 12:25:25,390:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:25:28,454:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,537:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,572:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,622:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,698:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,806:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,814:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,877:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,949:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:28,957:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:30,833:INFO:Calculating mean and std
2023-08-15 12:25:30,834:INFO:Creating metrics dataframe
2023-08-15 12:25:30,837:INFO:Finalizing model
2023-08-15 12:25:31,587:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:31,752:INFO:Uploading results into container
2023-08-15 12:25:31,752:INFO:Uploading model into container now
2023-08-15 12:25:31,759:INFO:_master_model_container: 21
2023-08-15 12:25:31,759:INFO:_display_container: 5
2023-08-15 12:25:31,760:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 12:25:31,760:INFO:create_model() successfully completed......................................
2023-08-15 12:25:31,891:INFO:Initializing tune_model()
2023-08-15 12:25:31,892:INFO:tune_model(estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>)
2023-08-15 12:25:31,892:INFO:Checking exceptions
2023-08-15 12:25:31,921:INFO:Copying training dataset
2023-08-15 12:25:31,952:INFO:Checking base model
2023-08-15 12:25:31,952:INFO:Base model : Quadratic Discriminant Analysis
2023-08-15 12:25:31,955:INFO:Declaring metric variables
2023-08-15 12:25:31,956:INFO:Defining Hyperparameters
2023-08-15 12:25:32,061:INFO:Tuning with n_jobs=-1
2023-08-15 12:25:32,061:INFO:Initializing RandomizedSearchCV
2023-08-15 12:25:36,761:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:36,963:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:37,577:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:37,817:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,060:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,159:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,191:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,281:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,331:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,603:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,777:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,836:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,890:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,921:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:38,926:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:39,157:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:39,169:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:39,498:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:39,570:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:39,594:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:43,750:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:43,820:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:45,104:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:45,371:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:45,556:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:45,596:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:45,819:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:45,884:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:45,888:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,160:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,264:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,368:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,418:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,735:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,787:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,932:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,932:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,942:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:46,943:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:47,055:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:50,444:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:50,717:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:52,551:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:52,737:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:52,825:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:52,892:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:52,969:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:53,471:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:53,487:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:53,615:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:53,887:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:53,923:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:54,066:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:54,145:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:54,256:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:54,292:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:54,462:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:54,489:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:54,682:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:54,948:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:57,237:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:57,386:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:59,313:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:59,374:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:59,486:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:59,945:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:25:59,949:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:00,019:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:00,063:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:00,295:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:00,348:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:00,758:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:00,870:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:01,194:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:01,342:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:02,046:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:02,174:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:02,523:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:02,841:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:03,325:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:03,674:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:04,015:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:04,894:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:04,969:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:05,186:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:05,717:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:05,992:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:06,340:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:06,826:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:07,142:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:07,519:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:07,942:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:08,238:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:08,460:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:08,771:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:08,993:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:09,184:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:09,339:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:09,421:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:09,571:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:13,792:INFO:best_params: {'actual_estimator__reg_param': 0.47}
2023-08-15 12:26:13,793:INFO:Hyperparameter search completed
2023-08-15 12:26:13,793:INFO:SubProcess create_model() called ==================================
2023-08-15 12:26:13,793:INFO:Initializing create_model()
2023-08-15 12:26:13,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7DBE77010>, model_only=True, return_train_score=False, kwargs={'reg_param': 0.47})
2023-08-15 12:26:13,794:INFO:Checking exceptions
2023-08-15 12:26:13,794:INFO:Importing libraries
2023-08-15 12:26:13,794:INFO:Copying training dataset
2023-08-15 12:26:13,841:INFO:Defining folds
2023-08-15 12:26:13,841:INFO:Declaring metric variables
2023-08-15 12:26:13,843:INFO:Importing untrained model
2023-08-15 12:26:13,843:INFO:Declaring custom model
2023-08-15 12:26:13,845:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 12:26:13,849:INFO:Starting cross validation
2023-08-15 12:26:13,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:26:17,085:INFO:Calculating mean and std
2023-08-15 12:26:17,086:INFO:Creating metrics dataframe
2023-08-15 12:26:17,090:INFO:Finalizing model
2023-08-15 12:26:17,807:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:26:17,989:INFO:Uploading results into container
2023-08-15 12:26:17,990:INFO:Uploading model into container now
2023-08-15 12:26:17,991:INFO:_master_model_container: 22
2023-08-15 12:26:17,991:INFO:_display_container: 6
2023-08-15 12:26:17,991:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001)
2023-08-15 12:26:17,991:INFO:create_model() successfully completed......................................
2023-08-15 12:26:18,091:INFO:SubProcess create_model() end ==================================
2023-08-15 12:26:18,091:INFO:choose_better activated
2023-08-15 12:26:18,093:INFO:SubProcess create_model() called ==================================
2023-08-15 12:26:18,093:INFO:Initializing create_model()
2023-08-15 12:26:18,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:26:18,093:INFO:Checking exceptions
2023-08-15 12:26:18,095:INFO:Importing libraries
2023-08-15 12:26:18,095:INFO:Copying training dataset
2023-08-15 12:26:18,141:INFO:Defining folds
2023-08-15 12:26:18,141:INFO:Declaring metric variables
2023-08-15 12:26:18,141:INFO:Importing untrained model
2023-08-15 12:26:18,141:INFO:Declaring custom model
2023-08-15 12:26:18,141:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 12:26:18,141:INFO:Starting cross validation
2023-08-15 12:26:18,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:26:21,092:INFO:Calculating mean and std
2023-08-15 12:26:21,092:INFO:Creating metrics dataframe
2023-08-15 12:26:21,094:INFO:Finalizing model
2023-08-15 12:26:21,751:INFO:Uploading results into container
2023-08-15 12:26:21,751:INFO:Uploading model into container now
2023-08-15 12:26:21,752:INFO:_master_model_container: 23
2023-08-15 12:26:21,752:INFO:_display_container: 7
2023-08-15 12:26:21,752:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 12:26:21,752:INFO:create_model() successfully completed......................................
2023-08-15 12:26:21,852:INFO:SubProcess create_model() end ==================================
2023-08-15 12:26:21,852:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Accuracy is 0.5545
2023-08-15 12:26:21,852:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001) result for Accuracy is 0.9175
2023-08-15 12:26:21,853:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001) is best model
2023-08-15 12:26:21,853:INFO:choose_better completed
2023-08-15 12:26:21,858:INFO:_master_model_container: 23
2023-08-15 12:26:21,859:INFO:_display_container: 6
2023-08-15 12:26:21,859:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001)
2023-08-15 12:26:21,859:INFO:tune_model() successfully completed......................................
2023-08-15 12:26:22,100:INFO:Initializing create_model()
2023-08-15 12:26:22,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:26:22,100:INFO:Checking exceptions
2023-08-15 12:26:22,111:INFO:Importing libraries
2023-08-15 12:26:22,111:INFO:Copying training dataset
2023-08-15 12:26:22,169:INFO:Defining folds
2023-08-15 12:26:22,169:INFO:Declaring metric variables
2023-08-15 12:26:22,172:INFO:Importing untrained model
2023-08-15 12:26:22,174:INFO:Naive Bayes Imported successfully
2023-08-15 12:26:22,178:INFO:Starting cross validation
2023-08-15 12:26:22,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:26:25,918:INFO:Calculating mean and std
2023-08-15 12:26:25,919:INFO:Creating metrics dataframe
2023-08-15 12:26:25,923:INFO:Finalizing model
2023-08-15 12:26:26,705:INFO:Uploading results into container
2023-08-15 12:26:26,705:INFO:Uploading model into container now
2023-08-15 12:26:26,712:INFO:_master_model_container: 24
2023-08-15 12:26:26,712:INFO:_display_container: 7
2023-08-15 12:26:26,712:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 12:26:26,712:INFO:create_model() successfully completed......................................
2023-08-15 12:26:26,831:INFO:Initializing tune_model()
2023-08-15 12:26:26,831:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>)
2023-08-15 12:26:26,831:INFO:Checking exceptions
2023-08-15 12:26:26,861:INFO:Copying training dataset
2023-08-15 12:26:26,897:INFO:Checking base model
2023-08-15 12:26:26,897:INFO:Base model : Naive Bayes
2023-08-15 12:26:26,899:INFO:Declaring metric variables
2023-08-15 12:26:26,901:INFO:Defining Hyperparameters
2023-08-15 12:26:27,004:INFO:Tuning with n_jobs=-1
2023-08-15 12:26:27,004:INFO:Initializing RandomizedSearchCV
2023-08-15 12:26:52,755:INFO:best_params: {'actual_estimator__var_smoothing': 1}
2023-08-15 12:26:52,755:INFO:Hyperparameter search completed
2023-08-15 12:26:52,755:INFO:SubProcess create_model() called ==================================
2023-08-15 12:26:52,756:INFO:Initializing create_model()
2023-08-15 12:26:52,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7DBE77010>, model_only=True, return_train_score=False, kwargs={'var_smoothing': 1})
2023-08-15 12:26:52,756:INFO:Checking exceptions
2023-08-15 12:26:52,756:INFO:Importing libraries
2023-08-15 12:26:52,756:INFO:Copying training dataset
2023-08-15 12:26:52,804:INFO:Defining folds
2023-08-15 12:26:52,804:INFO:Declaring metric variables
2023-08-15 12:26:52,806:INFO:Importing untrained model
2023-08-15 12:26:52,806:INFO:Declaring custom model
2023-08-15 12:26:52,808:INFO:Naive Bayes Imported successfully
2023-08-15 12:26:52,812:INFO:Starting cross validation
2023-08-15 12:26:52,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:26:54,434:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,525:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,562:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,603:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,624:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,625:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,695:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,700:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,754:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:54,911:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:26:56,200:INFO:Calculating mean and std
2023-08-15 12:26:56,200:INFO:Creating metrics dataframe
2023-08-15 12:26:56,205:INFO:Finalizing model
2023-08-15 12:26:56,963:INFO:Uploading results into container
2023-08-15 12:26:56,964:INFO:Uploading model into container now
2023-08-15 12:26:56,964:INFO:_master_model_container: 25
2023-08-15 12:26:56,964:INFO:_display_container: 8
2023-08-15 12:26:56,964:INFO:GaussianNB(priors=None, var_smoothing=1)
2023-08-15 12:26:56,964:INFO:create_model() successfully completed......................................
2023-08-15 12:26:57,066:INFO:SubProcess create_model() end ==================================
2023-08-15 12:26:57,066:INFO:choose_better activated
2023-08-15 12:26:57,068:INFO:SubProcess create_model() called ==================================
2023-08-15 12:26:57,068:INFO:Initializing create_model()
2023-08-15 12:26:57,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:26:57,068:INFO:Checking exceptions
2023-08-15 12:26:57,070:INFO:Importing libraries
2023-08-15 12:26:57,070:INFO:Copying training dataset
2023-08-15 12:26:57,114:INFO:Defining folds
2023-08-15 12:26:57,114:INFO:Declaring metric variables
2023-08-15 12:26:57,115:INFO:Importing untrained model
2023-08-15 12:26:57,115:INFO:Declaring custom model
2023-08-15 12:26:57,115:INFO:Naive Bayes Imported successfully
2023-08-15 12:26:57,115:INFO:Starting cross validation
2023-08-15 12:26:57,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:27:00,192:INFO:Calculating mean and std
2023-08-15 12:27:00,192:INFO:Creating metrics dataframe
2023-08-15 12:27:00,194:INFO:Finalizing model
2023-08-15 12:27:00,955:INFO:Uploading results into container
2023-08-15 12:27:00,955:INFO:Uploading model into container now
2023-08-15 12:27:00,956:INFO:_master_model_container: 26
2023-08-15 12:27:00,956:INFO:_display_container: 9
2023-08-15 12:27:00,956:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 12:27:00,956:INFO:create_model() successfully completed......................................
2023-08-15 12:27:01,060:INFO:SubProcess create_model() end ==================================
2023-08-15 12:27:01,060:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Accuracy is 0.6227
2023-08-15 12:27:01,060:INFO:GaussianNB(priors=None, var_smoothing=1) result for Accuracy is 0.919
2023-08-15 12:27:01,060:INFO:GaussianNB(priors=None, var_smoothing=1) is best model
2023-08-15 12:27:01,060:INFO:choose_better completed
2023-08-15 12:27:01,066:INFO:_master_model_container: 26
2023-08-15 12:27:01,067:INFO:_display_container: 8
2023-08-15 12:27:01,067:INFO:GaussianNB(priors=None, var_smoothing=1)
2023-08-15 12:27:01,067:INFO:tune_model() successfully completed......................................
2023-08-15 12:27:01,346:INFO:Initializing evaluate_model()
2023-08-15 12:27:01,346:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 12:27:01,374:INFO:Initializing plot_model()
2023-08-15 12:27:01,374:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, system=True)
2023-08-15 12:27:01,375:INFO:Checking exceptions
2023-08-15 12:27:01,393:INFO:Preloading libraries
2023-08-15 12:27:01,397:INFO:Copying training dataset
2023-08-15 12:27:01,397:INFO:Plot type: pipeline
2023-08-15 12:27:01,538:INFO:Visual Rendered Successfully
2023-08-15 12:27:01,642:INFO:plot_model() successfully completed......................................
2023-08-15 12:27:01,687:INFO:Initializing evaluate_model()
2023-08-15 12:27:01,687:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 12:27:01,723:INFO:Initializing plot_model()
2023-08-15 12:27:01,724:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, system=True)
2023-08-15 12:27:01,724:INFO:Checking exceptions
2023-08-15 12:27:01,744:INFO:Preloading libraries
2023-08-15 12:27:01,744:INFO:Copying training dataset
2023-08-15 12:27:01,744:INFO:Plot type: pipeline
2023-08-15 12:27:01,839:INFO:Visual Rendered Successfully
2023-08-15 12:27:01,944:INFO:plot_model() successfully completed......................................
2023-08-15 12:27:01,969:INFO:Initializing evaluate_model()
2023-08-15 12:27:01,969:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=GaussianNB(priors=None, var_smoothing=1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 12:27:01,996:INFO:Initializing plot_model()
2023-08-15 12:27:01,996:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, system=True)
2023-08-15 12:27:01,996:INFO:Checking exceptions
2023-08-15 12:27:02,015:INFO:Preloading libraries
2023-08-15 12:27:02,015:INFO:Copying training dataset
2023-08-15 12:27:02,015:INFO:Plot type: pipeline
2023-08-15 12:27:02,111:INFO:Visual Rendered Successfully
2023-08-15 12:27:02,215:INFO:plot_model() successfully completed......................................
2023-08-15 12:27:02,264:INFO:Initializing blend_models()
2023-08-15 12:27:02,264:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 12:27:02,264:INFO:Checking exceptions
2023-08-15 12:27:02,302:INFO:Importing libraries
2023-08-15 12:27:02,303:INFO:Copying training dataset
2023-08-15 12:27:02,305:INFO:Getting model names
2023-08-15 12:27:02,307:INFO:SubProcess create_model() called ==================================
2023-08-15 12:27:02,309:INFO:Initializing create_model()
2023-08-15 12:27:02,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7EE005AE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:27:02,309:INFO:Checking exceptions
2023-08-15 12:27:02,309:INFO:Importing libraries
2023-08-15 12:27:02,309:INFO:Copying training dataset
2023-08-15 12:27:02,361:INFO:Defining folds
2023-08-15 12:27:02,361:INFO:Declaring metric variables
2023-08-15 12:27:02,363:INFO:Importing untrained model
2023-08-15 12:27:02,363:INFO:Declaring custom model
2023-08-15 12:27:02,366:INFO:Voting Classifier Imported successfully
2023-08-15 12:27:02,370:INFO:Starting cross validation
2023-08-15 12:27:02,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:27:05,843:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:05,863:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:06,168:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:06,190:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:06,401:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:06,665:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:06,670:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:06,672:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:06,843:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:06,960:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:12,220:INFO:Calculating mean and std
2023-08-15 12:27:12,221:INFO:Creating metrics dataframe
2023-08-15 12:27:12,225:INFO:Finalizing model
2023-08-15 12:27:13,288:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:13,647:INFO:Uploading results into container
2023-08-15 12:27:13,648:INFO:Uploading model into container now
2023-08-15 12:27:13,649:INFO:_master_model_container: 27
2023-08-15 12:27:13,649:INFO:_display_container: 9
2023-08-15 12:27:13,650:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 12:27:13,651:INFO:create_model() successfully completed......................................
2023-08-15 12:27:13,755:INFO:SubProcess create_model() end ==================================
2023-08-15 12:27:13,761:INFO:_master_model_container: 27
2023-08-15 12:27:13,761:INFO:_display_container: 9
2023-08-15 12:27:13,763:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 12:27:13,763:INFO:blend_models() successfully completed......................................
2023-08-15 12:27:13,882:INFO:Initializing evaluate_model()
2023-08-15 12:27:13,882:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 12:27:13,910:INFO:Initializing plot_model()
2023-08-15 12:27:13,910:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, system=True)
2023-08-15 12:27:13,910:INFO:Checking exceptions
2023-08-15 12:27:13,929:INFO:Preloading libraries
2023-08-15 12:27:13,934:INFO:Copying training dataset
2023-08-15 12:27:13,934:INFO:Plot type: pipeline
2023-08-15 12:27:14,052:INFO:Visual Rendered Successfully
2023-08-15 12:27:14,162:INFO:plot_model() successfully completed......................................
2023-08-15 12:27:14,199:INFO:Initializing blend_models()
2023-08-15 12:27:14,199:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 12:27:14,199:INFO:Checking exceptions
2023-08-15 12:27:14,227:INFO:Importing libraries
2023-08-15 12:27:14,228:INFO:Copying training dataset
2023-08-15 12:27:14,231:INFO:Getting model names
2023-08-15 12:27:14,233:INFO:SubProcess create_model() called ==================================
2023-08-15 12:27:14,235:INFO:Initializing create_model()
2023-08-15 12:27:14,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.47,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7EE005AE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:27:14,235:INFO:Checking exceptions
2023-08-15 12:27:14,235:INFO:Importing libraries
2023-08-15 12:27:14,235:INFO:Copying training dataset
2023-08-15 12:27:14,285:INFO:Defining folds
2023-08-15 12:27:14,285:INFO:Declaring metric variables
2023-08-15 12:27:14,288:INFO:Importing untrained model
2023-08-15 12:27:14,288:INFO:Declaring custom model
2023-08-15 12:27:14,291:INFO:Voting Classifier Imported successfully
2023-08-15 12:27:14,294:INFO:Starting cross validation
2023-08-15 12:27:14,296:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:27:17,195:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:17,347:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:18,016:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:18,048:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:18,335:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:18,383:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:18,559:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:18,720:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:18,800:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:18,895:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:22,121:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:27:22,200:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:27:22,239:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:27:22,261:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:27:22,262:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:27:22,346:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:27:23,556:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:27:24,213:INFO:Calculating mean and std
2023-08-15 12:27:24,214:INFO:Creating metrics dataframe
2023-08-15 12:27:24,218:INFO:Finalizing model
2023-08-15 12:27:25,291:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:25,654:INFO:Uploading results into container
2023-08-15 12:27:25,655:INFO:Uploading model into container now
2023-08-15 12:27:25,656:INFO:_master_model_container: 28
2023-08-15 12:27:25,656:INFO:_display_container: 10
2023-08-15 12:27:25,657:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.47,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 12:27:25,657:INFO:create_model() successfully completed......................................
2023-08-15 12:27:25,763:INFO:SubProcess create_model() end ==================================
2023-08-15 12:27:25,769:INFO:_master_model_container: 28
2023-08-15 12:27:25,769:INFO:_display_container: 10
2023-08-15 12:27:25,770:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.47,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 12:27:25,770:INFO:blend_models() successfully completed......................................
2023-08-15 12:27:25,898:INFO:Initializing evaluate_model()
2023-08-15 12:27:25,899:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.47,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 12:27:25,928:INFO:Initializing plot_model()
2023-08-15 12:27:25,928:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.47,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, system=True)
2023-08-15 12:27:25,928:INFO:Checking exceptions
2023-08-15 12:27:25,949:INFO:Preloading libraries
2023-08-15 12:27:25,952:INFO:Copying training dataset
2023-08-15 12:27:25,952:INFO:Plot type: pipeline
2023-08-15 12:27:26,069:INFO:Visual Rendered Successfully
2023-08-15 12:27:26,173:INFO:plot_model() successfully completed......................................
2023-08-15 12:27:26,217:INFO:Initializing blend_models()
2023-08-15 12:27:26,218:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=hard, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 12:27:26,218:INFO:Checking exceptions
2023-08-15 12:27:26,244:INFO:Importing libraries
2023-08-15 12:27:26,245:INFO:Copying training dataset
2023-08-15 12:27:26,248:INFO:Getting model names
2023-08-15 12:27:26,250:INFO:SubProcess create_model() called ==================================
2023-08-15 12:27:26,252:INFO:Initializing create_model()
2023-08-15 12:27:26,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7DEC9DCC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:27:26,252:INFO:Checking exceptions
2023-08-15 12:27:26,253:INFO:Importing libraries
2023-08-15 12:27:26,253:INFO:Copying training dataset
2023-08-15 12:27:26,304:INFO:Defining folds
2023-08-15 12:27:26,304:INFO:Declaring metric variables
2023-08-15 12:27:26,306:INFO:Importing untrained model
2023-08-15 12:27:26,306:INFO:Declaring custom model
2023-08-15 12:27:26,309:INFO:Voting Classifier Imported successfully
2023-08-15 12:27:26,314:INFO:Starting cross validation
2023-08-15 12:27:26,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:27:29,856:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:29,880:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:30,055:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:30,471:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:30,500:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:30,536:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:30,703:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:30,802:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:30,918:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:30,952:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:33,577:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:33,676:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:33,707:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:33,719:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:33,720:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:33,721:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:34,607:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:34,757:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:34,767:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:34,832:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:35,869:INFO:Calculating mean and std
2023-08-15 12:27:35,870:INFO:Creating metrics dataframe
2023-08-15 12:27:35,874:INFO:Finalizing model
2023-08-15 12:27:36,951:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:37,335:INFO:Uploading results into container
2023-08-15 12:27:37,335:INFO:Uploading model into container now
2023-08-15 12:27:37,336:INFO:_master_model_container: 29
2023-08-15 12:27:37,336:INFO:_display_container: 11
2023-08-15 12:27:37,338:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 12:27:37,338:INFO:create_model() successfully completed......................................
2023-08-15 12:27:37,441:INFO:SubProcess create_model() end ==================================
2023-08-15 12:27:37,448:INFO:_master_model_container: 29
2023-08-15 12:27:37,448:INFO:_display_container: 11
2023-08-15 12:27:37,451:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 12:27:37,451:INFO:blend_models() successfully completed......................................
2023-08-15 12:27:37,618:INFO:Initializing blend_models()
2023-08-15 12:27:37,618:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.47,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=hard, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 12:27:37,618:INFO:Checking exceptions
2023-08-15 12:27:37,649:INFO:Importing libraries
2023-08-15 12:27:37,650:INFO:Copying training dataset
2023-08-15 12:27:37,652:INFO:Getting model names
2023-08-15 12:27:37,655:INFO:SubProcess create_model() called ==================================
2023-08-15 12:27:37,657:INFO:Initializing create_model()
2023-08-15 12:27:37,657:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A7E57F50F0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.47,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A7D8BDE920>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:27:37,657:INFO:Checking exceptions
2023-08-15 12:27:37,657:INFO:Importing libraries
2023-08-15 12:27:37,657:INFO:Copying training dataset
2023-08-15 12:27:37,705:INFO:Defining folds
2023-08-15 12:27:37,705:INFO:Declaring metric variables
2023-08-15 12:27:37,708:INFO:Importing untrained model
2023-08-15 12:27:37,708:INFO:Declaring custom model
2023-08-15 12:27:37,711:INFO:Voting Classifier Imported successfully
2023-08-15 12:27:37,715:INFO:Starting cross validation
2023-08-15 12:27:37,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:27:40,863:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:41,057:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:41,614:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:41,677:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:41,682:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:41,804:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:41,960:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:41,964:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:42,095:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:42,151:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:44,935:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:45,116:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:45,142:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:45,146:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:45,149:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:45,164:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:45,206:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:45,556:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:46,061:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:46,211:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:27:47,333:INFO:Calculating mean and std
2023-08-15 12:27:47,334:INFO:Creating metrics dataframe
2023-08-15 12:27:47,338:INFO:Finalizing model
2023-08-15 12:27:48,414:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 12:27:48,786:INFO:Uploading results into container
2023-08-15 12:27:48,787:INFO:Uploading model into container now
2023-08-15 12:27:48,787:INFO:_master_model_container: 30
2023-08-15 12:27:48,787:INFO:_display_container: 12
2023-08-15 12:27:48,788:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.47,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 12:27:48,789:INFO:create_model() successfully completed......................................
2023-08-15 12:27:48,891:INFO:SubProcess create_model() end ==================================
2023-08-15 12:27:48,897:INFO:_master_model_container: 30
2023-08-15 12:27:48,897:INFO:_display_container: 12
2023-08-15 12:27:48,899:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.47,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 12:27:48,899:INFO:blend_models() successfully completed......................................
2023-08-15 12:41:37,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 12:41:37,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 12:41:37,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 12:41:37,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 12:41:39,443:INFO:PyCaret ClassificationExperiment
2023-08-15 12:41:39,443:INFO:Logging name: clf-default-name
2023-08-15 12:41:39,444:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 12:41:39,444:INFO:version 3.0.4
2023-08-15 12:41:39,444:INFO:Initializing setup()
2023-08-15 12:41:39,444:INFO:self.USI: cef8
2023-08-15 12:41:39,444:INFO:self._variable_keys: {'y_test', 'logging_param', '_ml_usecase', 'pipeline', 'html_param', 'y', 'target_param', 'idx', 'X_test', 'fix_imbalance', 'seed', 'n_jobs_param', 'is_multiclass', '_available_plots', 'gpu_n_jobs_param', 'log_plots_param', 'USI', 'fold_generator', 'fold_shuffle_param', 'X_train', 'exp_id', 'exp_name_log', 'X', 'memory', 'y_train', 'gpu_param', 'fold_groups_param', 'data'}
2023-08-15 12:41:39,444:INFO:Checking environment
2023-08-15 12:41:39,444:INFO:python_version: 3.10.12
2023-08-15 12:41:39,444:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 12:41:39,444:INFO:machine: AMD64
2023-08-15 12:41:39,444:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 12:41:39,448:INFO:Memory: svmem(total=68448301056, available=47651770368, percent=30.4, used=20796530688, free=47651770368)
2023-08-15 12:41:39,448:INFO:Physical Core: 12
2023-08-15 12:41:39,448:INFO:Logical Core: 20
2023-08-15 12:41:39,448:INFO:Checking libraries
2023-08-15 12:41:39,448:INFO:System:
2023-08-15 12:41:39,448:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 12:41:39,448:INFO:executable: c:\Users\Ramon\anaconda3\envs\PycaretEnv\python.exe
2023-08-15 12:41:39,448:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 12:41:39,448:INFO:PyCaret required dependencies:
2023-08-15 12:41:39,921:INFO:                 pip: 23.2.1
2023-08-15 12:41:39,921:INFO:          setuptools: 68.0.0
2023-08-15 12:41:39,921:INFO:             pycaret: 3.0.4
2023-08-15 12:41:39,921:INFO:             IPython: 8.14.0
2023-08-15 12:41:39,921:INFO:          ipywidgets: 8.1.0
2023-08-15 12:41:39,921:INFO:                tqdm: 4.66.1
2023-08-15 12:41:39,921:INFO:               numpy: 1.25.2
2023-08-15 12:41:39,921:INFO:              pandas: 2.0.3
2023-08-15 12:41:39,921:INFO:              jinja2: 3.1.2
2023-08-15 12:41:39,921:INFO:               scipy: 1.11.1
2023-08-15 12:41:39,921:INFO:              joblib: 1.3.2
2023-08-15 12:41:39,921:INFO:             sklearn: 1.3.0
2023-08-15 12:41:39,921:INFO:                pyod: 1.1.0
2023-08-15 12:41:39,921:INFO:            imblearn: 0.11.0
2023-08-15 12:41:39,921:INFO:   category_encoders: 2.6.1
2023-08-15 12:41:39,921:INFO:            lightgbm: 4.0.0
2023-08-15 12:41:39,921:INFO:               numba: 0.57.1
2023-08-15 12:41:39,921:INFO:            requests: 2.31.0
2023-08-15 12:41:39,921:INFO:          matplotlib: 3.7.2
2023-08-15 12:41:39,921:INFO:          scikitplot: 0.3.7
2023-08-15 12:41:39,921:INFO:         yellowbrick: 1.5
2023-08-15 12:41:39,921:INFO:              plotly: 5.16.0
2023-08-15 12:41:39,921:INFO:    plotly-resampler: Not installed
2023-08-15 12:41:39,921:INFO:             kaleido: 0.2.1
2023-08-15 12:41:39,921:INFO:           schemdraw: 0.15
2023-08-15 12:41:39,921:INFO:         statsmodels: 0.14.0
2023-08-15 12:41:39,921:INFO:              sktime: 0.21.0
2023-08-15 12:41:39,921:INFO:               tbats: 1.1.3
2023-08-15 12:41:39,921:INFO:            pmdarima: 2.0.3
2023-08-15 12:41:39,921:INFO:              psutil: 5.9.5
2023-08-15 12:41:39,921:INFO:          markupsafe: 2.1.3
2023-08-15 12:41:39,921:INFO:             pickle5: Not installed
2023-08-15 12:41:39,921:INFO:         cloudpickle: 2.2.1
2023-08-15 12:41:39,921:INFO:         deprecation: 2.1.0
2023-08-15 12:41:39,921:INFO:              xxhash: 3.2.0
2023-08-15 12:41:39,921:INFO:           wurlitzer: Not installed
2023-08-15 12:41:39,921:INFO:PyCaret optional dependencies:
2023-08-15 12:41:40,027:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
  warnings.warn(

2023-08-15 12:41:41,056:INFO:                shap: 0.42.1
2023-08-15 12:41:41,056:INFO:           interpret: 0.4.3
2023-08-15 12:41:41,056:INFO:                umap: 0.5.3
2023-08-15 12:41:41,056:INFO:    pandas_profiling: 4.4.0
2023-08-15 12:41:41,056:INFO:  explainerdashboard: 0.4.3
2023-08-15 12:41:41,056:INFO:             autoviz: 0.1.730
2023-08-15 12:41:41,056:INFO:           fairlearn: 0.7.0
2023-08-15 12:41:41,056:INFO:          deepchecks: 0.17.4
2023-08-15 12:41:41,056:INFO:             xgboost: 1.7.6
2023-08-15 12:41:41,056:INFO:            catboost: 1.2
2023-08-15 12:41:41,056:INFO:              kmodes: 0.12.2
2023-08-15 12:41:41,056:INFO:             mlxtend: 0.22.0
2023-08-15 12:41:41,056:INFO:       statsforecast: 1.5.0
2023-08-15 12:41:41,056:INFO:        tune_sklearn: 0.4.6
2023-08-15 12:41:41,056:INFO:                 ray: 2.6.1
2023-08-15 12:41:41,056:INFO:            hyperopt: 0.2.7
2023-08-15 12:41:41,056:INFO:              optuna: 3.3.0
2023-08-15 12:41:41,056:INFO:               skopt: 0.9.0
2023-08-15 12:41:41,056:INFO:              mlflow: 1.30.1
2023-08-15 12:41:41,056:INFO:              gradio: 3.39.0
2023-08-15 12:41:41,056:INFO:             fastapi: 0.101.0
2023-08-15 12:41:41,056:INFO:             uvicorn: 0.23.2
2023-08-15 12:41:41,056:INFO:              m2cgen: 0.10.0
2023-08-15 12:41:41,056:INFO:           evidently: 0.2.8
2023-08-15 12:41:41,056:INFO:               fugue: 0.8.6
2023-08-15 12:41:41,056:INFO:           streamlit: Not installed
2023-08-15 12:41:41,056:INFO:             prophet: Not installed
2023-08-15 12:41:41,056:INFO:None
2023-08-15 12:41:41,056:INFO:Set up data.
2023-08-15 12:41:41,249:INFO:Set up train/test split.
2023-08-15 12:41:41,411:INFO:Set up index.
2023-08-15 12:41:41,416:INFO:Set up folding strategy.
2023-08-15 12:41:41,416:INFO:Assigning column types.
2023-08-15 12:41:41,450:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 12:41:41,473:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 12:41:41,476:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 12:41:41,495:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:41:41,514:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:41:41,549:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 12:41:41,550:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 12:41:41,564:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:41:41,565:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:41:41,566:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 12:41:41,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 12:41:41,605:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:41:41,607:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:41:41,631:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 12:41:41,645:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:41:41,647:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:41:41,647:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 12:41:41,685:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:41:41,686:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:41:41,725:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:41:41,726:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:41:41,728:INFO:Preparing preprocessing pipeline...
2023-08-15 12:41:41,734:INFO:Set up label encoding.
2023-08-15 12:41:41,734:INFO:Set up simple imputation.
2023-08-15 12:41:41,773:INFO:Set up encoding of ordinal features.
2023-08-15 12:41:41,846:INFO:Set up encoding of categorical features.
2023-08-15 12:41:41,851:INFO:Set up column name cleaning.
2023-08-15 12:41:42,383:INFO:Finished creating preprocessing pipeline.
2023-08-15 12:41:42,419:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 12:41:42,420:INFO:Creating final display dataframe.
2023-08-15 12:41:43,883:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              cef8
2023-08-15 12:41:43,928:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:41:43,929:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:41:43,968:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 12:41:43,969:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 12:41:43,970:INFO:setup() successfully completed in 4.69s...............
2023-08-15 12:41:54,605:INFO:Initializing compare_models()
2023-08-15 12:41:54,605:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-15 12:41:54,605:INFO:Checking exceptions
2023-08-15 12:41:54,638:INFO:Preparing display monitor
2023-08-15 12:41:54,654:INFO:Initializing Logistic Regression
2023-08-15 12:41:54,654:INFO:Total runtime is 0.0 minutes
2023-08-15 12:41:54,656:INFO:SubProcess create_model() called ==================================
2023-08-15 12:41:54,656:INFO:Initializing create_model()
2023-08-15 12:41:54,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:41:54,656:INFO:Checking exceptions
2023-08-15 12:41:54,656:INFO:Importing libraries
2023-08-15 12:41:54,656:INFO:Copying training dataset
2023-08-15 12:41:54,729:INFO:Defining folds
2023-08-15 12:41:54,729:INFO:Declaring metric variables
2023-08-15 12:41:54,735:INFO:Importing untrained model
2023-08-15 12:41:54,739:INFO:Logistic Regression Imported successfully
2023-08-15 12:41:54,746:INFO:Starting cross validation
2023-08-15 12:41:54,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:42:51,522:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:51,551:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:51,741:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:51,801:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:51,851:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:51,885:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:52,062:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:52,066:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:52,108:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:52,131:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 12:42:54,089:INFO:Calculating mean and std
2023-08-15 12:42:54,090:INFO:Creating metrics dataframe
2023-08-15 12:42:54,266:INFO:Uploading results into container
2023-08-15 12:42:54,267:INFO:Uploading model into container now
2023-08-15 12:42:54,268:INFO:_master_model_container: 1
2023-08-15 12:42:54,268:INFO:_display_container: 2
2023-08-15 12:42:54,268:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 12:42:54,268:INFO:create_model() successfully completed......................................
2023-08-15 12:42:54,351:INFO:SubProcess create_model() end ==================================
2023-08-15 12:42:54,351:INFO:Creating metrics dataframe
2023-08-15 12:42:54,356:INFO:Initializing K Neighbors Classifier
2023-08-15 12:42:54,356:INFO:Total runtime is 0.9950245976448059 minutes
2023-08-15 12:42:54,358:INFO:SubProcess create_model() called ==================================
2023-08-15 12:42:54,359:INFO:Initializing create_model()
2023-08-15 12:42:54,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:42:54,359:INFO:Checking exceptions
2023-08-15 12:42:54,359:INFO:Importing libraries
2023-08-15 12:42:54,359:INFO:Copying training dataset
2023-08-15 12:42:54,417:INFO:Defining folds
2023-08-15 12:42:54,417:INFO:Declaring metric variables
2023-08-15 12:42:54,420:INFO:Importing untrained model
2023-08-15 12:42:54,422:INFO:K Neighbors Classifier Imported successfully
2023-08-15 12:42:54,427:INFO:Starting cross validation
2023-08-15 12:42:54,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:42:58,909:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:58,976:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,002:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,077:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,100:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,106:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,162:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,170:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,203:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,209:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,259:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,267:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,271:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,280:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,318:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,387:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,442:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,443:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,501:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:42:59,638:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:00,839:INFO:Calculating mean and std
2023-08-15 12:43:00,841:INFO:Creating metrics dataframe
2023-08-15 12:43:01,019:INFO:Uploading results into container
2023-08-15 12:43:01,020:INFO:Uploading model into container now
2023-08-15 12:43:01,020:INFO:_master_model_container: 2
2023-08-15 12:43:01,020:INFO:_display_container: 2
2023-08-15 12:43:01,020:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-15 12:43:01,020:INFO:create_model() successfully completed......................................
2023-08-15 12:43:01,098:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2023-08-15 12:43:01,098:WARNING:Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2023-08-15 12:43:01,099:INFO:Initializing create_model()
2023-08-15 12:43:01,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:43:01,099:INFO:Checking exceptions
2023-08-15 12:43:01,099:INFO:Importing libraries
2023-08-15 12:43:01,099:INFO:Copying training dataset
2023-08-15 12:43:01,151:INFO:Defining folds
2023-08-15 12:43:01,152:INFO:Declaring metric variables
2023-08-15 12:43:01,154:INFO:Importing untrained model
2023-08-15 12:43:01,157:INFO:K Neighbors Classifier Imported successfully
2023-08-15 12:43:01,161:INFO:Starting cross validation
2023-08-15 12:43:01,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:43:02,163:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,236:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,239:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,386:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,402:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,523:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,609:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,615:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,686:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,689:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,692:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,700:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,705:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,734:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,778:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,848:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,864:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,873:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,891:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:02,933:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 12:43:04,301:INFO:Calculating mean and std
2023-08-15 12:43:04,302:INFO:Creating metrics dataframe
2023-08-15 12:43:04,484:INFO:Uploading results into container
2023-08-15 12:43:04,484:INFO:Uploading model into container now
2023-08-15 12:43:04,485:INFO:_master_model_container: 3
2023-08-15 12:43:04,485:INFO:_display_container: 2
2023-08-15 12:43:04,485:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-15 12:43:04,485:INFO:create_model() successfully completed......................................
2023-08-15 12:43:04,561:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2023-08-15 12:43:04,562:ERROR:Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 813, in compare_models
    np.sum(
AssertionError

2023-08-15 12:43:04,562:INFO:Initializing Naive Bayes
2023-08-15 12:43:04,562:INFO:Total runtime is 1.1651297291119893 minutes
2023-08-15 12:43:04,564:INFO:SubProcess create_model() called ==================================
2023-08-15 12:43:04,564:INFO:Initializing create_model()
2023-08-15 12:43:04,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:43:04,564:INFO:Checking exceptions
2023-08-15 12:43:04,564:INFO:Importing libraries
2023-08-15 12:43:04,564:INFO:Copying training dataset
2023-08-15 12:43:04,618:INFO:Defining folds
2023-08-15 12:43:04,618:INFO:Declaring metric variables
2023-08-15 12:43:04,620:INFO:Importing untrained model
2023-08-15 12:43:04,624:INFO:Naive Bayes Imported successfully
2023-08-15 12:43:04,628:INFO:Starting cross validation
2023-08-15 12:43:04,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:43:07,896:INFO:Calculating mean and std
2023-08-15 12:43:07,897:INFO:Creating metrics dataframe
2023-08-15 12:43:08,074:INFO:Uploading results into container
2023-08-15 12:43:08,074:INFO:Uploading model into container now
2023-08-15 12:43:08,074:INFO:_master_model_container: 4
2023-08-15 12:43:08,075:INFO:_display_container: 2
2023-08-15 12:43:08,075:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 12:43:08,075:INFO:create_model() successfully completed......................................
2023-08-15 12:43:08,156:INFO:SubProcess create_model() end ==================================
2023-08-15 12:43:08,156:INFO:Creating metrics dataframe
2023-08-15 12:43:08,161:INFO:Initializing Decision Tree Classifier
2023-08-15 12:43:08,161:INFO:Total runtime is 1.2251150409380596 minutes
2023-08-15 12:43:08,163:INFO:SubProcess create_model() called ==================================
2023-08-15 12:43:08,164:INFO:Initializing create_model()
2023-08-15 12:43:08,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:43:08,164:INFO:Checking exceptions
2023-08-15 12:43:08,164:INFO:Importing libraries
2023-08-15 12:43:08,164:INFO:Copying training dataset
2023-08-15 12:43:08,222:INFO:Defining folds
2023-08-15 12:43:08,222:INFO:Declaring metric variables
2023-08-15 12:43:08,225:INFO:Importing untrained model
2023-08-15 12:43:08,227:INFO:Decision Tree Classifier Imported successfully
2023-08-15 12:43:08,232:INFO:Starting cross validation
2023-08-15 12:43:08,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:43:13,899:INFO:Calculating mean and std
2023-08-15 12:43:13,900:INFO:Creating metrics dataframe
2023-08-15 12:43:14,087:INFO:Uploading results into container
2023-08-15 12:43:14,088:INFO:Uploading model into container now
2023-08-15 12:43:14,089:INFO:_master_model_container: 5
2023-08-15 12:43:14,089:INFO:_display_container: 2
2023-08-15 12:43:14,089:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-15 12:43:14,089:INFO:create_model() successfully completed......................................
2023-08-15 12:43:14,164:INFO:SubProcess create_model() end ==================================
2023-08-15 12:43:14,164:INFO:Creating metrics dataframe
2023-08-15 12:43:14,169:INFO:Initializing SVM - Linear Kernel
2023-08-15 12:43:14,169:INFO:Total runtime is 1.325251281261444 minutes
2023-08-15 12:43:14,172:INFO:SubProcess create_model() called ==================================
2023-08-15 12:43:14,172:INFO:Initializing create_model()
2023-08-15 12:43:14,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:43:14,172:INFO:Checking exceptions
2023-08-15 12:43:14,172:INFO:Importing libraries
2023-08-15 12:43:14,172:INFO:Copying training dataset
2023-08-15 12:43:14,232:INFO:Defining folds
2023-08-15 12:43:14,232:INFO:Declaring metric variables
2023-08-15 12:43:14,235:INFO:Importing untrained model
2023-08-15 12:43:14,238:INFO:SVM - Linear Kernel Imported successfully
2023-08-15 12:43:14,242:INFO:Starting cross validation
2023-08-15 12:43:14,244:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:43:33,920:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:34,701:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:34,807:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:34,893:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:43:35,380:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:35,814:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:35,948:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:36,037:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:36,067:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:36,684:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:36,918:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:37,358:INFO:Calculating mean and std
2023-08-15 12:43:37,359:INFO:Creating metrics dataframe
2023-08-15 12:43:37,549:INFO:Uploading results into container
2023-08-15 12:43:37,550:INFO:Uploading model into container now
2023-08-15 12:43:37,550:INFO:_master_model_container: 6
2023-08-15 12:43:37,550:INFO:_display_container: 2
2023-08-15 12:43:37,551:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-15 12:43:37,551:INFO:create_model() successfully completed......................................
2023-08-15 12:43:37,628:INFO:SubProcess create_model() end ==================================
2023-08-15 12:43:37,628:INFO:Creating metrics dataframe
2023-08-15 12:43:37,633:INFO:Initializing Ridge Classifier
2023-08-15 12:43:37,633:INFO:Total runtime is 1.7163073976834615 minutes
2023-08-15 12:43:37,635:INFO:SubProcess create_model() called ==================================
2023-08-15 12:43:37,635:INFO:Initializing create_model()
2023-08-15 12:43:37,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:43:37,636:INFO:Checking exceptions
2023-08-15 12:43:37,636:INFO:Importing libraries
2023-08-15 12:43:37,636:INFO:Copying training dataset
2023-08-15 12:43:37,695:INFO:Defining folds
2023-08-15 12:43:37,695:INFO:Declaring metric variables
2023-08-15 12:43:37,698:INFO:Importing untrained model
2023-08-15 12:43:37,700:INFO:Ridge Classifier Imported successfully
2023-08-15 12:43:37,704:INFO:Starting cross validation
2023-08-15 12:43:37,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:43:39,325:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,395:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,416:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,448:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,449:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,481:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,484:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,487:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,500:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:39,540:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 12:43:41,415:INFO:Calculating mean and std
2023-08-15 12:43:41,416:INFO:Creating metrics dataframe
2023-08-15 12:43:41,604:INFO:Uploading results into container
2023-08-15 12:43:41,605:INFO:Uploading model into container now
2023-08-15 12:43:41,605:INFO:_master_model_container: 7
2023-08-15 12:43:41,605:INFO:_display_container: 2
2023-08-15 12:43:41,606:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-15 12:43:41,606:INFO:create_model() successfully completed......................................
2023-08-15 12:43:41,683:INFO:SubProcess create_model() end ==================================
2023-08-15 12:43:41,683:INFO:Creating metrics dataframe
2023-08-15 12:43:41,689:INFO:Initializing Random Forest Classifier
2023-08-15 12:43:41,689:INFO:Total runtime is 1.78390820423762 minutes
2023-08-15 12:43:41,691:INFO:SubProcess create_model() called ==================================
2023-08-15 12:43:41,691:INFO:Initializing create_model()
2023-08-15 12:43:41,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:43:41,691:INFO:Checking exceptions
2023-08-15 12:43:41,691:INFO:Importing libraries
2023-08-15 12:43:41,692:INFO:Copying training dataset
2023-08-15 12:43:41,749:INFO:Defining folds
2023-08-15 12:43:41,750:INFO:Declaring metric variables
2023-08-15 12:43:41,753:INFO:Importing untrained model
2023-08-15 12:43:41,755:INFO:Random Forest Classifier Imported successfully
2023-08-15 12:43:41,759:INFO:Starting cross validation
2023-08-15 12:43:41,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:44:14,384:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.21s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:44:16,507:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.24s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:44:18,892:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:44:21,403:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:44:23,204:INFO:Calculating mean and std
2023-08-15 12:44:23,205:INFO:Creating metrics dataframe
2023-08-15 12:44:23,416:INFO:Uploading results into container
2023-08-15 12:44:23,416:INFO:Uploading model into container now
2023-08-15 12:44:23,417:INFO:_master_model_container: 8
2023-08-15 12:44:23,417:INFO:_display_container: 2
2023-08-15 12:44:23,417:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-15 12:44:23,417:INFO:create_model() successfully completed......................................
2023-08-15 12:44:23,496:INFO:SubProcess create_model() end ==================================
2023-08-15 12:44:23,496:INFO:Creating metrics dataframe
2023-08-15 12:44:23,502:INFO:Initializing Quadratic Discriminant Analysis
2023-08-15 12:44:23,503:INFO:Total runtime is 2.4808165947596232 minutes
2023-08-15 12:44:23,505:INFO:SubProcess create_model() called ==================================
2023-08-15 12:44:23,505:INFO:Initializing create_model()
2023-08-15 12:44:23,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:44:23,505:INFO:Checking exceptions
2023-08-15 12:44:23,505:INFO:Importing libraries
2023-08-15 12:44:23,506:INFO:Copying training dataset
2023-08-15 12:44:23,566:INFO:Defining folds
2023-08-15 12:44:23,567:INFO:Declaring metric variables
2023-08-15 12:44:23,570:INFO:Importing untrained model
2023-08-15 12:44:23,572:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 12:44:23,577:INFO:Starting cross validation
2023-08-15 12:44:23,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:44:26,966:INFO:Calculating mean and std
2023-08-15 12:44:26,967:INFO:Creating metrics dataframe
2023-08-15 12:44:27,155:INFO:Uploading results into container
2023-08-15 12:44:27,155:INFO:Uploading model into container now
2023-08-15 12:44:27,156:INFO:_master_model_container: 9
2023-08-15 12:44:27,156:INFO:_display_container: 2
2023-08-15 12:44:27,156:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 12:44:27,156:INFO:create_model() successfully completed......................................
2023-08-15 12:44:27,237:INFO:SubProcess create_model() end ==================================
2023-08-15 12:44:27,237:INFO:Creating metrics dataframe
2023-08-15 12:44:27,243:INFO:Initializing Ada Boost Classifier
2023-08-15 12:44:27,243:INFO:Total runtime is 2.543144182364146 minutes
2023-08-15 12:44:27,245:INFO:SubProcess create_model() called ==================================
2023-08-15 12:44:27,246:INFO:Initializing create_model()
2023-08-15 12:44:27,246:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:44:27,246:INFO:Checking exceptions
2023-08-15 12:44:27,246:INFO:Importing libraries
2023-08-15 12:44:27,246:INFO:Copying training dataset
2023-08-15 12:44:27,309:INFO:Defining folds
2023-08-15 12:44:27,309:INFO:Declaring metric variables
2023-08-15 12:44:27,312:INFO:Importing untrained model
2023-08-15 12:44:27,314:INFO:Ada Boost Classifier Imported successfully
2023-08-15 12:44:27,318:INFO:Starting cross validation
2023-08-15 12:44:27,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:44:47,118:INFO:Calculating mean and std
2023-08-15 12:44:47,119:INFO:Creating metrics dataframe
2023-08-15 12:44:47,326:INFO:Uploading results into container
2023-08-15 12:44:47,327:INFO:Uploading model into container now
2023-08-15 12:44:47,327:INFO:_master_model_container: 10
2023-08-15 12:44:47,327:INFO:_display_container: 2
2023-08-15 12:44:47,327:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-15 12:44:47,328:INFO:create_model() successfully completed......................................
2023-08-15 12:44:47,409:INFO:SubProcess create_model() end ==================================
2023-08-15 12:44:47,409:INFO:Creating metrics dataframe
2023-08-15 12:44:47,415:INFO:Initializing Gradient Boosting Classifier
2023-08-15 12:44:47,415:INFO:Total runtime is 2.8793529431025187 minutes
2023-08-15 12:44:47,418:INFO:SubProcess create_model() called ==================================
2023-08-15 12:44:47,418:INFO:Initializing create_model()
2023-08-15 12:44:47,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:44:47,418:INFO:Checking exceptions
2023-08-15 12:44:47,418:INFO:Importing libraries
2023-08-15 12:44:47,418:INFO:Copying training dataset
2023-08-15 12:44:47,477:INFO:Defining folds
2023-08-15 12:44:47,477:INFO:Declaring metric variables
2023-08-15 12:44:47,480:INFO:Importing untrained model
2023-08-15 12:44:47,482:INFO:Gradient Boosting Classifier Imported successfully
2023-08-15 12:44:47,487:INFO:Starting cross validation
2023-08-15 12:44:47,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:45:43,125:INFO:Calculating mean and std
2023-08-15 12:45:43,126:INFO:Creating metrics dataframe
2023-08-15 12:45:43,339:INFO:Uploading results into container
2023-08-15 12:45:43,339:INFO:Uploading model into container now
2023-08-15 12:45:43,340:INFO:_master_model_container: 11
2023-08-15 12:45:43,340:INFO:_display_container: 2
2023-08-15 12:45:43,341:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-15 12:45:43,341:INFO:create_model() successfully completed......................................
2023-08-15 12:45:43,427:INFO:SubProcess create_model() end ==================================
2023-08-15 12:45:43,427:INFO:Creating metrics dataframe
2023-08-15 12:45:43,433:INFO:Initializing Linear Discriminant Analysis
2023-08-15 12:45:43,433:INFO:Total runtime is 3.812972700595856 minutes
2023-08-15 12:45:43,436:INFO:SubProcess create_model() called ==================================
2023-08-15 12:45:43,436:INFO:Initializing create_model()
2023-08-15 12:45:43,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:45:43,436:INFO:Checking exceptions
2023-08-15 12:45:43,436:INFO:Importing libraries
2023-08-15 12:45:43,436:INFO:Copying training dataset
2023-08-15 12:45:43,501:INFO:Defining folds
2023-08-15 12:45:43,501:INFO:Declaring metric variables
2023-08-15 12:45:43,504:INFO:Importing untrained model
2023-08-15 12:45:43,507:INFO:Linear Discriminant Analysis Imported successfully
2023-08-15 12:45:43,512:INFO:Starting cross validation
2023-08-15 12:45:43,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:45:49,708:INFO:Calculating mean and std
2023-08-15 12:45:49,709:INFO:Creating metrics dataframe
2023-08-15 12:45:49,918:INFO:Uploading results into container
2023-08-15 12:45:49,919:INFO:Uploading model into container now
2023-08-15 12:45:49,919:INFO:_master_model_container: 12
2023-08-15 12:45:49,919:INFO:_display_container: 2
2023-08-15 12:45:49,920:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-15 12:45:49,920:INFO:create_model() successfully completed......................................
2023-08-15 12:45:49,998:INFO:SubProcess create_model() end ==================================
2023-08-15 12:45:49,998:INFO:Creating metrics dataframe
2023-08-15 12:45:50,004:INFO:Initializing Extra Trees Classifier
2023-08-15 12:45:50,004:INFO:Total runtime is 3.9224955558776857 minutes
2023-08-15 12:45:50,006:INFO:SubProcess create_model() called ==================================
2023-08-15 12:45:50,007:INFO:Initializing create_model()
2023-08-15 12:45:50,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:45:50,007:INFO:Checking exceptions
2023-08-15 12:45:50,007:INFO:Importing libraries
2023-08-15 12:45:50,007:INFO:Copying training dataset
2023-08-15 12:45:50,070:INFO:Defining folds
2023-08-15 12:45:50,070:INFO:Declaring metric variables
2023-08-15 12:45:50,073:INFO:Importing untrained model
2023-08-15 12:45:50,076:INFO:Extra Trees Classifier Imported successfully
2023-08-15 12:45:50,080:INFO:Starting cross validation
2023-08-15 12:45:50,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:46:03,834:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 12:46:07,384:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 12:46:09,090:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.06s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:46:11,789:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.39s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:46:26,885:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:46:28,544:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:46:28,544:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 12:46:28,549:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:46:29,999:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 12:46:31,873:INFO:Calculating mean and std
2023-08-15 12:46:31,875:INFO:Creating metrics dataframe
2023-08-15 12:46:31,991:INFO:Uploading results into container
2023-08-15 12:46:31,991:INFO:Uploading model into container now
2023-08-15 12:46:31,992:INFO:_master_model_container: 13
2023-08-15 12:46:31,992:INFO:_display_container: 2
2023-08-15 12:46:31,992:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-15 12:46:31,992:INFO:create_model() successfully completed......................................
2023-08-15 12:46:32,086:INFO:SubProcess create_model() end ==================================
2023-08-15 12:46:32,086:INFO:Creating metrics dataframe
2023-08-15 12:46:32,093:INFO:Initializing Extreme Gradient Boosting
2023-08-15 12:46:32,093:INFO:Total runtime is 4.623974406719208 minutes
2023-08-15 12:46:32,096:INFO:SubProcess create_model() called ==================================
2023-08-15 12:46:32,096:INFO:Initializing create_model()
2023-08-15 12:46:32,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:46:32,096:INFO:Checking exceptions
2023-08-15 12:46:32,096:INFO:Importing libraries
2023-08-15 12:46:32,097:INFO:Copying training dataset
2023-08-15 12:46:32,196:INFO:Defining folds
2023-08-15 12:46:32,196:INFO:Declaring metric variables
2023-08-15 12:46:32,200:INFO:Importing untrained model
2023-08-15 12:46:32,203:INFO:Extreme Gradient Boosting Imported successfully
2023-08-15 12:46:32,209:INFO:Starting cross validation
2023-08-15 12:46:32,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:47:01,974:INFO:Calculating mean and std
2023-08-15 12:47:01,975:INFO:Creating metrics dataframe
2023-08-15 12:47:02,085:INFO:Uploading results into container
2023-08-15 12:47:02,086:INFO:Uploading model into container now
2023-08-15 12:47:02,087:INFO:_master_model_container: 14
2023-08-15 12:47:02,087:INFO:_display_container: 2
2023-08-15 12:47:02,087:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-15 12:47:02,087:INFO:create_model() successfully completed......................................
2023-08-15 12:47:02,167:INFO:SubProcess create_model() end ==================================
2023-08-15 12:47:02,168:INFO:Creating metrics dataframe
2023-08-15 12:47:02,174:INFO:Initializing Light Gradient Boosting Machine
2023-08-15 12:47:02,174:INFO:Total runtime is 5.125333801905315 minutes
2023-08-15 12:47:02,177:INFO:SubProcess create_model() called ==================================
2023-08-15 12:47:02,177:INFO:Initializing create_model()
2023-08-15 12:47:02,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:47:02,177:INFO:Checking exceptions
2023-08-15 12:47:02,177:INFO:Importing libraries
2023-08-15 12:47:02,177:INFO:Copying training dataset
2023-08-15 12:47:02,241:INFO:Defining folds
2023-08-15 12:47:02,241:INFO:Declaring metric variables
2023-08-15 12:47:02,243:INFO:Importing untrained model
2023-08-15 12:47:02,246:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 12:47:02,251:INFO:Starting cross validation
2023-08-15 12:47:02,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:47:08,986:INFO:Calculating mean and std
2023-08-15 12:47:08,987:INFO:Creating metrics dataframe
2023-08-15 12:47:09,093:INFO:Uploading results into container
2023-08-15 12:47:09,094:INFO:Uploading model into container now
2023-08-15 12:47:09,094:INFO:_master_model_container: 15
2023-08-15 12:47:09,094:INFO:_display_container: 2
2023-08-15 12:47:09,095:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:47:09,095:INFO:create_model() successfully completed......................................
2023-08-15 12:47:09,177:INFO:SubProcess create_model() end ==================================
2023-08-15 12:47:09,177:INFO:Creating metrics dataframe
2023-08-15 12:47:09,184:INFO:Initializing CatBoost Classifier
2023-08-15 12:47:09,184:INFO:Total runtime is 5.242163256804149 minutes
2023-08-15 12:47:09,186:INFO:SubProcess create_model() called ==================================
2023-08-15 12:47:09,187:INFO:Initializing create_model()
2023-08-15 12:47:09,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:47:09,187:INFO:Checking exceptions
2023-08-15 12:47:09,187:INFO:Importing libraries
2023-08-15 12:47:09,187:INFO:Copying training dataset
2023-08-15 12:47:09,247:INFO:Defining folds
2023-08-15 12:47:09,247:INFO:Declaring metric variables
2023-08-15 12:47:09,250:INFO:Importing untrained model
2023-08-15 12:47:09,252:INFO:CatBoost Classifier Imported successfully
2023-08-15 12:47:09,256:INFO:Starting cross validation
2023-08-15 12:47:09,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:48:47,808:INFO:Calculating mean and std
2023-08-15 12:48:47,809:INFO:Creating metrics dataframe
2023-08-15 12:48:47,917:INFO:Uploading results into container
2023-08-15 12:48:47,918:INFO:Uploading model into container now
2023-08-15 12:48:47,918:INFO:_master_model_container: 16
2023-08-15 12:48:47,918:INFO:_display_container: 2
2023-08-15 12:48:47,918:INFO:<catboost.core.CatBoostClassifier object at 0x000001676BFF6830>
2023-08-15 12:48:47,918:INFO:create_model() successfully completed......................................
2023-08-15 12:48:48,007:INFO:SubProcess create_model() end ==================================
2023-08-15 12:48:48,007:INFO:Creating metrics dataframe
2023-08-15 12:48:48,014:INFO:Initializing Dummy Classifier
2023-08-15 12:48:48,014:INFO:Total runtime is 6.889327879746756 minutes
2023-08-15 12:48:48,016:INFO:SubProcess create_model() called ==================================
2023-08-15 12:48:48,016:INFO:Initializing create_model()
2023-08-15 12:48:48,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016757D9EA40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:48:48,016:INFO:Checking exceptions
2023-08-15 12:48:48,016:INFO:Importing libraries
2023-08-15 12:48:48,017:INFO:Copying training dataset
2023-08-15 12:48:48,074:INFO:Defining folds
2023-08-15 12:48:48,075:INFO:Declaring metric variables
2023-08-15 12:48:48,078:INFO:Importing untrained model
2023-08-15 12:48:48,080:INFO:Dummy Classifier Imported successfully
2023-08-15 12:48:48,084:INFO:Starting cross validation
2023-08-15 12:48:48,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:48:49,552:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,669:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,675:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,721:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,749:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,814:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,845:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,854:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,871:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:49,893:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 12:48:51,023:INFO:Calculating mean and std
2023-08-15 12:48:51,026:INFO:Creating metrics dataframe
2023-08-15 12:48:51,139:INFO:Uploading results into container
2023-08-15 12:48:51,140:INFO:Uploading model into container now
2023-08-15 12:48:51,140:INFO:_master_model_container: 17
2023-08-15 12:48:51,140:INFO:_display_container: 2
2023-08-15 12:48:51,140:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-15 12:48:51,140:INFO:create_model() successfully completed......................................
2023-08-15 12:48:51,222:INFO:SubProcess create_model() end ==================================
2023-08-15 12:48:51,222:INFO:Creating metrics dataframe
2023-08-15 12:48:51,237:INFO:Initializing create_model()
2023-08-15 12:48:51,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:48:51,238:INFO:Checking exceptions
2023-08-15 12:48:51,240:INFO:Importing libraries
2023-08-15 12:48:51,240:INFO:Copying training dataset
2023-08-15 12:48:51,312:INFO:Defining folds
2023-08-15 12:48:51,312:INFO:Declaring metric variables
2023-08-15 12:48:51,312:INFO:Importing untrained model
2023-08-15 12:48:51,312:INFO:Declaring custom model
2023-08-15 12:48:51,312:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 12:48:51,314:INFO:Cross validation set to False
2023-08-15 12:48:51,314:INFO:Fitting Model
2023-08-15 12:48:53,992:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 12:48:53,992:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 12:48:54,010:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006302 seconds.
2023-08-15 12:48:54,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 12:48:54,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 12:48:54,011:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 12:48:54,011:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-15 12:48:54,012:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 12:48:54,012:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 12:48:54,436:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:48:54,436:INFO:create_model() successfully completed......................................
2023-08-15 12:48:54,556:INFO:_master_model_container: 17
2023-08-15 12:48:54,556:INFO:_display_container: 2
2023-08-15 12:48:54,556:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:48:54,556:INFO:compare_models() successfully completed......................................
2023-08-15 12:55:39,894:INFO:Initializing create_model()
2023-08-15 12:55:39,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 12:55:39,894:INFO:Checking exceptions
2023-08-15 12:55:39,910:INFO:Importing libraries
2023-08-15 12:55:39,910:INFO:Copying training dataset
2023-08-15 12:55:39,989:INFO:Defining folds
2023-08-15 12:55:39,989:INFO:Declaring metric variables
2023-08-15 12:55:39,992:INFO:Importing untrained model
2023-08-15 12:55:39,995:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 12:55:40,000:INFO:Starting cross validation
2023-08-15 12:55:40,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 12:55:47,003:INFO:Calculating mean and std
2023-08-15 12:55:47,004:INFO:Creating metrics dataframe
2023-08-15 12:55:47,007:INFO:Finalizing model
2023-08-15 12:55:49,091:INFO:Uploading results into container
2023-08-15 12:55:49,092:INFO:Uploading model into container now
2023-08-15 12:55:49,098:INFO:_master_model_container: 18
2023-08-15 12:55:49,098:INFO:_display_container: 3
2023-08-15 12:55:49,098:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 12:55:49,099:INFO:create_model() successfully completed......................................
2023-08-15 13:01:42,719:INFO:Initializing tune_model()
2023-08-15 13:01:42,719:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>)
2023-08-15 13:01:42,720:INFO:Checking exceptions
2023-08-15 13:01:42,753:INFO:Copying training dataset
2023-08-15 13:01:42,790:INFO:Checking base model
2023-08-15 13:01:42,790:INFO:Base model : Light Gradient Boosting Machine
2023-08-15 13:01:42,793:INFO:Declaring metric variables
2023-08-15 13:01:42,795:INFO:Defining Hyperparameters
2023-08-15 13:01:42,902:INFO:Tuning with n_jobs=-1
2023-08-15 13:01:42,902:INFO:Initializing RandomizedSearchCV
2023-08-15 13:03:07,554:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-08-15 13:03:07,555:INFO:Hyperparameter search completed
2023-08-15 13:03:07,555:INFO:SubProcess create_model() called ==================================
2023-08-15 13:03:07,556:INFO:Initializing create_model()
2023-08-15 13:03:07,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001676398E680>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-08-15 13:03:07,556:INFO:Checking exceptions
2023-08-15 13:03:07,556:INFO:Importing libraries
2023-08-15 13:03:07,556:INFO:Copying training dataset
2023-08-15 13:03:07,613:INFO:Defining folds
2023-08-15 13:03:07,613:INFO:Declaring metric variables
2023-08-15 13:03:07,615:INFO:Importing untrained model
2023-08-15 13:03:07,615:INFO:Declaring custom model
2023-08-15 13:03:07,618:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 13:03:07,622:INFO:Starting cross validation
2023-08-15 13:03:07,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:03:11,283:INFO:Calculating mean and std
2023-08-15 13:03:11,284:INFO:Creating metrics dataframe
2023-08-15 13:03:11,288:INFO:Finalizing model
2023-08-15 13:03:11,939:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-15 13:03:11,939:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-15 13:03:11,939:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-15 13:03:12,184:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:03:12,184:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-15 13:03:12,184:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-15 13:03:12,184:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-15 13:03:12,184:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 13:03:12,204:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005654 seconds.
2023-08-15 13:03:12,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:03:12,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:03:12,204:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:03:12,205:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-15 13:03:12,207:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 13:03:12,207:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 13:03:12,845:INFO:Uploading results into container
2023-08-15 13:03:12,846:INFO:Uploading model into container now
2023-08-15 13:03:12,846:INFO:_master_model_container: 19
2023-08-15 13:03:12,846:INFO:_display_container: 4
2023-08-15 13:03:12,846:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-15 13:03:12,846:INFO:create_model() successfully completed......................................
2023-08-15 13:03:12,933:INFO:SubProcess create_model() end ==================================
2023-08-15 13:03:12,934:INFO:choose_better activated
2023-08-15 13:03:12,936:INFO:SubProcess create_model() called ==================================
2023-08-15 13:03:12,937:INFO:Initializing create_model()
2023-08-15 13:03:12,937:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 13:03:12,937:INFO:Checking exceptions
2023-08-15 13:03:12,938:INFO:Importing libraries
2023-08-15 13:03:12,938:INFO:Copying training dataset
2023-08-15 13:03:12,988:INFO:Defining folds
2023-08-15 13:03:12,988:INFO:Declaring metric variables
2023-08-15 13:03:12,988:INFO:Importing untrained model
2023-08-15 13:03:12,988:INFO:Declaring custom model
2023-08-15 13:03:12,989:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 13:03:12,989:INFO:Starting cross validation
2023-08-15 13:03:12,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:03:16,130:INFO:Calculating mean and std
2023-08-15 13:03:16,131:INFO:Creating metrics dataframe
2023-08-15 13:03:16,132:INFO:Finalizing model
2023-08-15 13:03:16,846:INFO:Uploading results into container
2023-08-15 13:03:16,846:INFO:Uploading model into container now
2023-08-15 13:03:16,847:INFO:_master_model_container: 20
2023-08-15 13:03:16,847:INFO:_display_container: 5
2023-08-15 13:03:16,847:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 13:03:16,847:INFO:create_model() successfully completed......................................
2023-08-15 13:03:16,929:INFO:SubProcess create_model() end ==================================
2023-08-15 13:03:16,930:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9194
2023-08-15 13:03:16,930:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9193
2023-08-15 13:03:16,930:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-15 13:03:16,930:INFO:choose_better completed
2023-08-15 13:03:16,930:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-15 13:03:16,937:INFO:_master_model_container: 20
2023-08-15 13:03:16,937:INFO:_display_container: 4
2023-08-15 13:03:16,937:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 13:03:16,937:INFO:tune_model() successfully completed......................................
2023-08-15 13:05:04,202:INFO:Initializing create_model()
2023-08-15 13:05:04,202:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 13:05:04,202:INFO:Checking exceptions
2023-08-15 13:05:04,212:INFO:Importing libraries
2023-08-15 13:05:04,213:INFO:Copying training dataset
2023-08-15 13:05:04,273:INFO:Defining folds
2023-08-15 13:05:04,273:INFO:Declaring metric variables
2023-08-15 13:05:04,275:INFO:Importing untrained model
2023-08-15 13:05:04,278:INFO:Logistic Regression Imported successfully
2023-08-15 13:05:04,282:INFO:Starting cross validation
2023-08-15 13:05:04,283:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:05:57,938:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:58,330:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:58,373:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:58,432:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:58,609:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:58,708:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:58,765:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:58,822:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:58,928:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:05:59,156:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:06:00,403:INFO:Calculating mean and std
2023-08-15 13:06:00,404:INFO:Creating metrics dataframe
2023-08-15 13:06:00,408:INFO:Finalizing model
2023-08-15 13:06:12,224:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:06:12,380:INFO:Uploading results into container
2023-08-15 13:06:12,381:INFO:Uploading model into container now
2023-08-15 13:06:12,388:INFO:_master_model_container: 21
2023-08-15 13:06:12,388:INFO:_display_container: 5
2023-08-15 13:06:12,389:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 13:06:12,389:INFO:create_model() successfully completed......................................
2023-08-15 13:06:39,689:INFO:Initializing tune_model()
2023-08-15 13:06:39,689:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>)
2023-08-15 13:06:39,689:INFO:Checking exceptions
2023-08-15 13:06:39,719:INFO:Copying training dataset
2023-08-15 13:06:39,754:INFO:Checking base model
2023-08-15 13:06:39,754:INFO:Base model : Logistic Regression
2023-08-15 13:06:39,757:INFO:Declaring metric variables
2023-08-15 13:06:39,759:INFO:Defining Hyperparameters
2023-08-15 13:06:39,858:INFO:Tuning with n_jobs=-1
2023-08-15 13:06:39,858:INFO:Initializing RandomizedSearchCV
2023-08-15 13:08:25,085:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:08:25,877:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:08:25,993:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:08:26,643:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:08:27,307:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:09:45,911:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:09:48,911:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:09:54,238:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:01,057:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:02,477:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:07,749:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:10,212:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:10,343:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:11,027:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:11,243:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:11,921:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:13,664:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:15,449:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:10:15,877:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:26,948:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:31,880:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:39,437:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:47,428:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:52,248:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:53,320:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:58,792:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:59,551:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:11:59,713:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:12:00,959:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:12:04,731:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:12:06,522:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:09,165:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:16,721:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:17,170:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:17,417:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:17,499:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:18,285:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:21,356:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:29,468:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:34,114:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:37,580:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:41,158:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:43,977:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:46,365:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:47,754:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:49,678:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:53,417:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:53,748:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:54,302:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:13:55,099:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:14:55,656:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:03,079:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:04,198:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:04,632:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:04,935:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:05,790:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:05,935:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:07,035:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:11,922:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:16,365:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:20,671:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:20,871:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:21,306:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 7.689}
2023-08-15 13:15:21,307:INFO:Hyperparameter search completed
2023-08-15 13:15:21,307:INFO:SubProcess create_model() called ==================================
2023-08-15 13:15:21,308:INFO:Initializing create_model()
2023-08-15 13:15:21,308:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001675697E0E0>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 7.689})
2023-08-15 13:15:21,308:INFO:Checking exceptions
2023-08-15 13:15:21,308:INFO:Importing libraries
2023-08-15 13:15:21,308:INFO:Copying training dataset
2023-08-15 13:15:21,362:INFO:Defining folds
2023-08-15 13:15:21,363:INFO:Declaring metric variables
2023-08-15 13:15:21,365:INFO:Importing untrained model
2023-08-15 13:15:21,365:INFO:Declaring custom model
2023-08-15 13:15:21,367:INFO:Logistic Regression Imported successfully
2023-08-15 13:15:21,371:INFO:Starting cross validation
2023-08-15 13:15:21,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:15:24,757:INFO:Calculating mean and std
2023-08-15 13:15:24,758:INFO:Creating metrics dataframe
2023-08-15 13:15:24,762:INFO:Finalizing model
2023-08-15 13:15:36,400:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:15:36,576:INFO:Uploading results into container
2023-08-15 13:15:36,577:INFO:Uploading model into container now
2023-08-15 13:15:36,577:INFO:_master_model_container: 22
2023-08-15 13:15:36,577:INFO:_display_container: 6
2023-08-15 13:15:36,578:INFO:LogisticRegression(C=7.689, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 13:15:36,578:INFO:create_model() successfully completed......................................
2023-08-15 13:15:36,673:INFO:SubProcess create_model() end ==================================
2023-08-15 13:15:36,674:INFO:choose_better activated
2023-08-15 13:15:36,676:INFO:SubProcess create_model() called ==================================
2023-08-15 13:15:36,676:INFO:Initializing create_model()
2023-08-15 13:15:36,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 13:15:36,677:INFO:Checking exceptions
2023-08-15 13:15:36,678:INFO:Importing libraries
2023-08-15 13:15:36,678:INFO:Copying training dataset
2023-08-15 13:15:36,731:INFO:Defining folds
2023-08-15 13:15:36,732:INFO:Declaring metric variables
2023-08-15 13:15:36,732:INFO:Importing untrained model
2023-08-15 13:15:36,732:INFO:Declaring custom model
2023-08-15 13:15:36,732:INFO:Logistic Regression Imported successfully
2023-08-15 13:15:36,732:INFO:Starting cross validation
2023-08-15 13:15:36,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:15:40,130:INFO:Calculating mean and std
2023-08-15 13:15:40,130:INFO:Creating metrics dataframe
2023-08-15 13:15:40,132:INFO:Finalizing model
2023-08-15 13:15:40,845:INFO:Uploading results into container
2023-08-15 13:15:40,845:INFO:Uploading model into container now
2023-08-15 13:15:40,846:INFO:_master_model_container: 23
2023-08-15 13:15:40,846:INFO:_display_container: 7
2023-08-15 13:15:40,846:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 13:15:40,846:INFO:create_model() successfully completed......................................
2023-08-15 13:15:40,926:INFO:SubProcess create_model() end ==================================
2023-08-15 13:15:40,927:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.919
2023-08-15 13:15:40,927:INFO:LogisticRegression(C=7.689, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.919
2023-08-15 13:15:40,927:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-08-15 13:15:40,927:INFO:choose_better completed
2023-08-15 13:15:40,927:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-15 13:15:40,933:INFO:_master_model_container: 23
2023-08-15 13:15:40,934:INFO:_display_container: 6
2023-08-15 13:15:40,934:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 13:15:40,934:INFO:tune_model() successfully completed......................................
2023-08-15 13:17:47,118:INFO:Initializing create_model()
2023-08-15 13:17:47,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 13:17:47,118:INFO:Checking exceptions
2023-08-15 13:17:47,129:INFO:Importing libraries
2023-08-15 13:17:47,130:INFO:Copying training dataset
2023-08-15 13:17:47,188:INFO:Defining folds
2023-08-15 13:17:47,188:INFO:Declaring metric variables
2023-08-15 13:17:47,191:INFO:Importing untrained model
2023-08-15 13:17:47,193:INFO:Naive Bayes Imported successfully
2023-08-15 13:17:47,198:INFO:Starting cross validation
2023-08-15 13:17:47,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:17:51,146:INFO:Calculating mean and std
2023-08-15 13:17:51,146:INFO:Creating metrics dataframe
2023-08-15 13:17:51,150:INFO:Finalizing model
2023-08-15 13:17:51,951:INFO:Uploading results into container
2023-08-15 13:17:51,952:INFO:Uploading model into container now
2023-08-15 13:17:51,958:INFO:_master_model_container: 24
2023-08-15 13:17:51,958:INFO:_display_container: 7
2023-08-15 13:17:51,959:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 13:17:51,959:INFO:create_model() successfully completed......................................
2023-08-15 13:17:54,526:INFO:Initializing tune_model()
2023-08-15 13:17:54,526:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>)
2023-08-15 13:17:54,526:INFO:Checking exceptions
2023-08-15 13:17:54,556:INFO:Copying training dataset
2023-08-15 13:17:54,592:INFO:Checking base model
2023-08-15 13:17:54,592:INFO:Base model : Naive Bayes
2023-08-15 13:17:54,595:INFO:Declaring metric variables
2023-08-15 13:17:54,597:INFO:Defining Hyperparameters
2023-08-15 13:17:54,702:INFO:Tuning with n_jobs=-1
2023-08-15 13:17:54,702:INFO:Initializing RandomizedSearchCV
2023-08-15 13:18:22,366:INFO:best_params: {'actual_estimator__var_smoothing': 1}
2023-08-15 13:18:22,367:INFO:Hyperparameter search completed
2023-08-15 13:18:22,367:INFO:SubProcess create_model() called ==================================
2023-08-15 13:18:22,369:INFO:Initializing create_model()
2023-08-15 13:18:22,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016767C35BA0>, model_only=True, return_train_score=False, kwargs={'var_smoothing': 1})
2023-08-15 13:18:22,369:INFO:Checking exceptions
2023-08-15 13:18:22,369:INFO:Importing libraries
2023-08-15 13:18:22,369:INFO:Copying training dataset
2023-08-15 13:18:22,421:INFO:Defining folds
2023-08-15 13:18:22,421:INFO:Declaring metric variables
2023-08-15 13:18:22,423:INFO:Importing untrained model
2023-08-15 13:18:22,423:INFO:Declaring custom model
2023-08-15 13:18:22,425:INFO:Naive Bayes Imported successfully
2023-08-15 13:18:22,428:INFO:Starting cross validation
2023-08-15 13:18:22,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:18:23,995:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,087:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,112:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,153:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,206:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,225:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,269:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,308:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,323:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:24,535:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:18:25,905:INFO:Calculating mean and std
2023-08-15 13:18:25,906:INFO:Creating metrics dataframe
2023-08-15 13:18:25,910:INFO:Finalizing model
2023-08-15 13:18:26,706:INFO:Uploading results into container
2023-08-15 13:18:26,707:INFO:Uploading model into container now
2023-08-15 13:18:26,707:INFO:_master_model_container: 25
2023-08-15 13:18:26,707:INFO:_display_container: 8
2023-08-15 13:18:26,707:INFO:GaussianNB(priors=None, var_smoothing=1)
2023-08-15 13:18:26,707:INFO:create_model() successfully completed......................................
2023-08-15 13:18:26,795:INFO:SubProcess create_model() end ==================================
2023-08-15 13:18:26,795:INFO:choose_better activated
2023-08-15 13:18:26,797:INFO:SubProcess create_model() called ==================================
2023-08-15 13:18:26,797:INFO:Initializing create_model()
2023-08-15 13:18:26,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 13:18:26,798:INFO:Checking exceptions
2023-08-15 13:18:26,799:INFO:Importing libraries
2023-08-15 13:18:26,799:INFO:Copying training dataset
2023-08-15 13:18:26,851:INFO:Defining folds
2023-08-15 13:18:26,851:INFO:Declaring metric variables
2023-08-15 13:18:26,852:INFO:Importing untrained model
2023-08-15 13:18:26,852:INFO:Declaring custom model
2023-08-15 13:18:26,852:INFO:Naive Bayes Imported successfully
2023-08-15 13:18:26,852:INFO:Starting cross validation
2023-08-15 13:18:26,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:18:30,257:INFO:Calculating mean and std
2023-08-15 13:18:30,257:INFO:Creating metrics dataframe
2023-08-15 13:18:30,259:INFO:Finalizing model
2023-08-15 13:18:31,078:INFO:Uploading results into container
2023-08-15 13:18:31,079:INFO:Uploading model into container now
2023-08-15 13:18:31,079:INFO:_master_model_container: 26
2023-08-15 13:18:31,079:INFO:_display_container: 9
2023-08-15 13:18:31,079:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 13:18:31,079:INFO:create_model() successfully completed......................................
2023-08-15 13:18:31,159:INFO:SubProcess create_model() end ==================================
2023-08-15 13:18:31,159:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Accuracy is 0.6227
2023-08-15 13:18:31,159:INFO:GaussianNB(priors=None, var_smoothing=1) result for Accuracy is 0.919
2023-08-15 13:18:31,159:INFO:GaussianNB(priors=None, var_smoothing=1) is best model
2023-08-15 13:18:31,159:INFO:choose_better completed
2023-08-15 13:18:31,165:INFO:_master_model_container: 26
2023-08-15 13:18:31,166:INFO:_display_container: 8
2023-08-15 13:18:31,166:INFO:GaussianNB(priors=None, var_smoothing=1)
2023-08-15 13:18:31,166:INFO:tune_model() successfully completed......................................
2023-08-15 13:22:23,873:INFO:Initializing evaluate_model()
2023-08-15 13:22:23,873:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:22:23,907:INFO:Initializing plot_model()
2023-08-15 13:22:23,908:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:22:23,908:INFO:Checking exceptions
2023-08-15 13:22:23,929:INFO:Preloading libraries
2023-08-15 13:22:23,934:INFO:Copying training dataset
2023-08-15 13:22:23,934:INFO:Plot type: pipeline
2023-08-15 13:22:24,068:INFO:Visual Rendered Successfully
2023-08-15 13:22:24,151:INFO:plot_model() successfully completed......................................
2023-08-15 13:22:34,735:INFO:Initializing evaluate_model()
2023-08-15 13:22:34,735:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:22:34,771:INFO:Initializing plot_model()
2023-08-15 13:22:34,771:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:22:34,771:INFO:Checking exceptions
2023-08-15 13:22:34,793:INFO:Preloading libraries
2023-08-15 13:22:34,793:INFO:Copying training dataset
2023-08-15 13:22:34,793:INFO:Plot type: pipeline
2023-08-15 13:22:34,880:INFO:Visual Rendered Successfully
2023-08-15 13:22:34,962:INFO:plot_model() successfully completed......................................
2023-08-15 13:22:39,488:INFO:Initializing evaluate_model()
2023-08-15 13:22:39,488:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=GaussianNB(priors=None, var_smoothing=1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:22:39,513:INFO:Initializing plot_model()
2023-08-15 13:22:39,513:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:22:39,513:INFO:Checking exceptions
2023-08-15 13:22:39,534:INFO:Preloading libraries
2023-08-15 13:22:39,534:INFO:Copying training dataset
2023-08-15 13:22:39,534:INFO:Plot type: pipeline
2023-08-15 13:22:39,621:INFO:Visual Rendered Successfully
2023-08-15 13:22:39,699:INFO:plot_model() successfully completed......................................
2023-08-15 13:23:46,694:INFO:Initializing create_model()
2023-08-15 13:23:46,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 13:23:46,695:INFO:Checking exceptions
2023-08-15 13:23:46,705:INFO:Importing libraries
2023-08-15 13:23:46,705:INFO:Copying training dataset
2023-08-15 13:23:46,786:INFO:Defining folds
2023-08-15 13:23:46,786:INFO:Declaring metric variables
2023-08-15 13:23:46,789:INFO:Importing untrained model
2023-08-15 13:23:46,791:INFO:Random Forest Classifier Imported successfully
2023-08-15 13:23:46,795:INFO:Starting cross validation
2023-08-15 13:23:46,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:24:22,630:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.88s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:24:24,644:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.32s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:24:27,803:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.42s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:24:28,963:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:24:29,121:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:24:32,786:INFO:Calculating mean and std
2023-08-15 13:24:32,787:INFO:Creating metrics dataframe
2023-08-15 13:24:32,792:INFO:Finalizing model
2023-08-15 13:24:37,774:INFO:Uploading results into container
2023-08-15 13:24:37,775:INFO:Uploading model into container now
2023-08-15 13:24:37,783:INFO:_master_model_container: 27
2023-08-15 13:24:37,783:INFO:_display_container: 9
2023-08-15 13:24:37,783:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-15 13:24:37,784:INFO:create_model() successfully completed......................................
2023-08-15 13:27:08,184:INFO:Initializing tune_model()
2023-08-15 13:27:08,184:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>)
2023-08-15 13:27:08,184:INFO:Checking exceptions
2023-08-15 13:27:08,216:INFO:Copying training dataset
2023-08-15 13:27:08,257:INFO:Checking base model
2023-08-15 13:27:08,257:INFO:Base model : Random Forest Classifier
2023-08-15 13:27:08,260:INFO:Declaring metric variables
2023-08-15 13:27:08,262:INFO:Defining Hyperparameters
2023-08-15 13:27:08,354:INFO:Tuning with n_jobs=-1
2023-08-15 13:27:08,354:INFO:Initializing RandomizedSearchCV
2023-08-15 13:27:14,605:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:15,968:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:16,225:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:16,282:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:16,906:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:17,027:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:25,133:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.32s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:29,102:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.31s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:31,389:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:31,391:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:31,391:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:31,714:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:33,787:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:34,294:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.10s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:34,680:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:34,844:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:34,877:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:40,894:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:41,373:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:42,364:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:43,533:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:44,123:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:44,861:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.09s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:44,984:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:45,820:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:45,846:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.27s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:46,308:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:47,020:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:47,387:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:47,698:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:47,938:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:47,978:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:27:48,844:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:49,132:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 13:27:50,050:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 13:27:50,705:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:51,115:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.45s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:51,467:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:51,800:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:27:57,836:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-15 13:27:59,283:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-15 13:28:00,855:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-15 13:28:02,129:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:05,005:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.26s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:05,405:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:05,820:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.29s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:06,136:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:07,044:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:08,713:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:08,754:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:08,855:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.46s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:10,314:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:11,534:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:12,320:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:16,054:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.85s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:16,498:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:33,416:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:36,741:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 4.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:40,515:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.90s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:43,596:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:44,352:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 13:28:47,147:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.39s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:47,915:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.27s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:49,445:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 13:28:50,473:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.42s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:52,144:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.84s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:52,364:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:52,901:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.91s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:53,552:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.44s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:54,196:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:55,258:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:55,840:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:55,913:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.40s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:56,473:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:56,742:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.34s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:56,805:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:56,981:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:57,133:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:57,450:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:57,492:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.29s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:58,497:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:59,341:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:28:59,396:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:59,418:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:59,471:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:59,523:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.05s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:28:59,827:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:29:00,659:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:29:01,613:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:29:01,778:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:29:02,630:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:29:03,803:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:29:04,594:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:29:05,988:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:29:08,170:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:29:09,811:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:30:53,029:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.48s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:30:59,762:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.95s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:31:10,568:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.37s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:31:12,212:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:31:18,005:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.28s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:31:18,294:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:31:29,061:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.36s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:31:35,812:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_transformer = self._memory_fit(

2023-08-15 13:31:37,831:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.98s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:31:43,795:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.32s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:31:51,257:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.17s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:31:53,563:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.23s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:31:58,172:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.02s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:00,925:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:02,821:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.11s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:06,466:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.17s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:09,084:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.27s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:13,415:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.39s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:14,213:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:20,264:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.91s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:20,823:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:22,726:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.33s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:24,702:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:29,664:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.15s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:30,557:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.28s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:31,471:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.26s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:35,392:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.85s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:40,211:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.97s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:40,804:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:42,662:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.23s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:45,951:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 13:32:50,133:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.10s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:50,173:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.88s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:32:53,057:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-15 13:32:56,588:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.45s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:32:58,441:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.20s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:33:03,925:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:33:10,189:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.04s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:33:17,246:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.17s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:33:18,487:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:33:25,211:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.35s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:33:27,632:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.12s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:33:34,325:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.22s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:12,026:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:34:16,862:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.07s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:18,871:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.09s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:34:23,337:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.12s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:24,878:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:34:28,646:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:31,078:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:34:34,459:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:35,862:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:34:38,782:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:39,145:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:34:41,255:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:41,653:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 13:34:42,994:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:49,296:INFO:best_params: {'actual_estimator__n_estimators': 70, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.1, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 3, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': {}, 'actual_estimator__bootstrap': False}
2023-08-15 13:34:49,297:INFO:Hyperparameter search completed
2023-08-15 13:34:49,297:INFO:SubProcess create_model() called ==================================
2023-08-15 13:34:49,298:INFO:Initializing create_model()
2023-08-15 13:34:49,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001676398EBC0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 70, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.1, 'max_features': 'sqrt', 'max_depth': 3, 'criterion': 'gini', 'class_weight': {}, 'bootstrap': False})
2023-08-15 13:34:49,298:INFO:Checking exceptions
2023-08-15 13:34:49,298:INFO:Importing libraries
2023-08-15 13:34:49,298:INFO:Copying training dataset
2023-08-15 13:34:49,351:INFO:Defining folds
2023-08-15 13:34:49,351:INFO:Declaring metric variables
2023-08-15 13:34:49,354:INFO:Importing untrained model
2023-08-15 13:34:49,354:INFO:Declaring custom model
2023-08-15 13:34:49,357:INFO:Random Forest Classifier Imported successfully
2023-08-15 13:34:49,361:INFO:Starting cross validation
2023-08-15 13:34:49,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:34:51,164:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,206:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,217:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,276:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,306:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,337:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,364:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,365:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,380:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:51,436:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 13:34:53,411:INFO:Calculating mean and std
2023-08-15 13:34:53,412:INFO:Creating metrics dataframe
2023-08-15 13:34:53,416:INFO:Finalizing model
2023-08-15 13:34:54,665:INFO:Uploading results into container
2023-08-15 13:34:54,666:INFO:Uploading model into container now
2023-08-15 13:34:54,666:INFO:_master_model_container: 28
2023-08-15 13:34:54,666:INFO:_display_container: 10
2023-08-15 13:34:54,667:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=70, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-15 13:34:54,667:INFO:create_model() successfully completed......................................
2023-08-15 13:34:54,762:INFO:SubProcess create_model() end ==================================
2023-08-15 13:34:54,763:INFO:choose_better activated
2023-08-15 13:34:54,765:INFO:SubProcess create_model() called ==================================
2023-08-15 13:34:54,765:INFO:Initializing create_model()
2023-08-15 13:34:54,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 13:34:54,766:INFO:Checking exceptions
2023-08-15 13:34:54,767:INFO:Importing libraries
2023-08-15 13:34:54,767:INFO:Copying training dataset
2023-08-15 13:34:54,822:INFO:Defining folds
2023-08-15 13:34:54,822:INFO:Declaring metric variables
2023-08-15 13:34:54,822:INFO:Importing untrained model
2023-08-15 13:34:54,822:INFO:Declaring custom model
2023-08-15 13:34:54,823:INFO:Random Forest Classifier Imported successfully
2023-08-15 13:34:54,823:INFO:Starting cross validation
2023-08-15 13:34:54,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 13:34:57,686:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:57,925:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:34:57,995:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.53s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 13:35:00,651:INFO:Calculating mean and std
2023-08-15 13:35:00,651:INFO:Creating metrics dataframe
2023-08-15 13:35:00,653:INFO:Finalizing model
2023-08-15 13:35:01,693:INFO:Uploading results into container
2023-08-15 13:35:01,693:INFO:Uploading model into container now
2023-08-15 13:35:01,694:INFO:_master_model_container: 29
2023-08-15 13:35:01,694:INFO:_display_container: 11
2023-08-15 13:35:01,694:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-15 13:35:01,694:INFO:create_model() successfully completed......................................
2023-08-15 13:35:01,777:INFO:SubProcess create_model() end ==================================
2023-08-15 13:35:01,778:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.9178
2023-08-15 13:35:01,778:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=70, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.919
2023-08-15 13:35:01,778:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=70, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-08-15 13:35:01,779:INFO:choose_better completed
2023-08-15 13:35:01,785:INFO:_master_model_container: 29
2023-08-15 13:35:01,785:INFO:_display_container: 10
2023-08-15 13:35:01,785:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},
                       criterion='gini', max_depth=3, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.1, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       n_estimators=70, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-15 13:35:01,785:INFO:tune_model() successfully completed......................................
2023-08-15 13:53:31,909:INFO:Initializing evaluate_model()
2023-08-15 13:53:31,909:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:53:31,939:INFO:Initializing plot_model()
2023-08-15 13:53:31,939:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:53:31,939:INFO:Checking exceptions
2023-08-15 13:53:31,958:INFO:Preloading libraries
2023-08-15 13:53:31,962:INFO:Copying training dataset
2023-08-15 13:53:31,962:INFO:Plot type: pipeline
2023-08-15 13:53:32,072:INFO:Visual Rendered Successfully
2023-08-15 13:53:32,174:INFO:plot_model() successfully completed......................................
2023-08-15 13:53:36,936:INFO:Initializing evaluate_model()
2023-08-15 13:53:36,936:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:53:36,958:INFO:Initializing plot_model()
2023-08-15 13:53:36,959:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:53:36,959:INFO:Checking exceptions
2023-08-15 13:53:36,978:INFO:Preloading libraries
2023-08-15 13:53:36,978:INFO:Copying training dataset
2023-08-15 13:53:36,978:INFO:Plot type: pipeline
2023-08-15 13:53:37,068:INFO:Visual Rendered Successfully
2023-08-15 13:53:37,156:INFO:plot_model() successfully completed......................................
2023-08-15 13:53:40,689:INFO:Initializing evaluate_model()
2023-08-15 13:53:40,690:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:53:40,716:INFO:Initializing plot_model()
2023-08-15 13:53:40,716:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:53:40,716:INFO:Checking exceptions
2023-08-15 13:53:40,734:INFO:Preloading libraries
2023-08-15 13:53:40,735:INFO:Copying training dataset
2023-08-15 13:53:40,735:INFO:Plot type: pipeline
2023-08-15 13:53:40,825:INFO:Visual Rendered Successfully
2023-08-15 13:53:40,913:INFO:plot_model() successfully completed......................................
2023-08-15 13:53:50,669:INFO:Initializing evaluate_model()
2023-08-15 13:53:50,669:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:53:50,692:INFO:Initializing plot_model()
2023-08-15 13:53:50,692:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:53:50,692:INFO:Checking exceptions
2023-08-15 13:53:50,708:INFO:Preloading libraries
2023-08-15 13:53:50,709:INFO:Copying training dataset
2023-08-15 13:53:50,709:INFO:Plot type: pipeline
2023-08-15 13:53:50,803:INFO:Visual Rendered Successfully
2023-08-15 13:53:50,891:INFO:plot_model() successfully completed......................................
2023-08-15 13:54:17,648:INFO:Initializing plot_model()
2023-08-15 13:54:17,649:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:54:17,649:INFO:Checking exceptions
2023-08-15 13:54:17,669:INFO:Preloading libraries
2023-08-15 13:54:17,673:INFO:Copying training dataset
2023-08-15 13:54:17,673:INFO:Plot type: parameter
2023-08-15 13:54:17,677:INFO:Visual Rendered Successfully
2023-08-15 13:54:17,765:INFO:plot_model() successfully completed......................................
2023-08-15 13:54:19,596:INFO:Initializing plot_model()
2023-08-15 13:54:19,596:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:54:19,596:INFO:Checking exceptions
2023-08-15 13:54:19,615:INFO:Preloading libraries
2023-08-15 13:54:19,619:INFO:Copying training dataset
2023-08-15 13:54:19,620:INFO:Plot type: auc
2023-08-15 13:54:20,977:INFO:Fitting Model
2023-08-15 13:54:20,979:INFO:Scoring test/hold-out set
2023-08-15 13:54:21,237:INFO:Visual Rendered Successfully
2023-08-15 13:54:21,319:INFO:plot_model() successfully completed......................................
2023-08-15 13:54:28,863:INFO:Initializing plot_model()
2023-08-15 13:54:28,863:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:54:28,863:INFO:Checking exceptions
2023-08-15 13:54:28,883:INFO:Preloading libraries
2023-08-15 13:54:28,886:INFO:Copying training dataset
2023-08-15 13:54:28,887:INFO:Plot type: confusion_matrix
2023-08-15 13:54:29,210:INFO:Fitting Model
2023-08-15 13:54:29,212:INFO:Scoring test/hold-out set
2023-08-15 13:54:29,385:INFO:Visual Rendered Successfully
2023-08-15 13:54:29,481:INFO:plot_model() successfully completed......................................
2023-08-15 13:54:30,724:INFO:Initializing plot_model()
2023-08-15 13:54:30,724:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:54:30,724:INFO:Checking exceptions
2023-08-15 13:54:30,744:INFO:Preloading libraries
2023-08-15 13:54:30,747:INFO:Copying training dataset
2023-08-15 13:54:30,747:INFO:Plot type: threshold
2023-08-15 13:54:31,073:INFO:Fitting Model
2023-08-15 13:54:31,215:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:31,215:INFO:[LightGBM] [Info] Number of positive: 14974, number of negative: 169874
2023-08-15 13:54:31,234:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005145 seconds.
2023-08-15 13:54:31,234:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:31,234:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:31,234:INFO:[LightGBM] [Info] Total Bins 850
2023-08-15 13:54:31,234:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:31,236:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081007 -> initscore=-2.428742
2023-08-15 13:54:31,236:INFO:[LightGBM] [Info] Start training from score -2.428742
2023-08-15 13:54:32,026:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:32,027:INFO:[LightGBM] [Info] Number of positive: 15012, number of negative: 169836
2023-08-15 13:54:32,044:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004755 seconds.
2023-08-15 13:54:32,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:32,044:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:32,044:INFO:[LightGBM] [Info] Total Bins 847
2023-08-15 13:54:32,044:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:32,045:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081213 -> initscore=-2.425983
2023-08-15 13:54:32,045:INFO:[LightGBM] [Info] Start training from score -2.425983
2023-08-15 13:54:32,841:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:32,842:INFO:[LightGBM] [Info] Number of positive: 14921, number of negative: 169927
2023-08-15 13:54:32,859:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005382 seconds.
2023-08-15 13:54:32,859:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:32,859:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:32,860:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:32,860:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:32,861:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080720 -> initscore=-2.432599
2023-08-15 13:54:32,861:INFO:[LightGBM] [Info] Start training from score -2.432599
2023-08-15 13:54:33,633:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:33,633:INFO:[LightGBM] [Info] Number of positive: 14978, number of negative: 169870
2023-08-15 13:54:33,650:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005054 seconds.
2023-08-15 13:54:33,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:33,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:33,651:INFO:[LightGBM] [Info] Total Bins 850
2023-08-15 13:54:33,651:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:33,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081029 -> initscore=-2.428451
2023-08-15 13:54:33,652:INFO:[LightGBM] [Info] Start training from score -2.428451
2023-08-15 13:54:34,427:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:34,427:INFO:[LightGBM] [Info] Number of positive: 14873, number of negative: 169975
2023-08-15 13:54:34,445:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004940 seconds.
2023-08-15 13:54:34,445:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:34,445:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:34,445:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:54:34,446:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:34,446:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080461 -> initscore=-2.436104
2023-08-15 13:54:34,447:INFO:[LightGBM] [Info] Start training from score -2.436104
2023-08-15 13:54:35,243:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:35,243:INFO:[LightGBM] [Info] Number of positive: 14956, number of negative: 169892
2023-08-15 13:54:35,260:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005402 seconds.
2023-08-15 13:54:35,260:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:35,260:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:35,260:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:54:35,260:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:35,261:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080910 -> initscore=-2.430050
2023-08-15 13:54:35,261:INFO:[LightGBM] [Info] Start training from score -2.430050
2023-08-15 13:54:36,069:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:36,069:INFO:[LightGBM] [Info] Number of positive: 14979, number of negative: 169869
2023-08-15 13:54:36,088:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005421 seconds.
2023-08-15 13:54:36,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:36,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:36,089:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:36,089:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:36,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081034 -> initscore=-2.428378
2023-08-15 13:54:36,090:INFO:[LightGBM] [Info] Start training from score -2.428378
2023-08-15 13:54:36,869:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:36,869:INFO:[LightGBM] [Info] Number of positive: 15026, number of negative: 169822
2023-08-15 13:54:36,886:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005184 seconds.
2023-08-15 13:54:36,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:36,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:36,886:INFO:[LightGBM] [Info] Total Bins 856
2023-08-15 13:54:36,886:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:36,887:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081288 -> initscore=-2.424969
2023-08-15 13:54:36,887:INFO:[LightGBM] [Info] Start training from score -2.424969
2023-08-15 13:54:37,659:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:37,659:INFO:[LightGBM] [Info] Number of positive: 14937, number of negative: 169911
2023-08-15 13:54:37,675:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005206 seconds.
2023-08-15 13:54:37,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:37,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:37,675:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:37,675:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:37,676:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080807 -> initscore=-2.431433
2023-08-15 13:54:37,676:INFO:[LightGBM] [Info] Start training from score -2.431433
2023-08-15 13:54:38,450:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:38,451:INFO:[LightGBM] [Info] Number of positive: 14919, number of negative: 169929
2023-08-15 13:54:38,467:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004769 seconds.
2023-08-15 13:54:38,467:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:38,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:38,468:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:38,468:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:38,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080710 -> initscore=-2.432745
2023-08-15 13:54:38,469:INFO:[LightGBM] [Info] Start training from score -2.432745
2023-08-15 13:54:39,245:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:39,245:INFO:[LightGBM] [Info] Number of positive: 14963, number of negative: 169885
2023-08-15 13:54:39,262:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005289 seconds.
2023-08-15 13:54:39,262:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:39,262:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:39,262:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:39,262:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:39,263:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080948 -> initscore=-2.429541
2023-08-15 13:54:39,263:INFO:[LightGBM] [Info] Start training from score -2.429541
2023-08-15 13:54:40,043:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:40,044:INFO:[LightGBM] [Info] Number of positive: 15021, number of negative: 169827
2023-08-15 13:54:40,060:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004883 seconds.
2023-08-15 13:54:40,060:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:40,060:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:40,060:INFO:[LightGBM] [Info] Total Bins 854
2023-08-15 13:54:40,061:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:40,062:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081261 -> initscore=-2.425331
2023-08-15 13:54:40,062:INFO:[LightGBM] [Info] Start training from score -2.425331
2023-08-15 13:54:40,856:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:40,857:INFO:[LightGBM] [Info] Number of positive: 14915, number of negative: 169933
2023-08-15 13:54:40,876:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005555 seconds.
2023-08-15 13:54:40,876:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:40,876:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:40,876:INFO:[LightGBM] [Info] Total Bins 850
2023-08-15 13:54:40,876:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:40,877:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080688 -> initscore=-2.433037
2023-08-15 13:54:40,877:INFO:[LightGBM] [Info] Start training from score -2.433037
2023-08-15 13:54:41,686:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:41,686:INFO:[LightGBM] [Info] Number of positive: 14961, number of negative: 169887
2023-08-15 13:54:41,703:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005725 seconds.
2023-08-15 13:54:41,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:41,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:41,704:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:54:41,704:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:41,705:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080937 -> initscore=-2.429687
2023-08-15 13:54:41,705:INFO:[LightGBM] [Info] Start training from score -2.429687
2023-08-15 13:54:42,519:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:42,519:INFO:[LightGBM] [Info] Number of positive: 14995, number of negative: 169853
2023-08-15 13:54:42,539:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006836 seconds.
2023-08-15 13:54:42,539:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:42,539:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:42,540:INFO:[LightGBM] [Info] Total Bins 852
2023-08-15 13:54:42,540:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:42,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081121 -> initscore=-2.427217
2023-08-15 13:54:42,541:INFO:[LightGBM] [Info] Start training from score -2.427217
2023-08-15 13:54:43,421:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:43,421:INFO:[LightGBM] [Info] Number of positive: 14987, number of negative: 169861
2023-08-15 13:54:43,438:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004982 seconds.
2023-08-15 13:54:43,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:43,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:43,439:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:54:43,439:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:43,440:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081077 -> initscore=-2.427797
2023-08-15 13:54:43,440:INFO:[LightGBM] [Info] Start training from score -2.427797
2023-08-15 13:54:44,340:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:44,341:INFO:[LightGBM] [Info] Number of positive: 14997, number of negative: 169851
2023-08-15 13:54:44,359:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006012 seconds.
2023-08-15 13:54:44,359:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:44,359:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:44,359:INFO:[LightGBM] [Info] Total Bins 852
2023-08-15 13:54:44,359:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:44,361:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081132 -> initscore=-2.427071
2023-08-15 13:54:44,361:INFO:[LightGBM] [Info] Start training from score -2.427071
2023-08-15 13:54:45,204:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:45,204:INFO:[LightGBM] [Info] Number of positive: 14996, number of negative: 169852
2023-08-15 13:54:45,222:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005078 seconds.
2023-08-15 13:54:45,223:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:45,223:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:45,223:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:54:45,223:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:45,223:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081126 -> initscore=-2.427144
2023-08-15 13:54:45,224:INFO:[LightGBM] [Info] Start training from score -2.427144
2023-08-15 13:54:46,101:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:46,101:INFO:[LightGBM] [Info] Number of positive: 14988, number of negative: 169860
2023-08-15 13:54:46,118:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005423 seconds.
2023-08-15 13:54:46,118:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:46,118:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:46,119:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:46,119:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:46,120:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081083 -> initscore=-2.427725
2023-08-15 13:54:46,120:INFO:[LightGBM] [Info] Start training from score -2.427725
2023-08-15 13:54:46,941:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:46,941:INFO:[LightGBM] [Info] Number of positive: 14912, number of negative: 169936
2023-08-15 13:54:46,958:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005109 seconds.
2023-08-15 13:54:46,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:46,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:46,958:INFO:[LightGBM] [Info] Total Bins 852
2023-08-15 13:54:46,958:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:46,959:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080672 -> initscore=-2.433256
2023-08-15 13:54:46,959:INFO:[LightGBM] [Info] Start training from score -2.433256
2023-08-15 13:54:47,766:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:47,766:INFO:[LightGBM] [Info] Number of positive: 14937, number of negative: 169911
2023-08-15 13:54:47,784:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006103 seconds.
2023-08-15 13:54:47,784:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:47,784:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:47,784:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:54:47,784:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:47,785:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080807 -> initscore=-2.431433
2023-08-15 13:54:47,785:INFO:[LightGBM] [Info] Start training from score -2.431433
2023-08-15 13:54:48,613:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:48,613:INFO:[LightGBM] [Info] Number of positive: 14938, number of negative: 169910
2023-08-15 13:54:48,632:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005323 seconds.
2023-08-15 13:54:48,633:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:48,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:48,633:INFO:[LightGBM] [Info] Total Bins 850
2023-08-15 13:54:48,633:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:48,634:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080812 -> initscore=-2.431361
2023-08-15 13:54:48,634:INFO:[LightGBM] [Info] Start training from score -2.431361
2023-08-15 13:54:49,487:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:49,487:INFO:[LightGBM] [Info] Number of positive: 15000, number of negative: 169848
2023-08-15 13:54:49,505:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006019 seconds.
2023-08-15 13:54:49,505:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:49,505:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:49,505:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:54:49,505:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:49,506:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081148 -> initscore=-2.426854
2023-08-15 13:54:49,506:INFO:[LightGBM] [Info] Start training from score -2.426854
2023-08-15 13:54:50,305:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:50,305:INFO:[LightGBM] [Info] Number of positive: 14989, number of negative: 169859
2023-08-15 13:54:50,322:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005485 seconds.
2023-08-15 13:54:50,322:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:50,322:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:50,323:INFO:[LightGBM] [Info] Total Bins 852
2023-08-15 13:54:50,323:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:50,323:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081088 -> initscore=-2.427652
2023-08-15 13:54:50,324:INFO:[LightGBM] [Info] Start training from score -2.427652
2023-08-15 13:54:51,119:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:51,119:INFO:[LightGBM] [Info] Number of positive: 14988, number of negative: 169860
2023-08-15 13:54:51,138:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005786 seconds.
2023-08-15 13:54:51,138:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:51,138:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:51,138:INFO:[LightGBM] [Info] Total Bins 852
2023-08-15 13:54:51,138:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:51,139:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081083 -> initscore=-2.427725
2023-08-15 13:54:51,139:INFO:[LightGBM] [Info] Start training from score -2.427725
2023-08-15 13:54:52,017:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:52,017:INFO:[LightGBM] [Info] Number of positive: 14997, number of negative: 169851
2023-08-15 13:54:52,034:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004982 seconds.
2023-08-15 13:54:52,035:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:52,035:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:52,035:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:52,035:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:52,036:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081132 -> initscore=-2.427071
2023-08-15 13:54:52,036:INFO:[LightGBM] [Info] Start training from score -2.427071
2023-08-15 13:54:52,908:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:52,909:INFO:[LightGBM] [Info] Number of positive: 14988, number of negative: 169860
2023-08-15 13:54:52,925:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004961 seconds.
2023-08-15 13:54:52,925:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:52,925:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:52,926:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:52,926:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:52,927:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081083 -> initscore=-2.427725
2023-08-15 13:54:52,927:INFO:[LightGBM] [Info] Start training from score -2.427725
2023-08-15 13:54:53,755:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:53,756:INFO:[LightGBM] [Info] Number of positive: 14982, number of negative: 169866
2023-08-15 13:54:53,773:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005138 seconds.
2023-08-15 13:54:53,773:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:53,773:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:53,773:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:53,773:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:53,774:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081050 -> initscore=-2.428160
2023-08-15 13:54:53,774:INFO:[LightGBM] [Info] Start training from score -2.428160
2023-08-15 13:54:54,608:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:54,609:INFO:[LightGBM] [Info] Number of positive: 14979, number of negative: 169869
2023-08-15 13:54:54,625:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004962 seconds.
2023-08-15 13:54:54,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:54,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:54,625:INFO:[LightGBM] [Info] Total Bins 849
2023-08-15 13:54:54,625:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:54,626:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081034 -> initscore=-2.428378
2023-08-15 13:54:54,626:INFO:[LightGBM] [Info] Start training from score -2.428378
2023-08-15 13:54:55,435:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:55,435:INFO:[LightGBM] [Info] Number of positive: 14979, number of negative: 169869
2023-08-15 13:54:55,453:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005896 seconds.
2023-08-15 13:54:55,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:55,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:55,453:INFO:[LightGBM] [Info] Total Bins 848
2023-08-15 13:54:55,453:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:55,454:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081034 -> initscore=-2.428378
2023-08-15 13:54:55,454:INFO:[LightGBM] [Info] Start training from score -2.428378
2023-08-15 13:54:56,232:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:56,232:INFO:[LightGBM] [Info] Number of positive: 14950, number of negative: 169898
2023-08-15 13:54:56,248:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005477 seconds.
2023-08-15 13:54:56,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:56,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:56,248:INFO:[LightGBM] [Info] Total Bins 849
2023-08-15 13:54:56,248:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:56,249:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080877 -> initscore=-2.430487
2023-08-15 13:54:56,249:INFO:[LightGBM] [Info] Start training from score -2.430487
2023-08-15 13:54:57,043:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:57,043:INFO:[LightGBM] [Info] Number of positive: 14995, number of negative: 169853
2023-08-15 13:54:57,058:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004850 seconds.
2023-08-15 13:54:57,058:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:57,059:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:57,059:INFO:[LightGBM] [Info] Total Bins 853
2023-08-15 13:54:57,059:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:57,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081121 -> initscore=-2.427217
2023-08-15 13:54:57,060:INFO:[LightGBM] [Info] Start training from score -2.427217
2023-08-15 13:54:57,844:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:57,844:INFO:[LightGBM] [Info] Number of positive: 15007, number of negative: 169841
2023-08-15 13:54:57,863:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005342 seconds.
2023-08-15 13:54:57,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:57,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:57,863:INFO:[LightGBM] [Info] Total Bins 849
2023-08-15 13:54:57,863:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:57,864:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081186 -> initscore=-2.426346
2023-08-15 13:54:57,864:INFO:[LightGBM] [Info] Start training from score -2.426346
2023-08-15 13:54:58,647:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:58,647:INFO:[LightGBM] [Info] Number of positive: 14955, number of negative: 169893
2023-08-15 13:54:58,664:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005994 seconds.
2023-08-15 13:54:58,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:58,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:58,664:INFO:[LightGBM] [Info] Total Bins 848
2023-08-15 13:54:58,664:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:58,665:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080904 -> initscore=-2.430123
2023-08-15 13:54:58,665:INFO:[LightGBM] [Info] Start training from score -2.430123
2023-08-15 13:54:59,448:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:54:59,448:INFO:[LightGBM] [Info] Number of positive: 14931, number of negative: 169917
2023-08-15 13:54:59,467:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005916 seconds.
2023-08-15 13:54:59,468:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:54:59,468:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:54:59,468:INFO:[LightGBM] [Info] Total Bins 850
2023-08-15 13:54:59,468:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:54:59,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080774 -> initscore=-2.431870
2023-08-15 13:54:59,469:INFO:[LightGBM] [Info] Start training from score -2.431870
2023-08-15 13:55:00,233:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:00,233:INFO:[LightGBM] [Info] Number of positive: 15015, number of negative: 169833
2023-08-15 13:55:00,252:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006150 seconds.
2023-08-15 13:55:00,252:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:00,252:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:00,252:INFO:[LightGBM] [Info] Total Bins 846
2023-08-15 13:55:00,252:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:00,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081229 -> initscore=-2.425766
2023-08-15 13:55:00,253:INFO:[LightGBM] [Info] Start training from score -2.425766
2023-08-15 13:55:01,042:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:01,042:INFO:[LightGBM] [Info] Number of positive: 14939, number of negative: 169909
2023-08-15 13:55:01,061:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005687 seconds.
2023-08-15 13:55:01,061:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:01,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:01,061:INFO:[LightGBM] [Info] Total Bins 854
2023-08-15 13:55:01,061:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:01,062:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080818 -> initscore=-2.431288
2023-08-15 13:55:01,062:INFO:[LightGBM] [Info] Start training from score -2.431288
2023-08-15 13:55:01,860:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:01,860:INFO:[LightGBM] [Info] Number of positive: 14993, number of negative: 169855
2023-08-15 13:55:01,878:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005546 seconds.
2023-08-15 13:55:01,878:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:01,878:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:01,878:INFO:[LightGBM] [Info] Total Bins 849
2023-08-15 13:55:01,878:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:01,879:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081110 -> initscore=-2.427362
2023-08-15 13:55:01,879:INFO:[LightGBM] [Info] Start training from score -2.427362
2023-08-15 13:55:02,672:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:02,672:INFO:[LightGBM] [Info] Number of positive: 14948, number of negative: 169900
2023-08-15 13:55:02,689:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005573 seconds.
2023-08-15 13:55:02,689:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:02,689:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:02,689:INFO:[LightGBM] [Info] Total Bins 849
2023-08-15 13:55:02,690:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:02,690:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080866 -> initscore=-2.430633
2023-08-15 13:55:02,691:INFO:[LightGBM] [Info] Start training from score -2.430633
2023-08-15 13:55:03,482:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:03,482:INFO:[LightGBM] [Info] Number of positive: 14951, number of negative: 169897
2023-08-15 13:55:03,501:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006309 seconds.
2023-08-15 13:55:03,501:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:03,501:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:03,502:INFO:[LightGBM] [Info] Total Bins 850
2023-08-15 13:55:03,502:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:03,502:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080883 -> initscore=-2.430414
2023-08-15 13:55:03,503:INFO:[LightGBM] [Info] Start training from score -2.430414
2023-08-15 13:55:04,290:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:04,290:INFO:[LightGBM] [Info] Number of positive: 14962, number of negative: 169886
2023-08-15 13:55:04,307:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005882 seconds.
2023-08-15 13:55:04,307:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:04,307:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:04,307:INFO:[LightGBM] [Info] Total Bins 855
2023-08-15 13:55:04,307:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:04,308:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080942 -> initscore=-2.429614
2023-08-15 13:55:04,308:INFO:[LightGBM] [Info] Start training from score -2.429614
2023-08-15 13:55:05,117:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:05,117:INFO:[LightGBM] [Info] Number of positive: 15011, number of negative: 169837
2023-08-15 13:55:05,134:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005252 seconds.
2023-08-15 13:55:05,134:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:05,134:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:05,134:INFO:[LightGBM] [Info] Total Bins 852
2023-08-15 13:55:05,134:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:05,135:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081207 -> initscore=-2.426056
2023-08-15 13:55:05,136:INFO:[LightGBM] [Info] Start training from score -2.426056
2023-08-15 13:55:05,980:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:05,981:INFO:[LightGBM] [Info] Number of positive: 14944, number of negative: 169904
2023-08-15 13:55:05,999:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006593 seconds.
2023-08-15 13:55:05,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:05,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:06,000:INFO:[LightGBM] [Info] Total Bins 854
2023-08-15 13:55:06,000:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:06,001:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080845 -> initscore=-2.430924
2023-08-15 13:55:06,001:INFO:[LightGBM] [Info] Start training from score -2.430924
2023-08-15 13:55:06,891:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:06,892:INFO:[LightGBM] [Info] Number of positive: 14958, number of negative: 169890
2023-08-15 13:55:06,909:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005363 seconds.
2023-08-15 13:55:06,909:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:06,909:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:06,909:INFO:[LightGBM] [Info] Total Bins 852
2023-08-15 13:55:06,909:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:06,910:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080921 -> initscore=-2.429905
2023-08-15 13:55:06,910:INFO:[LightGBM] [Info] Start training from score -2.429905
2023-08-15 13:55:07,683:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:07,683:INFO:[LightGBM] [Info] Number of positive: 14965, number of negative: 169883
2023-08-15 13:55:07,701:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005531 seconds.
2023-08-15 13:55:07,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:07,701:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:07,701:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:55:07,702:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:07,703:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080958 -> initscore=-2.429396
2023-08-15 13:55:07,703:INFO:[LightGBM] [Info] Start training from score -2.429396
2023-08-15 13:55:08,504:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:08,505:INFO:[LightGBM] [Info] Number of positive: 15018, number of negative: 169830
2023-08-15 13:55:08,523:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005379 seconds.
2023-08-15 13:55:08,523:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:08,523:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:08,523:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:55:08,523:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:08,524:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081245 -> initscore=-2.425548
2023-08-15 13:55:08,524:INFO:[LightGBM] [Info] Start training from score -2.425548
2023-08-15 13:55:09,317:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:09,317:INFO:[LightGBM] [Info] Number of positive: 14925, number of negative: 169923
2023-08-15 13:55:09,336:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005511 seconds.
2023-08-15 13:55:09,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:09,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:09,336:INFO:[LightGBM] [Info] Total Bins 850
2023-08-15 13:55:09,336:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:09,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080742 -> initscore=-2.432308
2023-08-15 13:55:09,337:INFO:[LightGBM] [Info] Start training from score -2.432308
2023-08-15 13:55:10,123:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:10,123:INFO:[LightGBM] [Info] Number of positive: 14947, number of negative: 169901
2023-08-15 13:55:10,141:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005927 seconds.
2023-08-15 13:55:10,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:10,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:10,141:INFO:[LightGBM] [Info] Total Bins 848
2023-08-15 13:55:10,141:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:10,142:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080861 -> initscore=-2.430705
2023-08-15 13:55:10,142:INFO:[LightGBM] [Info] Start training from score -2.430705
2023-08-15 13:55:10,922:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:10,922:INFO:[LightGBM] [Info] Number of positive: 14977, number of negative: 169871
2023-08-15 13:55:10,938:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005258 seconds.
2023-08-15 13:55:10,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:10,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:10,939:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:55:10,939:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:10,940:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081023 -> initscore=-2.428524
2023-08-15 13:55:10,940:INFO:[LightGBM] [Info] Start training from score -2.428524
2023-08-15 13:55:11,734:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 13:55:11,734:INFO:[LightGBM] [Info] Number of positive: 15010, number of negative: 169838
2023-08-15 13:55:11,753:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005730 seconds.
2023-08-15 13:55:11,753:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:55:11,753:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:55:11,754:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 13:55:11,754:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 41
2023-08-15 13:55:11,755:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.081202 -> initscore=-2.426128
2023-08-15 13:55:11,755:INFO:[LightGBM] [Info] Start training from score -2.426128
2023-08-15 13:55:16,014:INFO:Scoring test/hold-out set
2023-08-15 13:55:16,304:INFO:Visual Rendered Successfully
2023-08-15 13:55:16,386:INFO:plot_model() successfully completed......................................
2023-08-15 13:55:16,393:INFO:Initializing plot_model()
2023-08-15 13:55:16,393:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:55:16,393:INFO:Checking exceptions
2023-08-15 13:55:16,415:INFO:Preloading libraries
2023-08-15 13:55:16,415:INFO:Copying training dataset
2023-08-15 13:55:16,416:INFO:Plot type: threshold
2023-08-15 13:55:16,730:INFO:Fitting Model
2023-08-15 13:55:26,740:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:55:36,805:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:55:47,432:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:55:58,339:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:56:08,600:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:56:18,826:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:56:29,260:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:56:39,412:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:56:49,636:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:56:59,912:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:57:10,026:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:57:20,238:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:57:30,684:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:57:41,142:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:57:51,593:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:58:11,063:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:58:21,286:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:58:31,543:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:58:42,069:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:58:52,415:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:59:02,771:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:59:13,247:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 13:59:19,275:INFO:Initializing plot_model()
2023-08-15 13:59:19,275:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:59:19,275:INFO:Checking exceptions
2023-08-15 13:59:19,303:INFO:Preloading libraries
2023-08-15 13:59:19,325:INFO:Copying training dataset
2023-08-15 13:59:19,325:INFO:Plot type: boundary
2023-08-15 13:59:19,555:INFO:Fitting StandardScaler()
2023-08-15 13:59:19,662:INFO:Fitting PCA()
2023-08-15 13:59:20,245:INFO:Fitting Model
2023-08-15 13:59:20,287:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 13:59:20,288:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.
2023-08-15 13:59:20,289:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 13:59:20,289:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 13:59:20,289:INFO:[LightGBM] [Info] Total Bins 510
2023-08-15 13:59:20,289:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 2
2023-08-15 13:59:20,290:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 13:59:20,290:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 13:59:22,632:INFO:Visual Rendered Successfully
2023-08-15 13:59:22,762:INFO:plot_model() successfully completed......................................
2023-08-15 13:59:22,772:INFO:Initializing evaluate_model()
2023-08-15 13:59:22,772:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:59:22,799:INFO:Initializing plot_model()
2023-08-15 13:59:22,800:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:59:22,800:INFO:Checking exceptions
2023-08-15 13:59:22,818:INFO:Preloading libraries
2023-08-15 13:59:22,822:INFO:Copying training dataset
2023-08-15 13:59:22,822:INFO:Plot type: pipeline
2023-08-15 13:59:22,935:INFO:Visual Rendered Successfully
2023-08-15 13:59:23,034:INFO:plot_model() successfully completed......................................
2023-08-15 13:59:23,057:INFO:Initializing evaluate_model()
2023-08-15 13:59:23,057:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:59:23,091:INFO:Initializing plot_model()
2023-08-15 13:59:23,091:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:59:23,092:INFO:Checking exceptions
2023-08-15 13:59:23,110:INFO:Preloading libraries
2023-08-15 13:59:23,114:INFO:Copying training dataset
2023-08-15 13:59:23,114:INFO:Plot type: pipeline
2023-08-15 13:59:23,224:INFO:Visual Rendered Successfully
2023-08-15 13:59:23,336:INFO:plot_model() successfully completed......................................
2023-08-15 13:59:23,361:INFO:Initializing plot_model()
2023-08-15 13:59:23,361:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:59:23,361:INFO:Checking exceptions
2023-08-15 13:59:23,381:INFO:Preloading libraries
2023-08-15 13:59:23,385:INFO:Copying training dataset
2023-08-15 13:59:23,385:INFO:Plot type: pipeline
2023-08-15 13:59:23,499:INFO:Visual Rendered Successfully
2023-08-15 13:59:23,593:INFO:plot_model() successfully completed......................................
2023-08-15 13:59:35,959:INFO:Initializing evaluate_model()
2023-08-15 13:59:35,960:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 13:59:35,991:INFO:Initializing plot_model()
2023-08-15 13:59:35,992:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:59:35,992:INFO:Checking exceptions
2023-08-15 13:59:36,014:INFO:Preloading libraries
2023-08-15 13:59:36,014:INFO:Copying training dataset
2023-08-15 13:59:36,014:INFO:Plot type: pipeline
2023-08-15 13:59:36,101:INFO:Visual Rendered Successfully
2023-08-15 13:59:36,202:INFO:plot_model() successfully completed......................................
2023-08-15 13:59:52,590:INFO:Initializing plot_model()
2023-08-15 13:59:52,591:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:59:52,591:INFO:Checking exceptions
2023-08-15 13:59:52,608:INFO:Preloading libraries
2023-08-15 13:59:52,611:INFO:Copying training dataset
2023-08-15 13:59:52,611:INFO:Plot type: auc
2023-08-15 13:59:52,938:INFO:Fitting Model
2023-08-15 13:59:52,941:INFO:Scoring test/hold-out set
2023-08-15 13:59:53,195:INFO:Visual Rendered Successfully
2023-08-15 13:59:53,312:INFO:plot_model() successfully completed......................................
2023-08-15 13:59:55,252:INFO:Initializing plot_model()
2023-08-15 13:59:55,252:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:59:55,252:INFO:Checking exceptions
2023-08-15 13:59:55,270:INFO:Preloading libraries
2023-08-15 13:59:55,270:INFO:Copying training dataset
2023-08-15 13:59:55,270:INFO:Plot type: auc
2023-08-15 13:59:55,595:INFO:Fitting Model
2023-08-15 13:59:55,596:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-08-15 13:59:55,598:INFO:Scoring test/hold-out set
2023-08-15 13:59:55,778:INFO:Visual Rendered Successfully
2023-08-15 13:59:55,876:INFO:plot_model() successfully completed......................................
2023-08-15 13:59:58,648:INFO:Initializing plot_model()
2023-08-15 13:59:58,648:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 13:59:58,648:INFO:Checking exceptions
2023-08-15 13:59:58,666:INFO:Preloading libraries
2023-08-15 13:59:58,666:INFO:Copying training dataset
2023-08-15 13:59:58,666:INFO:Plot type: auc
2023-08-15 13:59:58,984:INFO:Fitting Model
2023-08-15 13:59:58,985:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\base.py:464: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-08-15 13:59:58,986:INFO:Scoring test/hold-out set
2023-08-15 13:59:59,235:INFO:Visual Rendered Successfully
2023-08-15 13:59:59,340:INFO:plot_model() successfully completed......................................
2023-08-15 14:00:02,048:INFO:Initializing plot_model()
2023-08-15 14:00:02,048:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 14:00:02,048:INFO:Checking exceptions
2023-08-15 14:00:02,064:INFO:Preloading libraries
2023-08-15 14:00:02,065:INFO:Copying training dataset
2023-08-15 14:00:02,065:INFO:Plot type: auc
2023-08-15 14:00:02,365:INFO:Fitting Model
2023-08-15 14:00:02,366:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\base.py:464: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(

2023-08-15 14:00:02,368:INFO:Scoring test/hold-out set
2023-08-15 14:00:02,623:INFO:Visual Rendered Successfully
2023-08-15 14:00:02,717:INFO:plot_model() successfully completed......................................
2023-08-15 14:01:23,774:INFO:Initializing blend_models()
2023-08-15 14:01:23,774:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 14:01:23,774:INFO:Checking exceptions
2023-08-15 14:01:23,802:INFO:Importing libraries
2023-08-15 14:01:23,802:INFO:Copying training dataset
2023-08-15 14:01:23,804:INFO:Getting model names
2023-08-15 14:01:23,806:INFO:SubProcess create_model() called ==================================
2023-08-15 14:01:23,808:INFO:Initializing create_model()
2023-08-15 14:01:23,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000167002FABF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 14:01:23,808:INFO:Checking exceptions
2023-08-15 14:01:23,808:INFO:Importing libraries
2023-08-15 14:01:23,809:INFO:Copying training dataset
2023-08-15 14:01:23,860:INFO:Defining folds
2023-08-15 14:01:23,860:INFO:Declaring metric variables
2023-08-15 14:01:23,862:INFO:Importing untrained model
2023-08-15 14:01:23,862:INFO:Declaring custom model
2023-08-15 14:01:23,865:INFO:Voting Classifier Imported successfully
2023-08-15 14:01:23,870:INFO:Starting cross validation
2023-08-15 14:01:23,872:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 14:02:39,770:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:39,975:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:40,176:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:40,253:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:40,271:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:40,332:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:40,719:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:40,724:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:41,054:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:41,258:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:02:46,356:INFO:Calculating mean and std
2023-08-15 14:02:46,357:INFO:Creating metrics dataframe
2023-08-15 14:02:46,362:INFO:Finalizing model
2023-08-15 14:03:01,936:INFO:Uploading results into container
2023-08-15 14:03:01,937:INFO:Uploading model into container now
2023-08-15 14:03:01,937:INFO:_master_model_container: 30
2023-08-15 14:03:01,937:INFO:_display_container: 11
2023-08-15 14:03:01,940:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:03:01,940:INFO:create_model() successfully completed......................................
2023-08-15 14:03:02,048:INFO:SubProcess create_model() end ==================================
2023-08-15 14:03:02,054:INFO:_master_model_container: 30
2023-08-15 14:03:02,055:INFO:_display_container: 11
2023-08-15 14:03:02,057:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:03:02,057:INFO:blend_models() successfully completed......................................
2023-08-15 14:03:55,636:INFO:Initializing evaluate_model()
2023-08-15 14:03:55,636:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 14:03:55,665:INFO:Initializing plot_model()
2023-08-15 14:03:55,665:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 14:03:55,665:INFO:Checking exceptions
2023-08-15 14:03:55,684:INFO:Preloading libraries
2023-08-15 14:03:55,688:INFO:Copying training dataset
2023-08-15 14:03:55,688:INFO:Plot type: pipeline
2023-08-15 14:03:55,800:INFO:Visual Rendered Successfully
2023-08-15 14:03:55,901:INFO:plot_model() successfully completed......................................
2023-08-15 14:03:57,922:INFO:Initializing plot_model()
2023-08-15 14:03:57,922:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 14:03:57,922:INFO:Checking exceptions
2023-08-15 14:03:57,939:INFO:Preloading libraries
2023-08-15 14:03:57,943:INFO:Copying training dataset
2023-08-15 14:03:57,943:INFO:Plot type: auc
2023-08-15 14:03:58,251:INFO:Fitting Model
2023-08-15 14:03:58,254:INFO:Scoring test/hold-out set
2023-08-15 14:03:58,645:INFO:Visual Rendered Successfully
2023-08-15 14:03:58,752:INFO:plot_model() successfully completed......................................
2023-08-15 14:04:58,815:INFO:Initializing blend_models()
2023-08-15 14:04:58,815:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 14:04:58,815:INFO:Checking exceptions
2023-08-15 14:04:58,848:INFO:Importing libraries
2023-08-15 14:04:58,848:INFO:Copying training dataset
2023-08-15 14:04:58,850:INFO:Getting model names
2023-08-15 14:04:58,853:INFO:SubProcess create_model() called ==================================
2023-08-15 14:04:58,856:INFO:Initializing create_model()
2023-08-15 14:04:58,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000167015A6A40>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 14:04:58,856:INFO:Checking exceptions
2023-08-15 14:04:58,856:INFO:Importing libraries
2023-08-15 14:04:58,856:INFO:Copying training dataset
2023-08-15 14:04:58,913:INFO:Defining folds
2023-08-15 14:04:58,913:INFO:Declaring metric variables
2023-08-15 14:04:58,915:INFO:Importing untrained model
2023-08-15 14:04:58,915:INFO:Declaring custom model
2023-08-15 14:04:58,918:INFO:Voting Classifier Imported successfully
2023-08-15 14:04:58,925:INFO:Starting cross validation
2023-08-15 14:04:58,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 14:05:43,630:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:05:43,643:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:05:43,796:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:06:30,114:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:06:31,090:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:06:31,736:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:06:32,041:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:06:33,385:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:06:33,657:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:06:35,196:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:07:01,308:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 14:07:01,408:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 14:07:01,410:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 14:07:01,421:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 14:07:01,465:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 14:07:01,481:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 14:07:04,880:INFO:Calculating mean and std
2023-08-15 14:07:04,881:INFO:Creating metrics dataframe
2023-08-15 14:07:04,886:INFO:Finalizing model
2023-08-15 14:07:22,293:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:07:22,919:INFO:Uploading results into container
2023-08-15 14:07:22,920:INFO:Uploading model into container now
2023-08-15 14:07:22,921:INFO:_master_model_container: 31
2023-08-15 14:07:22,921:INFO:_display_container: 12
2023-08-15 14:07:22,924:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:07:22,924:INFO:create_model() successfully completed......................................
2023-08-15 14:07:23,025:INFO:SubProcess create_model() end ==================================
2023-08-15 14:07:23,031:INFO:_master_model_container: 31
2023-08-15 14:07:23,031:INFO:_display_container: 12
2023-08-15 14:07:23,034:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=100,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:07:23,034:INFO:blend_models() successfully completed......................................
2023-08-15 14:07:27,620:INFO:Initializing evaluate_model()
2023-08-15 14:07:27,621:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 14:07:27,645:INFO:Initializing plot_model()
2023-08-15 14:07:27,645:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 14:07:27,645:INFO:Checking exceptions
2023-08-15 14:07:27,688:INFO:Preloading libraries
2023-08-15 14:07:27,872:INFO:Copying training dataset
2023-08-15 14:07:27,872:INFO:Plot type: pipeline
2023-08-15 14:07:27,960:INFO:Visual Rendered Successfully
2023-08-15 14:07:28,059:INFO:plot_model() successfully completed......................................
2023-08-15 14:07:30,215:INFO:Initializing plot_model()
2023-08-15 14:07:30,215:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 14:07:30,215:INFO:Checking exceptions
2023-08-15 14:07:30,252:INFO:Preloading libraries
2023-08-15 14:07:30,436:INFO:Copying training dataset
2023-08-15 14:07:30,436:INFO:Plot type: auc
2023-08-15 14:07:30,745:INFO:Fitting Model
2023-08-15 14:07:30,747:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-08-15 14:07:30,748:INFO:Scoring test/hold-out set
2023-08-15 14:07:31,327:INFO:Visual Rendered Successfully
2023-08-15 14:07:31,425:INFO:plot_model() successfully completed......................................
2023-08-15 14:08:07,161:INFO:Initializing blend_models()
2023-08-15 14:08:07,161:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 14:08:07,161:INFO:Checking exceptions
2023-08-15 14:08:07,195:INFO:Importing libraries
2023-08-15 14:08:07,195:INFO:Copying training dataset
2023-08-15 14:08:07,199:INFO:Getting model names
2023-08-15 14:08:07,201:INFO:SubProcess create_model() called ==================================
2023-08-15 14:08:07,204:INFO:Initializing create_model()
2023-08-15 14:08:07,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001676BFF7760>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 14:08:07,204:INFO:Checking exceptions
2023-08-15 14:08:07,204:INFO:Importing libraries
2023-08-15 14:08:07,204:INFO:Copying training dataset
2023-08-15 14:08:07,274:INFO:Defining folds
2023-08-15 14:08:07,274:INFO:Declaring metric variables
2023-08-15 14:08:07,277:INFO:Importing untrained model
2023-08-15 14:08:07,278:INFO:Declaring custom model
2023-08-15 14:08:07,283:INFO:Voting Classifier Imported successfully
2023-08-15 14:08:07,288:INFO:Starting cross validation
2023-08-15 14:08:07,291:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 14:08:11,435:INFO:Calculating mean and std
2023-08-15 14:08:11,437:INFO:Creating metrics dataframe
2023-08-15 14:08:11,441:INFO:Finalizing model
2023-08-15 14:08:12,218:INFO:Uploading results into container
2023-08-15 14:08:12,219:INFO:Uploading model into container now
2023-08-15 14:08:12,219:INFO:_master_model_container: 32
2023-08-15 14:08:12,219:INFO:_display_container: 13
2023-08-15 14:08:12,222:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:08:12,222:INFO:create_model() successfully completed......................................
2023-08-15 14:08:12,329:INFO:SubProcess create_model() end ==================================
2023-08-15 14:08:12,335:INFO:_master_model_container: 32
2023-08-15 14:08:12,336:INFO:_display_container: 13
2023-08-15 14:08:12,338:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:08:12,338:INFO:blend_models() successfully completed......................................
2023-08-15 14:12:26,419:INFO:Initializing evaluate_model()
2023-08-15 14:12:26,419:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 14:12:26,451:INFO:Initializing plot_model()
2023-08-15 14:12:26,451:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 14:12:26,451:INFO:Checking exceptions
2023-08-15 14:12:26,470:INFO:Preloading libraries
2023-08-15 14:12:26,474:INFO:Copying training dataset
2023-08-15 14:12:26,474:INFO:Plot type: pipeline
2023-08-15 14:12:26,587:INFO:Visual Rendered Successfully
2023-08-15 14:12:26,695:INFO:plot_model() successfully completed......................................
2023-08-15 14:12:57,248:INFO:Initializing blend_models()
2023-08-15 14:12:57,249:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=hard, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 14:12:57,249:INFO:Checking exceptions
2023-08-15 14:12:57,284:INFO:Importing libraries
2023-08-15 14:12:57,285:INFO:Copying training dataset
2023-08-15 14:12:57,288:INFO:Getting model names
2023-08-15 14:12:57,290:INFO:SubProcess create_model() called ==================================
2023-08-15 14:12:57,293:INFO:Initializing create_model()
2023-08-15 14:12:57,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001670000C310>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 14:12:57,293:INFO:Checking exceptions
2023-08-15 14:12:57,293:INFO:Importing libraries
2023-08-15 14:12:57,294:INFO:Copying training dataset
2023-08-15 14:12:57,348:INFO:Defining folds
2023-08-15 14:12:57,348:INFO:Declaring metric variables
2023-08-15 14:12:57,351:INFO:Importing untrained model
2023-08-15 14:12:57,351:INFO:Declaring custom model
2023-08-15 14:12:57,354:INFO:Voting Classifier Imported successfully
2023-08-15 14:12:57,359:INFO:Starting cross validation
2023-08-15 14:12:57,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 14:13:52,037:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:13:52,387:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:13:52,920:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:13:52,951:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:14:04,504:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:14:04,733:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:14:05,301:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:14:05,721:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:14:05,732:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:14:06,085:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:14:06,091:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:06,270:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:06,274:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:06,353:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:06,360:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:06,411:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:06,732:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:06,802:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:07,103:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:07,487:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 14:14:08,669:INFO:Calculating mean and std
2023-08-15 14:14:08,669:INFO:Creating metrics dataframe
2023-08-15 14:14:08,674:INFO:Finalizing model
2023-08-15 14:14:23,936:INFO:Uploading results into container
2023-08-15 14:14:23,936:INFO:Uploading model into container now
2023-08-15 14:14:23,937:INFO:_master_model_container: 33
2023-08-15 14:14:23,937:INFO:_display_container: 14
2023-08-15 14:14:23,939:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 14:14:23,939:INFO:create_model() successfully completed......................................
2023-08-15 14:14:24,051:INFO:SubProcess create_model() end ==================================
2023-08-15 14:14:24,057:INFO:_master_model_container: 33
2023-08-15 14:14:24,057:INFO:_display_container: 14
2023-08-15 14:14:24,059:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='hard', weights=None)
2023-08-15 14:14:24,059:INFO:blend_models() successfully completed......................................
2023-08-15 14:14:57,202:INFO:Initializing plot_model()
2023-08-15 14:14:57,202:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, system=True)
2023-08-15 14:14:57,202:INFO:Checking exceptions
2023-08-15 14:14:57,224:INFO:Preloading libraries
2023-08-15 14:14:57,228:INFO:Copying training dataset
2023-08-15 14:14:57,228:INFO:Plot type: auc
2023-08-15 14:14:57,577:INFO:Fitting Model
2023-08-15 14:14:57,580:INFO:Scoring test/hold-out set
2023-08-15 14:14:57,962:INFO:Visual Rendered Successfully
2023-08-15 14:14:58,070:INFO:plot_model() successfully completed......................................
2023-08-15 14:16:11,463:INFO:Initializing predict_model()
2023-08-15 14:16:11,463:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000167002E4D30>)
2023-08-15 14:16:11,463:INFO:Checking exceptions
2023-08-15 14:16:11,463:INFO:Preloading libraries
2023-08-15 14:16:39,052:INFO:Initializing predict_model()
2023-08-15 14:16:39,052:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000167002E6680>)
2023-08-15 14:16:39,052:INFO:Checking exceptions
2023-08-15 14:16:39,052:INFO:Preloading libraries
2023-08-15 14:17:51,673:INFO:Initializing finalize_model()
2023-08-15 14:17:51,673:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-15 14:17:51,675:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:17:51,700:INFO:Initializing create_model()
2023-08-15 14:17:51,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-15 14:17:51,701:INFO:Checking exceptions
2023-08-15 14:17:51,702:INFO:Importing libraries
2023-08-15 14:17:51,702:INFO:Copying training dataset
2023-08-15 14:17:51,707:INFO:Defining folds
2023-08-15 14:17:51,707:INFO:Declaring metric variables
2023-08-15 14:17:51,707:INFO:Importing untrained model
2023-08-15 14:17:51,707:INFO:Declaring custom model
2023-08-15 14:17:51,708:INFO:Voting Classifier Imported successfully
2023-08-15 14:17:51,710:INFO:Cross validation set to False
2023-08-15 14:17:51,710:INFO:Fitting Model
2023-08-15 14:18:14,354:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:18:14,681:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-15 14:18:14,681:INFO:create_model() successfully completed......................................
2023-08-15 14:18:14,789:INFO:_master_model_container: 33
2023-08-15 14:18:14,790:INFO:_display_container: 16
2023-08-15 14:18:14,831:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-15 14:18:14,831:INFO:finalize_model() successfully completed......................................
2023-08-15 14:19:16,240:INFO:Initializing predict_model()
2023-08-15 14:19:16,241:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001670210B130>)
2023-08-15 14:19:16,241:INFO:Checking exceptions
2023-08-15 14:19:16,241:INFO:Preloading libraries
2023-08-15 14:19:16,243:INFO:Set up data.
2023-08-15 14:19:16,259:INFO:Set up index.
2023-08-15 14:20:43,332:INFO:Initializing save_model()
2023-08-15 14:20:43,333:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), model_name=blended_final_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-15 14:20:43,333:INFO:Adding model into prep_pipe
2023-08-15 14:20:43,333:WARNING:Only Model saved as it was a pipeline.
2023-08-15 14:20:43,347:INFO:blended_final_model.pkl saved in current working directory
2023-08-15 14:20:43,399:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-15 14:20:43,399:INFO:save_model() successfully completed......................................
2023-08-15 14:21:26,688:INFO:Initializing load_model()
2023-08-15 14:21:26,688:INFO:load_model(model_name=blended_final_model, platform=None, authentication=None, verbose=True)
2023-08-15 14:22:29,228:INFO:Initializing predict_model()
2023-08-15 14:22:29,228:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001676398E9E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000167002E6680>)
2023-08-15 14:22:29,228:INFO:Checking exceptions
2023-08-15 14:22:29,228:INFO:Preloading libraries
2023-08-15 14:22:29,230:INFO:Set up data.
2023-08-15 14:22:29,247:INFO:Set up index.
2023-08-15 14:29:02,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 14:29:02,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 14:29:02,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 14:29:02,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-15 14:29:03,715:INFO:PyCaret ClassificationExperiment
2023-08-15 14:29:03,715:INFO:Logging name: clf-default-name
2023-08-15 14:29:03,715:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-15 14:29:03,715:INFO:version 3.0.4
2023-08-15 14:29:03,715:INFO:Initializing setup()
2023-08-15 14:29:03,715:INFO:self.USI: 2f0c
2023-08-15 14:29:03,715:INFO:self._variable_keys: {'n_jobs_param', 'y', 'gpu_n_jobs_param', 'exp_name_log', 'seed', 'fix_imbalance', 'gpu_param', 'X', 'fold_groups_param', 'data', 'USI', 'fold_generator', 'exp_id', 'logging_param', 'html_param', 'X_test', 'fold_shuffle_param', '_available_plots', 'y_train', 'is_multiclass', 'idx', '_ml_usecase', 'y_test', 'target_param', 'memory', 'X_train', 'pipeline', 'log_plots_param'}
2023-08-15 14:29:03,715:INFO:Checking environment
2023-08-15 14:29:03,715:INFO:python_version: 3.10.12
2023-08-15 14:29:03,715:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-15 14:29:03,716:INFO:machine: AMD64
2023-08-15 14:29:03,716:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-15 14:29:03,721:INFO:Memory: svmem(total=68448301056, available=46879899648, percent=31.5, used=21568401408, free=46879899648)
2023-08-15 14:29:03,721:INFO:Physical Core: 12
2023-08-15 14:29:03,721:INFO:Logical Core: 20
2023-08-15 14:29:03,721:INFO:Checking libraries
2023-08-15 14:29:03,721:INFO:System:
2023-08-15 14:29:03,721:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-15 14:29:03,721:INFO:executable: c:\Users\Ramon\anaconda3\envs\PycaretEnv\python.exe
2023-08-15 14:29:03,721:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-15 14:29:03,721:INFO:PyCaret required dependencies:
2023-08-15 14:29:04,108:INFO:                 pip: 23.2.1
2023-08-15 14:29:04,108:INFO:          setuptools: 68.0.0
2023-08-15 14:29:04,108:INFO:             pycaret: 3.0.4
2023-08-15 14:29:04,108:INFO:             IPython: 8.14.0
2023-08-15 14:29:04,108:INFO:          ipywidgets: 8.1.0
2023-08-15 14:29:04,108:INFO:                tqdm: 4.66.1
2023-08-15 14:29:04,108:INFO:               numpy: 1.25.2
2023-08-15 14:29:04,108:INFO:              pandas: 2.0.3
2023-08-15 14:29:04,108:INFO:              jinja2: 3.1.2
2023-08-15 14:29:04,108:INFO:               scipy: 1.11.1
2023-08-15 14:29:04,108:INFO:              joblib: 1.3.2
2023-08-15 14:29:04,108:INFO:             sklearn: 1.3.0
2023-08-15 14:29:04,108:INFO:                pyod: 1.1.0
2023-08-15 14:29:04,108:INFO:            imblearn: 0.11.0
2023-08-15 14:29:04,108:INFO:   category_encoders: 2.6.1
2023-08-15 14:29:04,108:INFO:            lightgbm: 4.0.0
2023-08-15 14:29:04,108:INFO:               numba: 0.57.1
2023-08-15 14:29:04,108:INFO:            requests: 2.31.0
2023-08-15 14:29:04,108:INFO:          matplotlib: 3.7.2
2023-08-15 14:29:04,108:INFO:          scikitplot: 0.3.7
2023-08-15 14:29:04,108:INFO:         yellowbrick: 1.5
2023-08-15 14:29:04,109:INFO:              plotly: 5.16.0
2023-08-15 14:29:04,109:INFO:    plotly-resampler: Not installed
2023-08-15 14:29:04,109:INFO:             kaleido: 0.2.1
2023-08-15 14:29:04,109:INFO:           schemdraw: 0.15
2023-08-15 14:29:04,109:INFO:         statsmodels: 0.14.0
2023-08-15 14:29:04,109:INFO:              sktime: 0.21.0
2023-08-15 14:29:04,109:INFO:               tbats: 1.1.3
2023-08-15 14:29:04,109:INFO:            pmdarima: 2.0.3
2023-08-15 14:29:04,109:INFO:              psutil: 5.9.5
2023-08-15 14:29:04,109:INFO:          markupsafe: 2.1.3
2023-08-15 14:29:04,109:INFO:             pickle5: Not installed
2023-08-15 14:29:04,109:INFO:         cloudpickle: 2.2.1
2023-08-15 14:29:04,109:INFO:         deprecation: 2.1.0
2023-08-15 14:29:04,109:INFO:              xxhash: 3.2.0
2023-08-15 14:29:04,109:INFO:           wurlitzer: Not installed
2023-08-15 14:29:04,109:INFO:PyCaret optional dependencies:
2023-08-15 14:29:04,280:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
  warnings.warn(

2023-08-15 14:29:05,310:INFO:                shap: 0.42.1
2023-08-15 14:29:05,311:INFO:           interpret: 0.4.3
2023-08-15 14:29:05,311:INFO:                umap: 0.5.3
2023-08-15 14:29:05,311:INFO:    pandas_profiling: 4.4.0
2023-08-15 14:29:05,311:INFO:  explainerdashboard: 0.4.3
2023-08-15 14:29:05,311:INFO:             autoviz: 0.1.730
2023-08-15 14:29:05,311:INFO:           fairlearn: 0.7.0
2023-08-15 14:29:05,311:INFO:          deepchecks: 0.17.4
2023-08-15 14:29:05,311:INFO:             xgboost: 1.7.6
2023-08-15 14:29:05,311:INFO:            catboost: 1.2
2023-08-15 14:29:05,311:INFO:              kmodes: 0.12.2
2023-08-15 14:29:05,311:INFO:             mlxtend: 0.22.0
2023-08-15 14:29:05,311:INFO:       statsforecast: 1.5.0
2023-08-15 14:29:05,311:INFO:        tune_sklearn: 0.4.6
2023-08-15 14:29:05,311:INFO:                 ray: 2.6.1
2023-08-15 14:29:05,311:INFO:            hyperopt: 0.2.7
2023-08-15 14:29:05,311:INFO:              optuna: 3.3.0
2023-08-15 14:29:05,311:INFO:               skopt: 0.9.0
2023-08-15 14:29:05,311:INFO:              mlflow: 1.30.1
2023-08-15 14:29:05,311:INFO:              gradio: 3.39.0
2023-08-15 14:29:05,311:INFO:             fastapi: 0.101.0
2023-08-15 14:29:05,311:INFO:             uvicorn: 0.23.2
2023-08-15 14:29:05,311:INFO:              m2cgen: 0.10.0
2023-08-15 14:29:05,311:INFO:           evidently: 0.2.8
2023-08-15 14:29:05,311:INFO:               fugue: 0.8.6
2023-08-15 14:29:05,311:INFO:           streamlit: Not installed
2023-08-15 14:29:05,311:INFO:             prophet: Not installed
2023-08-15 14:29:05,311:INFO:None
2023-08-15 14:29:05,311:INFO:Set up data.
2023-08-15 14:29:05,497:INFO:Set up train/test split.
2023-08-15 14:29:05,658:INFO:Set up index.
2023-08-15 14:29:05,663:INFO:Set up folding strategy.
2023-08-15 14:29:05,663:INFO:Assigning column types.
2023-08-15 14:29:05,696:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-15 14:29:05,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 14:29:05,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 14:29:05,738:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 14:29:05,755:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 14:29:05,794:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-15 14:29:05,795:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 14:29:05,810:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 14:29:05,811:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 14:29:05,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-15 14:29:05,835:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 14:29:05,849:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 14:29:05,851:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 14:29:05,874:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-15 14:29:05,889:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 14:29:05,890:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 14:29:05,890:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-15 14:29:05,928:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 14:29:05,929:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 14:29:05,967:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 14:29:05,969:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 14:29:05,970:INFO:Preparing preprocessing pipeline...
2023-08-15 14:29:05,976:INFO:Set up label encoding.
2023-08-15 14:29:05,976:INFO:Set up simple imputation.
2023-08-15 14:29:06,013:INFO:Set up encoding of ordinal features.
2023-08-15 14:29:06,087:INFO:Set up encoding of categorical features.
2023-08-15 14:29:06,092:INFO:Set up column name cleaning.
2023-08-15 14:29:06,643:INFO:Finished creating preprocessing pipeline.
2023-08-15 14:29:06,687:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-15 14:29:06,687:INFO:Creating final display dataframe.
2023-08-15 14:29:07,105:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              2f0c
2023-08-15 14:29:07,150:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 14:29:07,152:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 14:29:07,194:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-15 14:29:07,196:INFO:Soft dependency imported: catboost: 1.2
2023-08-15 14:29:07,197:INFO:setup() successfully completed in 3.69s...............
2023-08-15 14:29:07,251:INFO:Initializing create_model()
2023-08-15 14:29:07,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 14:29:07,252:INFO:Checking exceptions
2023-08-15 14:29:07,262:INFO:Importing libraries
2023-08-15 14:29:07,262:INFO:Copying training dataset
2023-08-15 14:29:07,327:INFO:Defining folds
2023-08-15 14:29:07,327:INFO:Declaring metric variables
2023-08-15 14:29:07,329:INFO:Importing untrained model
2023-08-15 14:29:07,331:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 14:29:07,336:INFO:Starting cross validation
2023-08-15 14:29:07,337:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 14:29:18,519:INFO:Calculating mean and std
2023-08-15 14:29:18,520:INFO:Creating metrics dataframe
2023-08-15 14:29:18,525:INFO:Finalizing model
2023-08-15 14:29:19,319:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 14:29:19,320:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 14:29:19,339:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006077 seconds.
2023-08-15 14:29:19,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 14:29:19,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 14:29:19,339:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 14:29:19,340:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-15 14:29:19,340:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 14:29:19,340:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 14:29:19,806:INFO:Uploading results into container
2023-08-15 14:29:19,807:INFO:Uploading model into container now
2023-08-15 14:29:19,819:INFO:_master_model_container: 1
2023-08-15 14:29:19,819:INFO:_display_container: 2
2023-08-15 14:29:19,819:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 14:29:19,819:INFO:create_model() successfully completed......................................
2023-08-15 14:29:19,974:INFO:Initializing create_model()
2023-08-15 14:29:19,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 14:29:19,974:INFO:Checking exceptions
2023-08-15 14:29:19,984:INFO:Importing libraries
2023-08-15 14:29:19,984:INFO:Copying training dataset
2023-08-15 14:29:20,038:INFO:Defining folds
2023-08-15 14:29:20,039:INFO:Declaring metric variables
2023-08-15 14:29:20,041:INFO:Importing untrained model
2023-08-15 14:29:20,043:INFO:Logistic Regression Imported successfully
2023-08-15 14:29:20,048:INFO:Starting cross validation
2023-08-15 14:29:20,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 14:30:19,384:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:19,438:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:19,684:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:19,688:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:19,726:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:19,727:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:19,848:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:19,988:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:20,025:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:20,170:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:21,921:INFO:Calculating mean and std
2023-08-15 14:30:21,922:INFO:Creating metrics dataframe
2023-08-15 14:30:21,927:INFO:Finalizing model
2023-08-15 14:30:33,753:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\linear_model\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-15 14:30:33,935:INFO:Uploading results into container
2023-08-15 14:30:33,936:INFO:Uploading model into container now
2023-08-15 14:30:33,944:INFO:_master_model_container: 2
2023-08-15 14:30:33,944:INFO:_display_container: 3
2023-08-15 14:30:33,944:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 14:30:33,944:INFO:create_model() successfully completed......................................
2023-08-15 14:30:34,138:INFO:Initializing create_model()
2023-08-15 14:30:34,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 14:30:34,138:INFO:Checking exceptions
2023-08-15 14:30:34,150:INFO:Importing libraries
2023-08-15 14:30:34,150:INFO:Copying training dataset
2023-08-15 14:30:34,207:INFO:Defining folds
2023-08-15 14:30:34,207:INFO:Declaring metric variables
2023-08-15 14:30:34,209:INFO:Importing untrained model
2023-08-15 14:30:34,211:INFO:Naive Bayes Imported successfully
2023-08-15 14:30:34,215:INFO:Starting cross validation
2023-08-15 14:30:34,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 14:30:38,372:INFO:Calculating mean and std
2023-08-15 14:30:38,373:INFO:Creating metrics dataframe
2023-08-15 14:30:38,378:INFO:Finalizing model
2023-08-15 14:30:39,217:INFO:Uploading results into container
2023-08-15 14:30:39,218:INFO:Uploading model into container now
2023-08-15 14:30:39,225:INFO:_master_model_container: 3
2023-08-15 14:30:39,225:INFO:_display_container: 4
2023-08-15 14:30:39,225:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 14:30:39,225:INFO:create_model() successfully completed......................................
2023-08-15 14:30:39,439:INFO:Initializing evaluate_model()
2023-08-15 14:30:39,439:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 14:30:39,466:INFO:Initializing plot_model()
2023-08-15 14:30:39,466:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:30:39,466:INFO:Checking exceptions
2023-08-15 14:30:39,495:INFO:Preloading libraries
2023-08-15 14:30:39,500:INFO:Copying training dataset
2023-08-15 14:30:39,501:INFO:Plot type: pipeline
2023-08-15 14:30:39,636:INFO:Visual Rendered Successfully
2023-08-15 14:30:39,714:INFO:plot_model() successfully completed......................................
2023-08-15 14:30:39,741:INFO:Initializing evaluate_model()
2023-08-15 14:30:39,741:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 14:30:39,766:INFO:Initializing plot_model()
2023-08-15 14:30:39,766:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:30:39,766:INFO:Checking exceptions
2023-08-15 14:30:39,786:INFO:Preloading libraries
2023-08-15 14:30:39,786:INFO:Copying training dataset
2023-08-15 14:30:39,786:INFO:Plot type: pipeline
2023-08-15 14:30:39,883:INFO:Visual Rendered Successfully
2023-08-15 14:30:39,965:INFO:plot_model() successfully completed......................................
2023-08-15 14:30:39,998:INFO:Initializing evaluate_model()
2023-08-15 14:30:39,998:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 14:30:40,030:INFO:Initializing plot_model()
2023-08-15 14:30:40,030:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:30:40,030:INFO:Checking exceptions
2023-08-15 14:30:40,050:INFO:Preloading libraries
2023-08-15 14:30:40,050:INFO:Copying training dataset
2023-08-15 14:30:40,051:INFO:Plot type: pipeline
2023-08-15 14:30:40,143:INFO:Visual Rendered Successfully
2023-08-15 14:30:40,226:INFO:plot_model() successfully completed......................................
2023-08-15 14:30:40,295:INFO:Initializing blend_models()
2023-08-15 14:30:40,295:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-15 14:30:40,295:INFO:Checking exceptions
2023-08-15 14:30:40,327:INFO:Importing libraries
2023-08-15 14:30:40,327:INFO:Copying training dataset
2023-08-15 14:30:40,329:INFO:Getting model names
2023-08-15 14:30:40,332:INFO:SubProcess create_model() called ==================================
2023-08-15 14:30:40,335:INFO:Initializing create_model()
2023-08-15 14:30:40,335:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB535B34F0>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 14:30:40,335:INFO:Checking exceptions
2023-08-15 14:30:40,335:INFO:Importing libraries
2023-08-15 14:30:40,335:INFO:Copying training dataset
2023-08-15 14:30:40,396:INFO:Defining folds
2023-08-15 14:30:40,396:INFO:Declaring metric variables
2023-08-15 14:30:40,399:INFO:Importing untrained model
2023-08-15 14:30:40,399:INFO:Declaring custom model
2023-08-15 14:30:40,402:INFO:Voting Classifier Imported successfully
2023-08-15 14:30:40,406:INFO:Starting cross validation
2023-08-15 14:30:40,408:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 14:30:43,936:INFO:Calculating mean and std
2023-08-15 14:30:43,937:INFO:Creating metrics dataframe
2023-08-15 14:30:43,941:INFO:Finalizing model
2023-08-15 14:30:44,721:INFO:Uploading results into container
2023-08-15 14:30:44,722:INFO:Uploading model into container now
2023-08-15 14:30:44,723:INFO:_master_model_container: 4
2023-08-15 14:30:44,723:INFO:_display_container: 5
2023-08-15 14:30:44,725:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:30:44,725:INFO:create_model() successfully completed......................................
2023-08-15 14:30:44,804:INFO:SubProcess create_model() end ==================================
2023-08-15 14:30:44,812:INFO:_master_model_container: 4
2023-08-15 14:30:44,812:INFO:_display_container: 5
2023-08-15 14:30:44,815:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:30:44,815:INFO:blend_models() successfully completed......................................
2023-08-15 14:30:44,953:INFO:Initializing evaluate_model()
2023-08-15 14:30:44,953:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 14:30:44,982:INFO:Initializing plot_model()
2023-08-15 14:30:44,982:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:30:44,982:INFO:Checking exceptions
2023-08-15 14:30:45,002:INFO:Preloading libraries
2023-08-15 14:30:45,005:INFO:Copying training dataset
2023-08-15 14:30:45,005:INFO:Plot type: pipeline
2023-08-15 14:30:45,113:INFO:Visual Rendered Successfully
2023-08-15 14:30:45,192:INFO:plot_model() successfully completed......................................
2023-08-15 14:30:45,217:INFO:Initializing predict_model()
2023-08-15 14:30:45,217:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB5377FD90>)
2023-08-15 14:30:45,217:INFO:Checking exceptions
2023-08-15 14:30:45,217:INFO:Preloading libraries
2023-08-15 14:30:47,480:INFO:Initializing finalize_model()
2023-08-15 14:30:47,480:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-15 14:30:47,482:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-15 14:30:47,508:INFO:Initializing create_model()
2023-08-15 14:30:47,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-15 14:30:47,509:INFO:Checking exceptions
2023-08-15 14:30:47,510:INFO:Importing libraries
2023-08-15 14:30:47,510:INFO:Copying training dataset
2023-08-15 14:30:47,516:INFO:Defining folds
2023-08-15 14:30:47,516:INFO:Declaring metric variables
2023-08-15 14:30:47,516:INFO:Importing untrained model
2023-08-15 14:30:47,516:INFO:Declaring custom model
2023-08-15 14:30:47,517:INFO:Voting Classifier Imported successfully
2023-08-15 14:30:47,518:INFO:Cross validation set to False
2023-08-15 14:30:47,518:INFO:Fitting Model
2023-08-15 14:30:50,199:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-15 14:30:50,199:INFO:create_model() successfully completed......................................
2023-08-15 14:30:50,286:INFO:_master_model_container: 4
2023-08-15 14:30:50,287:INFO:_display_container: 6
2023-08-15 14:30:50,330:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-15 14:30:50,330:INFO:finalize_model() successfully completed......................................
2023-08-15 14:30:50,516:INFO:Initializing predict_model()
2023-08-15 14:30:50,516:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB621C5C60>)
2023-08-15 14:30:50,516:INFO:Checking exceptions
2023-08-15 14:30:50,516:INFO:Preloading libraries
2023-08-15 14:30:50,517:INFO:Set up data.
2023-08-15 14:30:50,533:INFO:Set up index.
2023-08-15 14:32:36,748:INFO:Initializing plot_model()
2023-08-15 14:32:36,748:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=<function predict_model at 0x000001FB57087520>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:32:36,748:INFO:Checking exceptions
2023-08-15 14:33:53,660:INFO:Initializing plot_model()
2023-08-15 14:33:53,660:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=<function predict_model at 0x000001FB57087520>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:33:53,660:INFO:Checking exceptions
2023-08-15 14:34:13,621:INFO:Initializing plot_model()
2023-08-15 14:34:13,622:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:34:13,622:INFO:Checking exceptions
2023-08-15 14:35:26,762:INFO:Initializing load_model()
2023-08-15 14:35:26,762:INFO:load_model(model_name=blended_final_model, platform=None, authentication=None, verbose=True)
2023-08-15 14:35:28,509:INFO:Initializing predict_model()
2023-08-15 14:35:28,509:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB6450BB50>)
2023-08-15 14:35:28,509:INFO:Checking exceptions
2023-08-15 14:35:28,509:INFO:Preloading libraries
2023-08-15 14:35:28,513:INFO:Set up data.
2023-08-15 14:35:28,531:INFO:Set up index.
2023-08-15 14:35:48,963:INFO:Initializing predict_model()
2023-08-15 14:35:48,964:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB0001B640>)
2023-08-15 14:35:48,964:INFO:Checking exceptions
2023-08-15 14:35:48,964:INFO:Preloading libraries
2023-08-15 14:35:48,965:INFO:Set up data.
2023-08-15 14:35:48,980:INFO:Set up index.
2023-08-15 14:36:28,171:INFO:Initializing predict_model()
2023-08-15 14:36:28,171:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB0069DC60>)
2023-08-15 14:36:28,171:INFO:Checking exceptions
2023-08-15 14:36:28,171:INFO:Preloading libraries
2023-08-15 14:36:28,174:INFO:Set up data.
2023-08-15 14:36:28,195:INFO:Set up index.
2023-08-15 14:44:20,326:INFO:Initializing predict_model()
2023-08-15 14:44:20,326:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                                                  class_weight=None,
                                                                  dual=False,
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FB0069D900>)
2023-08-15 14:44:20,326:INFO:Checking exceptions
2023-08-15 14:44:20,326:INFO:Preloading libraries
2023-08-15 14:44:20,328:INFO:Set up data.
2023-08-15 14:44:20,345:INFO:Set up index.
2023-08-15 14:50:16,588:INFO:Initializing plot_model()
2023-08-15 14:50:16,588:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:50:16,588:INFO:Checking exceptions
2023-08-15 14:50:16,610:INFO:Preloading libraries
2023-08-15 14:50:16,615:INFO:Copying training dataset
2023-08-15 14:50:16,615:INFO:Plot type: feature
2023-08-15 14:50:16,615:WARNING:No coef_ found. Trying feature_importances_
2023-08-15 14:50:16,831:INFO:Visual Rendered Successfully
2023-08-15 14:50:17,110:INFO:plot_model() successfully completed......................................
2023-08-15 14:50:26,938:INFO:Initializing plot_model()
2023-08-15 14:50:26,938:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:50:26,938:INFO:Checking exceptions
2023-08-15 14:50:26,959:INFO:Preloading libraries
2023-08-15 14:50:26,959:INFO:Copying training dataset
2023-08-15 14:50:26,959:INFO:Plot type: feature
2023-08-15 14:50:27,266:INFO:Visual Rendered Successfully
2023-08-15 14:50:27,354:INFO:plot_model() successfully completed......................................
2023-08-15 14:50:33,142:INFO:Initializing plot_model()
2023-08-15 14:50:33,143:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:50:33,143:INFO:Checking exceptions
2023-08-15 14:50:47,348:INFO:Initializing plot_model()
2023-08-15 14:50:47,348:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GaussianNB(priors=None, var_smoothing=1e-09), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:50:47,348:INFO:Checking exceptions
2023-08-15 14:50:47,368:INFO:Preloading libraries
2023-08-15 14:50:47,369:INFO:Copying training dataset
2023-08-15 14:50:47,369:INFO:Plot type: boundary
2023-08-15 14:50:47,543:INFO:Fitting StandardScaler()
2023-08-15 14:50:47,653:INFO:Fitting PCA()
2023-08-15 14:50:48,241:INFO:Fitting Model
2023-08-15 14:50:50,255:INFO:Visual Rendered Successfully
2023-08-15 14:50:50,377:INFO:plot_model() successfully completed......................................
2023-08-15 14:51:00,492:INFO:Initializing plot_model()
2023-08-15 14:51:00,493:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:51:00,493:INFO:Checking exceptions
2023-08-15 14:51:03,051:INFO:Initializing plot_model()
2023-08-15 14:51:03,052:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:51:03,052:INFO:Checking exceptions
2023-08-15 14:51:03,072:INFO:Preloading libraries
2023-08-15 14:51:03,078:INFO:Copying training dataset
2023-08-15 14:51:03,078:INFO:Plot type: boundary
2023-08-15 14:51:03,280:INFO:Fitting StandardScaler()
2023-08-15 14:51:03,388:INFO:Fitting PCA()
2023-08-15 14:51:03,964:INFO:Fitting Model
2023-08-15 14:51:08,586:INFO:Visual Rendered Successfully
2023-08-15 14:51:08,701:INFO:plot_model() successfully completed......................................
2023-08-15 14:54:45,031:INFO:Initializing plot_model()
2023-08-15 14:54:45,031:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:54:45,031:INFO:Checking exceptions
2023-08-15 14:54:45,052:INFO:Preloading libraries
2023-08-15 14:54:45,056:INFO:Copying training dataset
2023-08-15 14:54:45,056:INFO:Plot type: pipeline
2023-08-15 14:54:45,162:INFO:Visual Rendered Successfully
2023-08-15 14:54:45,253:INFO:plot_model() successfully completed......................................
2023-08-15 14:55:18,597:INFO:Initializing plot_model()
2023-08-15 14:55:18,597:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:55:18,597:INFO:Checking exceptions
2023-08-15 14:55:18,616:INFO:Preloading libraries
2023-08-15 14:55:18,620:INFO:Copying training dataset
2023-08-15 14:55:18,620:INFO:Plot type: parameter
2023-08-15 14:55:18,623:INFO:Visual Rendered Successfully
2023-08-15 14:55:18,722:INFO:plot_model() successfully completed......................................
2023-08-15 14:55:22,110:INFO:Initializing plot_model()
2023-08-15 14:55:22,110:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:55:22,111:INFO:Checking exceptions
2023-08-15 14:55:22,128:INFO:Preloading libraries
2023-08-15 14:55:22,133:INFO:Copying training dataset
2023-08-15 14:55:22,133:INFO:Plot type: auc
2023-08-15 14:55:22,453:INFO:Fitting Model
2023-08-15 14:55:22,456:INFO:Scoring test/hold-out set
2023-08-15 14:55:22,834:INFO:Visual Rendered Successfully
2023-08-15 14:55:22,930:INFO:plot_model() successfully completed......................................
2023-08-15 14:55:52,028:INFO:Initializing plot_model()
2023-08-15 14:55:52,028:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:55:52,028:INFO:Checking exceptions
2023-08-15 14:55:52,048:INFO:Preloading libraries
2023-08-15 14:55:52,051:INFO:Copying training dataset
2023-08-15 14:55:52,052:INFO:Plot type: confusion_matrix
2023-08-15 14:55:52,373:INFO:Fitting Model
2023-08-15 14:55:52,375:INFO:Scoring test/hold-out set
2023-08-15 14:55:52,656:INFO:Visual Rendered Successfully
2023-08-15 14:55:52,743:INFO:plot_model() successfully completed......................................
2023-08-15 14:56:39,908:INFO:Initializing plot_model()
2023-08-15 14:56:39,908:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 14:56:39,908:INFO:Checking exceptions
2023-08-15 14:56:39,927:INFO:Preloading libraries
2023-08-15 14:56:39,931:INFO:Copying training dataset
2023-08-15 14:56:39,931:INFO:Plot type: threshold
2023-08-15 14:56:40,251:INFO:Fitting Model
2023-08-15 15:06:57,593:INFO:Scoring test/hold-out set
2023-08-15 15:06:57,954:INFO:Visual Rendered Successfully
2023-08-15 15:06:58,054:INFO:plot_model() successfully completed......................................
2023-08-15 15:06:58,113:INFO:Initializing plot_model()
2023-08-15 15:06:58,113:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 15:06:58,113:INFO:Checking exceptions
2023-08-15 15:16:32,035:INFO:Initializing compare_models()
2023-08-15 15:16:32,035:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-15 15:16:32,035:INFO:Checking exceptions
2023-08-15 15:16:32,057:INFO:Preparing display monitor
2023-08-15 15:16:32,071:INFO:Initializing Logistic Regression
2023-08-15 15:16:32,071:INFO:Total runtime is 0.0 minutes
2023-08-15 15:16:32,073:INFO:SubProcess create_model() called ==================================
2023-08-15 15:16:32,074:INFO:Initializing create_model()
2023-08-15 15:16:32,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:16:32,074:INFO:Checking exceptions
2023-08-15 15:16:32,074:INFO:Importing libraries
2023-08-15 15:16:32,074:INFO:Copying training dataset
2023-08-15 15:16:32,130:INFO:Defining folds
2023-08-15 15:16:32,130:INFO:Declaring metric variables
2023-08-15 15:16:32,132:INFO:Importing untrained model
2023-08-15 15:16:32,135:INFO:Logistic Regression Imported successfully
2023-08-15 15:16:32,139:INFO:Starting cross validation
2023-08-15 15:16:32,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:16:39,684:INFO:Calculating mean and std
2023-08-15 15:16:39,685:INFO:Creating metrics dataframe
2023-08-15 15:16:39,854:INFO:Uploading results into container
2023-08-15 15:16:39,855:INFO:Uploading model into container now
2023-08-15 15:16:39,856:INFO:_master_model_container: 5
2023-08-15 15:16:39,856:INFO:_display_container: 12
2023-08-15 15:16:39,856:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-15 15:16:39,856:INFO:create_model() successfully completed......................................
2023-08-15 15:16:40,089:INFO:SubProcess create_model() end ==================================
2023-08-15 15:16:40,089:INFO:Creating metrics dataframe
2023-08-15 15:16:40,093:INFO:Initializing K Neighbors Classifier
2023-08-15 15:16:40,093:INFO:Total runtime is 0.1336964726448059 minutes
2023-08-15 15:16:40,095:INFO:SubProcess create_model() called ==================================
2023-08-15 15:16:40,096:INFO:Initializing create_model()
2023-08-15 15:16:40,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:16:40,096:INFO:Checking exceptions
2023-08-15 15:16:40,096:INFO:Importing libraries
2023-08-15 15:16:40,096:INFO:Copying training dataset
2023-08-15 15:16:40,150:INFO:Defining folds
2023-08-15 15:16:40,150:INFO:Declaring metric variables
2023-08-15 15:16:40,153:INFO:Importing untrained model
2023-08-15 15:16:40,155:INFO:K Neighbors Classifier Imported successfully
2023-08-15 15:16:40,159:INFO:Starting cross validation
2023-08-15 15:16:40,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:16:45,112:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,122:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,124:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,126:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,127:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,137:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,139:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,226:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,325:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,326:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,335:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,359:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,359:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,370:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,550:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,562:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,719:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,730:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,774:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:45,805:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:47,025:INFO:Calculating mean and std
2023-08-15 15:16:47,026:INFO:Creating metrics dataframe
2023-08-15 15:16:47,178:INFO:Uploading results into container
2023-08-15 15:16:47,179:INFO:Uploading model into container now
2023-08-15 15:16:47,179:INFO:_master_model_container: 6
2023-08-15 15:16:47,179:INFO:_display_container: 12
2023-08-15 15:16:47,180:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-15 15:16:47,180:INFO:create_model() successfully completed......................................
2023-08-15 15:16:47,307:WARNING:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0, trying without fit_kwargs:
2023-08-15 15:16:47,309:WARNING:Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2023-08-15 15:16:47,309:INFO:Initializing create_model()
2023-08-15 15:16:47,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:16:47,309:INFO:Checking exceptions
2023-08-15 15:16:47,310:INFO:Importing libraries
2023-08-15 15:16:47,310:INFO:Copying training dataset
2023-08-15 15:16:47,369:INFO:Defining folds
2023-08-15 15:16:47,369:INFO:Declaring metric variables
2023-08-15 15:16:47,372:INFO:Importing untrained model
2023-08-15 15:16:47,374:INFO:K Neighbors Classifier Imported successfully
2023-08-15 15:16:47,378:INFO:Starting cross validation
2023-08-15 15:16:47,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:16:48,622:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:48,699:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:48,826:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:48,902:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:48,909:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:48,934:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:48,939:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:48,955:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:48,991:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,046:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,048:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,086:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,133:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,141:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,169:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,188:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,210:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 321, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 316, in predict_proba
    and ArgKminClassMode.is_usable_for(X, self._fit_X, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,549:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,561:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:49,637:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\model_selection\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: 
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 136, in __call__
    score = scorer._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 353, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 85, in _get_response_values
    y_pred = prediction_method(X)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 312, in predict
    y = self.steps[-1][-1].predict(X, **predict_params)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\neighbors\_classification.py", line 246, in predict
    if self._fit_method == "brute" and ArgKminClassMode.is_usable_for(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 471, in is_usable_for
    ArgKmin.is_usable_for(X, Y, metric)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 115, in is_usable_for
    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_pairwise_distances_reduction\_dispatcher.py", line 99, in is_numpy_c_ordered
    return hasattr(X, "flags") and X.flags.c_contiguous
AttributeError: 'Flags' object has no attribute 'c_contiguous'

  warnings.warn(

2023-08-15 15:16:50,575:INFO:Calculating mean and std
2023-08-15 15:16:50,577:INFO:Creating metrics dataframe
2023-08-15 15:16:50,757:INFO:Uploading results into container
2023-08-15 15:16:50,757:INFO:Uploading model into container now
2023-08-15 15:16:50,758:INFO:_master_model_container: 7
2023-08-15 15:16:50,758:INFO:_display_container: 12
2023-08-15 15:16:50,758:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-15 15:16:50,758:INFO:create_model() successfully completed......................................
2023-08-15 15:16:50,880:ERROR:create_model() for KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform') raised an exception or returned all 0.0:
2023-08-15 15:16:50,880:ERROR:Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 813, in compare_models
    np.sum(
AssertionError

2023-08-15 15:16:50,880:INFO:Initializing Naive Bayes
2023-08-15 15:16:50,880:INFO:Total runtime is 0.3134749889373779 minutes
2023-08-15 15:16:50,883:INFO:SubProcess create_model() called ==================================
2023-08-15 15:16:50,883:INFO:Initializing create_model()
2023-08-15 15:16:50,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:16:50,883:INFO:Checking exceptions
2023-08-15 15:16:50,883:INFO:Importing libraries
2023-08-15 15:16:50,883:INFO:Copying training dataset
2023-08-15 15:16:50,937:INFO:Defining folds
2023-08-15 15:16:50,937:INFO:Declaring metric variables
2023-08-15 15:16:50,939:INFO:Importing untrained model
2023-08-15 15:16:50,942:INFO:Naive Bayes Imported successfully
2023-08-15 15:16:50,946:INFO:Starting cross validation
2023-08-15 15:16:50,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:16:54,182:INFO:Calculating mean and std
2023-08-15 15:16:54,183:INFO:Creating metrics dataframe
2023-08-15 15:16:54,361:INFO:Uploading results into container
2023-08-15 15:16:54,362:INFO:Uploading model into container now
2023-08-15 15:16:54,362:INFO:_master_model_container: 8
2023-08-15 15:16:54,362:INFO:_display_container: 12
2023-08-15 15:16:54,362:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-15 15:16:54,363:INFO:create_model() successfully completed......................................
2023-08-15 15:16:54,479:INFO:SubProcess create_model() end ==================================
2023-08-15 15:16:54,480:INFO:Creating metrics dataframe
2023-08-15 15:16:54,485:INFO:Initializing Decision Tree Classifier
2023-08-15 15:16:54,485:INFO:Total runtime is 0.37356314261754353 minutes
2023-08-15 15:16:54,487:INFO:SubProcess create_model() called ==================================
2023-08-15 15:16:54,487:INFO:Initializing create_model()
2023-08-15 15:16:54,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:16:54,488:INFO:Checking exceptions
2023-08-15 15:16:54,488:INFO:Importing libraries
2023-08-15 15:16:54,488:INFO:Copying training dataset
2023-08-15 15:16:54,542:INFO:Defining folds
2023-08-15 15:16:54,543:INFO:Declaring metric variables
2023-08-15 15:16:54,545:INFO:Importing untrained model
2023-08-15 15:16:54,548:INFO:Decision Tree Classifier Imported successfully
2023-08-15 15:16:54,552:INFO:Starting cross validation
2023-08-15 15:16:54,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:17:00,406:INFO:Calculating mean and std
2023-08-15 15:17:00,407:INFO:Creating metrics dataframe
2023-08-15 15:17:00,558:INFO:Uploading results into container
2023-08-15 15:17:00,559:INFO:Uploading model into container now
2023-08-15 15:17:00,559:INFO:_master_model_container: 9
2023-08-15 15:17:00,559:INFO:_display_container: 12
2023-08-15 15:17:00,560:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-15 15:17:00,560:INFO:create_model() successfully completed......................................
2023-08-15 15:17:00,703:INFO:SubProcess create_model() end ==================================
2023-08-15 15:17:00,703:INFO:Creating metrics dataframe
2023-08-15 15:17:00,709:INFO:Initializing SVM - Linear Kernel
2023-08-15 15:17:00,709:INFO:Total runtime is 0.47729220390319826 minutes
2023-08-15 15:17:00,712:INFO:SubProcess create_model() called ==================================
2023-08-15 15:17:00,712:INFO:Initializing create_model()
2023-08-15 15:17:00,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:17:00,712:INFO:Checking exceptions
2023-08-15 15:17:00,712:INFO:Importing libraries
2023-08-15 15:17:00,712:INFO:Copying training dataset
2023-08-15 15:17:00,769:INFO:Defining folds
2023-08-15 15:17:00,769:INFO:Declaring metric variables
2023-08-15 15:17:00,772:INFO:Importing untrained model
2023-08-15 15:17:00,776:INFO:SVM - Linear Kernel Imported successfully
2023-08-15 15:17:00,782:INFO:Starting cross validation
2023-08-15 15:17:00,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:17:20,227:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:20,805:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:20,901:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:21,094:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:17:21,388:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:22,041:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:22,063:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:22,192:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:22,194:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:22,744:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:23,078:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:23,527:INFO:Calculating mean and std
2023-08-15 15:17:23,528:INFO:Creating metrics dataframe
2023-08-15 15:17:23,694:INFO:Uploading results into container
2023-08-15 15:17:23,695:INFO:Uploading model into container now
2023-08-15 15:17:23,695:INFO:_master_model_container: 10
2023-08-15 15:17:23,695:INFO:_display_container: 12
2023-08-15 15:17:23,696:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-15 15:17:23,696:INFO:create_model() successfully completed......................................
2023-08-15 15:17:23,817:INFO:SubProcess create_model() end ==================================
2023-08-15 15:17:23,817:INFO:Creating metrics dataframe
2023-08-15 15:17:23,822:INFO:Initializing Ridge Classifier
2023-08-15 15:17:23,822:INFO:Total runtime is 0.8625130891799927 minutes
2023-08-15 15:17:23,825:INFO:SubProcess create_model() called ==================================
2023-08-15 15:17:23,825:INFO:Initializing create_model()
2023-08-15 15:17:23,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:17:23,825:INFO:Checking exceptions
2023-08-15 15:17:23,825:INFO:Importing libraries
2023-08-15 15:17:23,825:INFO:Copying training dataset
2023-08-15 15:17:23,874:INFO:Defining folds
2023-08-15 15:17:23,874:INFO:Declaring metric variables
2023-08-15 15:17:23,876:INFO:Importing untrained model
2023-08-15 15:17:23,879:INFO:Ridge Classifier Imported successfully
2023-08-15 15:17:23,882:INFO:Starting cross validation
2023-08-15 15:17:23,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:17:25,392:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,505:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,541:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,565:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,575:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,577:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,613:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,634:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,650:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:25,709:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 399, in _score
    y_pred = method_caller(clf, "predict_proba", X, pos_label=self._get_pos_label())
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 86, in _cached_call
    result, _ = _get_response_values(
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\_response.py", line 73, in _get_response_values
    prediction_method = _check_response_method(estimator, response_method)
  File "c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\utils\validation.py", line 1940, in _check_response_method
    raise AttributeError(
AttributeError: Pipeline has none of the following attributes: predict_proba.

  warnings.warn(

2023-08-15 15:17:27,268:INFO:Calculating mean and std
2023-08-15 15:17:27,269:INFO:Creating metrics dataframe
2023-08-15 15:17:27,408:INFO:Uploading results into container
2023-08-15 15:17:27,408:INFO:Uploading model into container now
2023-08-15 15:17:27,409:INFO:_master_model_container: 11
2023-08-15 15:17:27,409:INFO:_display_container: 12
2023-08-15 15:17:27,409:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-15 15:17:27,409:INFO:create_model() successfully completed......................................
2023-08-15 15:17:27,523:INFO:SubProcess create_model() end ==================================
2023-08-15 15:17:27,523:INFO:Creating metrics dataframe
2023-08-15 15:17:27,528:INFO:Initializing Random Forest Classifier
2023-08-15 15:17:27,529:INFO:Total runtime is 0.9242960095405579 minutes
2023-08-15 15:17:27,531:INFO:SubProcess create_model() called ==================================
2023-08-15 15:17:27,531:INFO:Initializing create_model()
2023-08-15 15:17:27,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:17:27,531:INFO:Checking exceptions
2023-08-15 15:17:27,531:INFO:Importing libraries
2023-08-15 15:17:27,531:INFO:Copying training dataset
2023-08-15 15:17:27,583:INFO:Defining folds
2023-08-15 15:17:27,583:INFO:Declaring metric variables
2023-08-15 15:17:27,586:INFO:Importing untrained model
2023-08-15 15:17:27,589:INFO:Random Forest Classifier Imported successfully
2023-08-15 15:17:27,592:INFO:Starting cross validation
2023-08-15 15:17:27,594:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:17:35,018:INFO:Calculating mean and std
2023-08-15 15:17:35,019:INFO:Creating metrics dataframe
2023-08-15 15:17:35,164:INFO:Uploading results into container
2023-08-15 15:17:35,164:INFO:Uploading model into container now
2023-08-15 15:17:35,165:INFO:_master_model_container: 12
2023-08-15 15:17:35,165:INFO:_display_container: 12
2023-08-15 15:17:35,165:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-15 15:17:35,165:INFO:create_model() successfully completed......................................
2023-08-15 15:17:35,281:INFO:SubProcess create_model() end ==================================
2023-08-15 15:17:35,281:INFO:Creating metrics dataframe
2023-08-15 15:17:35,287:INFO:Initializing Quadratic Discriminant Analysis
2023-08-15 15:17:35,287:INFO:Total runtime is 1.0535954594612122 minutes
2023-08-15 15:17:35,289:INFO:SubProcess create_model() called ==================================
2023-08-15 15:17:35,289:INFO:Initializing create_model()
2023-08-15 15:17:35,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:17:35,290:INFO:Checking exceptions
2023-08-15 15:17:35,290:INFO:Importing libraries
2023-08-15 15:17:35,290:INFO:Copying training dataset
2023-08-15 15:17:35,342:INFO:Defining folds
2023-08-15 15:17:35,342:INFO:Declaring metric variables
2023-08-15 15:17:35,345:INFO:Importing untrained model
2023-08-15 15:17:35,347:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-15 15:17:35,351:INFO:Starting cross validation
2023-08-15 15:17:35,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:17:38,186:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,213:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,328:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,363:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,400:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,413:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,462:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,573:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,612:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:38,627:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-15 15:17:40,657:INFO:Calculating mean and std
2023-08-15 15:17:40,658:INFO:Creating metrics dataframe
2023-08-15 15:17:40,813:INFO:Uploading results into container
2023-08-15 15:17:40,814:INFO:Uploading model into container now
2023-08-15 15:17:40,814:INFO:_master_model_container: 13
2023-08-15 15:17:40,814:INFO:_display_container: 12
2023-08-15 15:17:40,814:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-15 15:17:40,814:INFO:create_model() successfully completed......................................
2023-08-15 15:17:40,924:INFO:SubProcess create_model() end ==================================
2023-08-15 15:17:40,924:INFO:Creating metrics dataframe
2023-08-15 15:17:40,930:INFO:Initializing Ada Boost Classifier
2023-08-15 15:17:40,930:INFO:Total runtime is 1.1476464748382569 minutes
2023-08-15 15:17:40,932:INFO:SubProcess create_model() called ==================================
2023-08-15 15:17:40,932:INFO:Initializing create_model()
2023-08-15 15:17:40,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:17:40,933:INFO:Checking exceptions
2023-08-15 15:17:40,933:INFO:Importing libraries
2023-08-15 15:17:40,933:INFO:Copying training dataset
2023-08-15 15:17:40,983:INFO:Defining folds
2023-08-15 15:17:40,983:INFO:Declaring metric variables
2023-08-15 15:17:40,985:INFO:Importing untrained model
2023-08-15 15:17:40,988:INFO:Ada Boost Classifier Imported successfully
2023-08-15 15:17:40,991:INFO:Starting cross validation
2023-08-15 15:17:40,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:18:00,704:INFO:Calculating mean and std
2023-08-15 15:18:00,705:INFO:Creating metrics dataframe
2023-08-15 15:18:00,861:INFO:Uploading results into container
2023-08-15 15:18:00,862:INFO:Uploading model into container now
2023-08-15 15:18:00,862:INFO:_master_model_container: 14
2023-08-15 15:18:00,863:INFO:_display_container: 12
2023-08-15 15:18:00,863:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-15 15:18:00,863:INFO:create_model() successfully completed......................................
2023-08-15 15:18:00,976:INFO:SubProcess create_model() end ==================================
2023-08-15 15:18:00,976:INFO:Creating metrics dataframe
2023-08-15 15:18:00,982:INFO:Initializing Gradient Boosting Classifier
2023-08-15 15:18:00,982:INFO:Total runtime is 1.4818479895591736 minutes
2023-08-15 15:18:00,984:INFO:SubProcess create_model() called ==================================
2023-08-15 15:18:00,984:INFO:Initializing create_model()
2023-08-15 15:18:00,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:18:00,984:INFO:Checking exceptions
2023-08-15 15:18:00,984:INFO:Importing libraries
2023-08-15 15:18:00,985:INFO:Copying training dataset
2023-08-15 15:18:01,032:INFO:Defining folds
2023-08-15 15:18:01,032:INFO:Declaring metric variables
2023-08-15 15:18:01,035:INFO:Importing untrained model
2023-08-15 15:18:01,037:INFO:Gradient Boosting Classifier Imported successfully
2023-08-15 15:18:01,041:INFO:Starting cross validation
2023-08-15 15:18:01,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:18:46,812:INFO:Calculating mean and std
2023-08-15 15:18:46,813:INFO:Creating metrics dataframe
2023-08-15 15:18:46,969:INFO:Uploading results into container
2023-08-15 15:18:46,970:INFO:Uploading model into container now
2023-08-15 15:18:46,971:INFO:_master_model_container: 15
2023-08-15 15:18:46,971:INFO:_display_container: 12
2023-08-15 15:18:46,971:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-15 15:18:46,971:INFO:create_model() successfully completed......................................
2023-08-15 15:18:47,084:INFO:SubProcess create_model() end ==================================
2023-08-15 15:18:47,084:INFO:Creating metrics dataframe
2023-08-15 15:18:47,092:INFO:Initializing Linear Discriminant Analysis
2023-08-15 15:18:47,092:INFO:Total runtime is 2.250337366263072 minutes
2023-08-15 15:18:47,094:INFO:SubProcess create_model() called ==================================
2023-08-15 15:18:47,095:INFO:Initializing create_model()
2023-08-15 15:18:47,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:18:47,095:INFO:Checking exceptions
2023-08-15 15:18:47,095:INFO:Importing libraries
2023-08-15 15:18:47,095:INFO:Copying training dataset
2023-08-15 15:18:47,141:INFO:Defining folds
2023-08-15 15:18:47,141:INFO:Declaring metric variables
2023-08-15 15:18:47,144:INFO:Importing untrained model
2023-08-15 15:18:47,146:INFO:Linear Discriminant Analysis Imported successfully
2023-08-15 15:18:47,150:INFO:Starting cross validation
2023-08-15 15:18:47,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:18:52,604:INFO:Calculating mean and std
2023-08-15 15:18:52,605:INFO:Creating metrics dataframe
2023-08-15 15:18:52,761:INFO:Uploading results into container
2023-08-15 15:18:52,762:INFO:Uploading model into container now
2023-08-15 15:18:52,762:INFO:_master_model_container: 16
2023-08-15 15:18:52,762:INFO:_display_container: 12
2023-08-15 15:18:52,762:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-15 15:18:52,763:INFO:create_model() successfully completed......................................
2023-08-15 15:18:52,879:INFO:SubProcess create_model() end ==================================
2023-08-15 15:18:52,880:INFO:Creating metrics dataframe
2023-08-15 15:18:52,886:INFO:Initializing Extra Trees Classifier
2023-08-15 15:18:52,886:INFO:Total runtime is 2.3469089587529504 minutes
2023-08-15 15:18:52,888:INFO:SubProcess create_model() called ==================================
2023-08-15 15:18:52,888:INFO:Initializing create_model()
2023-08-15 15:18:52,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:18:52,888:INFO:Checking exceptions
2023-08-15 15:18:52,888:INFO:Importing libraries
2023-08-15 15:18:52,888:INFO:Copying training dataset
2023-08-15 15:18:52,938:INFO:Defining folds
2023-08-15 15:18:52,938:INFO:Declaring metric variables
2023-08-15 15:18:52,940:INFO:Importing untrained model
2023-08-15 15:18:52,942:INFO:Extra Trees Classifier Imported successfully
2023-08-15 15:18:52,946:INFO:Starting cross validation
2023-08-15 15:18:52,947:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:19:33,760:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 15:19:35,039:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 15:19:37,499:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 15:19:37,706:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 15:19:39,274:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 15:19:39,274:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-15 15:19:40,618:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 15:19:40,977:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 15:19:41,092:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 15:19:41,202:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 15:19:41,276:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-15 15:19:43,147:INFO:Calculating mean and std
2023-08-15 15:19:43,148:INFO:Creating metrics dataframe
2023-08-15 15:19:43,337:INFO:Uploading results into container
2023-08-15 15:19:43,338:INFO:Uploading model into container now
2023-08-15 15:19:43,338:INFO:_master_model_container: 17
2023-08-15 15:19:43,339:INFO:_display_container: 12
2023-08-15 15:19:43,339:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-15 15:19:43,339:INFO:create_model() successfully completed......................................
2023-08-15 15:19:43,472:INFO:SubProcess create_model() end ==================================
2023-08-15 15:19:43,472:INFO:Creating metrics dataframe
2023-08-15 15:19:43,480:INFO:Initializing Extreme Gradient Boosting
2023-08-15 15:19:43,480:INFO:Total runtime is 3.1901450872421266 minutes
2023-08-15 15:19:43,483:INFO:SubProcess create_model() called ==================================
2023-08-15 15:19:43,483:INFO:Initializing create_model()
2023-08-15 15:19:43,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:19:43,483:INFO:Checking exceptions
2023-08-15 15:19:43,483:INFO:Importing libraries
2023-08-15 15:19:43,484:INFO:Copying training dataset
2023-08-15 15:19:43,539:INFO:Defining folds
2023-08-15 15:19:43,539:INFO:Declaring metric variables
2023-08-15 15:19:43,542:INFO:Importing untrained model
2023-08-15 15:19:43,545:INFO:Extreme Gradient Boosting Imported successfully
2023-08-15 15:19:43,549:INFO:Starting cross validation
2023-08-15 15:19:43,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:20:10,297:INFO:Calculating mean and std
2023-08-15 15:20:10,297:INFO:Creating metrics dataframe
2023-08-15 15:20:10,434:INFO:Uploading results into container
2023-08-15 15:20:10,434:INFO:Uploading model into container now
2023-08-15 15:20:10,435:INFO:_master_model_container: 18
2023-08-15 15:20:10,435:INFO:_display_container: 12
2023-08-15 15:20:10,435:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-15 15:20:10,436:INFO:create_model() successfully completed......................................
2023-08-15 15:20:10,557:INFO:SubProcess create_model() end ==================================
2023-08-15 15:20:10,557:INFO:Creating metrics dataframe
2023-08-15 15:20:10,563:INFO:Initializing Light Gradient Boosting Machine
2023-08-15 15:20:10,564:INFO:Total runtime is 3.6415353695551556 minutes
2023-08-15 15:20:10,566:INFO:SubProcess create_model() called ==================================
2023-08-15 15:20:10,566:INFO:Initializing create_model()
2023-08-15 15:20:10,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:20:10,566:INFO:Checking exceptions
2023-08-15 15:20:10,566:INFO:Importing libraries
2023-08-15 15:20:10,566:INFO:Copying training dataset
2023-08-15 15:20:10,620:INFO:Defining folds
2023-08-15 15:20:10,620:INFO:Declaring metric variables
2023-08-15 15:20:10,623:INFO:Importing untrained model
2023-08-15 15:20:10,625:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 15:20:10,630:INFO:Starting cross validation
2023-08-15 15:20:10,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:20:17,212:INFO:Calculating mean and std
2023-08-15 15:20:17,213:INFO:Creating metrics dataframe
2023-08-15 15:20:17,357:INFO:Uploading results into container
2023-08-15 15:20:17,358:INFO:Uploading model into container now
2023-08-15 15:20:17,358:INFO:_master_model_container: 19
2023-08-15 15:20:17,358:INFO:_display_container: 12
2023-08-15 15:20:17,359:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 15:20:17,359:INFO:create_model() successfully completed......................................
2023-08-15 15:20:17,486:INFO:SubProcess create_model() end ==================================
2023-08-15 15:20:17,486:INFO:Creating metrics dataframe
2023-08-15 15:20:17,493:INFO:Initializing CatBoost Classifier
2023-08-15 15:20:17,493:INFO:Total runtime is 3.757033109664917 minutes
2023-08-15 15:20:17,495:INFO:SubProcess create_model() called ==================================
2023-08-15 15:20:17,495:INFO:Initializing create_model()
2023-08-15 15:20:17,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:20:17,496:INFO:Checking exceptions
2023-08-15 15:20:17,496:INFO:Importing libraries
2023-08-15 15:20:17,496:INFO:Copying training dataset
2023-08-15 15:20:17,548:INFO:Defining folds
2023-08-15 15:20:17,548:INFO:Declaring metric variables
2023-08-15 15:20:17,551:INFO:Importing untrained model
2023-08-15 15:20:17,553:INFO:CatBoost Classifier Imported successfully
2023-08-15 15:20:17,557:INFO:Starting cross validation
2023-08-15 15:20:17,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:21:56,963:INFO:Calculating mean and std
2023-08-15 15:21:56,964:INFO:Creating metrics dataframe
2023-08-15 15:21:57,121:INFO:Uploading results into container
2023-08-15 15:21:57,122:INFO:Uploading model into container now
2023-08-15 15:21:57,122:INFO:_master_model_container: 20
2023-08-15 15:21:57,123:INFO:_display_container: 12
2023-08-15 15:21:57,123:INFO:<catboost.core.CatBoostClassifier object at 0x000001FB1AC9EEC0>
2023-08-15 15:21:57,123:INFO:create_model() successfully completed......................................
2023-08-15 15:21:57,244:INFO:SubProcess create_model() end ==================================
2023-08-15 15:21:57,244:INFO:Creating metrics dataframe
2023-08-15 15:21:57,252:INFO:Initializing Dummy Classifier
2023-08-15 15:21:57,252:INFO:Total runtime is 5.419672469298045 minutes
2023-08-15 15:21:57,254:INFO:SubProcess create_model() called ==================================
2023-08-15 15:21:57,255:INFO:Initializing create_model()
2023-08-15 15:21:57,255:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FB00DD4400>, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:21:57,255:INFO:Checking exceptions
2023-08-15 15:21:57,255:INFO:Importing libraries
2023-08-15 15:21:57,255:INFO:Copying training dataset
2023-08-15 15:21:57,309:INFO:Defining folds
2023-08-15 15:21:57,309:INFO:Declaring metric variables
2023-08-15 15:21:57,311:INFO:Importing untrained model
2023-08-15 15:21:57,314:INFO:Dummy Classifier Imported successfully
2023-08-15 15:21:57,318:INFO:Starting cross validation
2023-08-15 15:21:57,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-15 15:21:58,956:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:58,999:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:59,028:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:59,052:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:59,078:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:59,129:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:59,136:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:59,175:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:59,203:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:21:59,217:WARNING:c:\Users\Ramon\anaconda3\envs\PycaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-15 15:22:00,676:INFO:Calculating mean and std
2023-08-15 15:22:00,680:INFO:Creating metrics dataframe
2023-08-15 15:22:00,861:INFO:Uploading results into container
2023-08-15 15:22:00,861:INFO:Uploading model into container now
2023-08-15 15:22:00,862:INFO:_master_model_container: 21
2023-08-15 15:22:00,862:INFO:_display_container: 12
2023-08-15 15:22:00,862:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-15 15:22:00,862:INFO:create_model() successfully completed......................................
2023-08-15 15:22:00,981:INFO:SubProcess create_model() end ==================================
2023-08-15 15:22:00,981:INFO:Creating metrics dataframe
2023-08-15 15:22:00,994:INFO:Initializing create_model()
2023-08-15 15:22:00,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-15 15:22:00,994:INFO:Checking exceptions
2023-08-15 15:22:00,996:INFO:Importing libraries
2023-08-15 15:22:00,996:INFO:Copying training dataset
2023-08-15 15:22:01,049:INFO:Defining folds
2023-08-15 15:22:01,049:INFO:Declaring metric variables
2023-08-15 15:22:01,049:INFO:Importing untrained model
2023-08-15 15:22:01,049:INFO:Declaring custom model
2023-08-15 15:22:01,049:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-15 15:22:01,051:INFO:Cross validation set to False
2023-08-15 15:22:01,051:INFO:Fitting Model
2023-08-15 15:22:03,835:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-15 15:22:03,835:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-15 15:22:03,855:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006847 seconds.
2023-08-15 15:22:03,855:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-15 15:22:03,855:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-15 15:22:03,855:INFO:[LightGBM] [Info] Total Bins 851
2023-08-15 15:22:03,856:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-15 15:22:03,856:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-15 15:22:03,857:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-15 15:22:04,350:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 15:22:04,350:INFO:create_model() successfully completed......................................
2023-08-15 15:22:04,489:INFO:_master_model_container: 21
2023-08-15 15:22:04,489:INFO:_display_container: 12
2023-08-15 15:22:04,490:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-15 15:22:04,490:INFO:compare_models() successfully completed......................................
2023-08-15 15:23:36,060:INFO:Initializing evaluate_model()
2023-08-15 15:23:36,060:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-15 15:23:36,089:INFO:Initializing plot_model()
2023-08-15 15:23:36,089:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0, warm_start=False)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FB60265120>, system=True)
2023-08-15 15:23:36,089:INFO:Checking exceptions
2023-08-15 15:23:36,107:INFO:Preloading libraries
2023-08-15 15:23:36,112:INFO:Copying training dataset
2023-08-15 15:23:36,112:INFO:Plot type: pipeline
2023-08-15 15:23:36,223:INFO:Visual Rendered Successfully
2023-08-15 15:23:36,341:INFO:plot_model() successfully completed......................................
2023-08-16 18:44:39,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 18:44:39,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 18:44:39,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 18:44:39,584:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 18:47:39,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 18:47:39,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 18:47:39,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-16 18:47:39,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:29:00,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:29:00,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:29:00,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:29:00,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:39:17,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:39:17,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:39:17,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:39:17,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:55:14,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:55:14,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:55:14,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 07:55:14,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 08:08:32,055:INFO:PyCaret ClassificationExperiment
2023-08-17 08:08:32,055:INFO:Logging name: clf-default-name
2023-08-17 08:08:32,055:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 08:08:32,055:INFO:version 3.0.4
2023-08-17 08:08:32,055:INFO:Initializing setup()
2023-08-17 08:08:32,055:INFO:self.USI: 3acd
2023-08-17 08:08:32,055:INFO:self._variable_keys: {'html_param', 'pipeline', 'y_train', 'log_plots_param', 'memory', 'exp_name_log', 'fold_groups_param', 'data', 'gpu_param', 'fold_generator', 'gpu_n_jobs_param', 'y_test', 'y', 'X', 'fold_shuffle_param', '_ml_usecase', 'seed', 'X_test', 'X_train', 'n_jobs_param', 'fix_imbalance', 'idx', 'is_multiclass', 'exp_id', 'logging_param', '_available_plots', 'USI', 'target_param'}
2023-08-17 08:08:32,055:INFO:Checking environment
2023-08-17 08:08:32,055:INFO:python_version: 3.11.4
2023-08-17 08:08:32,055:INFO:python_build: ('main', 'Jun 10 2023 17:59:51')
2023-08-17 08:08:32,055:INFO:machine: AMD64
2023-08-17 08:08:32,055:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 08:08:32,059:INFO:Memory: svmem(total=68448301056, available=47354941440, percent=30.8, used=21093359616, free=47354941440)
2023-08-17 08:08:32,059:INFO:Physical Core: 12
2023-08-17 08:08:32,059:INFO:Logical Core: 20
2023-08-17 08:08:32,059:INFO:Checking libraries
2023-08-17 08:08:32,059:INFO:System:
2023-08-17 08:08:32,059:INFO:    python: 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 17:59:51) [MSC v.1935 64 bit (AMD64)]
2023-08-17 08:08:32,059:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaret\python.exe
2023-08-17 08:08:32,059:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 08:08:32,059:INFO:PyCaret required dependencies:
2023-08-17 08:08:32,089:INFO:                 pip: 23.2.1
2023-08-17 08:08:32,089:INFO:          setuptools: 68.0.0
2023-08-17 08:08:32,089:INFO:             pycaret: 3.0.4
2023-08-17 08:08:32,089:INFO:             IPython: 8.14.0
2023-08-17 08:08:32,089:INFO:          ipywidgets: 8.1.0
2023-08-17 08:08:32,089:INFO:                tqdm: 4.66.1
2023-08-17 08:08:32,089:INFO:               numpy: 1.23.5
2023-08-17 08:08:32,089:INFO:              pandas: 1.5.3
2023-08-17 08:08:32,089:INFO:              jinja2: 3.1.2
2023-08-17 08:08:32,089:INFO:               scipy: 1.11.1
2023-08-17 08:08:32,089:INFO:              joblib: 1.3.2
2023-08-17 08:08:32,089:INFO:             sklearn: 1.2.2
2023-08-17 08:08:32,089:INFO:                pyod: 1.1.0
2023-08-17 08:08:32,089:INFO:            imblearn: 0.11.0
2023-08-17 08:08:32,089:INFO:   category_encoders: 2.6.2
2023-08-17 08:08:32,090:INFO:            lightgbm: 4.0.0
2023-08-17 08:08:32,090:INFO:               numba: 0.57.1
2023-08-17 08:08:32,090:INFO:            requests: 2.31.0
2023-08-17 08:08:32,090:INFO:          matplotlib: 3.7.2
2023-08-17 08:08:32,090:INFO:          scikitplot: 0.3.7
2023-08-17 08:08:32,090:INFO:         yellowbrick: 1.5
2023-08-17 08:08:32,090:INFO:              plotly: 5.16.1
2023-08-17 08:08:32,090:INFO:    plotly-resampler: Not installed
2023-08-17 08:08:32,090:INFO:             kaleido: 0.2.1
2023-08-17 08:08:32,090:INFO:           schemdraw: 0.15
2023-08-17 08:08:32,090:INFO:         statsmodels: 0.14.0
2023-08-17 08:08:32,090:INFO:              sktime: 0.21.0
2023-08-17 08:08:32,090:INFO:               tbats: 1.1.3
2023-08-17 08:08:32,090:INFO:            pmdarima: 2.0.2
2023-08-17 08:08:32,090:INFO:              psutil: 5.9.5
2023-08-17 08:08:32,090:INFO:          markupsafe: 2.1.3
2023-08-17 08:08:32,090:INFO:             pickle5: Not installed
2023-08-17 08:08:32,090:INFO:         cloudpickle: 2.2.1
2023-08-17 08:08:32,090:INFO:         deprecation: 2.1.0
2023-08-17 08:08:32,090:INFO:              xxhash: Installed but version unavailable
2023-08-17 08:08:32,090:INFO:           wurlitzer: 3.0.3
2023-08-17 08:08:32,090:INFO:PyCaret optional dependencies:
2023-08-17 08:08:32,096:INFO:                shap: Not installed
2023-08-17 08:08:32,096:INFO:           interpret: Not installed
2023-08-17 08:08:32,096:INFO:                umap: 0.5.3
2023-08-17 08:08:32,096:INFO:    pandas_profiling: Not installed
2023-08-17 08:08:32,096:INFO:  explainerdashboard: Not installed
2023-08-17 08:08:32,096:INFO:             autoviz: Not installed
2023-08-17 08:08:32,096:INFO:           fairlearn: Not installed
2023-08-17 08:08:32,096:INFO:          deepchecks: Not installed
2023-08-17 08:08:32,096:INFO:             xgboost: Not installed
2023-08-17 08:08:32,096:INFO:            catboost: Not installed
2023-08-17 08:08:32,096:INFO:              kmodes: Not installed
2023-08-17 08:08:32,096:INFO:             mlxtend: Not installed
2023-08-17 08:08:32,096:INFO:       statsforecast: Not installed
2023-08-17 08:08:32,096:INFO:        tune_sklearn: Not installed
2023-08-17 08:08:32,096:INFO:                 ray: Not installed
2023-08-17 08:08:32,096:INFO:            hyperopt: Not installed
2023-08-17 08:08:32,096:INFO:              optuna: Not installed
2023-08-17 08:08:32,096:INFO:               skopt: Not installed
2023-08-17 08:08:32,096:INFO:              mlflow: Not installed
2023-08-17 08:08:32,096:INFO:              gradio: Not installed
2023-08-17 08:08:32,096:INFO:             fastapi: Not installed
2023-08-17 08:08:32,096:INFO:             uvicorn: Not installed
2023-08-17 08:08:32,096:INFO:              m2cgen: Not installed
2023-08-17 08:08:32,096:INFO:           evidently: Not installed
2023-08-17 08:08:32,097:INFO:               fugue: Not installed
2023-08-17 08:08:32,097:INFO:           streamlit: Not installed
2023-08-17 08:08:32,097:INFO:             prophet: Not installed
2023-08-17 08:08:32,097:INFO:None
2023-08-17 08:08:32,097:INFO:Set up data.
2023-08-17 08:08:32,288:INFO:Set up train/test split.
2023-08-17 08:08:32,437:INFO:Set up index.
2023-08-17 08:08:32,441:INFO:Set up folding strategy.
2023-08-17 08:08:32,442:INFO:Assigning column types.
2023-08-17 08:08:32,459:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 08:08:32,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 08:08:32,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 08:08:32,502:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 08:08:32,526:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 08:08:32,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,540:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 08:08:32,563:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 08:08:32,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,600:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 08:08:32,621:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,621:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 08:08:32,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:32,711:INFO:Preparing preprocessing pipeline...
2023-08-17 08:08:32,715:INFO:Set up label encoding.
2023-08-17 08:08:32,715:INFO:Set up simple imputation.
2023-08-17 08:08:32,750:INFO:Set up encoding of ordinal features.
2023-08-17 08:08:32,788:INFO:Set up encoding of categorical features.
2023-08-17 08:08:32,791:INFO:Set up column name cleaning.
2023-08-17 08:08:35,422:INFO:Finished creating preprocessing pipeline.
2023-08-17 08:08:35,453:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 08:08:35,454:INFO:Creating final display dataframe.
2023-08-17 08:08:37,427:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              3acd
2023-08-17 08:08:37,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:37,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:37,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:37,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:08:37,509:INFO:setup() successfully completed in 5.93s...............
2023-08-17 08:43:48,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 08:43:48,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 08:43:48,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 08:43:48,995:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 08:43:50,843:INFO:PyCaret ClassificationExperiment
2023-08-17 08:43:50,843:INFO:Logging name: clf-default-name
2023-08-17 08:43:50,843:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 08:43:50,843:INFO:version 3.0.4
2023-08-17 08:43:50,843:INFO:Initializing setup()
2023-08-17 08:43:50,843:INFO:self.USI: 370a
2023-08-17 08:43:50,843:INFO:self._variable_keys: {'n_jobs_param', 'X', 'fix_imbalance', 'data', 'y', 'fold_generator', 'X_test', 'target_param', 'fold_groups_param', 'log_plots_param', 'y_train', 'idx', 'y_test', '_ml_usecase', 'is_multiclass', 'memory', 'html_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'gpu_param', 'pipeline', 'logging_param', 'exp_id', 'USI', 'X_train', 'seed', '_available_plots', 'exp_name_log'}
2023-08-17 08:43:50,843:INFO:Checking environment
2023-08-17 08:43:50,843:INFO:python_version: 3.11.4
2023-08-17 08:43:50,843:INFO:python_build: ('main', 'Jun 10 2023 17:59:51')
2023-08-17 08:43:50,843:INFO:machine: AMD64
2023-08-17 08:43:50,843:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 08:43:50,847:INFO:Memory: svmem(total=68448301056, available=54418800640, percent=20.5, used=14029500416, free=54418800640)
2023-08-17 08:43:50,847:INFO:Physical Core: 12
2023-08-17 08:43:50,847:INFO:Logical Core: 20
2023-08-17 08:43:50,847:INFO:Checking libraries
2023-08-17 08:43:50,847:INFO:System:
2023-08-17 08:43:50,847:INFO:    python: 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 17:59:51) [MSC v.1935 64 bit (AMD64)]
2023-08-17 08:43:50,847:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-17 08:43:50,847:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 08:43:50,847:INFO:PyCaret required dependencies:
2023-08-17 08:43:50,858:INFO:                 pip: 23.2.1
2023-08-17 08:43:50,859:INFO:          setuptools: 68.0.0
2023-08-17 08:43:50,859:INFO:             pycaret: 3.0.4
2023-08-17 08:43:50,859:INFO:             IPython: 8.14.0
2023-08-17 08:43:50,859:INFO:          ipywidgets: 8.1.0
2023-08-17 08:43:50,859:INFO:                tqdm: 4.66.1
2023-08-17 08:43:50,859:INFO:               numpy: 1.23.5
2023-08-17 08:43:50,859:INFO:              pandas: 1.5.3
2023-08-17 08:43:50,859:INFO:              jinja2: 3.1.2
2023-08-17 08:43:50,859:INFO:               scipy: 1.11.1
2023-08-17 08:43:50,859:INFO:              joblib: 1.3.2
2023-08-17 08:43:50,859:INFO:             sklearn: 1.2.2
2023-08-17 08:43:50,859:INFO:                pyod: 1.1.0
2023-08-17 08:43:50,859:INFO:            imblearn: 0.11.0
2023-08-17 08:43:50,859:INFO:   category_encoders: 2.6.2
2023-08-17 08:43:50,859:INFO:            lightgbm: 4.0.0
2023-08-17 08:43:50,859:INFO:               numba: 0.57.1
2023-08-17 08:43:50,859:INFO:            requests: 2.31.0
2023-08-17 08:43:50,859:INFO:          matplotlib: 3.7.2
2023-08-17 08:43:50,859:INFO:          scikitplot: 0.3.7
2023-08-17 08:43:50,859:INFO:         yellowbrick: 1.5
2023-08-17 08:43:50,859:INFO:              plotly: 5.16.1
2023-08-17 08:43:50,859:INFO:    plotly-resampler: Not installed
2023-08-17 08:43:50,859:INFO:             kaleido: 0.2.1
2023-08-17 08:43:50,859:INFO:           schemdraw: 0.15
2023-08-17 08:43:50,859:INFO:         statsmodels: 0.14.0
2023-08-17 08:43:50,859:INFO:              sktime: 0.21.0
2023-08-17 08:43:50,859:INFO:               tbats: 1.1.3
2023-08-17 08:43:50,859:INFO:            pmdarima: 2.0.2
2023-08-17 08:43:50,859:INFO:              psutil: 5.9.5
2023-08-17 08:43:50,859:INFO:          markupsafe: 2.1.3
2023-08-17 08:43:50,859:INFO:             pickle5: Not installed
2023-08-17 08:43:50,859:INFO:         cloudpickle: 2.2.1
2023-08-17 08:43:50,859:INFO:         deprecation: 2.1.0
2023-08-17 08:43:50,859:INFO:              xxhash: 0.0.0
2023-08-17 08:43:50,859:INFO:           wurlitzer: 3.0.3
2023-08-17 08:43:50,859:INFO:PyCaret optional dependencies:
2023-08-17 08:43:50,865:INFO:                shap: Not installed
2023-08-17 08:43:50,865:INFO:           interpret: Not installed
2023-08-17 08:43:50,865:INFO:                umap: 0.5.3
2023-08-17 08:43:50,865:INFO:    pandas_profiling: Not installed
2023-08-17 08:43:50,865:INFO:  explainerdashboard: Not installed
2023-08-17 08:43:50,865:INFO:             autoviz: Not installed
2023-08-17 08:43:50,865:INFO:           fairlearn: Not installed
2023-08-17 08:43:50,865:INFO:          deepchecks: Not installed
2023-08-17 08:43:50,865:INFO:             xgboost: Not installed
2023-08-17 08:43:50,865:INFO:            catboost: Not installed
2023-08-17 08:43:50,865:INFO:              kmodes: Not installed
2023-08-17 08:43:50,865:INFO:             mlxtend: Not installed
2023-08-17 08:43:50,865:INFO:       statsforecast: Not installed
2023-08-17 08:43:50,866:INFO:        tune_sklearn: Not installed
2023-08-17 08:43:50,866:INFO:                 ray: Not installed
2023-08-17 08:43:50,866:INFO:            hyperopt: Not installed
2023-08-17 08:43:50,866:INFO:              optuna: Not installed
2023-08-17 08:43:50,866:INFO:               skopt: Not installed
2023-08-17 08:43:50,866:INFO:              mlflow: Not installed
2023-08-17 08:43:50,866:INFO:              gradio: Not installed
2023-08-17 08:43:50,866:INFO:             fastapi: Not installed
2023-08-17 08:43:50,866:INFO:             uvicorn: Not installed
2023-08-17 08:43:50,866:INFO:              m2cgen: Not installed
2023-08-17 08:43:50,866:INFO:           evidently: Not installed
2023-08-17 08:43:50,866:INFO:               fugue: Not installed
2023-08-17 08:43:50,866:INFO:           streamlit: Not installed
2023-08-17 08:43:50,866:INFO:             prophet: Not installed
2023-08-17 08:43:50,866:INFO:None
2023-08-17 08:43:50,866:INFO:Set up data.
2023-08-17 08:43:51,068:INFO:Set up train/test split.
2023-08-17 08:43:51,217:INFO:Set up index.
2023-08-17 08:43:51,238:INFO:Set up folding strategy.
2023-08-17 08:43:51,238:INFO:Assigning column types.
2023-08-17 08:43:51,254:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 08:43:51,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 08:43:51,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 08:43:51,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 08:43:51,320:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 08:43:51,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,334:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 08:43:51,356:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 08:43:51,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,369:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,391:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 08:43:51,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,405:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 08:43:51,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:51,510:INFO:Preparing preprocessing pipeline...
2023-08-17 08:43:51,515:INFO:Set up label encoding.
2023-08-17 08:43:51,515:INFO:Set up simple imputation.
2023-08-17 08:43:51,553:INFO:Set up encoding of ordinal features.
2023-08-17 08:43:51,612:INFO:Set up encoding of categorical features.
2023-08-17 08:43:51,615:INFO:Set up column name cleaning.
2023-08-17 08:43:53,154:INFO:Finished creating preprocessing pipeline.
2023-08-17 08:43:53,187:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 08:43:53,187:INFO:Creating final display dataframe.
2023-08-17 08:43:54,503:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (293411, 19)
5        Transformed data shape      (293411, 42)
6   Transformed train set shape      (205387, 42)
7    Transformed test set shape       (88024, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              370a
2023-08-17 08:43:54,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:54,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:54,586:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:54,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 08:43:54,587:INFO:setup() successfully completed in 4.16s...............
2023-08-17 08:43:59,635:INFO:Initializing compare_models()
2023-08-17 08:43:59,635:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-08-17 08:43:59,635:INFO:Checking exceptions
2023-08-17 08:43:59,657:INFO:Preparing display monitor
2023-08-17 08:43:59,670:INFO:Initializing Logistic Regression
2023-08-17 08:43:59,671:INFO:Total runtime is 1.81118647257487e-05 minutes
2023-08-17 08:43:59,675:INFO:SubProcess create_model() called ==================================
2023-08-17 08:43:59,675:INFO:Initializing create_model()
2023-08-17 08:43:59,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:43:59,675:INFO:Checking exceptions
2023-08-17 08:43:59,675:INFO:Importing libraries
2023-08-17 08:43:59,675:INFO:Copying training dataset
2023-08-17 08:43:59,719:INFO:Defining folds
2023-08-17 08:43:59,720:INFO:Declaring metric variables
2023-08-17 08:43:59,722:INFO:Importing untrained model
2023-08-17 08:43:59,724:INFO:Logistic Regression Imported successfully
2023-08-17 08:43:59,732:INFO:Starting cross validation
2023-08-17 08:43:59,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:45:00,763:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:00,968:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:01,164:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:01,206:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:01,306:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:01,570:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:01,700:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:01,727:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:01,789:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:01,790:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 08:45:03,385:INFO:Calculating mean and std
2023-08-17 08:45:03,386:INFO:Creating metrics dataframe
2023-08-17 08:45:03,542:INFO:Uploading results into container
2023-08-17 08:45:03,542:INFO:Uploading model into container now
2023-08-17 08:45:03,543:INFO:_master_model_container: 1
2023-08-17 08:45:03,543:INFO:_display_container: 2
2023-08-17 08:45:03,543:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-17 08:45:03,543:INFO:create_model() successfully completed......................................
2023-08-17 08:45:03,603:INFO:SubProcess create_model() end ==================================
2023-08-17 08:45:03,603:INFO:Creating metrics dataframe
2023-08-17 08:45:03,608:INFO:Initializing K Neighbors Classifier
2023-08-17 08:45:03,608:INFO:Total runtime is 1.0656346956888836 minutes
2023-08-17 08:45:03,610:INFO:SubProcess create_model() called ==================================
2023-08-17 08:45:03,610:INFO:Initializing create_model()
2023-08-17 08:45:03,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:45:03,610:INFO:Checking exceptions
2023-08-17 08:45:03,611:INFO:Importing libraries
2023-08-17 08:45:03,611:INFO:Copying training dataset
2023-08-17 08:45:03,652:INFO:Defining folds
2023-08-17 08:45:03,652:INFO:Declaring metric variables
2023-08-17 08:45:03,654:INFO:Importing untrained model
2023-08-17 08:45:03,656:INFO:K Neighbors Classifier Imported successfully
2023-08-17 08:45:03,659:INFO:Starting cross validation
2023-08-17 08:45:03,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:45:41,636:INFO:Calculating mean and std
2023-08-17 08:45:41,637:INFO:Creating metrics dataframe
2023-08-17 08:45:41,796:INFO:Uploading results into container
2023-08-17 08:45:41,796:INFO:Uploading model into container now
2023-08-17 08:45:41,797:INFO:_master_model_container: 2
2023-08-17 08:45:41,797:INFO:_display_container: 2
2023-08-17 08:45:41,797:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-17 08:45:41,797:INFO:create_model() successfully completed......................................
2023-08-17 08:45:41,846:INFO:SubProcess create_model() end ==================================
2023-08-17 08:45:41,846:INFO:Creating metrics dataframe
2023-08-17 08:45:41,851:INFO:Initializing Naive Bayes
2023-08-17 08:45:41,851:INFO:Total runtime is 1.7030153989791872 minutes
2023-08-17 08:45:41,853:INFO:SubProcess create_model() called ==================================
2023-08-17 08:45:41,853:INFO:Initializing create_model()
2023-08-17 08:45:41,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:45:41,853:INFO:Checking exceptions
2023-08-17 08:45:41,853:INFO:Importing libraries
2023-08-17 08:45:41,853:INFO:Copying training dataset
2023-08-17 08:45:41,890:INFO:Defining folds
2023-08-17 08:45:41,890:INFO:Declaring metric variables
2023-08-17 08:45:41,893:INFO:Importing untrained model
2023-08-17 08:45:41,895:INFO:Naive Bayes Imported successfully
2023-08-17 08:45:41,900:INFO:Starting cross validation
2023-08-17 08:45:41,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:45:46,039:INFO:Calculating mean and std
2023-08-17 08:45:46,039:INFO:Creating metrics dataframe
2023-08-17 08:45:46,223:INFO:Uploading results into container
2023-08-17 08:45:46,224:INFO:Uploading model into container now
2023-08-17 08:45:46,224:INFO:_master_model_container: 3
2023-08-17 08:45:46,224:INFO:_display_container: 2
2023-08-17 08:45:46,225:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-17 08:45:46,225:INFO:create_model() successfully completed......................................
2023-08-17 08:45:46,272:INFO:SubProcess create_model() end ==================================
2023-08-17 08:45:46,272:INFO:Creating metrics dataframe
2023-08-17 08:45:46,279:INFO:Initializing Decision Tree Classifier
2023-08-17 08:45:46,279:INFO:Total runtime is 1.776818923155467 minutes
2023-08-17 08:45:46,281:INFO:SubProcess create_model() called ==================================
2023-08-17 08:45:46,281:INFO:Initializing create_model()
2023-08-17 08:45:46,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:45:46,281:INFO:Checking exceptions
2023-08-17 08:45:46,281:INFO:Importing libraries
2023-08-17 08:45:46,281:INFO:Copying training dataset
2023-08-17 08:45:46,324:INFO:Defining folds
2023-08-17 08:45:46,324:INFO:Declaring metric variables
2023-08-17 08:45:46,326:INFO:Importing untrained model
2023-08-17 08:45:46,329:INFO:Decision Tree Classifier Imported successfully
2023-08-17 08:45:46,332:INFO:Starting cross validation
2023-08-17 08:45:46,334:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:45:51,609:INFO:Calculating mean and std
2023-08-17 08:45:51,609:INFO:Creating metrics dataframe
2023-08-17 08:45:51,764:INFO:Uploading results into container
2023-08-17 08:45:51,764:INFO:Uploading model into container now
2023-08-17 08:45:51,765:INFO:_master_model_container: 4
2023-08-17 08:45:51,765:INFO:_display_container: 2
2023-08-17 08:45:51,765:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-17 08:45:51,765:INFO:create_model() successfully completed......................................
2023-08-17 08:45:51,807:INFO:SubProcess create_model() end ==================================
2023-08-17 08:45:51,807:INFO:Creating metrics dataframe
2023-08-17 08:45:51,812:INFO:Initializing SVM - Linear Kernel
2023-08-17 08:45:51,812:INFO:Total runtime is 1.8690300981203718 minutes
2023-08-17 08:45:51,814:INFO:SubProcess create_model() called ==================================
2023-08-17 08:45:51,814:INFO:Initializing create_model()
2023-08-17 08:45:51,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:45:51,814:INFO:Checking exceptions
2023-08-17 08:45:51,814:INFO:Importing libraries
2023-08-17 08:45:51,814:INFO:Copying training dataset
2023-08-17 08:45:51,846:INFO:Defining folds
2023-08-17 08:45:51,846:INFO:Declaring metric variables
2023-08-17 08:45:51,848:INFO:Importing untrained model
2023-08-17 08:45:51,850:INFO:SVM - Linear Kernel Imported successfully
2023-08-17 08:45:51,853:INFO:Starting cross validation
2023-08-17 08:45:51,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:46:10,399:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:11,169:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:11,286:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:11,492:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:46:11,778:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:12,261:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:12,422:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:12,469:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:12,589:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:12,912:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:13,283:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 08:46:13,708:INFO:Calculating mean and std
2023-08-17 08:46:13,709:INFO:Creating metrics dataframe
2023-08-17 08:46:13,911:INFO:Uploading results into container
2023-08-17 08:46:13,912:INFO:Uploading model into container now
2023-08-17 08:46:13,912:INFO:_master_model_container: 5
2023-08-17 08:46:13,912:INFO:_display_container: 2
2023-08-17 08:46:13,912:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-17 08:46:13,913:INFO:create_model() successfully completed......................................
2023-08-17 08:46:13,960:INFO:SubProcess create_model() end ==================================
2023-08-17 08:46:13,961:INFO:Creating metrics dataframe
2023-08-17 08:46:13,967:INFO:Initializing Ridge Classifier
2023-08-17 08:46:13,967:INFO:Total runtime is 2.238278921445211 minutes
2023-08-17 08:46:13,969:INFO:SubProcess create_model() called ==================================
2023-08-17 08:46:13,969:INFO:Initializing create_model()
2023-08-17 08:46:13,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:46:13,969:INFO:Checking exceptions
2023-08-17 08:46:13,970:INFO:Importing libraries
2023-08-17 08:46:13,970:INFO:Copying training dataset
2023-08-17 08:46:14,009:INFO:Defining folds
2023-08-17 08:46:14,009:INFO:Declaring metric variables
2023-08-17 08:46:14,011:INFO:Importing untrained model
2023-08-17 08:46:14,013:INFO:Ridge Classifier Imported successfully
2023-08-17 08:46:14,017:INFO:Starting cross validation
2023-08-17 08:46:14,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:46:16,153:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,248:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,257:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,264:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,269:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,269:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,270:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,276:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,281:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:16,302:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 08:46:18,127:INFO:Calculating mean and std
2023-08-17 08:46:18,127:INFO:Creating metrics dataframe
2023-08-17 08:46:18,299:INFO:Uploading results into container
2023-08-17 08:46:18,299:INFO:Uploading model into container now
2023-08-17 08:46:18,299:INFO:_master_model_container: 6
2023-08-17 08:46:18,299:INFO:_display_container: 2
2023-08-17 08:46:18,300:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-17 08:46:18,300:INFO:create_model() successfully completed......................................
2023-08-17 08:46:18,347:INFO:SubProcess create_model() end ==================================
2023-08-17 08:46:18,347:INFO:Creating metrics dataframe
2023-08-17 08:46:18,353:INFO:Initializing Random Forest Classifier
2023-08-17 08:46:18,353:INFO:Total runtime is 2.311375908056895 minutes
2023-08-17 08:46:18,355:INFO:SubProcess create_model() called ==================================
2023-08-17 08:46:18,355:INFO:Initializing create_model()
2023-08-17 08:46:18,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:46:18,355:INFO:Checking exceptions
2023-08-17 08:46:18,355:INFO:Importing libraries
2023-08-17 08:46:18,355:INFO:Copying training dataset
2023-08-17 08:46:18,391:INFO:Defining folds
2023-08-17 08:46:18,391:INFO:Declaring metric variables
2023-08-17 08:46:18,393:INFO:Importing untrained model
2023-08-17 08:46:18,395:INFO:Random Forest Classifier Imported successfully
2023-08-17 08:46:18,399:INFO:Starting cross validation
2023-08-17 08:46:18,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:46:52,835:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 08:46:53,173:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 08:46:53,371:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 08:46:56,459:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-17 08:46:56,828:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-17 08:46:59,870:INFO:Calculating mean and std
2023-08-17 08:46:59,871:INFO:Creating metrics dataframe
2023-08-17 08:47:00,062:INFO:Uploading results into container
2023-08-17 08:47:00,063:INFO:Uploading model into container now
2023-08-17 08:47:00,063:INFO:_master_model_container: 7
2023-08-17 08:47:00,063:INFO:_display_container: 2
2023-08-17 08:47:00,063:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-17 08:47:00,063:INFO:create_model() successfully completed......................................
2023-08-17 08:47:00,118:INFO:SubProcess create_model() end ==================================
2023-08-17 08:47:00,118:INFO:Creating metrics dataframe
2023-08-17 08:47:00,126:INFO:Initializing Quadratic Discriminant Analysis
2023-08-17 08:47:00,126:INFO:Total runtime is 3.007601320743561 minutes
2023-08-17 08:47:00,128:INFO:SubProcess create_model() called ==================================
2023-08-17 08:47:00,129:INFO:Initializing create_model()
2023-08-17 08:47:00,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:47:00,129:INFO:Checking exceptions
2023-08-17 08:47:00,129:INFO:Importing libraries
2023-08-17 08:47:00,129:INFO:Copying training dataset
2023-08-17 08:47:00,173:INFO:Defining folds
2023-08-17 08:47:00,173:INFO:Declaring metric variables
2023-08-17 08:47:00,176:INFO:Importing untrained model
2023-08-17 08:47:00,179:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-17 08:47:00,183:INFO:Starting cross validation
2023-08-17 08:47:00,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:47:03,430:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,493:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,522:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,528:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,671:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,684:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,753:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,761:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,778:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:03,819:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 08:47:06,196:INFO:Calculating mean and std
2023-08-17 08:47:06,196:INFO:Creating metrics dataframe
2023-08-17 08:47:06,397:INFO:Uploading results into container
2023-08-17 08:47:06,397:INFO:Uploading model into container now
2023-08-17 08:47:06,398:INFO:_master_model_container: 8
2023-08-17 08:47:06,398:INFO:_display_container: 2
2023-08-17 08:47:06,398:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-17 08:47:06,398:INFO:create_model() successfully completed......................................
2023-08-17 08:47:06,444:INFO:SubProcess create_model() end ==================================
2023-08-17 08:47:06,444:INFO:Creating metrics dataframe
2023-08-17 08:47:06,450:INFO:Initializing Ada Boost Classifier
2023-08-17 08:47:06,450:INFO:Total runtime is 3.113003730773926 minutes
2023-08-17 08:47:06,452:INFO:SubProcess create_model() called ==================================
2023-08-17 08:47:06,452:INFO:Initializing create_model()
2023-08-17 08:47:06,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:47:06,453:INFO:Checking exceptions
2023-08-17 08:47:06,453:INFO:Importing libraries
2023-08-17 08:47:06,453:INFO:Copying training dataset
2023-08-17 08:47:06,497:INFO:Defining folds
2023-08-17 08:47:06,498:INFO:Declaring metric variables
2023-08-17 08:47:06,500:INFO:Importing untrained model
2023-08-17 08:47:06,502:INFO:Ada Boost Classifier Imported successfully
2023-08-17 08:47:06,505:INFO:Starting cross validation
2023-08-17 08:47:06,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:47:25,464:INFO:Calculating mean and std
2023-08-17 08:47:25,465:INFO:Creating metrics dataframe
2023-08-17 08:47:25,662:INFO:Uploading results into container
2023-08-17 08:47:25,663:INFO:Uploading model into container now
2023-08-17 08:47:25,663:INFO:_master_model_container: 9
2023-08-17 08:47:25,663:INFO:_display_container: 2
2023-08-17 08:47:25,663:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-17 08:47:25,663:INFO:create_model() successfully completed......................................
2023-08-17 08:47:25,709:INFO:SubProcess create_model() end ==================================
2023-08-17 08:47:25,709:INFO:Creating metrics dataframe
2023-08-17 08:47:25,716:INFO:Initializing Gradient Boosting Classifier
2023-08-17 08:47:25,716:INFO:Total runtime is 3.434097452958425 minutes
2023-08-17 08:47:25,718:INFO:SubProcess create_model() called ==================================
2023-08-17 08:47:25,719:INFO:Initializing create_model()
2023-08-17 08:47:25,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:47:25,719:INFO:Checking exceptions
2023-08-17 08:47:25,719:INFO:Importing libraries
2023-08-17 08:47:25,719:INFO:Copying training dataset
2023-08-17 08:47:25,758:INFO:Defining folds
2023-08-17 08:47:25,758:INFO:Declaring metric variables
2023-08-17 08:47:25,760:INFO:Importing untrained model
2023-08-17 08:47:25,762:INFO:Gradient Boosting Classifier Imported successfully
2023-08-17 08:47:25,766:INFO:Starting cross validation
2023-08-17 08:47:25,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:48:11,589:INFO:Calculating mean and std
2023-08-17 08:48:11,590:INFO:Creating metrics dataframe
2023-08-17 08:48:11,781:INFO:Uploading results into container
2023-08-17 08:48:11,782:INFO:Uploading model into container now
2023-08-17 08:48:11,782:INFO:_master_model_container: 10
2023-08-17 08:48:11,782:INFO:_display_container: 2
2023-08-17 08:48:11,783:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-17 08:48:11,783:INFO:create_model() successfully completed......................................
2023-08-17 08:48:11,834:INFO:SubProcess create_model() end ==================================
2023-08-17 08:48:11,834:INFO:Creating metrics dataframe
2023-08-17 08:48:11,840:INFO:Initializing Linear Discriminant Analysis
2023-08-17 08:48:11,840:INFO:Total runtime is 4.2028271595637 minutes
2023-08-17 08:48:11,842:INFO:SubProcess create_model() called ==================================
2023-08-17 08:48:11,843:INFO:Initializing create_model()
2023-08-17 08:48:11,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:48:11,843:INFO:Checking exceptions
2023-08-17 08:48:11,843:INFO:Importing libraries
2023-08-17 08:48:11,843:INFO:Copying training dataset
2023-08-17 08:48:11,882:INFO:Defining folds
2023-08-17 08:48:11,882:INFO:Declaring metric variables
2023-08-17 08:48:11,884:INFO:Importing untrained model
2023-08-17 08:48:11,887:INFO:Linear Discriminant Analysis Imported successfully
2023-08-17 08:48:11,890:INFO:Starting cross validation
2023-08-17 08:48:11,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:48:17,715:INFO:Calculating mean and std
2023-08-17 08:48:17,715:INFO:Creating metrics dataframe
2023-08-17 08:48:17,919:INFO:Uploading results into container
2023-08-17 08:48:17,920:INFO:Uploading model into container now
2023-08-17 08:48:17,920:INFO:_master_model_container: 11
2023-08-17 08:48:17,920:INFO:_display_container: 2
2023-08-17 08:48:17,920:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-17 08:48:17,921:INFO:create_model() successfully completed......................................
2023-08-17 08:48:17,966:INFO:SubProcess create_model() end ==================================
2023-08-17 08:48:17,967:INFO:Creating metrics dataframe
2023-08-17 08:48:17,973:INFO:Initializing Extra Trees Classifier
2023-08-17 08:48:17,973:INFO:Total runtime is 4.305050905545552 minutes
2023-08-17 08:48:17,974:INFO:SubProcess create_model() called ==================================
2023-08-17 08:48:17,975:INFO:Initializing create_model()
2023-08-17 08:48:17,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:48:17,975:INFO:Checking exceptions
2023-08-17 08:48:17,975:INFO:Importing libraries
2023-08-17 08:48:17,975:INFO:Copying training dataset
2023-08-17 08:48:18,009:INFO:Defining folds
2023-08-17 08:48:18,010:INFO:Declaring metric variables
2023-08-17 08:48:18,012:INFO:Importing untrained model
2023-08-17 08:48:18,014:INFO:Extra Trees Classifier Imported successfully
2023-08-17 08:48:18,017:INFO:Starting cross validation
2023-08-17 08:48:18,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:49:09,191:INFO:Calculating mean and std
2023-08-17 08:49:09,192:INFO:Creating metrics dataframe
2023-08-17 08:49:09,354:INFO:Uploading results into container
2023-08-17 08:49:09,354:INFO:Uploading model into container now
2023-08-17 08:49:09,354:INFO:_master_model_container: 12
2023-08-17 08:49:09,355:INFO:_display_container: 2
2023-08-17 08:49:09,356:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-17 08:49:09,356:INFO:create_model() successfully completed......................................
2023-08-17 08:49:09,401:INFO:SubProcess create_model() end ==================================
2023-08-17 08:49:09,401:INFO:Creating metrics dataframe
2023-08-17 08:49:09,408:INFO:Initializing Light Gradient Boosting Machine
2023-08-17 08:49:09,408:INFO:Total runtime is 5.162301985422769 minutes
2023-08-17 08:49:09,410:INFO:SubProcess create_model() called ==================================
2023-08-17 08:49:09,410:INFO:Initializing create_model()
2023-08-17 08:49:09,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:49:09,410:INFO:Checking exceptions
2023-08-17 08:49:09,410:INFO:Importing libraries
2023-08-17 08:49:09,411:INFO:Copying training dataset
2023-08-17 08:49:09,446:INFO:Defining folds
2023-08-17 08:49:09,446:INFO:Declaring metric variables
2023-08-17 08:49:09,448:INFO:Importing untrained model
2023-08-17 08:49:09,451:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 08:49:09,455:INFO:Starting cross validation
2023-08-17 08:49:09,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:49:15,600:INFO:Calculating mean and std
2023-08-17 08:49:15,601:INFO:Creating metrics dataframe
2023-08-17 08:49:15,753:INFO:Uploading results into container
2023-08-17 08:49:15,754:INFO:Uploading model into container now
2023-08-17 08:49:15,754:INFO:_master_model_container: 13
2023-08-17 08:49:15,754:INFO:_display_container: 2
2023-08-17 08:49:15,754:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 08:49:15,755:INFO:create_model() successfully completed......................................
2023-08-17 08:49:15,802:INFO:SubProcess create_model() end ==================================
2023-08-17 08:49:15,803:INFO:Creating metrics dataframe
2023-08-17 08:49:15,810:INFO:Initializing Dummy Classifier
2023-08-17 08:49:15,810:INFO:Total runtime is 5.268989833196003 minutes
2023-08-17 08:49:15,813:INFO:SubProcess create_model() called ==================================
2023-08-17 08:49:15,813:INFO:Initializing create_model()
2023-08-17 08:49:15,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDC1BE750>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:49:15,813:INFO:Checking exceptions
2023-08-17 08:49:15,813:INFO:Importing libraries
2023-08-17 08:49:15,813:INFO:Copying training dataset
2023-08-17 08:49:15,848:INFO:Defining folds
2023-08-17 08:49:15,848:INFO:Declaring metric variables
2023-08-17 08:49:15,850:INFO:Importing untrained model
2023-08-17 08:49:15,852:INFO:Dummy Classifier Imported successfully
2023-08-17 08:49:15,855:INFO:Starting cross validation
2023-08-17 08:49:15,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:49:17,283:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,340:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,355:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,376:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,383:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,423:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,452:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,482:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,489:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:17,509:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 08:49:18,890:INFO:Calculating mean and std
2023-08-17 08:49:18,890:INFO:Creating metrics dataframe
2023-08-17 08:49:19,042:INFO:Uploading results into container
2023-08-17 08:49:19,043:INFO:Uploading model into container now
2023-08-17 08:49:19,043:INFO:_master_model_container: 14
2023-08-17 08:49:19,044:INFO:_display_container: 2
2023-08-17 08:49:19,044:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-17 08:49:19,044:INFO:create_model() successfully completed......................................
2023-08-17 08:49:19,089:INFO:SubProcess create_model() end ==================================
2023-08-17 08:49:19,090:INFO:Creating metrics dataframe
2023-08-17 08:49:19,101:INFO:Initializing create_model()
2023-08-17 08:49:19,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:49:19,101:INFO:Checking exceptions
2023-08-17 08:49:19,102:INFO:Importing libraries
2023-08-17 08:49:19,102:INFO:Copying training dataset
2023-08-17 08:49:19,137:INFO:Defining folds
2023-08-17 08:49:19,137:INFO:Declaring metric variables
2023-08-17 08:49:19,137:INFO:Importing untrained model
2023-08-17 08:49:19,137:INFO:Declaring custom model
2023-08-17 08:49:19,138:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 08:49:19,139:INFO:Cross validation set to False
2023-08-17 08:49:19,139:INFO:Fitting Model
2023-08-17 08:49:21,759:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-17 08:49:21,759:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-17 08:49:21,777:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006279 seconds.
2023-08-17 08:49:21,777:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-17 08:49:21,777:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-17 08:49:21,778:INFO:[LightGBM] [Info] Total Bins 851
2023-08-17 08:49:21,778:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-17 08:49:21,779:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-17 08:49:21,779:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-17 08:49:22,227:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 08:49:22,227:INFO:create_model() successfully completed......................................
2023-08-17 08:49:22,290:INFO:_master_model_container: 14
2023-08-17 08:49:22,290:INFO:_display_container: 2
2023-08-17 08:49:22,290:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 08:49:22,290:INFO:compare_models() successfully completed......................................
2023-08-17 08:49:35,354:INFO:Initializing tune_model()
2023-08-17 08:49:35,355:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=best, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-08-17 08:49:35,355:INFO:Checking exceptions
2023-08-17 08:51:04,674:INFO:Initializing create_model()
2023-08-17 08:51:04,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:51:04,674:INFO:Checking exceptions
2023-08-17 08:51:04,682:INFO:Importing libraries
2023-08-17 08:51:04,683:INFO:Copying training dataset
2023-08-17 08:51:04,726:INFO:Defining folds
2023-08-17 08:51:04,726:INFO:Declaring metric variables
2023-08-17 08:51:04,728:INFO:Importing untrained model
2023-08-17 08:51:04,732:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 08:51:04,736:INFO:Starting cross validation
2023-08-17 08:51:04,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:51:08,213:INFO:Calculating mean and std
2023-08-17 08:51:08,214:INFO:Creating metrics dataframe
2023-08-17 08:51:08,218:INFO:Finalizing model
2023-08-17 08:51:10,381:INFO:Uploading results into container
2023-08-17 08:51:10,382:INFO:Uploading model into container now
2023-08-17 08:51:10,387:INFO:_master_model_container: 15
2023-08-17 08:51:10,389:INFO:_display_container: 3
2023-08-17 08:51:10,389:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 08:51:10,389:INFO:create_model() successfully completed......................................
2023-08-17 08:51:16,590:INFO:Initializing tune_model()
2023-08-17 08:51:16,590:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2023-08-17 08:51:16,591:INFO:Checking exceptions
2023-08-17 08:51:16,613:INFO:Copying training dataset
2023-08-17 08:51:16,639:INFO:Checking base model
2023-08-17 08:51:16,639:INFO:Base model : Light Gradient Boosting Machine
2023-08-17 08:51:16,641:INFO:Declaring metric variables
2023-08-17 08:51:16,643:INFO:Defining Hyperparameters
2023-08-17 08:51:16,710:INFO:Tuning with n_jobs=-1
2023-08-17 08:51:16,710:INFO:Initializing RandomizedSearchCV
2023-08-17 08:52:30,409:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-08-17 08:52:30,410:INFO:Hyperparameter search completed
2023-08-17 08:52:30,410:INFO:SubProcess create_model() called ==================================
2023-08-17 08:52:30,411:INFO:Initializing create_model()
2023-08-17 08:52:30,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001BFDBF46E90>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-08-17 08:52:30,411:INFO:Checking exceptions
2023-08-17 08:52:30,411:INFO:Importing libraries
2023-08-17 08:52:30,411:INFO:Copying training dataset
2023-08-17 08:52:30,450:INFO:Defining folds
2023-08-17 08:52:30,450:INFO:Declaring metric variables
2023-08-17 08:52:30,452:INFO:Importing untrained model
2023-08-17 08:52:30,452:INFO:Declaring custom model
2023-08-17 08:52:30,455:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 08:52:30,458:INFO:Starting cross validation
2023-08-17 08:52:30,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:52:34,298:INFO:Calculating mean and std
2023-08-17 08:52:34,298:INFO:Creating metrics dataframe
2023-08-17 08:52:34,302:INFO:Finalizing model
2023-08-17 08:52:34,860:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-17 08:52:34,860:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-17 08:52:34,860:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-17 08:52:34,941:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-17 08:52:34,941:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-17 08:52:34,941:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-17 08:52:34,941:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-17 08:52:34,941:INFO:[LightGBM] [Info] Number of positive: 16634, number of negative: 188753
2023-08-17 08:52:34,958:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005360 seconds.
2023-08-17 08:52:34,958:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-17 08:52:34,958:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-17 08:52:34,959:INFO:[LightGBM] [Info] Total Bins 851
2023-08-17 08:52:34,959:INFO:[LightGBM] [Info] Number of data points in the train set: 205387, number of used features: 41
2023-08-17 08:52:34,961:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080989 -> initscore=-2.428990
2023-08-17 08:52:34,961:INFO:[LightGBM] [Info] Start training from score -2.428990
2023-08-17 08:52:35,625:INFO:Uploading results into container
2023-08-17 08:52:35,626:INFO:Uploading model into container now
2023-08-17 08:52:35,626:INFO:_master_model_container: 16
2023-08-17 08:52:35,626:INFO:_display_container: 4
2023-08-17 08:52:35,626:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-17 08:52:35,626:INFO:create_model() successfully completed......................................
2023-08-17 08:52:35,693:INFO:SubProcess create_model() end ==================================
2023-08-17 08:52:35,693:INFO:choose_better activated
2023-08-17 08:52:35,695:INFO:SubProcess create_model() called ==================================
2023-08-17 08:52:35,695:INFO:Initializing create_model()
2023-08-17 08:52:35,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001BFD63D37D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 08:52:35,696:INFO:Checking exceptions
2023-08-17 08:52:35,697:INFO:Importing libraries
2023-08-17 08:52:35,697:INFO:Copying training dataset
2023-08-17 08:52:35,733:INFO:Defining folds
2023-08-17 08:52:35,733:INFO:Declaring metric variables
2023-08-17 08:52:35,733:INFO:Importing untrained model
2023-08-17 08:52:35,733:INFO:Declaring custom model
2023-08-17 08:52:35,734:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 08:52:35,734:INFO:Starting cross validation
2023-08-17 08:52:35,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 08:52:39,125:INFO:Calculating mean and std
2023-08-17 08:52:39,125:INFO:Creating metrics dataframe
2023-08-17 08:52:39,126:INFO:Finalizing model
2023-08-17 08:52:39,839:INFO:Uploading results into container
2023-08-17 08:52:39,840:INFO:Uploading model into container now
2023-08-17 08:52:39,840:INFO:_master_model_container: 17
2023-08-17 08:52:39,840:INFO:_display_container: 5
2023-08-17 08:52:39,840:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 08:52:39,840:INFO:create_model() successfully completed......................................
2023-08-17 08:52:39,908:INFO:SubProcess create_model() end ==================================
2023-08-17 08:52:39,909:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9194
2023-08-17 08:52:39,909:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9193
2023-08-17 08:52:39,909:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-17 08:52:39,909:INFO:choose_better completed
2023-08-17 08:52:39,909:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-17 08:52:39,915:INFO:_master_model_container: 17
2023-08-17 08:52:39,915:INFO:_display_container: 4
2023-08-17 08:52:39,915:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 08:52:39,915:INFO:tune_model() successfully completed......................................
2023-08-17 09:01:26,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 09:01:26,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 09:01:26,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 09:01:26,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 09:01:30,486:INFO:PyCaret ClassificationExperiment
2023-08-17 09:01:30,486:INFO:Logging name: clf-default-name
2023-08-17 09:01:30,486:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 09:01:30,486:INFO:version 3.0.4
2023-08-17 09:01:30,486:INFO:Initializing setup()
2023-08-17 09:01:30,486:INFO:self.USI: dde2
2023-08-17 09:01:30,486:INFO:self._variable_keys: {'fix_imbalance', 'exp_name_log', 'fold_shuffle_param', 'pipeline', '_ml_usecase', 'seed', 'idx', 'gpu_param', 'target_param', 'log_plots_param', 'logging_param', 'fold_groups_param', 'n_jobs_param', 'X', 'y_test', 'is_multiclass', 'memory', 'exp_id', 'gpu_n_jobs_param', 'html_param', 'X_train', 'USI', 'fold_generator', 'X_test', 'y', '_available_plots', 'y_train', 'data'}
2023-08-17 09:01:30,486:INFO:Checking environment
2023-08-17 09:01:30,486:INFO:python_version: 3.11.4
2023-08-17 09:01:30,486:INFO:python_build: ('main', 'Jun 10 2023 17:59:51')
2023-08-17 09:01:30,486:INFO:machine: AMD64
2023-08-17 09:01:30,486:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 09:01:30,489:INFO:Memory: svmem(total=68448301056, available=54122606592, percent=20.9, used=14325694464, free=54122606592)
2023-08-17 09:01:30,489:INFO:Physical Core: 12
2023-08-17 09:01:30,489:INFO:Logical Core: 20
2023-08-17 09:01:30,489:INFO:Checking libraries
2023-08-17 09:01:30,489:INFO:System:
2023-08-17 09:01:30,490:INFO:    python: 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 17:59:51) [MSC v.1935 64 bit (AMD64)]
2023-08-17 09:01:30,490:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-17 09:01:30,490:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 09:01:30,490:INFO:PyCaret required dependencies:
2023-08-17 09:01:30,500:INFO:                 pip: 23.2.1
2023-08-17 09:01:30,500:INFO:          setuptools: 68.0.0
2023-08-17 09:01:30,500:INFO:             pycaret: 3.0.4
2023-08-17 09:01:30,501:INFO:             IPython: 8.14.0
2023-08-17 09:01:30,501:INFO:          ipywidgets: 8.1.0
2023-08-17 09:01:30,501:INFO:                tqdm: 4.66.1
2023-08-17 09:01:30,501:INFO:               numpy: 1.23.5
2023-08-17 09:01:30,501:INFO:              pandas: 1.5.3
2023-08-17 09:01:30,501:INFO:              jinja2: 3.1.2
2023-08-17 09:01:30,501:INFO:               scipy: 1.10.1
2023-08-17 09:01:30,501:INFO:              joblib: 1.3.2
2023-08-17 09:01:30,501:INFO:             sklearn: 1.2.2
2023-08-17 09:01:30,501:INFO:                pyod: 1.1.0
2023-08-17 09:01:30,501:INFO:            imblearn: 0.11.0
2023-08-17 09:01:30,501:INFO:   category_encoders: 2.6.2
2023-08-17 09:01:30,501:INFO:            lightgbm: 4.0.0
2023-08-17 09:01:30,501:INFO:               numba: 0.57.1
2023-08-17 09:01:30,501:INFO:            requests: 2.31.0
2023-08-17 09:01:30,501:INFO:          matplotlib: 3.7.2
2023-08-17 09:01:30,501:INFO:          scikitplot: 0.3.7
2023-08-17 09:01:30,501:INFO:         yellowbrick: 1.5
2023-08-17 09:01:30,501:INFO:              plotly: 5.16.1
2023-08-17 09:01:30,501:INFO:    plotly-resampler: Not installed
2023-08-17 09:01:30,501:INFO:             kaleido: 0.2.1
2023-08-17 09:01:30,501:INFO:           schemdraw: 0.15
2023-08-17 09:01:30,501:INFO:         statsmodels: 0.14.0
2023-08-17 09:01:30,501:INFO:              sktime: 0.21.0
2023-08-17 09:01:30,501:INFO:               tbats: 1.1.3
2023-08-17 09:01:30,501:INFO:            pmdarima: 2.0.2
2023-08-17 09:01:30,501:INFO:              psutil: 5.9.5
2023-08-17 09:01:30,501:INFO:          markupsafe: 2.1.3
2023-08-17 09:01:30,501:INFO:             pickle5: Not installed
2023-08-17 09:01:30,501:INFO:         cloudpickle: 2.2.1
2023-08-17 09:01:30,501:INFO:         deprecation: 2.1.0
2023-08-17 09:01:30,501:INFO:              xxhash: 0.0.0
2023-08-17 09:01:30,501:INFO:           wurlitzer: 3.0.3
2023-08-17 09:01:30,501:INFO:PyCaret optional dependencies:
2023-08-17 09:01:30,507:INFO:                shap: Not installed
2023-08-17 09:01:30,507:INFO:           interpret: Not installed
2023-08-17 09:01:30,507:INFO:                umap: 0.5.3
2023-08-17 09:01:30,507:INFO:    pandas_profiling: 0.0.dev0
2023-08-17 09:01:30,507:INFO:  explainerdashboard: Not installed
2023-08-17 09:01:30,507:INFO:             autoviz: Not installed
2023-08-17 09:01:30,507:INFO:           fairlearn: Not installed
2023-08-17 09:01:30,507:INFO:          deepchecks: Not installed
2023-08-17 09:01:30,507:INFO:             xgboost: Not installed
2023-08-17 09:01:30,507:INFO:            catboost: Not installed
2023-08-17 09:01:30,507:INFO:              kmodes: Not installed
2023-08-17 09:01:30,507:INFO:             mlxtend: Not installed
2023-08-17 09:01:30,507:INFO:       statsforecast: Not installed
2023-08-17 09:01:30,507:INFO:        tune_sklearn: Not installed
2023-08-17 09:01:30,507:INFO:                 ray: Not installed
2023-08-17 09:01:30,507:INFO:            hyperopt: Not installed
2023-08-17 09:01:30,507:INFO:              optuna: Not installed
2023-08-17 09:01:30,507:INFO:               skopt: Not installed
2023-08-17 09:01:30,507:INFO:              mlflow: Not installed
2023-08-17 09:01:30,507:INFO:              gradio: Not installed
2023-08-17 09:01:30,507:INFO:             fastapi: Not installed
2023-08-17 09:01:30,507:INFO:             uvicorn: Not installed
2023-08-17 09:01:30,507:INFO:              m2cgen: Not installed
2023-08-17 09:01:30,507:INFO:           evidently: Not installed
2023-08-17 09:01:30,507:INFO:               fugue: Not installed
2023-08-17 09:01:30,507:INFO:           streamlit: Not installed
2023-08-17 09:01:30,507:INFO:             prophet: Not installed
2023-08-17 09:01:30,508:INFO:None
2023-08-17 09:01:30,508:INFO:Set up data.
2023-08-17 09:01:30,675:INFO:Set up train/test split.
2023-08-17 09:01:30,825:INFO:Set up index.
2023-08-17 09:01:30,829:INFO:Set up folding strategy.
2023-08-17 09:01:30,829:INFO:Assigning column types.
2023-08-17 09:01:30,844:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 09:01:30,868:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 09:01:30,869:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 09:01:30,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:30,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:30,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 09:01:30,912:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 09:01:30,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:30,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:30,928:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 09:01:30,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 09:01:30,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:30,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:30,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 09:01:31,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:31,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:31,003:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 09:01:31,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:31,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:31,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:31,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:31,080:INFO:Preparing preprocessing pipeline...
2023-08-17 09:01:31,084:INFO:Set up label encoding.
2023-08-17 09:01:31,084:INFO:Set up simple imputation.
2023-08-17 09:01:31,115:INFO:Set up encoding of ordinal features.
2023-08-17 09:01:31,148:INFO:Set up encoding of categorical features.
2023-08-17 09:01:31,150:INFO:Set up column name cleaning.
2023-08-17 09:01:33,513:INFO:Finished creating preprocessing pipeline.
2023-08-17 09:01:33,547:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=OneHotEncoder(cols=['General_Health',
                                                                    'Checkup',
                                                                    'Diabetes',
                                                                    'Age_Category'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 09:01:33,547:INFO:Creating final display dataframe.
2023-08-17 09:01:35,181:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277969, 19)
5        Transformed data shape      (277969, 42)
6   Transformed train set shape      (194578, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              dde2
2023-08-17 09:01:35,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:35,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:35,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:35,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 09:01:35,264:INFO:setup() successfully completed in 4.94s...............
2023-08-17 09:01:38,608:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\numba\core\decorators.py:262: NumbaDeprecationWarning: [1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.[0m
  warnings.warn(msg, NumbaDeprecationWarning)

2023-08-17 09:01:38,634:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\visions\backends\shared\nan_handling.py:50: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @nb.jit

2023-08-17 09:08:03,284:INFO:Initializing get_config()
2023-08-17 09:08:03,285:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, variable=None)
2023-08-17 09:10:39,124:INFO:Initializing compare_models()
2023-08-17 09:10:39,124:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-08-17 09:10:39,124:INFO:Checking exceptions
2023-08-17 09:10:39,149:INFO:Preparing display monitor
2023-08-17 09:10:39,164:INFO:Initializing Logistic Regression
2023-08-17 09:10:39,164:INFO:Total runtime is 0.0 minutes
2023-08-17 09:10:39,166:INFO:SubProcess create_model() called ==================================
2023-08-17 09:10:39,167:INFO:Initializing create_model()
2023-08-17 09:10:39,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C535D6050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:10:39,167:INFO:Checking exceptions
2023-08-17 09:10:39,167:INFO:Importing libraries
2023-08-17 09:10:39,167:INFO:Copying training dataset
2023-08-17 09:10:39,208:INFO:Defining folds
2023-08-17 09:10:39,208:INFO:Declaring metric variables
2023-08-17 09:10:39,211:INFO:Importing untrained model
2023-08-17 09:10:39,213:INFO:Logistic Regression Imported successfully
2023-08-17 09:10:39,216:INFO:Starting cross validation
2023-08-17 09:10:39,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:10:54,886:INFO:Initializing compare_models()
2023-08-17 09:10:54,886:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2023-08-17 09:10:54,886:INFO:Checking exceptions
2023-08-17 09:10:54,901:INFO:Preparing display monitor
2023-08-17 09:10:54,915:INFO:Initializing Logistic Regression
2023-08-17 09:10:54,915:INFO:Total runtime is 0.0 minutes
2023-08-17 09:10:54,917:INFO:SubProcess create_model() called ==================================
2023-08-17 09:10:54,917:INFO:Initializing create_model()
2023-08-17 09:10:54,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:10:54,918:INFO:Checking exceptions
2023-08-17 09:10:54,918:INFO:Importing libraries
2023-08-17 09:10:54,918:INFO:Copying training dataset
2023-08-17 09:10:54,969:INFO:Defining folds
2023-08-17 09:10:54,969:INFO:Declaring metric variables
2023-08-17 09:10:54,972:INFO:Importing untrained model
2023-08-17 09:10:54,974:INFO:Logistic Regression Imported successfully
2023-08-17 09:10:54,978:INFO:Starting cross validation
2023-08-17 09:10:54,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:11:50,056:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:11:50,209:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:11:50,450:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:11:50,485:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:11:50,895:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:11:50,941:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:11:51,122:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:11:51,143:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:11:52,413:INFO:Calculating mean and std
2023-08-17 09:11:52,414:INFO:Creating metrics dataframe
2023-08-17 09:11:52,631:INFO:Uploading results into container
2023-08-17 09:11:52,632:INFO:Uploading model into container now
2023-08-17 09:11:52,632:INFO:_master_model_container: 1
2023-08-17 09:11:52,632:INFO:_display_container: 2
2023-08-17 09:11:52,633:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-17 09:11:52,633:INFO:create_model() successfully completed......................................
2023-08-17 09:11:52,736:INFO:SubProcess create_model() end ==================================
2023-08-17 09:11:52,736:INFO:Creating metrics dataframe
2023-08-17 09:11:52,742:INFO:Initializing K Neighbors Classifier
2023-08-17 09:11:52,742:INFO:Total runtime is 0.9637794057528178 minutes
2023-08-17 09:11:52,744:INFO:SubProcess create_model() called ==================================
2023-08-17 09:11:52,744:INFO:Initializing create_model()
2023-08-17 09:11:52,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:11:52,744:INFO:Checking exceptions
2023-08-17 09:11:52,744:INFO:Importing libraries
2023-08-17 09:11:52,744:INFO:Copying training dataset
2023-08-17 09:11:52,779:INFO:Defining folds
2023-08-17 09:11:52,780:INFO:Declaring metric variables
2023-08-17 09:11:52,782:INFO:Importing untrained model
2023-08-17 09:11:52,785:INFO:K Neighbors Classifier Imported successfully
2023-08-17 09:11:52,788:INFO:Starting cross validation
2023-08-17 09:11:52,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:12:23,899:INFO:Calculating mean and std
2023-08-17 09:12:23,900:INFO:Creating metrics dataframe
2023-08-17 09:12:24,120:INFO:Uploading results into container
2023-08-17 09:12:24,121:INFO:Uploading model into container now
2023-08-17 09:12:24,121:INFO:_master_model_container: 2
2023-08-17 09:12:24,121:INFO:_display_container: 2
2023-08-17 09:12:24,121:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-17 09:12:24,122:INFO:create_model() successfully completed......................................
2023-08-17 09:12:24,218:INFO:SubProcess create_model() end ==================================
2023-08-17 09:12:24,218:INFO:Creating metrics dataframe
2023-08-17 09:12:24,224:INFO:Initializing Naive Bayes
2023-08-17 09:12:24,224:INFO:Total runtime is 1.488488813241323 minutes
2023-08-17 09:12:24,226:INFO:SubProcess create_model() called ==================================
2023-08-17 09:12:24,226:INFO:Initializing create_model()
2023-08-17 09:12:24,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:12:24,226:INFO:Checking exceptions
2023-08-17 09:12:24,226:INFO:Importing libraries
2023-08-17 09:12:24,226:INFO:Copying training dataset
2023-08-17 09:12:24,270:INFO:Defining folds
2023-08-17 09:12:24,270:INFO:Declaring metric variables
2023-08-17 09:12:24,272:INFO:Importing untrained model
2023-08-17 09:12:24,275:INFO:Naive Bayes Imported successfully
2023-08-17 09:12:24,278:INFO:Starting cross validation
2023-08-17 09:12:24,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:12:28,375:INFO:Calculating mean and std
2023-08-17 09:12:28,376:INFO:Creating metrics dataframe
2023-08-17 09:12:28,605:INFO:Uploading results into container
2023-08-17 09:12:28,606:INFO:Uploading model into container now
2023-08-17 09:12:28,606:INFO:_master_model_container: 3
2023-08-17 09:12:28,606:INFO:_display_container: 2
2023-08-17 09:12:28,606:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-17 09:12:28,607:INFO:create_model() successfully completed......................................
2023-08-17 09:12:28,703:INFO:SubProcess create_model() end ==================================
2023-08-17 09:12:28,703:INFO:Creating metrics dataframe
2023-08-17 09:12:28,709:INFO:Initializing Decision Tree Classifier
2023-08-17 09:12:28,709:INFO:Total runtime is 1.563234869639079 minutes
2023-08-17 09:12:28,711:INFO:SubProcess create_model() called ==================================
2023-08-17 09:12:28,711:INFO:Initializing create_model()
2023-08-17 09:12:28,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:12:28,711:INFO:Checking exceptions
2023-08-17 09:12:28,711:INFO:Importing libraries
2023-08-17 09:12:28,711:INFO:Copying training dataset
2023-08-17 09:12:28,751:INFO:Defining folds
2023-08-17 09:12:28,751:INFO:Declaring metric variables
2023-08-17 09:12:28,753:INFO:Importing untrained model
2023-08-17 09:12:28,755:INFO:Decision Tree Classifier Imported successfully
2023-08-17 09:12:28,759:INFO:Starting cross validation
2023-08-17 09:12:28,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:12:34,245:INFO:Calculating mean and std
2023-08-17 09:12:34,246:INFO:Creating metrics dataframe
2023-08-17 09:12:34,470:INFO:Uploading results into container
2023-08-17 09:12:34,471:INFO:Uploading model into container now
2023-08-17 09:12:34,472:INFO:_master_model_container: 4
2023-08-17 09:12:34,472:INFO:_display_container: 2
2023-08-17 09:12:34,472:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-17 09:12:34,472:INFO:create_model() successfully completed......................................
2023-08-17 09:12:34,580:INFO:SubProcess create_model() end ==================================
2023-08-17 09:12:34,580:INFO:Creating metrics dataframe
2023-08-17 09:12:34,588:INFO:Initializing SVM - Linear Kernel
2023-08-17 09:12:34,588:INFO:Total runtime is 1.6612096707026165 minutes
2023-08-17 09:12:34,589:INFO:SubProcess create_model() called ==================================
2023-08-17 09:12:34,589:INFO:Initializing create_model()
2023-08-17 09:12:34,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:12:34,590:INFO:Checking exceptions
2023-08-17 09:12:34,590:INFO:Importing libraries
2023-08-17 09:12:34,590:INFO:Copying training dataset
2023-08-17 09:12:34,625:INFO:Defining folds
2023-08-17 09:12:34,626:INFO:Declaring metric variables
2023-08-17 09:12:34,628:INFO:Importing untrained model
2023-08-17 09:12:34,630:INFO:SVM - Linear Kernel Imported successfully
2023-08-17 09:12:34,633:INFO:Starting cross validation
2023-08-17 09:12:34,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:12:51,406:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:53,187:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:53,385:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:12:53,426:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:53,563:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:53,749:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:12:53,922:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:55,150:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:55,159:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:55,221:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:55,800:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:56,053:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 09:12:56,452:INFO:Calculating mean and std
2023-08-17 09:12:56,453:INFO:Creating metrics dataframe
2023-08-17 09:12:56,690:INFO:Uploading results into container
2023-08-17 09:12:56,691:INFO:Uploading model into container now
2023-08-17 09:12:56,691:INFO:_master_model_container: 5
2023-08-17 09:12:56,691:INFO:_display_container: 2
2023-08-17 09:12:56,692:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-17 09:12:56,692:INFO:create_model() successfully completed......................................
2023-08-17 09:12:56,790:INFO:SubProcess create_model() end ==================================
2023-08-17 09:12:56,790:INFO:Creating metrics dataframe
2023-08-17 09:12:56,795:INFO:Initializing Ridge Classifier
2023-08-17 09:12:56,796:INFO:Total runtime is 2.0313559929529825 minutes
2023-08-17 09:12:56,797:INFO:SubProcess create_model() called ==================================
2023-08-17 09:12:56,798:INFO:Initializing create_model()
2023-08-17 09:12:56,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:12:56,798:INFO:Checking exceptions
2023-08-17 09:12:56,798:INFO:Importing libraries
2023-08-17 09:12:56,798:INFO:Copying training dataset
2023-08-17 09:12:56,834:INFO:Defining folds
2023-08-17 09:12:56,834:INFO:Declaring metric variables
2023-08-17 09:12:56,836:INFO:Importing untrained model
2023-08-17 09:12:56,838:INFO:Ridge Classifier Imported successfully
2023-08-17 09:12:56,842:INFO:Starting cross validation
2023-08-17 09:12:56,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:12:58,676:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,804:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,805:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,827:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,837:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,844:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,852:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,861:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,884:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:12:58,898:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
           ~~~~~^^^^^^^^
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 09:13:00,913:INFO:Calculating mean and std
2023-08-17 09:13:00,914:INFO:Creating metrics dataframe
2023-08-17 09:13:01,141:INFO:Uploading results into container
2023-08-17 09:13:01,141:INFO:Uploading model into container now
2023-08-17 09:13:01,142:INFO:_master_model_container: 6
2023-08-17 09:13:01,142:INFO:_display_container: 2
2023-08-17 09:13:01,142:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-17 09:13:01,142:INFO:create_model() successfully completed......................................
2023-08-17 09:13:01,238:INFO:SubProcess create_model() end ==================================
2023-08-17 09:13:01,238:INFO:Creating metrics dataframe
2023-08-17 09:13:01,244:INFO:Initializing Random Forest Classifier
2023-08-17 09:13:01,244:INFO:Total runtime is 2.1054806470870973 minutes
2023-08-17 09:13:01,247:INFO:SubProcess create_model() called ==================================
2023-08-17 09:13:01,247:INFO:Initializing create_model()
2023-08-17 09:13:01,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:13:01,247:INFO:Checking exceptions
2023-08-17 09:13:01,247:INFO:Importing libraries
2023-08-17 09:13:01,248:INFO:Copying training dataset
2023-08-17 09:13:01,285:INFO:Defining folds
2023-08-17 09:13:01,285:INFO:Declaring metric variables
2023-08-17 09:13:01,287:INFO:Importing untrained model
2023-08-17 09:13:01,290:INFO:Random Forest Classifier Imported successfully
2023-08-17 09:13:01,293:INFO:Starting cross validation
2023-08-17 09:13:01,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:13:31,526:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 09:13:31,642:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 09:13:32,203:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 09:13:33,241:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 09:13:38,941:INFO:Calculating mean and std
2023-08-17 09:13:38,942:INFO:Creating metrics dataframe
2023-08-17 09:13:39,185:INFO:Uploading results into container
2023-08-17 09:13:39,186:INFO:Uploading model into container now
2023-08-17 09:13:39,186:INFO:_master_model_container: 7
2023-08-17 09:13:39,186:INFO:_display_container: 2
2023-08-17 09:13:39,186:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-17 09:13:39,187:INFO:create_model() successfully completed......................................
2023-08-17 09:13:39,292:INFO:SubProcess create_model() end ==================================
2023-08-17 09:13:39,292:INFO:Creating metrics dataframe
2023-08-17 09:13:39,298:INFO:Initializing Quadratic Discriminant Analysis
2023-08-17 09:13:39,298:INFO:Total runtime is 2.739708995819092 minutes
2023-08-17 09:13:39,300:INFO:SubProcess create_model() called ==================================
2023-08-17 09:13:39,300:INFO:Initializing create_model()
2023-08-17 09:13:39,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:13:39,300:INFO:Checking exceptions
2023-08-17 09:13:39,300:INFO:Importing libraries
2023-08-17 09:13:39,300:INFO:Copying training dataset
2023-08-17 09:13:39,350:INFO:Defining folds
2023-08-17 09:13:39,350:INFO:Declaring metric variables
2023-08-17 09:13:39,352:INFO:Importing untrained model
2023-08-17 09:13:39,353:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-17 09:13:39,357:INFO:Starting cross validation
2023-08-17 09:13:39,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:13:42,390:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,400:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,484:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,505:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,549:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,599:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,604:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,609:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,646:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:42,686:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 09:13:45,226:INFO:Calculating mean and std
2023-08-17 09:13:45,226:INFO:Creating metrics dataframe
2023-08-17 09:13:45,462:INFO:Uploading results into container
2023-08-17 09:13:45,462:INFO:Uploading model into container now
2023-08-17 09:13:45,463:INFO:_master_model_container: 8
2023-08-17 09:13:45,463:INFO:_display_container: 2
2023-08-17 09:13:45,463:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-17 09:13:45,463:INFO:create_model() successfully completed......................................
2023-08-17 09:13:45,565:INFO:SubProcess create_model() end ==================================
2023-08-17 09:13:45,565:INFO:Creating metrics dataframe
2023-08-17 09:13:45,571:INFO:Initializing Ada Boost Classifier
2023-08-17 09:13:45,571:INFO:Total runtime is 2.8442678610483805 minutes
2023-08-17 09:13:45,573:INFO:SubProcess create_model() called ==================================
2023-08-17 09:13:45,573:INFO:Initializing create_model()
2023-08-17 09:13:45,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:13:45,573:INFO:Checking exceptions
2023-08-17 09:13:45,573:INFO:Importing libraries
2023-08-17 09:13:45,573:INFO:Copying training dataset
2023-08-17 09:13:45,607:INFO:Defining folds
2023-08-17 09:13:45,607:INFO:Declaring metric variables
2023-08-17 09:13:45,610:INFO:Importing untrained model
2023-08-17 09:13:45,612:INFO:Ada Boost Classifier Imported successfully
2023-08-17 09:13:45,617:INFO:Starting cross validation
2023-08-17 09:13:45,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:14:03,123:INFO:Calculating mean and std
2023-08-17 09:14:03,124:INFO:Creating metrics dataframe
2023-08-17 09:14:03,367:INFO:Uploading results into container
2023-08-17 09:14:03,368:INFO:Uploading model into container now
2023-08-17 09:14:03,368:INFO:_master_model_container: 9
2023-08-17 09:14:03,368:INFO:_display_container: 2
2023-08-17 09:14:03,369:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-17 09:14:03,369:INFO:create_model() successfully completed......................................
2023-08-17 09:14:03,465:INFO:SubProcess create_model() end ==================================
2023-08-17 09:14:03,465:INFO:Creating metrics dataframe
2023-08-17 09:14:03,472:INFO:Initializing Gradient Boosting Classifier
2023-08-17 09:14:03,472:INFO:Total runtime is 3.1426249464352924 minutes
2023-08-17 09:14:03,474:INFO:SubProcess create_model() called ==================================
2023-08-17 09:14:03,475:INFO:Initializing create_model()
2023-08-17 09:14:03,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:14:03,475:INFO:Checking exceptions
2023-08-17 09:14:03,475:INFO:Importing libraries
2023-08-17 09:14:03,475:INFO:Copying training dataset
2023-08-17 09:14:03,512:INFO:Defining folds
2023-08-17 09:14:03,512:INFO:Declaring metric variables
2023-08-17 09:14:03,516:INFO:Importing untrained model
2023-08-17 09:14:03,518:INFO:Gradient Boosting Classifier Imported successfully
2023-08-17 09:14:03,522:INFO:Starting cross validation
2023-08-17 09:14:03,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:14:47,209:INFO:Calculating mean and std
2023-08-17 09:14:47,210:INFO:Creating metrics dataframe
2023-08-17 09:14:47,455:INFO:Uploading results into container
2023-08-17 09:14:47,456:INFO:Uploading model into container now
2023-08-17 09:14:47,456:INFO:_master_model_container: 10
2023-08-17 09:14:47,456:INFO:_display_container: 2
2023-08-17 09:14:47,457:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-17 09:14:47,457:INFO:create_model() successfully completed......................................
2023-08-17 09:14:47,558:INFO:SubProcess create_model() end ==================================
2023-08-17 09:14:47,558:INFO:Creating metrics dataframe
2023-08-17 09:14:47,565:INFO:Initializing Linear Discriminant Analysis
2023-08-17 09:14:47,565:INFO:Total runtime is 3.877494116624196 minutes
2023-08-17 09:14:47,567:INFO:SubProcess create_model() called ==================================
2023-08-17 09:14:47,567:INFO:Initializing create_model()
2023-08-17 09:14:47,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:14:47,567:INFO:Checking exceptions
2023-08-17 09:14:47,567:INFO:Importing libraries
2023-08-17 09:14:47,567:INFO:Copying training dataset
2023-08-17 09:14:47,604:INFO:Defining folds
2023-08-17 09:14:47,604:INFO:Declaring metric variables
2023-08-17 09:14:47,606:INFO:Importing untrained model
2023-08-17 09:14:47,609:INFO:Linear Discriminant Analysis Imported successfully
2023-08-17 09:14:47,612:INFO:Starting cross validation
2023-08-17 09:14:47,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:14:53,792:INFO:Calculating mean and std
2023-08-17 09:14:53,793:INFO:Creating metrics dataframe
2023-08-17 09:14:54,040:INFO:Uploading results into container
2023-08-17 09:14:54,040:INFO:Uploading model into container now
2023-08-17 09:14:54,040:INFO:_master_model_container: 11
2023-08-17 09:14:54,041:INFO:_display_container: 2
2023-08-17 09:14:54,041:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-17 09:14:54,041:INFO:create_model() successfully completed......................................
2023-08-17 09:14:54,137:INFO:SubProcess create_model() end ==================================
2023-08-17 09:14:54,137:INFO:Creating metrics dataframe
2023-08-17 09:14:54,144:INFO:Initializing Extra Trees Classifier
2023-08-17 09:14:54,144:INFO:Total runtime is 3.987153784434 minutes
2023-08-17 09:14:54,146:INFO:SubProcess create_model() called ==================================
2023-08-17 09:14:54,146:INFO:Initializing create_model()
2023-08-17 09:14:54,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:14:54,146:INFO:Checking exceptions
2023-08-17 09:14:54,146:INFO:Importing libraries
2023-08-17 09:14:54,146:INFO:Copying training dataset
2023-08-17 09:14:54,185:INFO:Defining folds
2023-08-17 09:14:54,185:INFO:Declaring metric variables
2023-08-17 09:14:54,187:INFO:Importing untrained model
2023-08-17 09:14:54,189:INFO:Extra Trees Classifier Imported successfully
2023-08-17 09:14:54,194:INFO:Starting cross validation
2023-08-17 09:14:54,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:15:34,031:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 09:15:33,963:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.28s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 09:15:40,216:INFO:Calculating mean and std
2023-08-17 09:15:40,216:INFO:Creating metrics dataframe
2023-08-17 09:15:40,455:INFO:Uploading results into container
2023-08-17 09:15:40,455:INFO:Uploading model into container now
2023-08-17 09:15:40,456:INFO:_master_model_container: 12
2023-08-17 09:15:40,456:INFO:_display_container: 2
2023-08-17 09:15:40,456:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-17 09:15:40,456:INFO:create_model() successfully completed......................................
2023-08-17 09:15:40,598:INFO:SubProcess create_model() end ==================================
2023-08-17 09:15:40,599:INFO:Creating metrics dataframe
2023-08-17 09:15:40,608:INFO:Initializing Light Gradient Boosting Machine
2023-08-17 09:15:40,609:INFO:Total runtime is 4.761564036210378 minutes
2023-08-17 09:15:40,612:INFO:SubProcess create_model() called ==================================
2023-08-17 09:15:40,612:INFO:Initializing create_model()
2023-08-17 09:15:40,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:15:40,612:INFO:Checking exceptions
2023-08-17 09:15:40,612:INFO:Importing libraries
2023-08-17 09:15:40,612:INFO:Copying training dataset
2023-08-17 09:15:40,670:INFO:Defining folds
2023-08-17 09:15:40,670:INFO:Declaring metric variables
2023-08-17 09:15:40,672:INFO:Importing untrained model
2023-08-17 09:15:40,674:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 09:15:40,678:INFO:Starting cross validation
2023-08-17 09:15:40,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:15:47,270:INFO:Calculating mean and std
2023-08-17 09:15:47,271:INFO:Creating metrics dataframe
2023-08-17 09:15:47,451:INFO:Uploading results into container
2023-08-17 09:15:47,452:INFO:Uploading model into container now
2023-08-17 09:15:47,452:INFO:_master_model_container: 13
2023-08-17 09:15:47,452:INFO:_display_container: 2
2023-08-17 09:15:47,452:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 09:15:47,453:INFO:create_model() successfully completed......................................
2023-08-17 09:15:47,552:INFO:SubProcess create_model() end ==================================
2023-08-17 09:15:47,552:INFO:Creating metrics dataframe
2023-08-17 09:15:47,559:INFO:Initializing Dummy Classifier
2023-08-17 09:15:47,559:INFO:Total runtime is 4.877405532201131 minutes
2023-08-17 09:15:47,561:INFO:SubProcess create_model() called ==================================
2023-08-17 09:15:47,561:INFO:Initializing create_model()
2023-08-17 09:15:47,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023C53666050>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:15:47,561:INFO:Checking exceptions
2023-08-17 09:15:47,561:INFO:Importing libraries
2023-08-17 09:15:47,561:INFO:Copying training dataset
2023-08-17 09:15:47,598:INFO:Defining folds
2023-08-17 09:15:47,598:INFO:Declaring metric variables
2023-08-17 09:15:47,600:INFO:Importing untrained model
2023-08-17 09:15:47,602:INFO:Dummy Classifier Imported successfully
2023-08-17 09:15:47,606:INFO:Starting cross validation
2023-08-17 09:15:47,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 09:15:49,110:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,138:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,151:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,191:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,211:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,221:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,251:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,262:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,275:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:49,344:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 09:15:50,893:INFO:Calculating mean and std
2023-08-17 09:15:50,894:INFO:Creating metrics dataframe
2023-08-17 09:15:51,086:INFO:Uploading results into container
2023-08-17 09:15:51,087:INFO:Uploading model into container now
2023-08-17 09:15:51,087:INFO:_master_model_container: 14
2023-08-17 09:15:51,087:INFO:_display_container: 2
2023-08-17 09:15:51,088:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-17 09:15:51,088:INFO:create_model() successfully completed......................................
2023-08-17 09:15:51,188:INFO:SubProcess create_model() end ==================================
2023-08-17 09:15:51,188:INFO:Creating metrics dataframe
2023-08-17 09:15:51,200:INFO:Initializing create_model()
2023-08-17 09:15:51,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:15:51,200:INFO:Checking exceptions
2023-08-17 09:15:51,202:INFO:Importing libraries
2023-08-17 09:15:51,202:INFO:Copying training dataset
2023-08-17 09:15:51,241:INFO:Defining folds
2023-08-17 09:15:51,241:INFO:Declaring metric variables
2023-08-17 09:15:51,241:INFO:Importing untrained model
2023-08-17 09:15:51,241:INFO:Declaring custom model
2023-08-17 09:15:51,241:INFO:Gradient Boosting Classifier Imported successfully
2023-08-17 09:15:51,242:INFO:Cross validation set to False
2023-08-17 09:15:51,242:INFO:Fitting Model
2023-08-17 09:16:14,379:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-17 09:16:14,379:INFO:create_model() successfully completed......................................
2023-08-17 09:16:14,488:INFO:Initializing create_model()
2023-08-17 09:16:14,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:16:14,489:INFO:Checking exceptions
2023-08-17 09:16:14,490:INFO:Importing libraries
2023-08-17 09:16:14,490:INFO:Copying training dataset
2023-08-17 09:16:14,529:INFO:Defining folds
2023-08-17 09:16:14,529:INFO:Declaring metric variables
2023-08-17 09:16:14,529:INFO:Importing untrained model
2023-08-17 09:16:14,529:INFO:Declaring custom model
2023-08-17 09:16:14,529:INFO:Logistic Regression Imported successfully
2023-08-17 09:16:14,530:INFO:Cross validation set to False
2023-08-17 09:16:14,530:INFO:Fitting Model
2023-08-17 09:16:26,671:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-08-17 09:16:26,850:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-17 09:16:26,850:INFO:create_model() successfully completed......................................
2023-08-17 09:16:26,952:INFO:Initializing create_model()
2023-08-17 09:16:26,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023C2ECEC850>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 09:16:26,952:INFO:Checking exceptions
2023-08-17 09:16:26,953:INFO:Importing libraries
2023-08-17 09:16:26,953:INFO:Copying training dataset
2023-08-17 09:16:26,990:INFO:Defining folds
2023-08-17 09:16:26,990:INFO:Declaring metric variables
2023-08-17 09:16:26,990:INFO:Importing untrained model
2023-08-17 09:16:26,990:INFO:Declaring custom model
2023-08-17 09:16:26,991:INFO:Ridge Classifier Imported successfully
2023-08-17 09:16:26,991:INFO:Cross validation set to False
2023-08-17 09:16:26,991:INFO:Fitting Model
2023-08-17 09:16:27,792:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-17 09:16:27,792:INFO:create_model() successfully completed......................................
2023-08-17 09:16:27,913:INFO:_master_model_container: 14
2023-08-17 09:16:27,913:INFO:_display_container: 2
2023-08-17 09:16:27,914:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)]
2023-08-17 09:16:27,914:INFO:compare_models() successfully completed......................................
2023-08-17 11:08:41,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 11:08:41,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 11:08:41,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 11:08:41,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 11:14:15,442:WARNING:C:\Users\Ramon\AppData\Local\Temp\ipykernel_12352\438238842.py:4: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlation_matrix = df.corr()

2023-08-17 11:15:09,588:INFO:PyCaret ClassificationExperiment
2023-08-17 11:15:09,588:INFO:Logging name: clf-default-name
2023-08-17 11:15:09,589:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 11:15:09,589:INFO:version 3.0.4
2023-08-17 11:15:09,589:INFO:Initializing setup()
2023-08-17 11:15:09,589:INFO:self.USI: fab2
2023-08-17 11:15:09,589:INFO:self._variable_keys: {'y_test', 'exp_id', 'pipeline', 'X_test', 'data', 'html_param', 'log_plots_param', 'USI', '_available_plots', 'fold_shuffle_param', 'target_param', 'gpu_param', 'exp_name_log', 'is_multiclass', 'X_train', 'fold_groups_param', 'y', 'fix_imbalance', 'gpu_n_jobs_param', 'X', 'n_jobs_param', 'memory', 'y_train', 'fold_generator', '_ml_usecase', 'idx', 'seed', 'logging_param'}
2023-08-17 11:15:09,589:INFO:Checking environment
2023-08-17 11:15:09,589:INFO:python_version: 3.11.4
2023-08-17 11:15:09,589:INFO:python_build: ('main', 'Jun 10 2023 17:59:51')
2023-08-17 11:15:09,589:INFO:machine: AMD64
2023-08-17 11:15:09,589:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 11:15:09,591:INFO:Memory: svmem(total=68448301056, available=53970325504, percent=21.2, used=14477975552, free=53970325504)
2023-08-17 11:15:09,592:INFO:Physical Core: 12
2023-08-17 11:15:09,592:INFO:Logical Core: 20
2023-08-17 11:15:09,592:INFO:Checking libraries
2023-08-17 11:15:09,592:INFO:System:
2023-08-17 11:15:09,592:INFO:    python: 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 17:59:51) [MSC v.1935 64 bit (AMD64)]
2023-08-17 11:15:09,592:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-17 11:15:09,592:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 11:15:09,592:INFO:PyCaret required dependencies:
2023-08-17 11:15:09,604:INFO:                 pip: 23.2.1
2023-08-17 11:15:09,604:INFO:          setuptools: 68.0.0
2023-08-17 11:15:09,604:INFO:             pycaret: 3.0.4
2023-08-17 11:15:09,604:INFO:             IPython: 8.14.0
2023-08-17 11:15:09,604:INFO:          ipywidgets: 8.1.0
2023-08-17 11:15:09,604:INFO:                tqdm: 4.66.1
2023-08-17 11:15:09,604:INFO:               numpy: 1.23.5
2023-08-17 11:15:09,604:INFO:              pandas: 1.5.3
2023-08-17 11:15:09,604:INFO:              jinja2: 3.1.2
2023-08-17 11:15:09,604:INFO:               scipy: 1.10.1
2023-08-17 11:15:09,604:INFO:              joblib: 1.3.2
2023-08-17 11:15:09,604:INFO:             sklearn: 1.2.2
2023-08-17 11:15:09,604:INFO:                pyod: 1.1.0
2023-08-17 11:15:09,604:INFO:            imblearn: 0.11.0
2023-08-17 11:15:09,604:INFO:   category_encoders: 2.6.2
2023-08-17 11:15:09,604:INFO:            lightgbm: 4.0.0
2023-08-17 11:15:09,604:INFO:               numba: 0.57.1
2023-08-17 11:15:09,604:INFO:            requests: 2.31.0
2023-08-17 11:15:09,604:INFO:          matplotlib: 3.7.2
2023-08-17 11:15:09,604:INFO:          scikitplot: 0.3.7
2023-08-17 11:15:09,604:INFO:         yellowbrick: 1.5
2023-08-17 11:15:09,604:INFO:              plotly: 5.16.1
2023-08-17 11:15:09,604:INFO:    plotly-resampler: Not installed
2023-08-17 11:15:09,604:INFO:             kaleido: 0.2.1
2023-08-17 11:15:09,604:INFO:           schemdraw: 0.15
2023-08-17 11:15:09,604:INFO:         statsmodels: 0.14.0
2023-08-17 11:15:09,604:INFO:              sktime: 0.21.0
2023-08-17 11:15:09,604:INFO:               tbats: 1.1.3
2023-08-17 11:15:09,604:INFO:            pmdarima: 2.0.2
2023-08-17 11:15:09,604:INFO:              psutil: 5.9.5
2023-08-17 11:15:09,604:INFO:          markupsafe: 2.1.3
2023-08-17 11:15:09,605:INFO:             pickle5: Not installed
2023-08-17 11:15:09,605:INFO:         cloudpickle: 2.2.1
2023-08-17 11:15:09,605:INFO:         deprecation: 2.1.0
2023-08-17 11:15:09,605:INFO:              xxhash: 0.0.0
2023-08-17 11:15:09,605:INFO:           wurlitzer: 3.0.3
2023-08-17 11:15:09,605:INFO:PyCaret optional dependencies:
2023-08-17 11:15:09,610:INFO:                shap: Not installed
2023-08-17 11:15:09,610:INFO:           interpret: Not installed
2023-08-17 11:15:09,610:INFO:                umap: 0.5.3
2023-08-17 11:15:09,610:INFO:    pandas_profiling: 0.0.dev0
2023-08-17 11:15:09,610:INFO:  explainerdashboard: Not installed
2023-08-17 11:15:09,610:INFO:             autoviz: Not installed
2023-08-17 11:15:09,610:INFO:           fairlearn: Not installed
2023-08-17 11:15:09,610:INFO:          deepchecks: Not installed
2023-08-17 11:15:09,610:INFO:             xgboost: Not installed
2023-08-17 11:15:09,610:INFO:            catboost: Not installed
2023-08-17 11:15:09,610:INFO:              kmodes: Not installed
2023-08-17 11:15:09,610:INFO:             mlxtend: Not installed
2023-08-17 11:15:09,610:INFO:       statsforecast: Not installed
2023-08-17 11:15:09,610:INFO:        tune_sklearn: Not installed
2023-08-17 11:15:09,610:INFO:                 ray: Not installed
2023-08-17 11:15:09,610:INFO:            hyperopt: Not installed
2023-08-17 11:15:09,610:INFO:              optuna: Not installed
2023-08-17 11:15:09,610:INFO:               skopt: Not installed
2023-08-17 11:15:09,610:INFO:              mlflow: Not installed
2023-08-17 11:15:09,610:INFO:              gradio: Not installed
2023-08-17 11:15:09,610:INFO:             fastapi: Not installed
2023-08-17 11:15:09,611:INFO:             uvicorn: Not installed
2023-08-17 11:15:09,611:INFO:              m2cgen: Not installed
2023-08-17 11:15:09,611:INFO:           evidently: Not installed
2023-08-17 11:15:09,611:INFO:               fugue: Not installed
2023-08-17 11:15:09,611:INFO:           streamlit: Not installed
2023-08-17 11:15:09,611:INFO:             prophet: Not installed
2023-08-17 11:15:09,611:INFO:None
2023-08-17 11:15:09,611:INFO:Set up data.
2023-08-17 11:15:09,760:INFO:Set up train/test split.
2023-08-17 11:15:09,867:INFO:Set up index.
2023-08-17 11:15:09,872:INFO:Set up folding strategy.
2023-08-17 11:15:09,872:INFO:Assigning column types.
2023-08-17 11:15:09,883:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 11:15:09,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 11:15:09,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 11:15:09,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:09,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:09,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 11:15:09,950:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 11:15:09,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:09,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:09,965:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 11:15:09,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 11:15:10,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:10,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:10,026:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 11:15:10,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:10,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:10,041:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 11:15:10,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:10,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:10,112:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:10,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:10,114:INFO:Preparing preprocessing pipeline...
2023-08-17 11:15:10,116:INFO:Set up label encoding.
2023-08-17 11:15:10,116:INFO:Set up simple imputation.
2023-08-17 11:15:10,140:INFO:Set up encoding of ordinal features.
2023-08-17 11:15:10,167:INFO:Set up encoding of categorical features.
2023-08-17 11:15:10,167:INFO:Set up removing outliers.
2023-08-17 11:15:10,167:INFO:Set up feature normalization.
2023-08-17 11:15:10,168:INFO:Set up column name cleaning.
2023-08-17 11:15:12,235:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 11:15:19,456:INFO:Finished creating preprocessing pipeline.
2023-08-17 11:15:19,490:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=6366,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 11:15:19,490:INFO:Creating final display dataframe.
2023-08-17 11:15:20,316:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 11:15:28,248:INFO:Setup _display_container:                     Description             Value
0                    Session id              6366
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (216203, 19)
5        Transformed data shape      (208635, 42)
6   Transformed train set shape      (143774, 42)
7    Transformed test set shape       (64861, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              fab2
2023-08-17 11:15:28,289:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:28,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:28,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:28,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:15:28,329:INFO:setup() successfully completed in 18.96s...............
2023-08-17 11:18:38,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 11:18:38,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 11:18:38,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 11:18:38,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 11:18:39,266:INFO:PyCaret ClassificationExperiment
2023-08-17 11:18:39,266:INFO:Logging name: clf-default-name
2023-08-17 11:18:39,266:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 11:18:39,266:INFO:version 3.0.4
2023-08-17 11:18:39,266:INFO:Initializing setup()
2023-08-17 11:18:39,266:INFO:self.USI: f3b9
2023-08-17 11:18:39,266:INFO:self._variable_keys: {'pipeline', 'memory', 'X_train', '_available_plots', 'exp_name_log', 'X_test', 'data', 'idx', 'seed', 'logging_param', 'exp_id', 'fix_imbalance', 'USI', 'y_train', 'gpu_param', 'y', 'X', 'fold_shuffle_param', 'is_multiclass', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_generator', 'html_param', 'fold_groups_param', 'target_param', '_ml_usecase', 'log_plots_param', 'y_test'}
2023-08-17 11:18:39,266:INFO:Checking environment
2023-08-17 11:18:39,266:INFO:python_version: 3.11.4
2023-08-17 11:18:39,266:INFO:python_build: ('main', 'Jun 10 2023 17:59:51')
2023-08-17 11:18:39,266:INFO:machine: AMD64
2023-08-17 11:18:39,266:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 11:18:39,270:INFO:Memory: svmem(total=68448301056, available=54199906304, percent=20.8, used=14248394752, free=54199906304)
2023-08-17 11:18:39,270:INFO:Physical Core: 12
2023-08-17 11:18:39,270:INFO:Logical Core: 20
2023-08-17 11:18:39,270:INFO:Checking libraries
2023-08-17 11:18:39,270:INFO:System:
2023-08-17 11:18:39,270:INFO:    python: 3.11.4 | packaged by conda-forge | (main, Jun 10 2023, 17:59:51) [MSC v.1935 64 bit (AMD64)]
2023-08-17 11:18:39,270:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-17 11:18:39,270:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 11:18:39,270:INFO:PyCaret required dependencies:
2023-08-17 11:18:39,283:INFO:                 pip: 23.2.1
2023-08-17 11:18:39,283:INFO:          setuptools: 68.0.0
2023-08-17 11:18:39,283:INFO:             pycaret: 3.0.4
2023-08-17 11:18:39,283:INFO:             IPython: 8.14.0
2023-08-17 11:18:39,283:INFO:          ipywidgets: 8.1.0
2023-08-17 11:18:39,283:INFO:                tqdm: 4.66.1
2023-08-17 11:18:39,283:INFO:               numpy: 1.23.5
2023-08-17 11:18:39,283:INFO:              pandas: 1.5.3
2023-08-17 11:18:39,283:INFO:              jinja2: 3.1.2
2023-08-17 11:18:39,283:INFO:               scipy: 1.10.1
2023-08-17 11:18:39,283:INFO:              joblib: 1.3.2
2023-08-17 11:18:39,283:INFO:             sklearn: 1.2.2
2023-08-17 11:18:39,283:INFO:                pyod: 1.1.0
2023-08-17 11:18:39,283:INFO:            imblearn: 0.11.0
2023-08-17 11:18:39,283:INFO:   category_encoders: 2.6.2
2023-08-17 11:18:39,283:INFO:            lightgbm: 4.0.0
2023-08-17 11:18:39,283:INFO:               numba: 0.57.1
2023-08-17 11:18:39,283:INFO:            requests: 2.31.0
2023-08-17 11:18:39,283:INFO:          matplotlib: 3.7.2
2023-08-17 11:18:39,283:INFO:          scikitplot: 0.3.7
2023-08-17 11:18:39,283:INFO:         yellowbrick: 1.5
2023-08-17 11:18:39,283:INFO:              plotly: 5.16.1
2023-08-17 11:18:39,283:INFO:    plotly-resampler: Not installed
2023-08-17 11:18:39,283:INFO:             kaleido: 0.2.1
2023-08-17 11:18:39,283:INFO:           schemdraw: 0.15
2023-08-17 11:18:39,283:INFO:         statsmodels: 0.14.0
2023-08-17 11:18:39,283:INFO:              sktime: 0.21.0
2023-08-17 11:18:39,283:INFO:               tbats: 1.1.3
2023-08-17 11:18:39,283:INFO:            pmdarima: 2.0.2
2023-08-17 11:18:39,283:INFO:              psutil: 5.9.5
2023-08-17 11:18:39,283:INFO:          markupsafe: 2.1.3
2023-08-17 11:18:39,283:INFO:             pickle5: Not installed
2023-08-17 11:18:39,283:INFO:         cloudpickle: 2.2.1
2023-08-17 11:18:39,283:INFO:         deprecation: 2.1.0
2023-08-17 11:18:39,283:INFO:              xxhash: 0.0.0
2023-08-17 11:18:39,283:INFO:           wurlitzer: 3.0.3
2023-08-17 11:18:39,283:INFO:PyCaret optional dependencies:
2023-08-17 11:18:39,289:INFO:                shap: Not installed
2023-08-17 11:18:39,289:INFO:           interpret: Not installed
2023-08-17 11:18:39,289:INFO:                umap: 0.5.3
2023-08-17 11:18:39,289:INFO:    pandas_profiling: 0.0.dev0
2023-08-17 11:18:39,289:INFO:  explainerdashboard: Not installed
2023-08-17 11:18:39,289:INFO:             autoviz: Not installed
2023-08-17 11:18:39,289:INFO:           fairlearn: Not installed
2023-08-17 11:18:39,289:INFO:          deepchecks: Not installed
2023-08-17 11:18:39,289:INFO:             xgboost: Not installed
2023-08-17 11:18:39,289:INFO:            catboost: Not installed
2023-08-17 11:18:39,289:INFO:              kmodes: Not installed
2023-08-17 11:18:39,289:INFO:             mlxtend: Not installed
2023-08-17 11:18:39,290:INFO:       statsforecast: Not installed
2023-08-17 11:18:39,290:INFO:        tune_sklearn: Not installed
2023-08-17 11:18:39,290:INFO:                 ray: Not installed
2023-08-17 11:18:39,290:INFO:            hyperopt: Not installed
2023-08-17 11:18:39,290:INFO:              optuna: Not installed
2023-08-17 11:18:39,290:INFO:               skopt: Not installed
2023-08-17 11:18:39,290:INFO:              mlflow: Not installed
2023-08-17 11:18:39,290:INFO:              gradio: Not installed
2023-08-17 11:18:39,290:INFO:             fastapi: Not installed
2023-08-17 11:18:39,290:INFO:             uvicorn: Not installed
2023-08-17 11:18:39,290:INFO:              m2cgen: Not installed
2023-08-17 11:18:39,290:INFO:           evidently: Not installed
2023-08-17 11:18:39,290:INFO:               fugue: Not installed
2023-08-17 11:18:39,290:INFO:           streamlit: Not installed
2023-08-17 11:18:39,290:INFO:             prophet: Not installed
2023-08-17 11:18:39,290:INFO:None
2023-08-17 11:18:39,290:INFO:Set up data.
2023-08-17 11:18:39,465:INFO:Set up train/test split.
2023-08-17 11:18:39,600:INFO:Set up index.
2023-08-17 11:18:39,605:INFO:Set up folding strategy.
2023-08-17 11:18:39,605:INFO:Assigning column types.
2023-08-17 11:18:39,621:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 11:18:39,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 11:18:39,643:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 11:18:39,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 11:18:39,683:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 11:18:39,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,697:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 11:18:39,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 11:18:39,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,756:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 11:18:39,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,770:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 11:18:39,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,842:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:18:39,843:INFO:Preparing preprocessing pipeline...
2023-08-17 11:18:39,847:INFO:Set up label encoding.
2023-08-17 11:18:39,847:INFO:Set up simple imputation.
2023-08-17 11:18:39,876:INFO:Set up encoding of ordinal features.
2023-08-17 11:18:39,908:INFO:Set up encoding of categorical features.
2023-08-17 11:18:39,909:INFO:Set up removing outliers.
2023-08-17 11:18:39,909:INFO:Set up feature normalization.
2023-08-17 11:18:39,911:INFO:Set up column name cleaning.
2023-08-17 11:18:42,459:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 11:18:52,109:INFO:Finished creating preprocessing pipeline.
2023-08-17 11:18:52,142:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1776,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 11:18:52,142:INFO:Creating final display dataframe.
2023-08-17 11:18:53,185:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 11:19:03,570:INFO:Setup _display_container:                     Description             Value
0                    Session id              1776
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (268239, 42)
6   Transformed train set shape      (184848, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              f3b9
2023-08-17 11:19:03,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:19:03,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:19:03,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:19:03,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-17 11:19:03,653:INFO:setup() successfully completed in 24.59s...............
2023-08-17 11:35:15,542:ERROR:
'autoviz' is a soft dependency and not included in the pycaret installation. Please run: `pip install autoviz` to install.
Alternately, you can install this by running `pip install pycaret[mlops]`
NoneType: None
2023-08-17 11:36:35,234:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\numba\core\decorators.py:262: NumbaDeprecationWarning: [1mnumba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.[0m
  warnings.warn(msg, NumbaDeprecationWarning)

2023-08-17 11:36:35,237:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\Lib\site-packages\visions\backends\shared\nan_handling.py:50: NumbaDeprecationWarning: [1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.[0m
  @nb.jit

2023-08-17 12:02:23,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:02:23,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:02:23,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:02:23,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:02:25,019:INFO:PyCaret ClassificationExperiment
2023-08-17 12:02:25,019:INFO:Logging name: clf-default-name
2023-08-17 12:02:25,019:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 12:02:25,019:INFO:version 3.0.4
2023-08-17 12:02:25,019:INFO:Initializing setup()
2023-08-17 12:02:25,019:INFO:self.USI: e762
2023-08-17 12:02:25,019:INFO:self._variable_keys: {'memory', 'logging_param', 'pipeline', 'exp_name_log', 'y_test', 'y_train', '_ml_usecase', '_available_plots', 'html_param', 'gpu_param', 'fold_shuffle_param', 'is_multiclass', 'n_jobs_param', 'exp_id', 'idx', 'fix_imbalance', 'log_plots_param', 'USI', 'target_param', 'gpu_n_jobs_param', 'X_train', 'data', 'seed', 'X_test', 'fold_groups_param', 'fold_generator', 'y', 'X'}
2023-08-17 12:02:25,019:INFO:Checking environment
2023-08-17 12:02:25,019:INFO:python_version: 3.10.12
2023-08-17 12:02:25,019:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-17 12:02:25,019:INFO:machine: AMD64
2023-08-17 12:02:25,019:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 12:02:25,023:INFO:Memory: svmem(total=68448301056, available=51299147776, percent=25.1, used=17149153280, free=51299147776)
2023-08-17 12:02:25,023:INFO:Physical Core: 12
2023-08-17 12:02:25,023:INFO:Logical Core: 20
2023-08-17 12:02:25,023:INFO:Checking libraries
2023-08-17 12:02:25,024:INFO:System:
2023-08-17 12:02:25,024:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-17 12:02:25,024:INFO:executable: c:\Users\Ramon\miniforge3\envs\piptest\python.exe
2023-08-17 12:02:25,024:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 12:02:25,024:INFO:PyCaret required dependencies:
2023-08-17 12:02:25,496:INFO:                 pip: 23.2.1
2023-08-17 12:02:25,496:INFO:          setuptools: 68.0.0
2023-08-17 12:02:25,496:INFO:             pycaret: 3.0.4
2023-08-17 12:02:25,496:INFO:             IPython: 7.34.0
2023-08-17 12:02:25,496:INFO:          ipywidgets: 7.8.0
2023-08-17 12:02:25,496:INFO:                tqdm: 4.66.1
2023-08-17 12:02:25,496:INFO:               numpy: 1.23.5
2023-08-17 12:02:25,496:INFO:              pandas: 1.5.3
2023-08-17 12:02:25,497:INFO:              jinja2: 3.1.2
2023-08-17 12:02:25,497:INFO:               scipy: 1.10.1
2023-08-17 12:02:25,497:INFO:              joblib: 1.3.2
2023-08-17 12:02:25,497:INFO:             sklearn: 1.2.2
2023-08-17 12:02:25,497:INFO:                pyod: 1.1.0
2023-08-17 12:02:25,497:INFO:            imblearn: 0.11.0
2023-08-17 12:02:25,497:INFO:   category_encoders: 2.6.2
2023-08-17 12:02:25,497:INFO:            lightgbm: 4.0.0
2023-08-17 12:02:25,497:INFO:               numba: 0.57.1
2023-08-17 12:02:25,497:INFO:            requests: 2.31.0
2023-08-17 12:02:25,497:INFO:          matplotlib: 3.7.2
2023-08-17 12:02:25,497:INFO:          scikitplot: 0.3.7
2023-08-17 12:02:25,497:INFO:         yellowbrick: 1.5
2023-08-17 12:02:25,497:INFO:              plotly: 5.16.1
2023-08-17 12:02:25,497:INFO:    plotly-resampler: Not installed
2023-08-17 12:02:25,497:INFO:             kaleido: 0.2.1
2023-08-17 12:02:25,497:INFO:           schemdraw: 0.15
2023-08-17 12:02:25,497:INFO:         statsmodels: 0.14.0
2023-08-17 12:02:25,497:INFO:              sktime: 0.21.0
2023-08-17 12:02:25,497:INFO:               tbats: 1.1.3
2023-08-17 12:02:25,497:INFO:            pmdarima: 2.0.3
2023-08-17 12:02:25,497:INFO:              psutil: 5.9.5
2023-08-17 12:02:25,497:INFO:          markupsafe: 2.1.3
2023-08-17 12:02:25,497:INFO:             pickle5: Not installed
2023-08-17 12:02:25,497:INFO:         cloudpickle: 2.2.1
2023-08-17 12:02:25,497:INFO:         deprecation: 2.1.0
2023-08-17 12:02:25,497:INFO:              xxhash: 3.3.0
2023-08-17 12:02:25,497:INFO:           wurlitzer: Not installed
2023-08-17 12:02:25,497:INFO:PyCaret optional dependencies:
2023-08-17 12:02:26,863:INFO:                shap: 0.42.1
2023-08-17 12:02:26,863:INFO:           interpret: 0.4.3
2023-08-17 12:02:26,863:INFO:                umap: 0.5.3
2023-08-17 12:02:26,863:INFO:    pandas_profiling: 4.5.1
2023-08-17 12:02:26,863:INFO:  explainerdashboard: 0.4.3
2023-08-17 12:02:26,863:INFO:             autoviz: 0.1.730
2023-08-17 12:02:26,863:INFO:           fairlearn: 0.7.0
2023-08-17 12:02:26,863:INFO:          deepchecks: 0.17.4
2023-08-17 12:02:26,863:INFO:             xgboost: 1.7.6
2023-08-17 12:02:26,863:INFO:            catboost: 1.2
2023-08-17 12:02:26,863:INFO:              kmodes: 0.12.2
2023-08-17 12:02:26,863:INFO:             mlxtend: 0.22.0
2023-08-17 12:02:26,863:INFO:       statsforecast: 1.5.0
2023-08-17 12:02:26,863:INFO:        tune_sklearn: 0.4.6
2023-08-17 12:02:26,863:INFO:                 ray: 2.6.3
2023-08-17 12:02:26,863:INFO:            hyperopt: 0.2.7
2023-08-17 12:02:26,863:INFO:              optuna: 3.3.0
2023-08-17 12:02:26,863:INFO:               skopt: 0.9.0
2023-08-17 12:02:26,863:INFO:              mlflow: 1.30.1
2023-08-17 12:02:26,863:INFO:              gradio: 3.40.1
2023-08-17 12:02:26,864:INFO:             fastapi: 0.101.1
2023-08-17 12:02:26,864:INFO:             uvicorn: 0.23.2
2023-08-17 12:02:26,864:INFO:              m2cgen: 0.10.0
2023-08-17 12:02:26,864:INFO:           evidently: 0.2.8
2023-08-17 12:02:26,864:INFO:               fugue: 0.8.6
2023-08-17 12:02:26,864:INFO:           streamlit: Not installed
2023-08-17 12:02:26,864:INFO:             prophet: Not installed
2023-08-17 12:02:26,864:INFO:None
2023-08-17 12:02:26,864:INFO:Set up data.
2023-08-17 12:02:27,033:INFO:Set up train/test split.
2023-08-17 12:02:27,171:INFO:Set up index.
2023-08-17 12:02:27,175:INFO:Set up folding strategy.
2023-08-17 12:02:27,175:INFO:Assigning column types.
2023-08-17 12:02:27,190:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 12:02:27,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 12:02:27,215:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:02:27,234:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:02:27,235:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:02:27,467:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 12:02:27,468:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:02:27,482:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:02:27,484:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:02:27,484:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 12:02:27,508:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:02:27,523:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:02:27,524:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:02:27,547:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:02:27,562:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:02:27,563:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:02:27,564:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 12:02:27,602:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:02:27,603:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:02:27,642:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:02:27,643:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:02:27,646:INFO:Preparing preprocessing pipeline...
2023-08-17 12:02:27,649:INFO:Set up label encoding.
2023-08-17 12:02:27,649:INFO:Set up simple imputation.
2023-08-17 12:02:27,680:INFO:Set up encoding of ordinal features.
2023-08-17 12:02:27,715:INFO:Set up encoding of categorical features.
2023-08-17 12:02:27,715:INFO:Set up removing outliers.
2023-08-17 12:02:27,715:INFO:Set up feature normalization.
2023-08-17 12:02:27,717:INFO:Set up column name cleaning.
2023-08-17 12:02:39,996:INFO:Finished creating preprocessing pipeline.
2023-08-17 12:02:40,034:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1974,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 12:02:40,034:INFO:Creating final display dataframe.
2023-08-17 12:02:51,838:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (268239, 42)
6   Transformed train set shape      (184848, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              e762
2023-08-17 12:02:51,884:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:02:51,886:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:02:51,933:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:02:51,935:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:02:51,935:INFO:setup() successfully completed in 27.18s...............
2023-08-17 12:06:35,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:06:35,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:06:35,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:06:35,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:06:36,437:INFO:PyCaret ClassificationExperiment
2023-08-17 12:06:36,437:INFO:Logging name: clf-default-name
2023-08-17 12:06:36,437:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 12:06:36,437:INFO:version 3.0.4
2023-08-17 12:06:36,437:INFO:Initializing setup()
2023-08-17 12:06:36,437:INFO:self.USI: 2025
2023-08-17 12:06:36,437:INFO:self._variable_keys: {'exp_name_log', 'gpu_n_jobs_param', 'exp_id', 'X_train', '_available_plots', 'fold_shuffle_param', 'y', 'fix_imbalance', 'html_param', '_ml_usecase', 'USI', 'pipeline', 'fold_generator', 'y_train', 'log_plots_param', 'X', 'data', 'seed', 'logging_param', 'gpu_param', 'target_param', 'fold_groups_param', 'idx', 'is_multiclass', 'memory', 'n_jobs_param', 'X_test', 'y_test'}
2023-08-17 12:06:36,438:INFO:Checking environment
2023-08-17 12:06:36,438:INFO:python_version: 3.10.12
2023-08-17 12:06:36,438:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-17 12:06:36,438:INFO:machine: AMD64
2023-08-17 12:06:36,438:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 12:06:36,441:INFO:Memory: svmem(total=68448301056, available=51236507648, percent=25.1, used=17211793408, free=51236507648)
2023-08-17 12:06:36,441:INFO:Physical Core: 12
2023-08-17 12:06:36,441:INFO:Logical Core: 20
2023-08-17 12:06:36,441:INFO:Checking libraries
2023-08-17 12:06:36,441:INFO:System:
2023-08-17 12:06:36,441:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-17 12:06:36,441:INFO:executable: c:\Users\Ramon\miniforge3\envs\piptest\python.exe
2023-08-17 12:06:36,442:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 12:06:36,442:INFO:PyCaret required dependencies:
2023-08-17 12:06:36,776:INFO:                 pip: 23.2.1
2023-08-17 12:06:36,776:INFO:          setuptools: 68.0.0
2023-08-17 12:06:36,776:INFO:             pycaret: 3.0.4
2023-08-17 12:06:36,776:INFO:             IPython: 7.34.0
2023-08-17 12:06:36,776:INFO:          ipywidgets: 7.8.0
2023-08-17 12:06:36,776:INFO:                tqdm: 4.66.1
2023-08-17 12:06:36,776:INFO:               numpy: 1.23.5
2023-08-17 12:06:36,776:INFO:              pandas: 1.5.3
2023-08-17 12:06:36,776:INFO:              jinja2: 3.1.2
2023-08-17 12:06:36,776:INFO:               scipy: 1.10.1
2023-08-17 12:06:36,776:INFO:              joblib: 1.3.2
2023-08-17 12:06:36,776:INFO:             sklearn: 1.2.2
2023-08-17 12:06:36,776:INFO:                pyod: 1.1.0
2023-08-17 12:06:36,776:INFO:            imblearn: 0.11.0
2023-08-17 12:06:36,776:INFO:   category_encoders: 2.6.2
2023-08-17 12:06:36,776:INFO:            lightgbm: 4.0.0
2023-08-17 12:06:36,776:INFO:               numba: 0.57.1
2023-08-17 12:06:36,776:INFO:            requests: 2.31.0
2023-08-17 12:06:36,776:INFO:          matplotlib: 3.7.2
2023-08-17 12:06:36,776:INFO:          scikitplot: 0.3.7
2023-08-17 12:06:36,776:INFO:         yellowbrick: 1.5
2023-08-17 12:06:36,776:INFO:              plotly: 5.16.1
2023-08-17 12:06:36,776:INFO:    plotly-resampler: Not installed
2023-08-17 12:06:36,776:INFO:             kaleido: 0.2.1
2023-08-17 12:06:36,776:INFO:           schemdraw: 0.15
2023-08-17 12:06:36,776:INFO:         statsmodels: 0.14.0
2023-08-17 12:06:36,776:INFO:              sktime: 0.21.0
2023-08-17 12:06:36,776:INFO:               tbats: 1.1.3
2023-08-17 12:06:36,776:INFO:            pmdarima: 2.0.3
2023-08-17 12:06:36,776:INFO:              psutil: 5.9.5
2023-08-17 12:06:36,776:INFO:          markupsafe: 2.1.3
2023-08-17 12:06:36,776:INFO:             pickle5: Not installed
2023-08-17 12:06:36,776:INFO:         cloudpickle: 2.2.1
2023-08-17 12:06:36,776:INFO:         deprecation: 2.1.0
2023-08-17 12:06:36,776:INFO:              xxhash: 3.3.0
2023-08-17 12:06:36,776:INFO:           wurlitzer: Not installed
2023-08-17 12:06:36,776:INFO:PyCaret optional dependencies:
2023-08-17 12:06:37,781:INFO:                shap: 0.42.1
2023-08-17 12:06:37,782:INFO:           interpret: 0.4.3
2023-08-17 12:06:37,782:INFO:                umap: 0.5.3
2023-08-17 12:06:37,782:INFO:    pandas_profiling: 4.5.1
2023-08-17 12:06:37,782:INFO:  explainerdashboard: 0.4.3
2023-08-17 12:06:37,782:INFO:             autoviz: 0.1.730
2023-08-17 12:06:37,782:INFO:           fairlearn: 0.7.0
2023-08-17 12:06:37,782:INFO:          deepchecks: 0.17.4
2023-08-17 12:06:37,782:INFO:             xgboost: 1.7.6
2023-08-17 12:06:37,782:INFO:            catboost: 1.2
2023-08-17 12:06:37,782:INFO:              kmodes: 0.12.2
2023-08-17 12:06:37,782:INFO:             mlxtend: 0.22.0
2023-08-17 12:06:37,782:INFO:       statsforecast: 1.5.0
2023-08-17 12:06:37,782:INFO:        tune_sklearn: 0.4.6
2023-08-17 12:06:37,782:INFO:                 ray: 2.6.3
2023-08-17 12:06:37,782:INFO:            hyperopt: 0.2.7
2023-08-17 12:06:37,782:INFO:              optuna: 3.3.0
2023-08-17 12:06:37,782:INFO:               skopt: 0.9.0
2023-08-17 12:06:37,782:INFO:              mlflow: 1.30.1
2023-08-17 12:06:37,782:INFO:              gradio: 3.40.1
2023-08-17 12:06:37,782:INFO:             fastapi: 0.101.1
2023-08-17 12:06:37,782:INFO:             uvicorn: 0.23.2
2023-08-17 12:06:37,782:INFO:              m2cgen: 0.10.0
2023-08-17 12:06:37,782:INFO:           evidently: 0.2.8
2023-08-17 12:06:37,782:INFO:               fugue: 0.8.6
2023-08-17 12:06:37,782:INFO:           streamlit: Not installed
2023-08-17 12:06:37,782:INFO:             prophet: Not installed
2023-08-17 12:06:37,782:INFO:None
2023-08-17 12:06:37,782:INFO:Set up data.
2023-08-17 12:06:37,949:INFO:Set up train/test split.
2023-08-17 12:06:38,090:INFO:Set up index.
2023-08-17 12:06:38,094:INFO:Set up folding strategy.
2023-08-17 12:06:38,094:INFO:Assigning column types.
2023-08-17 12:06:38,108:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 12:06:38,131:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 12:06:38,132:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:06:38,152:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:06:38,154:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:06:38,194:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 12:06:38,194:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:06:38,209:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:06:38,211:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:06:38,212:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 12:06:38,236:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:06:38,250:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:06:38,252:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:06:38,276:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:06:38,291:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:06:38,293:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:06:38,293:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 12:06:38,333:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:06:38,334:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:06:38,374:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:06:38,376:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:06:38,377:INFO:Preparing preprocessing pipeline...
2023-08-17 12:06:38,380:INFO:Set up label encoding.
2023-08-17 12:06:38,381:INFO:Set up simple imputation.
2023-08-17 12:06:38,411:INFO:Set up encoding of ordinal features.
2023-08-17 12:06:38,444:INFO:Set up encoding of categorical features.
2023-08-17 12:06:38,444:INFO:Set up removing outliers.
2023-08-17 12:06:38,444:INFO:Set up feature normalization.
2023-08-17 12:06:38,446:INFO:Set up column name cleaning.
2023-08-17 12:06:40,011:INFO:Finished creating preprocessing pipeline.
2023-08-17 12:06:40,047:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1974,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 12:06:40,047:INFO:Creating final display dataframe.
2023-08-17 12:06:41,293:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (268239, 42)
6   Transformed train set shape      (184848, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              2025
2023-08-17 12:06:41,338:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:06:41,340:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:06:41,380:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:06:41,382:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:06:41,382:INFO:setup() successfully completed in 5.13s...............
2023-08-17 12:10:57,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:10:57,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:10:57,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:10:57,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-17 12:10:57,784:INFO:PyCaret ClassificationExperiment
2023-08-17 12:10:57,784:INFO:Logging name: clf-default-name
2023-08-17 12:10:57,784:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 12:10:57,784:INFO:version 3.0.4
2023-08-17 12:10:57,784:INFO:Initializing setup()
2023-08-17 12:10:57,784:INFO:self.USI: dda7
2023-08-17 12:10:57,784:INFO:self._variable_keys: {'pipeline', 'logging_param', 'X_train', '_ml_usecase', 'html_param', 'n_jobs_param', 'y_test', 'memory', 'y', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'is_multiclass', 'idx', 'data', 'X_test', 'gpu_param', 'log_plots_param', 'seed', 'X', '_available_plots', 'USI', 'y_train', 'target_param', 'exp_name_log', 'gpu_n_jobs_param', 'fix_imbalance', 'fold_generator'}
2023-08-17 12:10:57,784:INFO:Checking environment
2023-08-17 12:10:57,784:INFO:python_version: 3.10.12
2023-08-17 12:10:57,784:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-17 12:10:57,784:INFO:machine: AMD64
2023-08-17 12:10:57,784:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 12:10:57,787:INFO:Memory: svmem(total=68448301056, available=51411742720, percent=24.9, used=17036558336, free=51411742720)
2023-08-17 12:10:57,787:INFO:Physical Core: 12
2023-08-17 12:10:57,788:INFO:Logical Core: 20
2023-08-17 12:10:57,788:INFO:Checking libraries
2023-08-17 12:10:57,788:INFO:System:
2023-08-17 12:10:57,788:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-17 12:10:57,788:INFO:executable: c:\Users\Ramon\miniforge3\envs\piptest\python.exe
2023-08-17 12:10:57,788:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 12:10:57,788:INFO:PyCaret required dependencies:
2023-08-17 12:10:58,118:INFO:                 pip: 23.2.1
2023-08-17 12:10:58,118:INFO:          setuptools: 68.0.0
2023-08-17 12:10:58,118:INFO:             pycaret: 3.0.4
2023-08-17 12:10:58,118:INFO:             IPython: 7.34.0
2023-08-17 12:10:58,118:INFO:          ipywidgets: 7.8.0
2023-08-17 12:10:58,118:INFO:                tqdm: 4.66.1
2023-08-17 12:10:58,118:INFO:               numpy: 1.23.5
2023-08-17 12:10:58,118:INFO:              pandas: 1.5.3
2023-08-17 12:10:58,118:INFO:              jinja2: 3.1.2
2023-08-17 12:10:58,119:INFO:               scipy: 1.10.1
2023-08-17 12:10:58,119:INFO:              joblib: 1.3.2
2023-08-17 12:10:58,119:INFO:             sklearn: 1.2.2
2023-08-17 12:10:58,119:INFO:                pyod: 1.1.0
2023-08-17 12:10:58,119:INFO:            imblearn: 0.11.0
2023-08-17 12:10:58,119:INFO:   category_encoders: 2.6.2
2023-08-17 12:10:58,119:INFO:            lightgbm: 4.0.0
2023-08-17 12:10:58,119:INFO:               numba: 0.57.1
2023-08-17 12:10:58,119:INFO:            requests: 2.31.0
2023-08-17 12:10:58,119:INFO:          matplotlib: 3.7.2
2023-08-17 12:10:58,119:INFO:          scikitplot: 0.3.7
2023-08-17 12:10:58,119:INFO:         yellowbrick: 1.5
2023-08-17 12:10:58,119:INFO:              plotly: 5.16.1
2023-08-17 12:10:58,119:INFO:    plotly-resampler: Not installed
2023-08-17 12:10:58,119:INFO:             kaleido: 0.2.1
2023-08-17 12:10:58,119:INFO:           schemdraw: 0.15
2023-08-17 12:10:58,119:INFO:         statsmodels: 0.14.0
2023-08-17 12:10:58,119:INFO:              sktime: 0.21.0
2023-08-17 12:10:58,119:INFO:               tbats: 1.1.3
2023-08-17 12:10:58,119:INFO:            pmdarima: 2.0.3
2023-08-17 12:10:58,119:INFO:              psutil: 5.9.5
2023-08-17 12:10:58,119:INFO:          markupsafe: 2.1.3
2023-08-17 12:10:58,119:INFO:             pickle5: Not installed
2023-08-17 12:10:58,119:INFO:         cloudpickle: 2.2.1
2023-08-17 12:10:58,119:INFO:         deprecation: 2.1.0
2023-08-17 12:10:58,119:INFO:              xxhash: 3.3.0
2023-08-17 12:10:58,119:INFO:           wurlitzer: Not installed
2023-08-17 12:10:58,119:INFO:PyCaret optional dependencies:
2023-08-17 12:10:59,122:INFO:                shap: 0.42.1
2023-08-17 12:10:59,122:INFO:           interpret: 0.4.3
2023-08-17 12:10:59,123:INFO:                umap: 0.5.3
2023-08-17 12:10:59,123:INFO:    pandas_profiling: 4.5.1
2023-08-17 12:10:59,123:INFO:  explainerdashboard: 0.4.3
2023-08-17 12:10:59,123:INFO:             autoviz: 0.1.730
2023-08-17 12:10:59,123:INFO:           fairlearn: 0.7.0
2023-08-17 12:10:59,123:INFO:          deepchecks: 0.17.4
2023-08-17 12:10:59,123:INFO:             xgboost: 1.7.6
2023-08-17 12:10:59,123:INFO:            catboost: 1.2
2023-08-17 12:10:59,123:INFO:              kmodes: 0.12.2
2023-08-17 12:10:59,123:INFO:             mlxtend: 0.22.0
2023-08-17 12:10:59,123:INFO:       statsforecast: 1.5.0
2023-08-17 12:10:59,123:INFO:        tune_sklearn: 0.4.6
2023-08-17 12:10:59,123:INFO:                 ray: 2.6.3
2023-08-17 12:10:59,123:INFO:            hyperopt: 0.2.7
2023-08-17 12:10:59,123:INFO:              optuna: 3.3.0
2023-08-17 12:10:59,123:INFO:               skopt: 0.9.0
2023-08-17 12:10:59,123:INFO:              mlflow: 1.30.1
2023-08-17 12:10:59,123:INFO:              gradio: 3.40.1
2023-08-17 12:10:59,123:INFO:             fastapi: 0.101.1
2023-08-17 12:10:59,123:INFO:             uvicorn: 0.23.2
2023-08-17 12:10:59,123:INFO:              m2cgen: 0.10.0
2023-08-17 12:10:59,123:INFO:           evidently: 0.2.8
2023-08-17 12:10:59,123:INFO:               fugue: 0.8.6
2023-08-17 12:10:59,123:INFO:           streamlit: Not installed
2023-08-17 12:10:59,123:INFO:             prophet: Not installed
2023-08-17 12:10:59,123:INFO:None
2023-08-17 12:10:59,123:INFO:Set up data.
2023-08-17 12:10:59,291:INFO:Set up train/test split.
2023-08-17 12:10:59,437:INFO:Set up index.
2023-08-17 12:10:59,442:INFO:Set up folding strategy.
2023-08-17 12:10:59,442:INFO:Assigning column types.
2023-08-17 12:10:59,458:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 12:10:59,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 12:10:59,484:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:10:59,505:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:10:59,507:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:10:59,545:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 12:10:59,546:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:10:59,560:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:10:59,562:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:10:59,563:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 12:10:59,586:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:10:59,601:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:10:59,603:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:10:59,628:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:10:59,643:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:10:59,644:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:10:59,645:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 12:10:59,684:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:10:59,686:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:10:59,726:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:10:59,728:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:10:59,731:INFO:Preparing preprocessing pipeline...
2023-08-17 12:10:59,734:INFO:Set up label encoding.
2023-08-17 12:10:59,734:INFO:Set up simple imputation.
2023-08-17 12:10:59,765:INFO:Set up encoding of ordinal features.
2023-08-17 12:10:59,800:INFO:Set up encoding of categorical features.
2023-08-17 12:10:59,800:INFO:Set up removing outliers.
2023-08-17 12:10:59,800:INFO:Set up feature normalization.
2023-08-17 12:10:59,802:INFO:Set up column name cleaning.
2023-08-17 12:11:00,468:INFO:Finished creating preprocessing pipeline.
2023-08-17 12:11:00,513:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=1974,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 12:11:00,513:INFO:Creating final display dataframe.
2023-08-17 12:11:01,761:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (268239, 42)
6   Transformed train set shape      (184848, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              dda7
2023-08-17 12:11:01,807:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:11:01,809:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:11:01,849:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:11:01,850:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:11:01,851:INFO:setup() successfully completed in 4.26s...............
2023-08-17 12:41:57,965:INFO:PyCaret ClassificationExperiment
2023-08-17 12:41:57,965:INFO:Logging name: clf-default-name
2023-08-17 12:41:57,965:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-17 12:41:57,965:INFO:version 3.0.4
2023-08-17 12:41:57,965:INFO:Initializing setup()
2023-08-17 12:41:57,965:INFO:self.USI: 2fbd
2023-08-17 12:41:57,965:INFO:self._variable_keys: {'pipeline', 'logging_param', 'X_train', '_ml_usecase', 'html_param', 'n_jobs_param', 'y_test', 'memory', 'y', 'fold_shuffle_param', 'fold_groups_param', 'exp_id', 'is_multiclass', 'idx', 'data', 'X_test', 'gpu_param', 'log_plots_param', 'seed', 'X', '_available_plots', 'USI', 'y_train', 'target_param', 'exp_name_log', 'gpu_n_jobs_param', 'fix_imbalance', 'fold_generator'}
2023-08-17 12:41:57,966:INFO:Checking environment
2023-08-17 12:41:57,966:INFO:python_version: 3.10.12
2023-08-17 12:41:57,966:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-17 12:41:57,966:INFO:machine: AMD64
2023-08-17 12:41:57,966:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-17 12:41:57,969:INFO:Memory: svmem(total=68448301056, available=50456866816, percent=26.3, used=17991434240, free=50456866816)
2023-08-17 12:41:57,969:INFO:Physical Core: 12
2023-08-17 12:41:57,969:INFO:Logical Core: 20
2023-08-17 12:41:57,969:INFO:Checking libraries
2023-08-17 12:41:57,969:INFO:System:
2023-08-17 12:41:57,969:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-17 12:41:57,969:INFO:executable: c:\Users\Ramon\miniforge3\envs\piptest\python.exe
2023-08-17 12:41:57,969:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-17 12:41:57,969:INFO:PyCaret required dependencies:
2023-08-17 12:41:57,969:INFO:                 pip: 23.2.1
2023-08-17 12:41:57,969:INFO:          setuptools: 68.0.0
2023-08-17 12:41:57,969:INFO:             pycaret: 3.0.4
2023-08-17 12:41:57,969:INFO:             IPython: 7.34.0
2023-08-17 12:41:57,969:INFO:          ipywidgets: 7.8.0
2023-08-17 12:41:57,969:INFO:                tqdm: 4.66.1
2023-08-17 12:41:57,969:INFO:               numpy: 1.23.5
2023-08-17 12:41:57,969:INFO:              pandas: 1.5.3
2023-08-17 12:41:57,969:INFO:              jinja2: 3.1.2
2023-08-17 12:41:57,969:INFO:               scipy: 1.10.1
2023-08-17 12:41:57,969:INFO:              joblib: 1.3.2
2023-08-17 12:41:57,969:INFO:             sklearn: 1.2.2
2023-08-17 12:41:57,969:INFO:                pyod: 1.1.0
2023-08-17 12:41:57,969:INFO:            imblearn: 0.11.0
2023-08-17 12:41:57,969:INFO:   category_encoders: 2.6.2
2023-08-17 12:41:57,969:INFO:            lightgbm: 4.0.0
2023-08-17 12:41:57,969:INFO:               numba: 0.57.1
2023-08-17 12:41:57,970:INFO:            requests: 2.31.0
2023-08-17 12:41:57,970:INFO:          matplotlib: 3.7.2
2023-08-17 12:41:57,970:INFO:          scikitplot: 0.3.7
2023-08-17 12:41:57,970:INFO:         yellowbrick: 1.5
2023-08-17 12:41:57,970:INFO:              plotly: 5.16.1
2023-08-17 12:41:57,970:INFO:    plotly-resampler: Not installed
2023-08-17 12:41:57,970:INFO:             kaleido: 0.2.1
2023-08-17 12:41:57,970:INFO:           schemdraw: 0.15
2023-08-17 12:41:57,970:INFO:         statsmodels: 0.14.0
2023-08-17 12:41:57,970:INFO:              sktime: 0.21.0
2023-08-17 12:41:57,970:INFO:               tbats: 1.1.3
2023-08-17 12:41:57,970:INFO:            pmdarima: 2.0.3
2023-08-17 12:41:57,970:INFO:              psutil: 5.9.5
2023-08-17 12:41:57,970:INFO:          markupsafe: 2.1.3
2023-08-17 12:41:57,970:INFO:             pickle5: Not installed
2023-08-17 12:41:57,970:INFO:         cloudpickle: 2.2.1
2023-08-17 12:41:57,970:INFO:         deprecation: 2.1.0
2023-08-17 12:41:57,970:INFO:              xxhash: 3.3.0
2023-08-17 12:41:57,970:INFO:           wurlitzer: Not installed
2023-08-17 12:41:57,970:INFO:PyCaret optional dependencies:
2023-08-17 12:41:57,970:INFO:                shap: 0.42.1
2023-08-17 12:41:57,970:INFO:           interpret: 0.4.3
2023-08-17 12:41:57,970:INFO:                umap: 0.5.3
2023-08-17 12:41:57,970:INFO:    pandas_profiling: 4.5.1
2023-08-17 12:41:57,970:INFO:  explainerdashboard: 0.4.3
2023-08-17 12:41:57,970:INFO:             autoviz: 0.1.730
2023-08-17 12:41:57,970:INFO:           fairlearn: 0.7.0
2023-08-17 12:41:57,970:INFO:          deepchecks: 0.17.4
2023-08-17 12:41:57,970:INFO:             xgboost: 1.7.6
2023-08-17 12:41:57,970:INFO:            catboost: 1.2
2023-08-17 12:41:57,970:INFO:              kmodes: 0.12.2
2023-08-17 12:41:57,970:INFO:             mlxtend: 0.22.0
2023-08-17 12:41:57,970:INFO:       statsforecast: 1.5.0
2023-08-17 12:41:57,970:INFO:        tune_sklearn: 0.4.6
2023-08-17 12:41:57,970:INFO:                 ray: 2.6.3
2023-08-17 12:41:57,970:INFO:            hyperopt: 0.2.7
2023-08-17 12:41:57,970:INFO:              optuna: 3.3.0
2023-08-17 12:41:57,970:INFO:               skopt: 0.9.0
2023-08-17 12:41:57,970:INFO:              mlflow: 1.30.1
2023-08-17 12:41:57,970:INFO:              gradio: 3.40.1
2023-08-17 12:41:57,970:INFO:             fastapi: 0.101.1
2023-08-17 12:41:57,970:INFO:             uvicorn: 0.23.2
2023-08-17 12:41:57,970:INFO:              m2cgen: 0.10.0
2023-08-17 12:41:57,970:INFO:           evidently: 0.2.8
2023-08-17 12:41:57,970:INFO:               fugue: 0.8.6
2023-08-17 12:41:57,970:INFO:           streamlit: Not installed
2023-08-17 12:41:57,970:INFO:             prophet: Not installed
2023-08-17 12:41:57,970:INFO:None
2023-08-17 12:41:57,970:INFO:Set up data.
2023-08-17 12:41:58,134:INFO:Set up train/test split.
2023-08-17 12:41:58,268:INFO:Set up index.
2023-08-17 12:41:58,272:INFO:Set up folding strategy.
2023-08-17 12:41:58,273:INFO:Assigning column types.
2023-08-17 12:41:58,282:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-17 12:41:58,308:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 12:41:58,308:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:41:58,324:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:41:58,326:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:41:58,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-17 12:41:58,353:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:41:58,369:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:41:58,370:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:41:58,371:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-17 12:41:58,396:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:41:58,412:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:41:58,414:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:41:58,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-17 12:41:58,453:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:41:58,455:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:41:58,456:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-17 12:41:58,496:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:41:58,497:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:41:58,538:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:41:58,540:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:41:58,541:INFO:Preparing preprocessing pipeline...
2023-08-17 12:41:58,543:INFO:Set up label encoding.
2023-08-17 12:41:58,543:INFO:Set up simple imputation.
2023-08-17 12:41:58,571:INFO:Set up encoding of ordinal features.
2023-08-17 12:41:58,598:INFO:Set up encoding of categorical features.
2023-08-17 12:41:58,599:INFO:Set up removing outliers.
2023-08-17 12:41:58,599:INFO:Set up feature normalization.
2023-08-17 12:41:58,600:INFO:Set up column name cleaning.
2023-08-17 12:42:10,173:INFO:Finished creating preprocessing pipeline.
2023-08-17 12:42:10,211:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=559,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-17 12:42:10,211:INFO:Creating final display dataframe.
2023-08-17 12:42:21,235:INFO:Setup _display_container:            Description                Value      
0                    Session id               559
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 17)
5        Transformed data shape      (268239, 35)
6   Transformed train set shape      (184848, 35)
7    Transformed test set shape       (83391, 35)
8              Ordinal features                 7
9              Numeric features                 6
10         Categorical features                10
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              2fbd
2023-08-17 12:42:21,279:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:42:21,281:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:42:21,321:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-17 12:42:21,323:INFO:Soft dependency imported: catboost: 1.2
2023-08-17 12:42:21,323:INFO:setup() successfully completed in 23.54s...............
2023-08-17 12:45:00,224:INFO:Initializing compare_models()
2023-08-17 12:45:00,224:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-17 12:45:00,224:INFO:Checking exceptions
2023-08-17 12:45:00,242:INFO:Preparing display monitor
2023-08-17 12:45:00,259:INFO:Initializing Logistic Regression
2023-08-17 12:45:00,259:INFO:Total runtime is 0.0 minutes
2023-08-17 12:45:00,261:INFO:SubProcess create_model() called ==================================
2023-08-17 12:45:00,262:INFO:Initializing create_model()
2023-08-17 12:45:00,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:45:00,262:INFO:Checking exceptions
2023-08-17 12:45:00,262:INFO:Importing libraries
2023-08-17 12:45:00,262:INFO:Copying training dataset
2023-08-17 12:45:00,307:INFO:Defining folds
2023-08-17 12:45:00,307:INFO:Declaring metric variables
2023-08-17 12:45:00,310:INFO:Importing untrained model
2023-08-17 12:45:00,313:INFO:Logistic Regression Imported successfully
2023-08-17 12:45:00,320:INFO:Starting cross validation
2023-08-17 12:45:00,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:45:09,313:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,332:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,388:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,460:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,484:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,507:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,547:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,577:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,607:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:09,617:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-17 12:45:40,995:INFO:Calculating mean and std
2023-08-17 12:45:40,997:INFO:Creating metrics dataframe
2023-08-17 12:45:41,207:INFO:Uploading results into container
2023-08-17 12:45:41,207:INFO:Uploading model into container now
2023-08-17 12:45:41,208:INFO:_master_model_container: 1
2023-08-17 12:45:41,208:INFO:_display_container: 2
2023-08-17 12:45:41,208:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=559, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-17 12:45:41,208:INFO:create_model() successfully completed......................................
2023-08-17 12:45:41,434:INFO:SubProcess create_model() end ==================================
2023-08-17 12:45:41,434:INFO:Creating metrics dataframe
2023-08-17 12:45:41,440:INFO:Initializing K Neighbors Classifier
2023-08-17 12:45:41,441:INFO:Total runtime is 0.6863630255063374 minutes
2023-08-17 12:45:41,443:INFO:SubProcess create_model() called ==================================
2023-08-17 12:45:41,443:INFO:Initializing create_model()
2023-08-17 12:45:41,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:45:41,444:INFO:Checking exceptions
2023-08-17 12:45:41,444:INFO:Importing libraries
2023-08-17 12:45:41,444:INFO:Copying training dataset
2023-08-17 12:45:41,478:INFO:Defining folds
2023-08-17 12:45:41,479:INFO:Declaring metric variables
2023-08-17 12:45:41,481:INFO:Importing untrained model
2023-08-17 12:45:41,483:INFO:K Neighbors Classifier Imported successfully
2023-08-17 12:45:41,487:INFO:Starting cross validation
2023-08-17 12:45:41,493:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:46:16,206:INFO:Calculating mean and std
2023-08-17 12:46:16,207:INFO:Creating metrics dataframe
2023-08-17 12:46:16,439:INFO:Uploading results into container
2023-08-17 12:46:16,440:INFO:Uploading model into container now
2023-08-17 12:46:16,440:INFO:_master_model_container: 2
2023-08-17 12:46:16,440:INFO:_display_container: 2
2023-08-17 12:46:16,440:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-17 12:46:16,440:INFO:create_model() successfully completed......................................
2023-08-17 12:46:16,580:INFO:SubProcess create_model() end ==================================
2023-08-17 12:46:16,580:INFO:Creating metrics dataframe
2023-08-17 12:46:16,586:INFO:Initializing Naive Bayes
2023-08-17 12:46:16,586:INFO:Total runtime is 1.2721107403437295 minutes
2023-08-17 12:46:16,588:INFO:SubProcess create_model() called ==================================
2023-08-17 12:46:16,589:INFO:Initializing create_model()
2023-08-17 12:46:16,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:46:16,589:INFO:Checking exceptions
2023-08-17 12:46:16,589:INFO:Importing libraries
2023-08-17 12:46:16,589:INFO:Copying training dataset
2023-08-17 12:46:16,622:INFO:Defining folds
2023-08-17 12:46:16,623:INFO:Declaring metric variables
2023-08-17 12:46:16,625:INFO:Importing untrained model
2023-08-17 12:46:16,628:INFO:Naive Bayes Imported successfully
2023-08-17 12:46:16,633:INFO:Starting cross validation
2023-08-17 12:46:16,641:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:46:21,074:INFO:Calculating mean and std
2023-08-17 12:46:21,075:INFO:Creating metrics dataframe
2023-08-17 12:46:21,304:INFO:Uploading results into container
2023-08-17 12:46:21,305:INFO:Uploading model into container now
2023-08-17 12:46:21,306:INFO:_master_model_container: 3
2023-08-17 12:46:21,306:INFO:_display_container: 2
2023-08-17 12:46:21,306:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-17 12:46:21,306:INFO:create_model() successfully completed......................................
2023-08-17 12:46:21,446:INFO:SubProcess create_model() end ==================================
2023-08-17 12:46:21,446:INFO:Creating metrics dataframe
2023-08-17 12:46:21,453:INFO:Initializing Decision Tree Classifier
2023-08-17 12:46:21,454:INFO:Total runtime is 1.353244372208913 minutes
2023-08-17 12:46:21,456:INFO:SubProcess create_model() called ==================================
2023-08-17 12:46:21,456:INFO:Initializing create_model()
2023-08-17 12:46:21,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:46:21,456:INFO:Checking exceptions
2023-08-17 12:46:21,456:INFO:Importing libraries
2023-08-17 12:46:21,456:INFO:Copying training dataset
2023-08-17 12:46:21,492:INFO:Defining folds
2023-08-17 12:46:21,492:INFO:Declaring metric variables
2023-08-17 12:46:21,495:INFO:Importing untrained model
2023-08-17 12:46:21,498:INFO:Decision Tree Classifier Imported successfully
2023-08-17 12:46:21,502:INFO:Starting cross validation
2023-08-17 12:46:21,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:46:26,774:INFO:Calculating mean and std
2023-08-17 12:46:26,775:INFO:Creating metrics dataframe
2023-08-17 12:46:27,020:INFO:Uploading results into container
2023-08-17 12:46:27,021:INFO:Uploading model into container now
2023-08-17 12:46:27,021:INFO:_master_model_container: 4
2023-08-17 12:46:27,021:INFO:_display_container: 2
2023-08-17 12:46:27,022:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=559, splitter='best')
2023-08-17 12:46:27,022:INFO:create_model() successfully completed......................................
2023-08-17 12:46:27,158:INFO:SubProcess create_model() end ==================================
2023-08-17 12:46:27,158:INFO:Creating metrics dataframe
2023-08-17 12:46:27,164:INFO:Initializing SVM - Linear Kernel
2023-08-17 12:46:27,164:INFO:Total runtime is 1.4484192331631975 minutes
2023-08-17 12:46:27,167:INFO:SubProcess create_model() called ==================================
2023-08-17 12:46:27,167:INFO:Initializing create_model()
2023-08-17 12:46:27,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:46:27,167:INFO:Checking exceptions
2023-08-17 12:46:27,167:INFO:Importing libraries
2023-08-17 12:46:27,167:INFO:Copying training dataset
2023-08-17 12:46:27,197:INFO:Defining folds
2023-08-17 12:46:27,197:INFO:Declaring metric variables
2023-08-17 12:46:27,201:INFO:Importing untrained model
2023-08-17 12:46:27,204:INFO:SVM - Linear Kernel Imported successfully
2023-08-17 12:46:27,209:INFO:Starting cross validation
2023-08-17 12:46:27,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:46:29,838:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,862:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,899:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,899:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,938:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,949:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,965:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,967:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,976:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:29,999:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-17 12:46:30,065:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,067:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,099:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,117:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,141:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,164:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,184:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,185:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,194:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:30,227:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:32,173:INFO:Calculating mean and std
2023-08-17 12:46:32,174:INFO:Creating metrics dataframe
2023-08-17 12:46:32,406:INFO:Uploading results into container
2023-08-17 12:46:32,407:INFO:Uploading model into container now
2023-08-17 12:46:32,407:INFO:_master_model_container: 5
2023-08-17 12:46:32,407:INFO:_display_container: 2
2023-08-17 12:46:32,408:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=559, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-17 12:46:32,408:INFO:create_model() successfully completed......................................
2023-08-17 12:46:32,546:INFO:SubProcess create_model() end ==================================
2023-08-17 12:46:32,546:INFO:Creating metrics dataframe
2023-08-17 12:46:32,553:INFO:Initializing Ridge Classifier
2023-08-17 12:46:32,553:INFO:Total runtime is 1.5382345398267108 minutes
2023-08-17 12:46:32,556:INFO:SubProcess create_model() called ==================================
2023-08-17 12:46:32,556:INFO:Initializing create_model()
2023-08-17 12:46:32,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:46:32,557:INFO:Checking exceptions
2023-08-17 12:46:32,557:INFO:Importing libraries
2023-08-17 12:46:32,557:INFO:Copying training dataset
2023-08-17 12:46:32,591:INFO:Defining folds
2023-08-17 12:46:32,591:INFO:Declaring metric variables
2023-08-17 12:46:32,594:INFO:Importing untrained model
2023-08-17 12:46:32,596:INFO:Ridge Classifier Imported successfully
2023-08-17 12:46:32,600:INFO:Starting cross validation
2023-08-17 12:46:32,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:46:34,587:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,595:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,616:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,663:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,681:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,686:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,689:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,723:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,730:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,748:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-17 12:46:34,802:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:34,805:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:34,840:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:34,884:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:34,903:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:34,905:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:34,908:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:34,926:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:34,939:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:46:36,951:INFO:Calculating mean and std
2023-08-17 12:46:36,952:INFO:Creating metrics dataframe
2023-08-17 12:46:37,197:INFO:Uploading results into container
2023-08-17 12:46:37,198:INFO:Uploading model into container now
2023-08-17 12:46:37,198:INFO:_master_model_container: 6
2023-08-17 12:46:37,198:INFO:_display_container: 2
2023-08-17 12:46:37,198:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=559, solver='auto',
                tol=0.0001)
2023-08-17 12:46:37,198:INFO:create_model() successfully completed......................................
2023-08-17 12:46:37,335:INFO:SubProcess create_model() end ==================================
2023-08-17 12:46:37,335:INFO:Creating metrics dataframe
2023-08-17 12:46:37,342:INFO:Initializing Random Forest Classifier
2023-08-17 12:46:37,342:INFO:Total runtime is 1.6180483937263486 minutes
2023-08-17 12:46:37,344:INFO:SubProcess create_model() called ==================================
2023-08-17 12:46:37,344:INFO:Initializing create_model()
2023-08-17 12:46:37,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:46:37,344:INFO:Checking exceptions
2023-08-17 12:46:37,344:INFO:Importing libraries
2023-08-17 12:46:37,344:INFO:Copying training dataset
2023-08-17 12:46:37,380:INFO:Defining folds
2023-08-17 12:46:37,380:INFO:Declaring metric variables
2023-08-17 12:46:37,383:INFO:Importing untrained model
2023-08-17 12:46:37,385:INFO:Random Forest Classifier Imported successfully
2023-08-17 12:46:37,389:INFO:Starting cross validation
2023-08-17 12:46:37,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:46:58,006:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 12:46:58,352:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 12:46:58,608:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 12:47:02,919:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-17 12:47:03,247:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-17 12:47:08,167:INFO:Calculating mean and std
2023-08-17 12:47:08,168:INFO:Creating metrics dataframe
2023-08-17 12:47:08,444:INFO:Uploading results into container
2023-08-17 12:47:08,445:INFO:Uploading model into container now
2023-08-17 12:47:08,446:INFO:_master_model_container: 7
2023-08-17 12:47:08,446:INFO:_display_container: 2
2023-08-17 12:47:08,446:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=559, verbose=0, warm_start=False)
2023-08-17 12:47:08,446:INFO:create_model() successfully completed......................................
2023-08-17 12:47:08,593:INFO:SubProcess create_model() end ==================================
2023-08-17 12:47:08,593:INFO:Creating metrics dataframe
2023-08-17 12:47:08,600:INFO:Initializing Quadratic Discriminant Analysis
2023-08-17 12:47:08,600:INFO:Total runtime is 2.139019664128621 minutes
2023-08-17 12:47:08,602:INFO:SubProcess create_model() called ==================================
2023-08-17 12:47:08,603:INFO:Initializing create_model()
2023-08-17 12:47:08,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:47:08,603:INFO:Checking exceptions
2023-08-17 12:47:08,603:INFO:Importing libraries
2023-08-17 12:47:08,603:INFO:Copying training dataset
2023-08-17 12:47:08,640:INFO:Defining folds
2023-08-17 12:47:08,640:INFO:Declaring metric variables
2023-08-17 12:47:08,644:INFO:Importing untrained model
2023-08-17 12:47:08,646:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-17 12:47:08,650:INFO:Starting cross validation
2023-08-17 12:47:08,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:47:11,904:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:11,910:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:11,933:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:11,941:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:12,017:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:12,024:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:12,044:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:12,086:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:12,132:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:12,212:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 12:47:15,076:INFO:Calculating mean and std
2023-08-17 12:47:15,077:INFO:Creating metrics dataframe
2023-08-17 12:47:15,336:INFO:Uploading results into container
2023-08-17 12:47:15,337:INFO:Uploading model into container now
2023-08-17 12:47:15,338:INFO:_master_model_container: 8
2023-08-17 12:47:15,338:INFO:_display_container: 2
2023-08-17 12:47:15,338:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-17 12:47:15,338:INFO:create_model() successfully completed......................................
2023-08-17 12:47:15,482:INFO:SubProcess create_model() end ==================================
2023-08-17 12:47:15,482:INFO:Creating metrics dataframe
2023-08-17 12:47:15,489:INFO:Initializing Ada Boost Classifier
2023-08-17 12:47:15,489:INFO:Total runtime is 2.253822104136149 minutes
2023-08-17 12:47:15,492:INFO:SubProcess create_model() called ==================================
2023-08-17 12:47:15,492:INFO:Initializing create_model()
2023-08-17 12:47:15,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:47:15,492:INFO:Checking exceptions
2023-08-17 12:47:15,492:INFO:Importing libraries
2023-08-17 12:47:15,492:INFO:Copying training dataset
2023-08-17 12:47:15,530:INFO:Defining folds
2023-08-17 12:47:15,530:INFO:Declaring metric variables
2023-08-17 12:47:15,533:INFO:Importing untrained model
2023-08-17 12:47:15,535:INFO:Ada Boost Classifier Imported successfully
2023-08-17 12:47:15,539:INFO:Starting cross validation
2023-08-17 12:47:15,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:47:31,022:INFO:Calculating mean and std
2023-08-17 12:47:31,023:INFO:Creating metrics dataframe
2023-08-17 12:47:31,282:INFO:Uploading results into container
2023-08-17 12:47:31,283:INFO:Uploading model into container now
2023-08-17 12:47:31,283:INFO:_master_model_container: 9
2023-08-17 12:47:31,283:INFO:_display_container: 2
2023-08-17 12:47:31,283:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=559)
2023-08-17 12:47:31,284:INFO:create_model() successfully completed......................................
2023-08-17 12:47:31,426:INFO:SubProcess create_model() end ==================================
2023-08-17 12:47:31,426:INFO:Creating metrics dataframe
2023-08-17 12:47:31,434:INFO:Initializing Gradient Boosting Classifier
2023-08-17 12:47:31,434:INFO:Total runtime is 2.519580364227295 minutes
2023-08-17 12:47:31,437:INFO:SubProcess create_model() called ==================================
2023-08-17 12:47:31,437:INFO:Initializing create_model()
2023-08-17 12:47:31,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:47:31,437:INFO:Checking exceptions
2023-08-17 12:47:31,437:INFO:Importing libraries
2023-08-17 12:47:31,437:INFO:Copying training dataset
2023-08-17 12:47:31,477:INFO:Defining folds
2023-08-17 12:47:31,477:INFO:Declaring metric variables
2023-08-17 12:47:31,480:INFO:Importing untrained model
2023-08-17 12:47:31,482:INFO:Gradient Boosting Classifier Imported successfully
2023-08-17 12:47:31,486:INFO:Starting cross validation
2023-08-17 12:47:31,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:48:07,486:INFO:Calculating mean and std
2023-08-17 12:48:07,487:INFO:Creating metrics dataframe
2023-08-17 12:48:07,750:INFO:Uploading results into container
2023-08-17 12:48:07,751:INFO:Uploading model into container now
2023-08-17 12:48:07,752:INFO:_master_model_container: 10
2023-08-17 12:48:07,752:INFO:_display_container: 2
2023-08-17 12:48:07,754:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=559, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-17 12:48:07,754:INFO:create_model() successfully completed......................................
2023-08-17 12:48:07,901:INFO:SubProcess create_model() end ==================================
2023-08-17 12:48:07,901:INFO:Creating metrics dataframe
2023-08-17 12:48:07,908:INFO:Initializing Linear Discriminant Analysis
2023-08-17 12:48:07,909:INFO:Total runtime is 3.127499485015869 minutes
2023-08-17 12:48:07,911:INFO:SubProcess create_model() called ==================================
2023-08-17 12:48:07,911:INFO:Initializing create_model()
2023-08-17 12:48:07,911:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:48:07,911:INFO:Checking exceptions
2023-08-17 12:48:07,911:INFO:Importing libraries
2023-08-17 12:48:07,911:INFO:Copying training dataset
2023-08-17 12:48:07,951:INFO:Defining folds
2023-08-17 12:48:07,952:INFO:Declaring metric variables
2023-08-17 12:48:07,954:INFO:Importing untrained model
2023-08-17 12:48:07,957:INFO:Linear Discriminant Analysis Imported successfully
2023-08-17 12:48:07,961:INFO:Starting cross validation
2023-08-17 12:48:07,967:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:48:14,163:INFO:Calculating mean and std
2023-08-17 12:48:14,164:INFO:Creating metrics dataframe
2023-08-17 12:48:14,434:INFO:Uploading results into container
2023-08-17 12:48:14,435:INFO:Uploading model into container now
2023-08-17 12:48:14,435:INFO:_master_model_container: 11
2023-08-17 12:48:14,435:INFO:_display_container: 2
2023-08-17 12:48:14,435:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-17 12:48:14,436:INFO:create_model() successfully completed......................................
2023-08-17 12:48:14,574:INFO:SubProcess create_model() end ==================================
2023-08-17 12:48:14,574:INFO:Creating metrics dataframe
2023-08-17 12:48:14,581:INFO:Initializing Extra Trees Classifier
2023-08-17 12:48:14,581:INFO:Total runtime is 3.238689104715983 minutes
2023-08-17 12:48:14,583:INFO:SubProcess create_model() called ==================================
2023-08-17 12:48:14,583:INFO:Initializing create_model()
2023-08-17 12:48:14,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:48:14,583:INFO:Checking exceptions
2023-08-17 12:48:14,584:INFO:Importing libraries
2023-08-17 12:48:14,584:INFO:Copying training dataset
2023-08-17 12:48:14,618:INFO:Defining folds
2023-08-17 12:48:14,618:INFO:Declaring metric variables
2023-08-17 12:48:14,620:INFO:Importing untrained model
2023-08-17 12:48:14,624:INFO:Extra Trees Classifier Imported successfully
2023-08-17 12:48:14,629:INFO:Starting cross validation
2023-08-17 12:48:14,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:48:44,183:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.15s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 12:48:44,389:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.09s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-17 12:48:50,652:INFO:Calculating mean and std
2023-08-17 12:48:50,653:INFO:Creating metrics dataframe
2023-08-17 12:48:50,867:INFO:Uploading results into container
2023-08-17 12:48:50,868:INFO:Uploading model into container now
2023-08-17 12:48:50,868:INFO:_master_model_container: 12
2023-08-17 12:48:50,868:INFO:_display_container: 2
2023-08-17 12:48:50,869:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=559, verbose=0, warm_start=False)
2023-08-17 12:48:50,869:INFO:create_model() successfully completed......................................
2023-08-17 12:48:51,009:INFO:SubProcess create_model() end ==================================
2023-08-17 12:48:51,009:INFO:Creating metrics dataframe
2023-08-17 12:48:51,017:INFO:Initializing Extreme Gradient Boosting
2023-08-17 12:48:51,017:INFO:Total runtime is 3.8459701299667355 minutes
2023-08-17 12:48:51,019:INFO:SubProcess create_model() called ==================================
2023-08-17 12:48:51,020:INFO:Initializing create_model()
2023-08-17 12:48:51,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:48:51,020:INFO:Checking exceptions
2023-08-17 12:48:51,020:INFO:Importing libraries
2023-08-17 12:48:51,020:INFO:Copying training dataset
2023-08-17 12:48:51,059:INFO:Defining folds
2023-08-17 12:48:51,059:INFO:Declaring metric variables
2023-08-17 12:48:51,062:INFO:Importing untrained model
2023-08-17 12:48:51,065:INFO:Extreme Gradient Boosting Imported successfully
2023-08-17 12:48:51,069:INFO:Starting cross validation
2023-08-17 12:48:51,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:49:11,356:INFO:Calculating mean and std
2023-08-17 12:49:11,357:INFO:Creating metrics dataframe
2023-08-17 12:49:11,581:INFO:Uploading results into container
2023-08-17 12:49:11,582:INFO:Uploading model into container now
2023-08-17 12:49:11,582:INFO:_master_model_container: 13
2023-08-17 12:49:11,582:INFO:_display_container: 2
2023-08-17 12:49:11,583:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-17 12:49:11,583:INFO:create_model() successfully completed......................................
2023-08-17 12:49:11,721:INFO:SubProcess create_model() end ==================================
2023-08-17 12:49:11,721:INFO:Creating metrics dataframe
2023-08-17 12:49:11,730:INFO:Initializing Light Gradient Boosting Machine
2023-08-17 12:49:11,730:INFO:Total runtime is 4.191172762711843 minutes
2023-08-17 12:49:11,732:INFO:SubProcess create_model() called ==================================
2023-08-17 12:49:11,733:INFO:Initializing create_model()
2023-08-17 12:49:11,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:49:11,733:INFO:Checking exceptions
2023-08-17 12:49:11,733:INFO:Importing libraries
2023-08-17 12:49:11,733:INFO:Copying training dataset
2023-08-17 12:49:11,763:INFO:Defining folds
2023-08-17 12:49:11,763:INFO:Declaring metric variables
2023-08-17 12:49:11,766:INFO:Importing untrained model
2023-08-17 12:49:11,769:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 12:49:11,773:INFO:Starting cross validation
2023-08-17 12:49:11,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:49:18,783:INFO:Calculating mean and std
2023-08-17 12:49:18,784:INFO:Creating metrics dataframe
2023-08-17 12:49:19,004:INFO:Uploading results into container
2023-08-17 12:49:19,005:INFO:Uploading model into container now
2023-08-17 12:49:19,005:INFO:_master_model_container: 14
2023-08-17 12:49:19,005:INFO:_display_container: 2
2023-08-17 12:49:19,005:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 12:49:19,005:INFO:create_model() successfully completed......................................
2023-08-17 12:49:19,144:INFO:SubProcess create_model() end ==================================
2023-08-17 12:49:19,144:INFO:Creating metrics dataframe
2023-08-17 12:49:19,152:INFO:Initializing CatBoost Classifier
2023-08-17 12:49:19,152:INFO:Total runtime is 4.314881698290507 minutes
2023-08-17 12:49:19,154:INFO:SubProcess create_model() called ==================================
2023-08-17 12:49:19,154:INFO:Initializing create_model()
2023-08-17 12:49:19,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:49:19,155:INFO:Checking exceptions
2023-08-17 12:49:19,155:INFO:Importing libraries
2023-08-17 12:49:19,155:INFO:Copying training dataset
2023-08-17 12:49:19,184:INFO:Defining folds
2023-08-17 12:49:19,184:INFO:Declaring metric variables
2023-08-17 12:49:19,187:INFO:Importing untrained model
2023-08-17 12:49:19,190:INFO:CatBoost Classifier Imported successfully
2023-08-17 12:49:19,197:INFO:Starting cross validation
2023-08-17 12:49:19,203:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:50:45,041:INFO:Calculating mean and std
2023-08-17 12:50:45,042:INFO:Creating metrics dataframe
2023-08-17 12:50:45,270:INFO:Uploading results into container
2023-08-17 12:50:45,271:INFO:Uploading model into container now
2023-08-17 12:50:45,271:INFO:_master_model_container: 15
2023-08-17 12:50:45,271:INFO:_display_container: 2
2023-08-17 12:50:45,272:INFO:<catboost.core.CatBoostClassifier object at 0x000001A7E0B504C0>
2023-08-17 12:50:45,272:INFO:create_model() successfully completed......................................
2023-08-17 12:50:45,415:INFO:SubProcess create_model() end ==================================
2023-08-17 12:50:45,416:INFO:Creating metrics dataframe
2023-08-17 12:50:45,424:INFO:Initializing Dummy Classifier
2023-08-17 12:50:45,424:INFO:Total runtime is 5.7527376731236775 minutes
2023-08-17 12:50:45,426:INFO:SubProcess create_model() called ==================================
2023-08-17 12:50:45,427:INFO:Initializing create_model()
2023-08-17 12:50:45,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E0CC58A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:50:45,427:INFO:Checking exceptions
2023-08-17 12:50:45,427:INFO:Importing libraries
2023-08-17 12:50:45,427:INFO:Copying training dataset
2023-08-17 12:50:45,461:INFO:Defining folds
2023-08-17 12:50:45,462:INFO:Declaring metric variables
2023-08-17 12:50:45,464:INFO:Importing untrained model
2023-08-17 12:50:45,467:INFO:Dummy Classifier Imported successfully
2023-08-17 12:50:45,471:INFO:Starting cross validation
2023-08-17 12:50:45,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 12:50:47,173:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,235:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,249:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,351:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,360:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,377:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,443:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,448:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,450:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:47,460:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-17 12:50:49,256:INFO:Calculating mean and std
2023-08-17 12:50:49,257:INFO:Creating metrics dataframe
2023-08-17 12:50:49,498:INFO:Uploading results into container
2023-08-17 12:50:49,499:INFO:Uploading model into container now
2023-08-17 12:50:49,499:INFO:_master_model_container: 16
2023-08-17 12:50:49,499:INFO:_display_container: 2
2023-08-17 12:50:49,500:INFO:DummyClassifier(constant=None, random_state=559, strategy='prior')
2023-08-17 12:50:49,500:INFO:create_model() successfully completed......................................
2023-08-17 12:50:49,640:INFO:SubProcess create_model() end ==================================
2023-08-17 12:50:49,640:INFO:Creating metrics dataframe
2023-08-17 12:50:49,656:INFO:Initializing create_model()
2023-08-17 12:50:49,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 12:50:49,656:INFO:Checking exceptions
2023-08-17 12:50:49,657:INFO:Importing libraries
2023-08-17 12:50:49,657:INFO:Copying training dataset
2023-08-17 12:50:49,694:INFO:Defining folds
2023-08-17 12:50:49,694:INFO:Declaring metric variables
2023-08-17 12:50:49,694:INFO:Importing untrained model
2023-08-17 12:50:49,694:INFO:Declaring custom model
2023-08-17 12:50:49,695:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 12:50:49,700:INFO:Cross validation set to False
2023-08-17 12:50:49,700:INFO:Fitting Model
2023-08-17 12:51:01,146:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-17 12:51:01,146:INFO:[LightGBM] [Info] Number of positive: 13228, number of negative: 171620
2023-08-17 12:51:01,166:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006467 seconds.
2023-08-17 12:51:01,166:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-17 12:51:01,166:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-17 12:51:01,166:INFO:[LightGBM] [Info] Total Bins 477
2023-08-17 12:51:01,167:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 34
2023-08-17 12:51:01,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.071561 -> initscore=-2.562947
2023-08-17 12:51:01,168:INFO:[LightGBM] [Info] Start training from score -2.562947
2023-08-17 12:51:01,637:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 12:51:01,637:INFO:create_model() successfully completed......................................
2023-08-17 12:51:01,796:INFO:_master_model_container: 16
2023-08-17 12:51:01,796:INFO:_display_container: 2
2023-08-17 12:51:01,797:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 12:51:01,797:INFO:compare_models() successfully completed......................................
2023-08-17 13:02:17,534:INFO:Initializing create_model()
2023-08-17 13:02:17,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 13:02:17,535:INFO:Checking exceptions
2023-08-17 13:02:17,545:INFO:Importing libraries
2023-08-17 13:02:17,545:INFO:Copying training dataset
2023-08-17 13:02:17,583:INFO:Defining folds
2023-08-17 13:02:17,583:INFO:Declaring metric variables
2023-08-17 13:02:17,585:INFO:Importing untrained model
2023-08-17 13:02:17,587:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 13:02:17,591:INFO:Starting cross validation
2023-08-17 13:02:17,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 13:02:24,716:INFO:Calculating mean and std
2023-08-17 13:02:24,717:INFO:Creating metrics dataframe
2023-08-17 13:02:24,721:INFO:Finalizing model
2023-08-17 13:02:26,791:INFO:Uploading results into container
2023-08-17 13:02:26,792:INFO:Uploading model into container now
2023-08-17 13:02:26,798:INFO:_master_model_container: 17
2023-08-17 13:02:26,799:INFO:_display_container: 3
2023-08-17 13:02:26,799:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 13:02:26,799:INFO:create_model() successfully completed......................................
2023-08-17 13:02:26,967:INFO:Initializing create_model()
2023-08-17 13:02:26,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 13:02:26,967:INFO:Checking exceptions
2023-08-17 13:02:26,976:INFO:Importing libraries
2023-08-17 13:02:26,976:INFO:Copying training dataset
2023-08-17 13:02:27,020:INFO:Defining folds
2023-08-17 13:02:27,020:INFO:Declaring metric variables
2023-08-17 13:02:27,022:INFO:Importing untrained model
2023-08-17 13:02:27,024:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-17 13:02:27,028:INFO:Starting cross validation
2023-08-17 13:02:27,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 13:02:33,702:INFO:Calculating mean and std
2023-08-17 13:02:33,703:INFO:Creating metrics dataframe
2023-08-17 13:02:33,707:INFO:Finalizing model
2023-08-17 13:02:34,732:INFO:Uploading results into container
2023-08-17 13:02:34,733:INFO:Uploading model into container now
2023-08-17 13:02:34,740:INFO:_master_model_container: 18
2023-08-17 13:02:34,740:INFO:_display_container: 4
2023-08-17 13:02:34,740:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-17 13:02:34,740:INFO:create_model() successfully completed......................................
2023-08-17 13:02:34,913:INFO:Initializing create_model()
2023-08-17 13:02:34,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 13:02:34,913:INFO:Checking exceptions
2023-08-17 13:02:34,922:INFO:Importing libraries
2023-08-17 13:02:34,922:INFO:Copying training dataset
2023-08-17 13:02:34,968:INFO:Defining folds
2023-08-17 13:02:34,968:INFO:Declaring metric variables
2023-08-17 13:02:34,971:INFO:Importing untrained model
2023-08-17 13:02:34,975:INFO:Naive Bayes Imported successfully
2023-08-17 13:02:34,980:INFO:Starting cross validation
2023-08-17 13:02:34,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 13:02:39,344:INFO:Calculating mean and std
2023-08-17 13:02:39,345:INFO:Creating metrics dataframe
2023-08-17 13:02:39,349:INFO:Finalizing model
2023-08-17 13:02:40,216:INFO:Uploading results into container
2023-08-17 13:02:40,216:INFO:Uploading model into container now
2023-08-17 13:02:40,223:INFO:_master_model_container: 19
2023-08-17 13:02:40,223:INFO:_display_container: 5
2023-08-17 13:02:40,223:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-17 13:02:40,223:INFO:create_model() successfully completed......................................
2023-08-17 13:02:40,372:INFO:Initializing blend_models()
2023-08-17 13:02:40,372:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-17 13:02:40,372:INFO:Checking exceptions
2023-08-17 13:02:40,391:INFO:Importing libraries
2023-08-17 13:02:40,391:INFO:Copying training dataset
2023-08-17 13:02:40,394:INFO:Getting model names
2023-08-17 13:02:40,396:INFO:SubProcess create_model() called ==================================
2023-08-17 13:02:40,398:INFO:Initializing create_model()
2023-08-17 13:02:40,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E09F9BD0>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 13:02:40,398:INFO:Checking exceptions
2023-08-17 13:02:40,398:INFO:Importing libraries
2023-08-17 13:02:40,398:INFO:Copying training dataset
2023-08-17 13:02:40,450:INFO:Defining folds
2023-08-17 13:02:40,450:INFO:Declaring metric variables
2023-08-17 13:02:40,453:INFO:Importing untrained model
2023-08-17 13:02:40,453:INFO:Declaring custom model
2023-08-17 13:02:40,457:INFO:Voting Classifier Imported successfully
2023-08-17 13:02:40,463:INFO:Starting cross validation
2023-08-17 13:02:40,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 13:02:43,567:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:43,573:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:43,690:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:44,363:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:44,548:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:44,584:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:44,606:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:44,736:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:44,749:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:44,897:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:50,410:INFO:Calculating mean and std
2023-08-17 13:02:50,411:INFO:Creating metrics dataframe
2023-08-17 13:02:50,415:INFO:Finalizing model
2023-08-17 13:02:51,490:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 13:02:51,973:INFO:Uploading results into container
2023-08-17 13:02:51,974:INFO:Uploading model into container now
2023-08-17 13:02:51,974:INFO:_master_model_container: 20
2023-08-17 13:02:51,974:INFO:_display_container: 6
2023-08-17 13:02:51,976:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-17 13:02:51,976:INFO:create_model() successfully completed......................................
2023-08-17 13:02:52,112:INFO:SubProcess create_model() end ==================================
2023-08-17 13:02:52,118:INFO:_master_model_container: 20
2023-08-17 13:02:52,118:INFO:_display_container: 6
2023-08-17 13:02:52,120:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-17 13:02:52,120:INFO:blend_models() successfully completed......................................
2023-08-17 13:07:31,980:INFO:Initializing evaluate_model()
2023-08-17 13:07:31,981:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-17 13:07:32,004:INFO:Initializing plot_model()
2023-08-17 13:07:32,004:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:07:32,004:INFO:Checking exceptions
2023-08-17 13:07:32,014:INFO:Preloading libraries
2023-08-17 13:07:32,018:INFO:Copying training dataset
2023-08-17 13:07:32,018:INFO:Plot type: pipeline
2023-08-17 13:07:32,228:INFO:Visual Rendered Successfully
2023-08-17 13:07:32,384:INFO:plot_model() successfully completed......................................
2023-08-17 13:07:42,612:INFO:Initializing plot_model()
2023-08-17 13:07:42,612:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:07:42,612:INFO:Checking exceptions
2023-08-17 13:07:42,623:INFO:Preloading libraries
2023-08-17 13:07:42,627:INFO:Copying training dataset
2023-08-17 13:07:42,627:INFO:Plot type: pr
2023-08-17 13:07:53,617:INFO:Fitting Model
2023-08-17 13:07:53,621:INFO:Scoring test/hold-out set
2023-08-17 13:07:54,120:INFO:Visual Rendered Successfully
2023-08-17 13:07:54,294:INFO:plot_model() successfully completed......................................
2023-08-17 13:09:02,808:INFO:Initializing plot_model()
2023-08-17 13:09:02,809:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:09:02,809:INFO:Checking exceptions
2023-08-17 13:09:02,820:INFO:Preloading libraries
2023-08-17 13:09:02,824:INFO:Copying training dataset
2023-08-17 13:09:02,824:INFO:Plot type: pipeline
2023-08-17 13:09:03,011:INFO:Visual Rendered Successfully
2023-08-17 13:09:03,165:INFO:plot_model() successfully completed......................................
2023-08-17 13:09:07,453:INFO:Initializing plot_model()
2023-08-17 13:09:07,454:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:09:07,454:INFO:Checking exceptions
2023-08-17 13:09:07,464:INFO:Preloading libraries
2023-08-17 13:09:07,468:INFO:Copying training dataset
2023-08-17 13:09:07,469:INFO:Plot type: parameter
2023-08-17 13:09:07,472:INFO:Visual Rendered Successfully
2023-08-17 13:09:07,629:INFO:plot_model() successfully completed......................................
2023-08-17 13:09:12,747:INFO:Initializing plot_model()
2023-08-17 13:09:12,747:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:09:12,748:INFO:Checking exceptions
2023-08-17 13:09:12,758:INFO:Preloading libraries
2023-08-17 13:09:12,762:INFO:Copying training dataset
2023-08-17 13:09:12,762:INFO:Plot type: auc
2023-08-17 13:09:13,096:INFO:Fitting Model
2023-08-17 13:09:13,099:INFO:Scoring test/hold-out set
2023-08-17 13:09:13,611:INFO:Visual Rendered Successfully
2023-08-17 13:09:13,784:INFO:plot_model() successfully completed......................................
2023-08-17 13:09:43,572:INFO:Initializing plot_model()
2023-08-17 13:09:43,573:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:09:43,573:INFO:Checking exceptions
2023-08-17 13:09:43,584:INFO:Preloading libraries
2023-08-17 13:09:43,587:INFO:Copying training dataset
2023-08-17 13:09:43,588:INFO:Plot type: confusion_matrix
2023-08-17 13:09:43,921:INFO:Fitting Model
2023-08-17 13:09:43,922:INFO:Scoring test/hold-out set
2023-08-17 13:09:44,280:INFO:Visual Rendered Successfully
2023-08-17 13:09:44,425:INFO:plot_model() successfully completed......................................
2023-08-17 13:10:14,576:INFO:Initializing plot_model()
2023-08-17 13:10:14,576:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:10:14,576:INFO:Checking exceptions
2023-08-17 13:10:14,586:INFO:Preloading libraries
2023-08-17 13:10:14,590:INFO:Copying training dataset
2023-08-17 13:10:14,590:INFO:Plot type: threshold
2023-08-17 13:10:14,939:INFO:Fitting Model
2023-08-17 13:11:31,793:INFO:Scoring test/hold-out set
2023-08-17 13:11:32,330:INFO:Visual Rendered Successfully
2023-08-17 13:11:32,485:INFO:plot_model() successfully completed......................................
2023-08-17 13:12:40,745:INFO:Initializing plot_model()
2023-08-17 13:12:40,745:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:12:40,745:INFO:Checking exceptions
2023-08-17 13:13:27,194:INFO:Initializing plot_model()
2023-08-17 13:13:27,194:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:13:27,195:INFO:Checking exceptions
2023-08-17 13:13:27,206:INFO:Preloading libraries
2023-08-17 13:13:27,211:INFO:Copying training dataset
2023-08-17 13:13:27,211:INFO:Plot type: error
2023-08-17 13:13:27,574:INFO:Fitting Model
2023-08-17 13:13:27,575:INFO:Scoring test/hold-out set
2023-08-17 13:13:28,026:INFO:Visual Rendered Successfully
2023-08-17 13:13:28,204:INFO:plot_model() successfully completed......................................
2023-08-17 13:13:42,349:INFO:Initializing plot_model()
2023-08-17 13:13:42,349:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:13:42,349:INFO:Checking exceptions
2023-08-17 13:14:28,125:INFO:Initializing plot_model()
2023-08-17 13:14:28,126:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:14:28,126:INFO:Checking exceptions
2023-08-17 13:14:28,140:INFO:Preloading libraries
2023-08-17 13:14:28,143:INFO:Copying training dataset
2023-08-17 13:14:28,143:INFO:Plot type: class_report
2023-08-17 13:14:28,514:INFO:Fitting Model
2023-08-17 13:14:28,516:INFO:Scoring test/hold-out set
2023-08-17 13:14:28,963:INFO:Visual Rendered Successfully
2023-08-17 13:14:29,115:INFO:plot_model() successfully completed......................................
2023-08-17 13:15:09,195:INFO:Initializing plot_model()
2023-08-17 13:15:09,195:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:15:09,195:INFO:Checking exceptions
2023-08-17 13:15:11,830:INFO:Initializing plot_model()
2023-08-17 13:15:11,831:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:15:11,831:INFO:Checking exceptions
2023-08-17 13:15:11,843:INFO:Preloading libraries
2023-08-17 13:15:11,847:INFO:Copying training dataset
2023-08-17 13:15:11,847:INFO:Plot type: learning
2023-08-17 13:15:12,193:INFO:Fitting Model
2023-08-17 13:15:58,540:INFO:Visual Rendered Successfully
2023-08-17 13:15:58,719:INFO:plot_model() successfully completed......................................
2023-08-17 13:16:17,119:INFO:Initializing plot_model()
2023-08-17 13:16:17,119:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:16:17,119:INFO:Checking exceptions
2023-08-17 13:16:17,130:INFO:Preloading libraries
2023-08-17 13:16:17,134:INFO:Copying training dataset
2023-08-17 13:16:17,134:INFO:Plot type: manifold
2023-08-17 13:16:17,520:INFO:Fitting & Transforming Model
2023-08-17 13:22:57,617:INFO:Visual Rendered Successfully
2023-08-17 13:22:57,803:INFO:plot_model() successfully completed......................................
2023-08-17 13:23:37,140:INFO:Initializing plot_model()
2023-08-17 13:23:37,140:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:23:37,140:INFO:Checking exceptions
2023-08-17 13:23:37,152:INFO:Preloading libraries
2023-08-17 13:23:37,156:INFO:Copying training dataset
2023-08-17 13:23:37,157:INFO:Plot type: calibration
2023-08-17 13:23:37,167:INFO:Scoring test/hold-out set
2023-08-17 13:23:37,603:INFO:Visual Rendered Successfully
2023-08-17 13:23:37,742:INFO:plot_model() successfully completed......................................
2023-08-17 13:24:08,864:INFO:Initializing plot_model()
2023-08-17 13:24:08,864:INFO:plot_model(plot=vc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:24:08,864:INFO:Checking exceptions
2023-08-17 13:24:08,876:INFO:Preloading libraries
2023-08-17 13:24:08,879:INFO:Copying training dataset
2023-08-17 13:24:08,879:INFO:Plot type: vc
2023-08-17 13:24:08,880:INFO:Determining param_name
2023-08-17 13:24:10,397:INFO:Initializing plot_model()
2023-08-17 13:24:10,397:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:24:10,397:INFO:Checking exceptions
2023-08-17 13:24:10,410:INFO:Preloading libraries
2023-08-17 13:24:10,414:INFO:Copying training dataset
2023-08-17 13:24:10,414:INFO:Plot type: dimension
2023-08-17 13:24:10,546:INFO:Fitting StandardScaler()
2023-08-17 13:24:10,703:INFO:Fitting PCA()
2023-08-17 13:24:11,333:INFO:Fitting & Transforming Model
2023-08-17 13:24:14,072:INFO:Visual Rendered Successfully
2023-08-17 13:24:14,215:INFO:plot_model() successfully completed......................................
2023-08-17 13:24:56,006:INFO:Initializing plot_model()
2023-08-17 13:24:56,006:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:24:56,006:INFO:Checking exceptions
2023-08-17 13:24:57,920:INFO:Initializing plot_model()
2023-08-17 13:24:57,920:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:24:57,920:INFO:Checking exceptions
2023-08-17 13:25:01,217:INFO:Initializing plot_model()
2023-08-17 13:25:01,217:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:25:01,217:INFO:Checking exceptions
2023-08-17 13:25:01,228:INFO:Preloading libraries
2023-08-17 13:25:01,232:INFO:Copying training dataset
2023-08-17 13:25:01,232:INFO:Plot type: boundary
2023-08-17 13:25:01,433:INFO:Fitting StandardScaler()
2023-08-17 13:25:01,513:INFO:Fitting PCA()
2023-08-17 13:25:02,185:INFO:Fitting Model
2023-08-17 13:25:06,094:INFO:Visual Rendered Successfully
2023-08-17 13:25:06,290:INFO:plot_model() successfully completed......................................
2023-08-17 13:25:55,074:INFO:Initializing plot_model()
2023-08-17 13:25:55,074:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:25:55,075:INFO:Checking exceptions
2023-08-17 13:25:59,132:INFO:Initializing plot_model()
2023-08-17 13:25:59,132:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:25:59,132:INFO:Checking exceptions
2023-08-17 13:25:59,162:INFO:Preloading libraries
2023-08-17 13:25:59,168:INFO:Copying training dataset
2023-08-17 13:25:59,168:INFO:Plot type: dimension
2023-08-17 13:25:59,302:INFO:Fitting StandardScaler()
2023-08-17 13:25:59,463:INFO:Fitting PCA()
2023-08-17 13:26:00,100:INFO:Fitting & Transforming Model
2023-08-17 13:26:02,753:INFO:Visual Rendered Successfully
2023-08-17 13:26:02,897:INFO:plot_model() successfully completed......................................
2023-08-17 13:26:03,544:INFO:Initializing plot_model()
2023-08-17 13:26:03,544:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:26:03,544:INFO:Checking exceptions
2023-08-17 13:26:04,800:INFO:Initializing plot_model()
2023-08-17 13:26:04,800:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:26:04,800:INFO:Checking exceptions
2023-08-17 13:26:04,812:INFO:Preloading libraries
2023-08-17 13:26:04,815:INFO:Copying training dataset
2023-08-17 13:26:04,815:INFO:Plot type: lift
2023-08-17 13:26:04,816:INFO:Generating predictions / predict_proba on X_test
2023-08-17 13:26:05,266:INFO:Visual Rendered Successfully
2023-08-17 13:26:05,419:INFO:plot_model() successfully completed......................................
2023-08-17 13:26:29,258:INFO:Initializing plot_model()
2023-08-17 13:26:29,258:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:26:29,258:INFO:Checking exceptions
2023-08-17 13:26:29,269:INFO:Preloading libraries
2023-08-17 13:26:29,272:INFO:Copying training dataset
2023-08-17 13:26:29,272:INFO:Plot type: gain
2023-08-17 13:26:29,273:INFO:Generating predictions / predict_proba on X_test
2023-08-17 13:26:29,707:INFO:Visual Rendered Successfully
2023-08-17 13:26:29,849:INFO:plot_model() successfully completed......................................
2023-08-17 13:26:52,746:INFO:Initializing plot_model()
2023-08-17 13:26:52,746:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:26:52,746:INFO:Checking exceptions
2023-08-17 13:26:53,997:INFO:Initializing plot_model()
2023-08-17 13:26:53,997:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:26:53,997:INFO:Checking exceptions
2023-08-17 13:26:54,009:INFO:Preloading libraries
2023-08-17 13:26:54,013:INFO:Copying training dataset
2023-08-17 13:26:54,013:INFO:Plot type: ks
2023-08-17 13:26:54,014:INFO:Generating predictions / predict_proba on X_test
2023-08-17 13:26:54,840:INFO:Visual Rendered Successfully
2023-08-17 13:26:54,992:INFO:plot_model() successfully completed......................................
2023-08-17 13:27:25,983:INFO:Initializing plot_model()
2023-08-17 13:27:25,983:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 13:27:25,983:INFO:Checking exceptions
2023-08-17 13:27:25,995:INFO:Preloading libraries
2023-08-17 13:27:25,999:INFO:Copying training dataset
2023-08-17 13:27:25,999:INFO:Plot type: confusion_matrix
2023-08-17 13:27:26,375:INFO:Fitting Model
2023-08-17 13:27:26,377:INFO:Scoring test/hold-out set
2023-08-17 13:27:26,744:INFO:Visual Rendered Successfully
2023-08-17 13:27:26,892:INFO:plot_model() successfully completed......................................
2023-08-17 14:07:04,112:INFO:Initializing tune_model()
2023-08-17 14:07:04,112:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>)
2023-08-17 14:07:04,112:INFO:Checking exceptions
2023-08-17 14:07:04,137:INFO:Copying training dataset
2023-08-17 14:07:04,163:INFO:Checking base model
2023-08-17 14:07:04,163:INFO:Base model : Light Gradient Boosting Machine
2023-08-17 14:07:04,166:INFO:Declaring metric variables
2023-08-17 14:07:04,168:INFO:Defining Hyperparameters
2023-08-17 14:07:04,346:INFO:Tuning with n_jobs=-1
2023-08-17 14:07:04,346:INFO:Initializing RandomizedSearchCV
2023-08-17 14:08:51,145:INFO:best_params: {'actual_estimator__reg_lambda': 1e-06, 'actual_estimator__reg_alpha': 0.05, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.3, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 3, 'actual_estimator__bagging_fraction': 0.7}
2023-08-17 14:08:51,145:INFO:Hyperparameter search completed
2023-08-17 14:08:51,146:INFO:SubProcess create_model() called ==================================
2023-08-17 14:08:51,146:INFO:Initializing create_model()
2023-08-17 14:08:51,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805394820>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 1e-06, 'reg_alpha': 0.05, 'num_leaves': 90, 'n_estimators': 230, 'min_split_gain': 0.9, 'min_child_samples': 61, 'learning_rate': 0.3, 'feature_fraction': 0.8, 'bagging_freq': 3, 'bagging_fraction': 0.7})
2023-08-17 14:08:51,146:INFO:Checking exceptions
2023-08-17 14:08:51,146:INFO:Importing libraries
2023-08-17 14:08:51,147:INFO:Copying training dataset
2023-08-17 14:08:51,177:INFO:Defining folds
2023-08-17 14:08:51,177:INFO:Declaring metric variables
2023-08-17 14:08:51,179:INFO:Importing untrained model
2023-08-17 14:08:51,179:INFO:Declaring custom model
2023-08-17 14:08:51,182:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 14:08:51,185:INFO:Starting cross validation
2023-08-17 14:08:51,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 14:08:55,685:INFO:Calculating mean and std
2023-08-17 14:08:55,686:INFO:Creating metrics dataframe
2023-08-17 14:08:55,690:INFO:Finalizing model
2023-08-17 14:08:56,270:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:08:56,270:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:08:56,270:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:08:56,401:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-17 14:08:56,401:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:08:56,401:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:08:56,401:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:08:56,401:INFO:[LightGBM] [Info] Number of positive: 13228, number of negative: 171620
2023-08-17 14:08:56,419:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005866 seconds.
2023-08-17 14:08:56,419:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-17 14:08:56,420:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-17 14:08:56,420:INFO:[LightGBM] [Info] Total Bins 477
2023-08-17 14:08:56,420:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 34
2023-08-17 14:08:56,421:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.071561 -> initscore=-2.562947
2023-08-17 14:08:56,421:INFO:[LightGBM] [Info] Start training from score -2.562947
2023-08-17 14:08:56,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,736:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,737:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,738:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,739:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,740:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,741:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,742:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,743:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,744:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,745:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,746:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,747:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,748:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,761:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,762:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,763:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,764:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,765:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,766:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,767:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,768:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,769:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,782:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,783:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,784:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,785:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,786:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,787:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,788:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,789:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,790:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,791:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,804:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,805:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,806:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,807:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,808:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,809:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,811:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,812:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,813:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,826:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,827:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,828:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,829:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,830:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,831:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,832:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,833:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,837:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,838:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,839:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,841:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,842:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,843:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,844:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,845:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,846:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,847:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,848:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,849:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,850:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,851:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,852:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,853:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,854:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,855:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,856:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,857:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,858:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,859:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,860:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,861:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,862:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,863:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,864:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,865:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,866:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,867:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,868:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,869:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,870:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,871:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:56,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-17 14:08:56,872:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-17 14:08:57,166:INFO:Uploading results into container
2023-08-17 14:08:57,167:INFO:Uploading model into container now
2023-08-17 14:08:57,168:INFO:_master_model_container: 21
2023-08-17 14:08:57,168:INFO:_display_container: 7
2023-08-17 14:08:57,168:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=230, n_jobs=-1, num_leaves=90, objective=None,
               random_state=559, reg_alpha=0.05, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-17 14:08:57,168:INFO:create_model() successfully completed......................................
2023-08-17 14:08:57,319:INFO:SubProcess create_model() end ==================================
2023-08-17 14:08:57,320:INFO:choose_better activated
2023-08-17 14:08:57,322:INFO:SubProcess create_model() called ==================================
2023-08-17 14:08:57,322:INFO:Initializing create_model()
2023-08-17 14:08:57,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 14:08:57,323:INFO:Checking exceptions
2023-08-17 14:08:57,323:INFO:Importing libraries
2023-08-17 14:08:57,323:INFO:Copying training dataset
2023-08-17 14:08:57,353:INFO:Defining folds
2023-08-17 14:08:57,353:INFO:Declaring metric variables
2023-08-17 14:08:57,353:INFO:Importing untrained model
2023-08-17 14:08:57,353:INFO:Declaring custom model
2023-08-17 14:08:57,354:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-17 14:08:57,354:INFO:Starting cross validation
2023-08-17 14:08:57,360:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 14:09:01,219:INFO:Calculating mean and std
2023-08-17 14:09:01,220:INFO:Creating metrics dataframe
2023-08-17 14:09:01,221:INFO:Finalizing model
2023-08-17 14:09:02,027:INFO:Uploading results into container
2023-08-17 14:09:02,027:INFO:Uploading model into container now
2023-08-17 14:09:02,028:INFO:_master_model_container: 22
2023-08-17 14:09:02,028:INFO:_display_container: 8
2023-08-17 14:09:02,028:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-17 14:09:02,028:INFO:create_model() successfully completed......................................
2023-08-17 14:09:02,165:INFO:SubProcess create_model() end ==================================
2023-08-17 14:09:02,165:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=559, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.0291
2023-08-17 14:09:02,165:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=230, n_jobs=-1, num_leaves=90, objective=None,
               random_state=559, reg_alpha=0.05, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Recall is 0.0727
2023-08-17 14:09:02,166:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=230, n_jobs=-1, num_leaves=90, objective=None,
               random_state=559, reg_alpha=0.05, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-17 14:09:02,166:INFO:choose_better completed
2023-08-17 14:09:02,172:INFO:_master_model_container: 22
2023-08-17 14:09:02,172:INFO:_display_container: 7
2023-08-17 14:09:02,172:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=230, n_jobs=-1, num_leaves=90, objective=None,
               random_state=559, reg_alpha=0.05, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-17 14:09:02,172:INFO:tune_model() successfully completed......................................
2023-08-17 14:09:02,542:INFO:Initializing tune_model()
2023-08-17 14:09:02,542:INFO:tune_model(estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>)
2023-08-17 14:09:02,542:INFO:Checking exceptions
2023-08-17 14:09:02,562:INFO:Copying training dataset
2023-08-17 14:09:02,587:INFO:Checking base model
2023-08-17 14:09:02,588:INFO:Base model : Quadratic Discriminant Analysis
2023-08-17 14:09:02,590:INFO:Declaring metric variables
2023-08-17 14:09:02,592:INFO:Defining Hyperparameters
2023-08-17 14:09:02,740:INFO:Tuning with n_jobs=-1
2023-08-17 14:09:02,740:INFO:Initializing RandomizedSearchCV
2023-08-17 14:09:07,517:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:07,908:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:08,059:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:08,297:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:08,693:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:08,784:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:08,784:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:08,871:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:08,874:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,022:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,094:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,101:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,214:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,376:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,422:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,472:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,505:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,515:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,786:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:09,818:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:14,635:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:14,774:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:15,090:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:15,418:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:15,580:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,035:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,134:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,169:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,199:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,392:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,496:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,696:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,949:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:16,973:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:17,032:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:17,043:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:17,086:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:17,135:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:17,168:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:17,184:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:19,518:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:19,767:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:20,229:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:20,414:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:20,486:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:20,754:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:20,763:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:21,262:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:21,600:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:21,930:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:22,284:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:22,609:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:22,898:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:23,258:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:23,668:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:24,193:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:24,660:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:25,022:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:25,398:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:25,690:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:26,219:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:26,473:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:26,950:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:27,304:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:27,719:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:28,008:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:28,296:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:28,774:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:29,111:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:29,385:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:29,936:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:30,236:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:30,564:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:30,999:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:31,316:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:31,674:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:32,070:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:32,475:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:32,906:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:33,282:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:33,795:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:34,119:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:34,471:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:34,897:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:35,248:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:35,596:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:35,943:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:36,311:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:36,680:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:37,063:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:37,437:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:37,807:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:38,131:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:38,382:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:39,020:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:39,310:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:39,745:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:40,187:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:40,485:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:40,785:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:09:50,031:INFO:best_params: {'actual_estimator__reg_param': 0.03}
2023-08-17 14:09:50,032:INFO:Hyperparameter search completed
2023-08-17 14:09:50,032:INFO:SubProcess create_model() called ==================================
2023-08-17 14:09:50,032:INFO:Initializing create_model()
2023-08-17 14:09:50,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A805395690>, model_only=True, return_train_score=False, kwargs={'reg_param': 0.03})
2023-08-17 14:09:50,033:INFO:Checking exceptions
2023-08-17 14:09:50,033:INFO:Importing libraries
2023-08-17 14:09:50,033:INFO:Copying training dataset
2023-08-17 14:09:50,063:INFO:Defining folds
2023-08-17 14:09:50,063:INFO:Declaring metric variables
2023-08-17 14:09:50,065:INFO:Importing untrained model
2023-08-17 14:09:50,065:INFO:Declaring custom model
2023-08-17 14:09:50,068:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-17 14:09:50,072:INFO:Starting cross validation
2023-08-17 14:09:50,078:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 14:09:54,467:INFO:Calculating mean and std
2023-08-17 14:09:54,468:INFO:Creating metrics dataframe
2023-08-17 14:09:54,472:INFO:Finalizing model
2023-08-17 14:09:55,569:INFO:Uploading results into container
2023-08-17 14:09:55,570:INFO:Uploading model into container now
2023-08-17 14:09:55,570:INFO:_master_model_container: 23
2023-08-17 14:09:55,570:INFO:_display_container: 8
2023-08-17 14:09:55,571:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.03,
                              store_covariance=False, tol=0.0001)
2023-08-17 14:09:55,571:INFO:create_model() successfully completed......................................
2023-08-17 14:09:55,779:INFO:SubProcess create_model() end ==================================
2023-08-17 14:09:55,779:INFO:choose_better activated
2023-08-17 14:09:55,782:INFO:SubProcess create_model() called ==================================
2023-08-17 14:09:55,783:INFO:Initializing create_model()
2023-08-17 14:09:55,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 14:09:55,783:INFO:Checking exceptions
2023-08-17 14:09:55,785:INFO:Importing libraries
2023-08-17 14:09:55,785:INFO:Copying training dataset
2023-08-17 14:09:55,820:INFO:Defining folds
2023-08-17 14:09:55,820:INFO:Declaring metric variables
2023-08-17 14:09:55,820:INFO:Importing untrained model
2023-08-17 14:09:55,820:INFO:Declaring custom model
2023-08-17 14:09:55,820:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-17 14:09:55,820:INFO:Starting cross validation
2023-08-17 14:09:55,826:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 14:09:59,922:INFO:Calculating mean and std
2023-08-17 14:09:59,923:INFO:Creating metrics dataframe
2023-08-17 14:09:59,924:INFO:Finalizing model
2023-08-17 14:10:00,801:INFO:Uploading results into container
2023-08-17 14:10:00,802:INFO:Uploading model into container now
2023-08-17 14:10:00,802:INFO:_master_model_container: 24
2023-08-17 14:10:00,802:INFO:_display_container: 9
2023-08-17 14:10:00,803:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-17 14:10:00,803:INFO:create_model() successfully completed......................................
2023-08-17 14:10:00,946:INFO:SubProcess create_model() end ==================================
2023-08-17 14:10:00,947:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) result for Recall is 0.9251
2023-08-17 14:10:00,947:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.03,
                              store_covariance=False, tol=0.0001) result for Recall is 0.8484
2023-08-17 14:10:00,947:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001) is best model
2023-08-17 14:10:00,947:INFO:choose_better completed
2023-08-17 14:10:00,947:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-17 14:10:00,954:INFO:_master_model_container: 24
2023-08-17 14:10:00,954:INFO:_display_container: 8
2023-08-17 14:10:00,955:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-17 14:10:00,955:INFO:tune_model() successfully completed......................................
2023-08-17 14:10:01,353:INFO:Initializing tune_model()
2023-08-17 14:10:01,353:INFO:tune_model(estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>)
2023-08-17 14:10:01,353:INFO:Checking exceptions
2023-08-17 14:10:01,373:INFO:Copying training dataset
2023-08-17 14:10:01,400:INFO:Checking base model
2023-08-17 14:10:01,400:INFO:Base model : Naive Bayes
2023-08-17 14:10:01,403:INFO:Declaring metric variables
2023-08-17 14:10:01,406:INFO:Defining Hyperparameters
2023-08-17 14:10:01,557:INFO:Tuning with n_jobs=-1
2023-08-17 14:10:01,557:INFO:Initializing RandomizedSearchCV
2023-08-17 14:10:37,954:INFO:best_params: {'actual_estimator__var_smoothing': 2e-09}
2023-08-17 14:10:37,954:INFO:Hyperparameter search completed
2023-08-17 14:10:37,955:INFO:SubProcess create_model() called ==================================
2023-08-17 14:10:37,955:INFO:Initializing create_model()
2023-08-17 14:10:37,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7E24AA290>, model_only=True, return_train_score=False, kwargs={'var_smoothing': 2e-09})
2023-08-17 14:10:37,955:INFO:Checking exceptions
2023-08-17 14:10:37,955:INFO:Importing libraries
2023-08-17 14:10:37,955:INFO:Copying training dataset
2023-08-17 14:10:37,986:INFO:Defining folds
2023-08-17 14:10:37,986:INFO:Declaring metric variables
2023-08-17 14:10:37,988:INFO:Importing untrained model
2023-08-17 14:10:37,988:INFO:Declaring custom model
2023-08-17 14:10:37,990:INFO:Naive Bayes Imported successfully
2023-08-17 14:10:37,994:INFO:Starting cross validation
2023-08-17 14:10:38,001:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 14:10:42,526:INFO:Calculating mean and std
2023-08-17 14:10:42,527:INFO:Creating metrics dataframe
2023-08-17 14:10:42,530:INFO:Finalizing model
2023-08-17 14:10:43,443:INFO:Uploading results into container
2023-08-17 14:10:43,444:INFO:Uploading model into container now
2023-08-17 14:10:43,444:INFO:_master_model_container: 25
2023-08-17 14:10:43,444:INFO:_display_container: 9
2023-08-17 14:10:43,444:INFO:GaussianNB(priors=None, var_smoothing=2e-09)
2023-08-17 14:10:43,444:INFO:create_model() successfully completed......................................
2023-08-17 14:10:43,625:INFO:SubProcess create_model() end ==================================
2023-08-17 14:10:43,625:INFO:choose_better activated
2023-08-17 14:10:43,627:INFO:SubProcess create_model() called ==================================
2023-08-17 14:10:43,627:INFO:Initializing create_model()
2023-08-17 14:10:43,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-17 14:10:43,628:INFO:Checking exceptions
2023-08-17 14:10:43,629:INFO:Importing libraries
2023-08-17 14:10:43,629:INFO:Copying training dataset
2023-08-17 14:10:43,667:INFO:Defining folds
2023-08-17 14:10:43,667:INFO:Declaring metric variables
2023-08-17 14:10:43,668:INFO:Importing untrained model
2023-08-17 14:10:43,668:INFO:Declaring custom model
2023-08-17 14:10:43,668:INFO:Naive Bayes Imported successfully
2023-08-17 14:10:43,668:INFO:Starting cross validation
2023-08-17 14:10:43,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 14:10:47,942:INFO:Calculating mean and std
2023-08-17 14:10:47,942:INFO:Creating metrics dataframe
2023-08-17 14:10:47,944:INFO:Finalizing model
2023-08-17 14:10:48,914:INFO:Uploading results into container
2023-08-17 14:10:48,915:INFO:Uploading model into container now
2023-08-17 14:10:48,915:INFO:_master_model_container: 26
2023-08-17 14:10:48,915:INFO:_display_container: 10
2023-08-17 14:10:48,915:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-17 14:10:48,915:INFO:create_model() successfully completed......................................
2023-08-17 14:10:49,060:INFO:SubProcess create_model() end ==================================
2023-08-17 14:10:49,061:INFO:GaussianNB(priors=None, var_smoothing=1e-09) result for Recall is 0.8458
2023-08-17 14:10:49,061:INFO:GaussianNB(priors=None, var_smoothing=2e-09) result for Recall is 0.8458
2023-08-17 14:10:49,061:INFO:GaussianNB(priors=None, var_smoothing=1e-09) is best model
2023-08-17 14:10:49,061:INFO:choose_better completed
2023-08-17 14:10:49,061:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-17 14:10:49,067:INFO:_master_model_container: 26
2023-08-17 14:10:49,067:INFO:_display_container: 9
2023-08-17 14:10:49,067:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-17 14:10:49,067:INFO:tune_model() successfully completed......................................
2023-08-17 14:10:49,495:INFO:Initializing blend_models()
2023-08-17 14:10:49,495:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator_list=[LGBMClassifier(bagging_fraction=0.7, bagging_freq=3, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.3, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=230, n_jobs=-1, num_leaves=90, objective=None,
               random_state=559, reg_alpha=0.05, reg_lambda=1e-06,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-17 14:10:49,495:INFO:Checking exceptions
2023-08-17 14:10:49,518:INFO:Importing libraries
2023-08-17 14:10:49,518:INFO:Copying training dataset
2023-08-17 14:10:49,521:INFO:Getting model names
2023-08-17 14:10:49,523:INFO:SubProcess create_model() called ==================================
2023-08-17 14:10:49,525:INFO:Initializing create_model()
2023-08-17 14:10:49,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A7D96D7430>, model_only=True, return_train_score=False, kwargs={})
2023-08-17 14:10:49,525:INFO:Checking exceptions
2023-08-17 14:10:49,525:INFO:Importing libraries
2023-08-17 14:10:49,525:INFO:Copying training dataset
2023-08-17 14:10:49,566:INFO:Defining folds
2023-08-17 14:10:49,566:INFO:Declaring metric variables
2023-08-17 14:10:49,568:INFO:Importing untrained model
2023-08-17 14:10:49,568:INFO:Declaring custom model
2023-08-17 14:10:49,571:INFO:Voting Classifier Imported successfully
2023-08-17 14:10:49,575:INFO:Starting cross validation
2023-08-17 14:10:49,582:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-17 14:10:52,393:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:52,450:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:52,465:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:53,346:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:53,602:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:53,610:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:53,616:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:53,839:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:53,882:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:10:53,935:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:11:00,549:INFO:Calculating mean and std
2023-08-17 14:11:00,550:INFO:Creating metrics dataframe
2023-08-17 14:11:00,554:INFO:Finalizing model
2023-08-17 14:11:01,667:WARNING:c:\Users\Ramon\miniforge3\envs\piptest\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-17 14:11:02,451:INFO:Uploading results into container
2023-08-17 14:11:02,451:INFO:Uploading model into container now
2023-08-17 14:11:02,452:INFO:_master_model_container: 27
2023-08-17 14:11:02,452:INFO:_display_container: 10
2023-08-17 14:11:02,454:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-17 14:11:02,454:INFO:create_model() successfully completed......................................
2023-08-17 14:11:02,601:INFO:SubProcess create_model() end ==================================
2023-08-17 14:11:02,607:INFO:_master_model_container: 27
2023-08-17 14:11:02,607:INFO:_display_container: 10
2023-08-17 14:11:02,609:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-17 14:11:02,609:INFO:blend_models() successfully completed......................................
2023-08-17 14:11:02,748:INFO:Initializing evaluate_model()
2023-08-17 14:11:02,748:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-17 14:11:02,769:INFO:Initializing plot_model()
2023-08-17 14:11:02,769:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:11:02,769:INFO:Checking exceptions
2023-08-17 14:11:02,780:INFO:Preloading libraries
2023-08-17 14:11:02,785:INFO:Copying training dataset
2023-08-17 14:11:02,785:INFO:Plot type: pipeline
2023-08-17 14:11:02,975:INFO:Visual Rendered Successfully
2023-08-17 14:11:03,120:INFO:plot_model() successfully completed......................................
2023-08-17 14:14:42,825:INFO:Initializing plot_model()
2023-08-17 14:14:42,826:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:14:42,826:INFO:Checking exceptions
2023-08-17 14:14:42,839:INFO:Preloading libraries
2023-08-17 14:14:42,844:INFO:Copying training dataset
2023-08-17 14:14:42,844:INFO:Plot type: confusion_matrix
2023-08-17 14:14:43,198:INFO:Fitting Model
2023-08-17 14:14:43,200:INFO:Scoring test/hold-out set
2023-08-17 14:14:43,205:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:14:43,205:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:14:43,205:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:14:43,348:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:14:43,349:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:14:43,349:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:14:43,575:INFO:Visual Rendered Successfully
2023-08-17 14:14:43,734:INFO:plot_model() successfully completed......................................
2023-08-17 14:15:55,631:INFO:Initializing plot_model()
2023-08-17 14:15:55,631:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:15:55,631:INFO:Checking exceptions
2023-08-17 14:15:55,643:INFO:Preloading libraries
2023-08-17 14:15:55,647:INFO:Copying training dataset
2023-08-17 14:15:55,647:INFO:Plot type: auc
2023-08-17 14:15:55,967:INFO:Fitting Model
2023-08-17 14:15:55,969:INFO:Scoring test/hold-out set
2023-08-17 14:15:55,974:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:15:55,974:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:15:55,974:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:15:56,112:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:15:56,113:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:15:56,113:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:15:56,427:INFO:Visual Rendered Successfully
2023-08-17 14:15:56,590:INFO:plot_model() successfully completed......................................
2023-08-17 14:17:06,290:INFO:Initializing plot_model()
2023-08-17 14:17:06,290:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:17:06,290:INFO:Checking exceptions
2023-08-17 14:17:06,300:INFO:Preloading libraries
2023-08-17 14:17:06,305:INFO:Copying training dataset
2023-08-17 14:17:06,305:INFO:Plot type: threshold
2023-08-17 14:17:06,643:INFO:Fitting Model
2023-08-17 14:17:09,131:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:09,132:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:09,132:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:11,903:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:11,903:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:11,903:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:14,546:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:14,546:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:14,546:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:17,407:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:17,407:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:17,407:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:19,935:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:19,935:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:19,935:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:22,528:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:22,528:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:22,528:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:25,141:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:25,142:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:25,142:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:27,246:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:27,246:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:27,246:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:29,292:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:29,292:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:29,293:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:31,222:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:31,224:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:31,224:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:33,300:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:33,300:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:33,300:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:35,486:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:35,486:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:35,486:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:37,624:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:37,624:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:37,624:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:39,841:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:39,841:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:39,841:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:41,153:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:41,153:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:41,153:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:42,357:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:42,357:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:42,357:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:43,624:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:43,624:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:43,624:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:45,003:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:45,003:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:45,003:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:46,254:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:46,254:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:46,254:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:47,553:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:47,553:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:47,553:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:48,822:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:48,822:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:48,822:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:50,135:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:50,135:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:50,135:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:51,322:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:51,322:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:51,322:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:52,511:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:52,511:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:52,511:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:54,032:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:54,032:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:54,032:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:55,281:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:55,281:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:55,281:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:56,484:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:56,484:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:56,484:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:57,724:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:57,724:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:57,724:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:17:58,908:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:17:58,909:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:17:58,909:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:00,176:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:00,176:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:00,176:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:01,508:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:01,508:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:01,508:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:02,822:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:02,822:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:02,822:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:04,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:04,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:04,040:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:05,260:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:05,260:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:05,260:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:06,670:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:06,670:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:06,670:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:08,032:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:08,032:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:08,032:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:09,238:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:09,238:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:09,238:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:10,587:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:10,587:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:10,587:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:11,760:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:11,760:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:11,760:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:13,040:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:13,040:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:13,040:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:14,305:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:14,305:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:14,305:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:15,478:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:15,478:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:15,478:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:16,732:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:16,732:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:16,732:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:17,922:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:17,922:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:17,922:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:19,203:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:19,204:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:19,204:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:20,612:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:20,612:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:20,612:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:21,912:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:21,912:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:21,912:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:23,321:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:23,321:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:23,321:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:24,619:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:24,619:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:24,619:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:25,806:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:25,806:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:25,806:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:30,127:INFO:Scoring test/hold-out set
2023-08-17 14:18:30,132:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:30,132:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:30,132:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:30,567:INFO:Visual Rendered Successfully
2023-08-17 14:18:30,726:INFO:plot_model() successfully completed......................................
2023-08-17 14:18:55,531:INFO:Initializing plot_model()
2023-08-17 14:18:55,531:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:18:55,531:INFO:Checking exceptions
2023-08-17 14:18:55,544:INFO:Preloading libraries
2023-08-17 14:18:55,548:INFO:Copying training dataset
2023-08-17 14:18:55,549:INFO:Plot type: pr
2023-08-17 14:18:55,871:INFO:Fitting Model
2023-08-17 14:18:55,875:INFO:Scoring test/hold-out set
2023-08-17 14:18:55,879:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:55,879:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:55,879:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:56,015:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:18:56,015:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:18:56,016:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:18:56,359:INFO:Visual Rendered Successfully
2023-08-17 14:18:56,496:INFO:plot_model() successfully completed......................................
2023-08-17 14:20:02,079:INFO:Initializing plot_model()
2023-08-17 14:20:02,079:INFO:plot_model(plot=error, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:20:02,079:INFO:Checking exceptions
2023-08-17 14:20:02,091:INFO:Preloading libraries
2023-08-17 14:20:02,096:INFO:Copying training dataset
2023-08-17 14:20:02,096:INFO:Plot type: error
2023-08-17 14:20:02,459:INFO:Fitting Model
2023-08-17 14:20:02,460:INFO:Scoring test/hold-out set
2023-08-17 14:20:02,465:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:20:02,465:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:20:02,465:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:20:02,605:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:20:02,606:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:20:02,606:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:20:02,871:INFO:Visual Rendered Successfully
2023-08-17 14:20:03,009:INFO:plot_model() successfully completed......................................
2023-08-17 14:20:11,015:INFO:Initializing plot_model()
2023-08-17 14:20:11,015:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:20:11,015:INFO:Checking exceptions
2023-08-17 14:20:11,025:INFO:Preloading libraries
2023-08-17 14:20:11,030:INFO:Copying training dataset
2023-08-17 14:20:11,030:INFO:Plot type: class_report
2023-08-17 14:20:11,352:INFO:Fitting Model
2023-08-17 14:20:11,353:INFO:Scoring test/hold-out set
2023-08-17 14:20:11,358:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:20:11,358:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:20:11,358:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:20:11,507:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:20:11,507:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:20:11,507:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:20:11,813:INFO:Visual Rendered Successfully
2023-08-17 14:20:11,966:INFO:plot_model() successfully completed......................................
2023-08-17 14:20:58,255:INFO:Initializing plot_model()
2023-08-17 14:20:58,255:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:20:58,256:INFO:Checking exceptions
2023-08-17 14:20:59,381:INFO:Initializing plot_model()
2023-08-17 14:20:59,381:INFO:plot_model(plot=learning, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:20:59,381:INFO:Checking exceptions
2023-08-17 14:20:59,392:INFO:Preloading libraries
2023-08-17 14:20:59,397:INFO:Copying training dataset
2023-08-17 14:20:59,397:INFO:Plot type: learning
2023-08-17 14:20:59,745:INFO:Fitting Model
2023-08-17 14:21:52,455:INFO:Visual Rendered Successfully
2023-08-17 14:21:52,624:INFO:plot_model() successfully completed......................................
2023-08-17 14:22:26,820:INFO:Initializing plot_model()
2023-08-17 14:22:26,820:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:22:26,820:INFO:Checking exceptions
2023-08-17 14:22:26,831:INFO:Preloading libraries
2023-08-17 14:22:26,835:INFO:Copying training dataset
2023-08-17 14:22:26,835:INFO:Plot type: manifold
2023-08-17 14:22:27,197:INFO:Fitting & Transforming Model
2023-08-17 14:28:43,667:INFO:Visual Rendered Successfully
2023-08-17 14:28:43,820:INFO:plot_model() successfully completed......................................
2023-08-17 14:29:08,578:INFO:Initializing plot_model()
2023-08-17 14:29:08,578:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:29:08,578:INFO:Checking exceptions
2023-08-17 14:29:08,590:INFO:Preloading libraries
2023-08-17 14:29:08,595:INFO:Copying training dataset
2023-08-17 14:29:08,595:INFO:Plot type: calibration
2023-08-17 14:29:08,605:INFO:Scoring test/hold-out set
2023-08-17 14:29:08,702:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:29:08,702:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:29:08,702:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:29:09,058:INFO:Visual Rendered Successfully
2023-08-17 14:29:09,215:INFO:plot_model() successfully completed......................................
2023-08-17 14:29:34,832:INFO:Initializing plot_model()
2023-08-17 14:29:34,832:INFO:plot_model(plot=vc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:29:34,832:INFO:Checking exceptions
2023-08-17 14:29:34,843:INFO:Preloading libraries
2023-08-17 14:29:34,848:INFO:Copying training dataset
2023-08-17 14:29:34,848:INFO:Plot type: vc
2023-08-17 14:29:34,848:INFO:Determining param_name
2023-08-17 14:29:37,061:INFO:Initializing plot_model()
2023-08-17 14:29:37,061:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:29:37,061:INFO:Checking exceptions
2023-08-17 14:29:37,071:INFO:Preloading libraries
2023-08-17 14:29:37,076:INFO:Copying training dataset
2023-08-17 14:29:37,076:INFO:Plot type: dimension
2023-08-17 14:29:37,203:INFO:Fitting StandardScaler()
2023-08-17 14:29:37,359:INFO:Fitting PCA()
2023-08-17 14:29:38,059:INFO:Fitting & Transforming Model
2023-08-17 14:29:40,764:INFO:Visual Rendered Successfully
2023-08-17 14:29:40,921:INFO:plot_model() successfully completed......................................
2023-08-17 14:30:14,703:INFO:Initializing plot_model()
2023-08-17 14:30:14,703:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:30:14,703:INFO:Checking exceptions
2023-08-17 14:30:14,714:INFO:Preloading libraries
2023-08-17 14:30:14,719:INFO:Copying training dataset
2023-08-17 14:30:14,719:INFO:Plot type: boundary
2023-08-17 14:30:14,922:INFO:Fitting StandardScaler()
2023-08-17 14:30:15,006:INFO:Fitting PCA()
2023-08-17 14:30:15,699:INFO:Fitting Model
2023-08-17 14:30:18,096:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:30:18,096:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:30:18,096:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:30:19,896:INFO:Visual Rendered Successfully
2023-08-17 14:30:20,076:INFO:plot_model() successfully completed......................................
2023-08-17 14:31:12,618:INFO:Initializing plot_model()
2023-08-17 14:31:12,619:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:31:12,619:INFO:Checking exceptions
2023-08-17 14:31:12,631:INFO:Preloading libraries
2023-08-17 14:31:12,636:INFO:Copying training dataset
2023-08-17 14:31:12,636:INFO:Plot type: lift
2023-08-17 14:31:12,636:INFO:Generating predictions / predict_proba on X_test
2023-08-17 14:31:12,800:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:31:12,800:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:31:12,800:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:31:13,108:INFO:Visual Rendered Successfully
2023-08-17 14:31:13,253:INFO:plot_model() successfully completed......................................
2023-08-17 14:31:57,995:INFO:Initializing plot_model()
2023-08-17 14:31:57,995:INFO:plot_model(plot=gain, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:31:57,995:INFO:Checking exceptions
2023-08-17 14:31:58,007:INFO:Preloading libraries
2023-08-17 14:31:58,011:INFO:Copying training dataset
2023-08-17 14:31:58,011:INFO:Plot type: gain
2023-08-17 14:31:58,012:INFO:Generating predictions / predict_proba on X_test
2023-08-17 14:31:58,187:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:31:58,188:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:31:58,188:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:31:58,466:INFO:Visual Rendered Successfully
2023-08-17 14:31:58,602:INFO:plot_model() successfully completed......................................
2023-08-17 14:32:34,540:INFO:Initializing plot_model()
2023-08-17 14:32:34,540:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:32:34,540:INFO:Checking exceptions
2023-08-17 14:32:35,484:INFO:Initializing plot_model()
2023-08-17 14:32:35,484:INFO:plot_model(plot=ks, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, system=True)
2023-08-17 14:32:35,484:INFO:Checking exceptions
2023-08-17 14:32:35,496:INFO:Preloading libraries
2023-08-17 14:32:35,500:INFO:Copying training dataset
2023-08-17 14:32:35,500:INFO:Plot type: ks
2023-08-17 14:32:35,501:INFO:Generating predictions / predict_proba on X_test
2023-08-17 14:32:35,628:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-08-17 14:32:35,628:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2023-08-17 14:32:35,628:INFO:[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3
2023-08-17 14:32:36,340:INFO:Visual Rendered Successfully
2023-08-17 14:32:36,484:INFO:plot_model() successfully completed......................................
2023-08-17 14:33:24,275:INFO:Initializing predict_model()
2023-08-17 14:33:24,275:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A7D337C430>)
2023-08-17 14:33:24,275:INFO:Checking exceptions
2023-08-17 14:33:24,275:INFO:Preloading libraries
2023-08-17 14:33:24,277:INFO:Set up data.
2023-08-17 14:33:24,302:INFO:Set up index.
2023-08-17 14:33:25,521:INFO:Initializing predict_model()
2023-08-17 14:33:25,522:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A7D337C430>)
2023-08-17 14:33:25,522:INFO:Checking exceptions
2023-08-17 14:33:25,522:INFO:Preloading libraries
2023-08-17 14:33:25,523:INFO:Set up data.
2023-08-17 14:33:25,552:INFO:Set up index.
2023-08-17 14:34:47,532:INFO:Initializing predict_model()
2023-08-17 14:34:47,533:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A804C6EA70>)
2023-08-17 14:34:47,533:INFO:Checking exceptions
2023-08-17 14:34:47,533:INFO:Preloading libraries
2023-08-17 14:34:47,534:INFO:Set up data.
2023-08-17 14:34:47,565:INFO:Set up index.
2023-08-17 14:34:48,521:INFO:Initializing predict_model()
2023-08-17 14:34:48,521:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A804C6EA70>)
2023-08-17 14:34:48,521:INFO:Checking exceptions
2023-08-17 14:34:48,521:INFO:Preloading libraries
2023-08-17 14:34:48,522:INFO:Set up data.
2023-08-17 14:34:48,548:INFO:Set up index.
2023-08-17 14:35:17,722:INFO:Initializing predict_model()
2023-08-17 14:35:17,722:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A8012FFC70>)
2023-08-17 14:35:17,722:INFO:Checking exceptions
2023-08-17 14:35:17,722:INFO:Preloading libraries
2023-08-17 14:35:17,724:INFO:Set up data.
2023-08-17 14:35:17,749:INFO:Set up index.
2023-08-17 14:35:18,691:INFO:Initializing predict_model()
2023-08-17 14:35:18,691:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.7,
                                             bagging_freq=3,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.8,
                                             importance_type='split',
                                             learning_rate=0.3, max_depth=-1,
                                             min_child_samples=61,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=230, n_jobs=-1,
                                             num_leaves=9...
                                             random_state=559, reg_alpha=0.05,
                                             reg_lambda=1e-06, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A8012FFC70>)
2023-08-17 14:35:18,691:INFO:Checking exceptions
2023-08-17 14:35:18,691:INFO:Preloading libraries
2023-08-17 14:35:18,693:INFO:Set up data.
2023-08-17 14:35:18,718:INFO:Set up index.
2023-08-17 14:41:24,582:INFO:Initializing finalize_model()
2023-08-17 14:41:24,582:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-17 14:41:24,583:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-17 14:41:24,592:INFO:Initializing create_model()
2023-08-17 14:41:24,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-17 14:41:24,593:INFO:Checking exceptions
2023-08-17 14:41:24,595:INFO:Importing libraries
2023-08-17 14:41:24,596:INFO:Copying training dataset
2023-08-17 14:41:24,599:INFO:Defining folds
2023-08-17 14:41:24,599:INFO:Declaring metric variables
2023-08-17 14:41:24,600:INFO:Importing untrained model
2023-08-17 14:41:24,600:INFO:Declaring custom model
2023-08-17 14:41:24,601:INFO:Voting Classifier Imported successfully
2023-08-17 14:41:24,608:INFO:Cross validation set to False
2023-08-17 14:41:24,608:INFO:Fitting Model
2023-08-17 14:41:43,971:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-17 14:41:43,971:INFO:create_model() successfully completed......................................
2023-08-17 14:41:44,132:INFO:_master_model_container: 27
2023-08-17 14:41:44,132:INFO:_display_container: 16
2023-08-17 14:41:44,172:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-17 14:41:44,172:INFO:finalize_model() successfully completed......................................
2023-08-17 14:43:01,690:INFO:Initializing save_model()
2023-08-17 14:43:01,690:INFO:save_model(model=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=559, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), model_name=final_blended_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=559,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-17 14:43:01,690:INFO:Adding model into prep_pipe
2023-08-17 14:43:01,731:INFO:final_blended_model.pkl saved in current working directory
2023-08-17 14:43:01,787:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-17 14:43:01,787:INFO:save_model() successfully completed......................................
2023-08-17 14:43:13,540:INFO:Initializing save_model()
2023-08-17 14:43:13,540:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), model_name=final_blended_model, prep_pipe_=None, verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={'format': 'json'})
2023-08-17 14:43:13,540:INFO:Adding model into prep_pipe
2023-08-17 14:43:13,540:WARNING:Only Model saved as it was a pipeline.
2023-08-17 14:45:08,745:INFO:Initializing load_model()
2023-08-17 14:45:08,745:INFO:load_model(model_name=final_blended_model, platform=None, authentication=None, verbose=True)
2023-08-17 14:45:08,832:INFO:Initializing predict_model()
2023-08-17 14:45:08,832:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A7D73CBF40>)
2023-08-17 14:45:08,833:INFO:Checking exceptions
2023-08-17 14:45:08,833:INFO:Preloading libraries
2023-08-17 14:45:08,835:INFO:Set up data.
2023-08-17 14:45:08,864:INFO:Set up index.
2023-08-17 14:45:30,146:INFO:Initializing load_model()
2023-08-17 14:45:30,146:INFO:load_model(model_name=final_blended_model, platform=None, authentication=None, verbose=True)
2023-08-17 14:45:30,525:INFO:Initializing predict_model()
2023-08-17 14:45:30,525:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A7E0C1CD00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001A7D9B78160>)
2023-08-17 14:45:30,525:INFO:Checking exceptions
2023-08-17 14:45:30,525:INFO:Preloading libraries
2023-08-17 14:45:30,527:INFO:Set up data.
2023-08-17 14:45:30,548:INFO:Set up index.
2023-08-18 14:27:16,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:27:16,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:27:16,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:27:16,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:27:19,395:INFO:PyCaret ClassificationExperiment
2023-08-18 14:27:19,395:INFO:Logging name: clf-default-name
2023-08-18 14:27:19,395:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 14:27:19,396:INFO:version 3.0.4
2023-08-18 14:27:19,396:INFO:Initializing setup()
2023-08-18 14:27:19,396:INFO:self.USI: 06c3
2023-08-18 14:27:19,396:INFO:self._variable_keys: {'pipeline', 'gpu_param', 'y_test', 'fold_generator', 'html_param', 'X', 'X_test', 'y_train', 'log_plots_param', 'data', 'idx', 'y', 'n_jobs_param', 'fold_groups_param', 'is_multiclass', 'logging_param', 'fix_imbalance', 'exp_id', 'fold_shuffle_param', 'gpu_n_jobs_param', 'X_train', 'exp_name_log', 'target_param', '_ml_usecase', 'seed', 'memory', 'USI', '_available_plots'}
2023-08-18 14:27:19,396:INFO:Checking environment
2023-08-18 14:27:19,396:INFO:python_version: 3.10.12
2023-08-18 14:27:19,396:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 14:27:19,396:INFO:machine: AMD64
2023-08-18 14:27:19,396:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 14:27:19,401:INFO:Memory: svmem(total=68448301056, available=53386821632, percent=22.0, used=15061479424, free=53386821632)
2023-08-18 14:27:19,401:INFO:Physical Core: 12
2023-08-18 14:27:19,401:INFO:Logical Core: 20
2023-08-18 14:27:19,401:INFO:Checking libraries
2023-08-18 14:27:19,401:INFO:System:
2023-08-18 14:27:19,401:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 14:27:19,401:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 14:27:19,401:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 14:27:19,401:INFO:PyCaret required dependencies:
2023-08-18 14:27:20,073:INFO:                 pip: 23.2.1
2023-08-18 14:27:20,073:INFO:          setuptools: 68.0.0
2023-08-18 14:27:20,073:INFO:             pycaret: 3.0.4
2023-08-18 14:27:20,073:INFO:             IPython: 7.34.0
2023-08-18 14:27:20,073:INFO:          ipywidgets: 7.8.0
2023-08-18 14:27:20,073:INFO:                tqdm: 4.66.1
2023-08-18 14:27:20,073:INFO:               numpy: 1.23.5
2023-08-18 14:27:20,074:INFO:              pandas: 1.5.3
2023-08-18 14:27:20,074:INFO:              jinja2: 3.1.2
2023-08-18 14:27:20,074:INFO:               scipy: 1.10.1
2023-08-18 14:27:20,074:INFO:              joblib: 1.3.2
2023-08-18 14:27:20,074:INFO:             sklearn: 1.2.2
2023-08-18 14:27:20,074:INFO:                pyod: 1.1.0
2023-08-18 14:27:20,074:INFO:            imblearn: 0.11.0
2023-08-18 14:27:20,074:INFO:   category_encoders: 2.6.2
2023-08-18 14:27:20,074:INFO:            lightgbm: 4.0.0
2023-08-18 14:27:20,074:INFO:               numba: 0.57.1
2023-08-18 14:27:20,074:INFO:            requests: 2.31.0
2023-08-18 14:27:20,074:INFO:          matplotlib: 3.7.2
2023-08-18 14:27:20,074:INFO:          scikitplot: 0.3.7
2023-08-18 14:27:20,074:INFO:         yellowbrick: 1.5
2023-08-18 14:27:20,074:INFO:              plotly: 5.16.1
2023-08-18 14:27:20,074:INFO:    plotly-resampler: Not installed
2023-08-18 14:27:20,074:INFO:             kaleido: 0.2.1
2023-08-18 14:27:20,074:INFO:           schemdraw: 0.15
2023-08-18 14:27:20,074:INFO:         statsmodels: 0.14.0
2023-08-18 14:27:20,074:INFO:              sktime: 0.21.0
2023-08-18 14:27:20,074:INFO:               tbats: 1.1.3
2023-08-18 14:27:20,074:INFO:            pmdarima: 2.0.3
2023-08-18 14:27:20,074:INFO:              psutil: 5.9.5
2023-08-18 14:27:20,074:INFO:          markupsafe: 2.1.3
2023-08-18 14:27:20,074:INFO:             pickle5: Not installed
2023-08-18 14:27:20,074:INFO:         cloudpickle: 2.2.1
2023-08-18 14:27:20,074:INFO:         deprecation: 2.1.0
2023-08-18 14:27:20,074:INFO:              xxhash: 3.3.0
2023-08-18 14:27:20,074:INFO:           wurlitzer: 3.0.3
2023-08-18 14:27:20,074:INFO:PyCaret optional dependencies:
2023-08-18 14:27:20,363:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\trio\_core\_multierror.py:412: RuntimeWarning: IPython detected, but you already have a custom exception handler installed. I'll skip installing Trio's custom handler, but this means exception groups will not show full tracebacks.
  warnings.warn(

2023-08-18 14:27:22,234:INFO:                shap: 0.42.1
2023-08-18 14:27:22,234:INFO:           interpret: 0.4.3
2023-08-18 14:27:22,234:INFO:                umap: 0.5.3
2023-08-18 14:27:22,234:INFO:    pandas_profiling: 4.5.1
2023-08-18 14:27:22,234:INFO:  explainerdashboard: 0.4.3
2023-08-18 14:27:22,234:INFO:             autoviz: 0.1.730
2023-08-18 14:27:22,234:INFO:           fairlearn: 0.7.0
2023-08-18 14:27:22,234:INFO:          deepchecks: 0.17.4
2023-08-18 14:27:22,234:INFO:             xgboost: 1.7.6
2023-08-18 14:27:22,234:INFO:            catboost: 1.2
2023-08-18 14:27:22,234:INFO:              kmodes: 0.12.2
2023-08-18 14:27:22,234:INFO:             mlxtend: 0.22.0
2023-08-18 14:27:22,234:INFO:       statsforecast: 1.5.0
2023-08-18 14:27:22,234:INFO:        tune_sklearn: 0.4.6
2023-08-18 14:27:22,234:INFO:                 ray: 2.6.3
2023-08-18 14:27:22,234:INFO:            hyperopt: 0.2.7
2023-08-18 14:27:22,234:INFO:              optuna: 3.3.0
2023-08-18 14:27:22,234:INFO:               skopt: 0.9.0
2023-08-18 14:27:22,234:INFO:              mlflow: 1.30.1
2023-08-18 14:27:22,234:INFO:              gradio: 3.40.1
2023-08-18 14:27:22,234:INFO:             fastapi: 0.101.1
2023-08-18 14:27:22,234:INFO:             uvicorn: 0.23.2
2023-08-18 14:27:22,234:INFO:              m2cgen: 0.10.0
2023-08-18 14:27:22,234:INFO:           evidently: 0.2.8
2023-08-18 14:27:22,234:INFO:               fugue: 0.8.6
2023-08-18 14:27:22,234:INFO:           streamlit: 1.25.0
2023-08-18 14:27:22,234:INFO:             prophet: 1.1.4
2023-08-18 14:27:22,234:INFO:None
2023-08-18 14:27:22,235:INFO:Set up data.
2023-08-18 14:27:22,417:INFO:Set up train/test split.
2023-08-18 14:27:22,563:INFO:Set up index.
2023-08-18 14:27:22,567:INFO:Set up folding strategy.
2023-08-18 14:27:22,567:INFO:Assigning column types.
2023-08-18 14:27:22,586:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 14:27:22,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 14:27:22,612:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 14:27:22,633:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:27:22,700:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:27:23,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 14:27:23,011:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 14:27:23,026:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:27:23,028:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:27:23,028:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 14:27:23,052:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 14:27:23,068:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:27:23,069:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:27:23,094:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 14:27:23,184:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:27:23,185:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:27:23,186:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 14:27:23,224:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:27:23,226:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:27:23,265:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:27:23,267:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:27:23,275:INFO:Preparing preprocessing pipeline...
2023-08-18 14:27:23,279:INFO:Set up label encoding.
2023-08-18 14:27:23,279:INFO:Set up simple imputation.
2023-08-18 14:27:23,313:INFO:Set up encoding of ordinal features.
2023-08-18 14:27:23,350:INFO:Set up encoding of categorical features.
2023-08-18 14:27:23,350:INFO:Set up removing outliers.
2023-08-18 14:27:23,350:INFO:Set up imbalanced handling.
2023-08-18 14:27:23,350:INFO:Set up feature normalization.
2023-08-18 14:27:23,352:INFO:Set up column name cleaning.
2023-08-18 14:27:26,115:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 14:27:37,507:INFO:Finished creating preprocessing pipeline.
2023-08-18 14:27:37,552:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 14:27:37,552:INFO:Creating final display dataframe.
2023-08-18 14:27:38,703:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 14:27:51,570:INFO:Setup _display_container:                     Description             Value
0                    Session id              5146
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (425717, 42)
6   Transformed train set shape      (342326, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              06c3
2023-08-18 14:27:51,616:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:27:51,617:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:27:51,658:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:27:51,660:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:27:51,660:INFO:setup() successfully completed in 33.17s...............
2023-08-18 14:55:59,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:55:59,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:55:59,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:55:59,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:00,594:INFO:PyCaret ClassificationExperiment
2023-08-18 14:56:00,594:INFO:Logging name: clf-default-name
2023-08-18 14:56:00,594:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 14:56:00,594:INFO:version 3.0.4
2023-08-18 14:56:00,594:INFO:Initializing setup()
2023-08-18 14:56:00,594:INFO:self.USI: 8b8a
2023-08-18 14:56:00,594:INFO:self._variable_keys: {'_ml_usecase', 'data', 'y_test', 'X_test', 'y_train', 'seed', 'USI', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'X', 'is_multiclass', 'target_param', 'fix_imbalance', 'html_param', 'exp_id', 'gpu_param', '_available_plots', 'logging_param', 'fold_groups_param', 'y', 'n_jobs_param', 'pipeline', 'X_train', 'idx', 'log_plots_param', 'fold_shuffle_param', 'exp_name_log'}
2023-08-18 14:56:00,595:INFO:Checking environment
2023-08-18 14:56:00,595:INFO:python_version: 3.10.12
2023-08-18 14:56:00,595:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 14:56:00,595:INFO:machine: AMD64
2023-08-18 14:56:00,595:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 14:56:00,598:INFO:Memory: svmem(total=68448301056, available=51268194304, percent=25.1, used=17180106752, free=51268194304)
2023-08-18 14:56:00,598:INFO:Physical Core: 12
2023-08-18 14:56:00,598:INFO:Logical Core: 20
2023-08-18 14:56:00,598:INFO:Checking libraries
2023-08-18 14:56:00,598:INFO:System:
2023-08-18 14:56:00,598:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 14:56:00,598:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 14:56:00,598:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 14:56:00,598:INFO:PyCaret required dependencies:
2023-08-18 14:56:00,831:INFO:                 pip: 23.2.1
2023-08-18 14:56:00,831:INFO:          setuptools: 68.0.0
2023-08-18 14:56:00,831:INFO:             pycaret: 3.0.4
2023-08-18 14:56:00,831:INFO:             IPython: 7.34.0
2023-08-18 14:56:00,831:INFO:          ipywidgets: 7.8.0
2023-08-18 14:56:00,831:INFO:                tqdm: 4.66.1
2023-08-18 14:56:00,831:INFO:               numpy: 1.23.5
2023-08-18 14:56:00,831:INFO:              pandas: 1.5.3
2023-08-18 14:56:00,831:INFO:              jinja2: 3.1.2
2023-08-18 14:56:00,831:INFO:               scipy: 1.10.1
2023-08-18 14:56:00,831:INFO:              joblib: 1.3.2
2023-08-18 14:56:00,831:INFO:             sklearn: 1.2.2
2023-08-18 14:56:00,831:INFO:                pyod: 1.1.0
2023-08-18 14:56:00,831:INFO:            imblearn: 0.11.0
2023-08-18 14:56:00,831:INFO:   category_encoders: 2.6.2
2023-08-18 14:56:00,831:INFO:            lightgbm: 4.0.0
2023-08-18 14:56:00,833:INFO:               numba: 0.57.1
2023-08-18 14:56:00,833:INFO:            requests: 2.31.0
2023-08-18 14:56:00,833:INFO:          matplotlib: 3.7.2
2023-08-18 14:56:00,833:INFO:          scikitplot: 0.3.7
2023-08-18 14:56:00,833:INFO:         yellowbrick: 1.5
2023-08-18 14:56:00,833:INFO:              plotly: 5.16.1
2023-08-18 14:56:00,833:INFO:    plotly-resampler: Not installed
2023-08-18 14:56:00,833:INFO:             kaleido: 0.2.1
2023-08-18 14:56:00,833:INFO:           schemdraw: 0.15
2023-08-18 14:56:00,833:INFO:         statsmodels: 0.14.0
2023-08-18 14:56:00,833:INFO:              sktime: 0.21.0
2023-08-18 14:56:00,833:INFO:               tbats: 1.1.3
2023-08-18 14:56:00,833:INFO:            pmdarima: 2.0.3
2023-08-18 14:56:00,833:INFO:              psutil: 5.9.5
2023-08-18 14:56:00,833:INFO:          markupsafe: 2.1.3
2023-08-18 14:56:00,833:INFO:             pickle5: Not installed
2023-08-18 14:56:00,833:INFO:         cloudpickle: 2.2.1
2023-08-18 14:56:00,833:INFO:         deprecation: 2.1.0
2023-08-18 14:56:00,833:INFO:              xxhash: 3.3.0
2023-08-18 14:56:00,833:INFO:           wurlitzer: 3.0.3
2023-08-18 14:56:00,833:INFO:PyCaret optional dependencies:
2023-08-18 14:56:01,969:INFO:                shap: 0.42.1
2023-08-18 14:56:01,969:INFO:           interpret: 0.4.3
2023-08-18 14:56:01,969:INFO:                umap: 0.5.3
2023-08-18 14:56:01,969:INFO:    pandas_profiling: 4.5.1
2023-08-18 14:56:01,969:INFO:  explainerdashboard: 0.4.3
2023-08-18 14:56:01,969:INFO:             autoviz: 0.1.730
2023-08-18 14:56:01,969:INFO:           fairlearn: 0.7.0
2023-08-18 14:56:01,969:INFO:          deepchecks: 0.17.4
2023-08-18 14:56:01,969:INFO:             xgboost: 1.7.6
2023-08-18 14:56:01,969:INFO:            catboost: 1.2
2023-08-18 14:56:01,969:INFO:              kmodes: 0.12.2
2023-08-18 14:56:01,969:INFO:             mlxtend: 0.22.0
2023-08-18 14:56:01,969:INFO:       statsforecast: 1.5.0
2023-08-18 14:56:01,969:INFO:        tune_sklearn: 0.4.6
2023-08-18 14:56:01,969:INFO:                 ray: 2.6.3
2023-08-18 14:56:01,969:INFO:            hyperopt: 0.2.7
2023-08-18 14:56:01,969:INFO:              optuna: 3.3.0
2023-08-18 14:56:01,969:INFO:               skopt: 0.9.0
2023-08-18 14:56:01,969:INFO:              mlflow: 1.30.1
2023-08-18 14:56:01,969:INFO:              gradio: 3.40.1
2023-08-18 14:56:01,969:INFO:             fastapi: 0.101.1
2023-08-18 14:56:01,969:INFO:             uvicorn: 0.23.2
2023-08-18 14:56:01,969:INFO:              m2cgen: 0.10.0
2023-08-18 14:56:01,969:INFO:           evidently: 0.2.8
2023-08-18 14:56:01,969:INFO:               fugue: 0.8.6
2023-08-18 14:56:01,969:INFO:           streamlit: 1.25.0
2023-08-18 14:56:01,969:INFO:             prophet: 1.1.4
2023-08-18 14:56:01,969:INFO:None
2023-08-18 14:56:01,969:INFO:Set up GPU usage.
2023-08-18 14:56:01,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:01,969:WARNING:cuML is outdated or not found. Required version is >=22.10.
                Please visit https://rapids.ai/ for installation instructions.
2023-08-18 14:56:01,969:INFO:Set up data.
2023-08-18 14:56:02,145:INFO:Set up train/test split.
2023-08-18 14:56:02,286:INFO:Set up index.
2023-08-18 14:56:02,290:INFO:Set up folding strategy.
2023-08-18 14:56:02,290:INFO:Assigning column types.
2023-08-18 14:56:02,306:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 14:56:02,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:02,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 14:56:02,330:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:02,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:02,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 14:56:02,331:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:02,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:02,349:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:02,351:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:56:04,991:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:56:05,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,050:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 14:56:05,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,052:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 14:56:05,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,074:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,077:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,078:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:56:05,325:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:56:05,327:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 14:56:05,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,356:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 14:56:05,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,372:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,376:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,376:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:56:05,477:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:56:05,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 14:56:05,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,534:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,537:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,538:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:56:05,636:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:56:05,637:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 14:56:05,637:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,688:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:56:05,817:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:56:05,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,851:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,852:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:05,875:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:56:05,994:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:56:05,996:INFO:Preparing preprocessing pipeline...
2023-08-18 14:56:06,001:INFO:Set up label encoding.
2023-08-18 14:56:06,002:INFO:Set up simple imputation.
2023-08-18 14:56:06,046:INFO:Set up encoding of ordinal features.
2023-08-18 14:56:06,097:INFO:Set up encoding of categorical features.
2023-08-18 14:56:06,098:INFO:Set up removing outliers.
2023-08-18 14:56:06,098:INFO:Set up imbalanced handling.
2023-08-18 14:56:06,098:INFO:Set up feature normalization.
2023-08-18 14:56:06,101:INFO:Set up column name cleaning.
2023-08-18 14:56:20,848:INFO:Finished creating preprocessing pipeline.
2023-08-18 14:56:20,892:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 14:56:20,893:INFO:Creating final display dataframe.
2023-08-18 14:56:34,831:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (426079, 42)
6   Transformed train set shape      (342688, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU              True
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              8b8a
2023-08-18 14:56:34,836:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:34,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:34,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:34,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:34,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:34,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:34,883:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:56:35,049:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:56:35,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:35,077:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:35,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:35,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:35,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:35,096:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 14:56:35,097:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 14:56:35,203:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 14:56:35,205:INFO:setup() successfully completed in 34.99s...............
2023-08-18 15:12:45,933:INFO:PyCaret ClassificationExperiment
2023-08-18 15:12:45,933:INFO:Logging name: clf-default-name
2023-08-18 15:12:45,933:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:12:45,933:INFO:version 3.0.4
2023-08-18 15:12:45,933:INFO:Initializing setup()
2023-08-18 15:12:45,933:INFO:self.USI: 90fc
2023-08-18 15:12:45,934:INFO:self._variable_keys: {'_ml_usecase', 'data', 'y_test', 'X_test', 'y_train', 'seed', 'USI', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'X', 'is_multiclass', 'target_param', 'fix_imbalance', 'html_param', 'exp_id', 'gpu_param', '_available_plots', 'logging_param', 'fold_groups_param', 'y', 'n_jobs_param', 'pipeline', 'X_train', 'idx', 'log_plots_param', 'fold_shuffle_param', 'exp_name_log'}
2023-08-18 15:12:45,934:INFO:Checking environment
2023-08-18 15:12:45,934:INFO:python_version: 3.10.12
2023-08-18 15:12:45,934:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:12:45,934:INFO:machine: AMD64
2023-08-18 15:12:45,934:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:12:45,938:INFO:Memory: svmem(total=68448301056, available=50023829504, percent=26.9, used=18424471552, free=50023829504)
2023-08-18 15:12:45,938:INFO:Physical Core: 12
2023-08-18 15:12:45,938:INFO:Logical Core: 20
2023-08-18 15:12:45,938:INFO:Checking libraries
2023-08-18 15:12:45,938:INFO:System:
2023-08-18 15:12:45,938:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:12:45,938:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:12:45,938:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:12:45,938:INFO:PyCaret required dependencies:
2023-08-18 15:12:45,938:INFO:                 pip: 23.2.1
2023-08-18 15:12:45,938:INFO:          setuptools: 68.0.0
2023-08-18 15:12:45,938:INFO:             pycaret: 3.0.4
2023-08-18 15:12:45,938:INFO:             IPython: 7.34.0
2023-08-18 15:12:45,938:INFO:          ipywidgets: 7.8.0
2023-08-18 15:12:45,938:INFO:                tqdm: 4.66.1
2023-08-18 15:12:45,938:INFO:               numpy: 1.23.5
2023-08-18 15:12:45,938:INFO:              pandas: 1.5.3
2023-08-18 15:12:45,938:INFO:              jinja2: 3.1.2
2023-08-18 15:12:45,938:INFO:               scipy: 1.10.1
2023-08-18 15:12:45,938:INFO:              joblib: 1.3.2
2023-08-18 15:12:45,938:INFO:             sklearn: 1.2.2
2023-08-18 15:12:45,938:INFO:                pyod: 1.1.0
2023-08-18 15:12:45,938:INFO:            imblearn: 0.11.0
2023-08-18 15:12:45,938:INFO:   category_encoders: 2.6.2
2023-08-18 15:12:45,938:INFO:            lightgbm: 4.0.0
2023-08-18 15:12:45,938:INFO:               numba: 0.57.1
2023-08-18 15:12:45,938:INFO:            requests: 2.31.0
2023-08-18 15:12:45,938:INFO:          matplotlib: 3.7.2
2023-08-18 15:12:45,938:INFO:          scikitplot: 0.3.7
2023-08-18 15:12:45,938:INFO:         yellowbrick: 1.5
2023-08-18 15:12:45,938:INFO:              plotly: 5.16.1
2023-08-18 15:12:45,938:INFO:    plotly-resampler: Not installed
2023-08-18 15:12:45,939:INFO:             kaleido: 0.2.1
2023-08-18 15:12:45,939:INFO:           schemdraw: 0.15
2023-08-18 15:12:45,939:INFO:         statsmodels: 0.14.0
2023-08-18 15:12:45,939:INFO:              sktime: 0.21.0
2023-08-18 15:12:45,939:INFO:               tbats: 1.1.3
2023-08-18 15:12:45,939:INFO:            pmdarima: 2.0.3
2023-08-18 15:12:45,939:INFO:              psutil: 5.9.5
2023-08-18 15:12:45,939:INFO:          markupsafe: 2.1.3
2023-08-18 15:12:45,939:INFO:             pickle5: Not installed
2023-08-18 15:12:45,939:INFO:         cloudpickle: 2.2.1
2023-08-18 15:12:45,939:INFO:         deprecation: 2.1.0
2023-08-18 15:12:45,939:INFO:              xxhash: 3.3.0
2023-08-18 15:12:45,939:INFO:           wurlitzer: 3.0.3
2023-08-18 15:12:45,939:INFO:PyCaret optional dependencies:
2023-08-18 15:12:45,939:INFO:                shap: 0.42.1
2023-08-18 15:12:45,939:INFO:           interpret: 0.4.3
2023-08-18 15:12:45,939:INFO:                umap: 0.5.3
2023-08-18 15:12:45,939:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:12:45,939:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:12:45,939:INFO:             autoviz: 0.1.730
2023-08-18 15:12:45,939:INFO:           fairlearn: 0.7.0
2023-08-18 15:12:45,939:INFO:          deepchecks: 0.17.4
2023-08-18 15:12:45,939:INFO:             xgboost: 1.7.6
2023-08-18 15:12:45,939:INFO:            catboost: 1.2
2023-08-18 15:12:45,939:INFO:              kmodes: 0.12.2
2023-08-18 15:12:45,939:INFO:             mlxtend: 0.22.0
2023-08-18 15:12:45,939:INFO:       statsforecast: 1.5.0
2023-08-18 15:12:45,939:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:12:45,939:INFO:                 ray: 2.6.3
2023-08-18 15:12:45,939:INFO:            hyperopt: 0.2.7
2023-08-18 15:12:45,939:INFO:              optuna: 3.3.0
2023-08-18 15:12:45,939:INFO:               skopt: 0.9.0
2023-08-18 15:12:45,939:INFO:              mlflow: 1.30.1
2023-08-18 15:12:45,939:INFO:              gradio: 3.40.1
2023-08-18 15:12:45,939:INFO:             fastapi: 0.101.1
2023-08-18 15:12:45,939:INFO:             uvicorn: 0.23.2
2023-08-18 15:12:45,939:INFO:              m2cgen: 0.10.0
2023-08-18 15:12:45,939:INFO:           evidently: 0.2.8
2023-08-18 15:12:45,939:INFO:               fugue: 0.8.6
2023-08-18 15:12:45,939:INFO:           streamlit: 1.25.0
2023-08-18 15:12:45,939:INFO:             prophet: 1.1.4
2023-08-18 15:12:45,939:INFO:None
2023-08-18 15:12:45,939:INFO:Set up GPU usage.
2023-08-18 15:12:45,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:45,939:WARNING:cuML is outdated or not found. Required version is >=22.10.
                Please visit https://rapids.ai/ for installation instructions.
2023-08-18 15:12:45,939:INFO:Set up data.
2023-08-18 15:12:46,123:INFO:Set up train/test split.
2023-08-18 15:12:46,276:INFO:Set up index.
2023-08-18 15:12:46,280:INFO:Set up folding strategy.
2023-08-18 15:12:46,280:INFO:Assigning column types.
2023-08-18 15:12:46,299:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:12:46,299:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,325:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:12:46,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,325:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:12:46,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,338:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,341:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,342:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:12:46,472:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:12:46,473:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,504:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:12:46,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,505:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:12:46,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,522:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:12:46,632:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:12:46,633:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:12:46,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,686:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:12:46,686:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,707:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,708:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:12:46,811:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:12:46,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,842:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,843:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:12:46,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,867:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:46,872:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:12:46,989:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:12:46,990:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:12:46,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,020:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,042:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:12:47,148:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:12:47,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,178:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,207:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:12:47,208:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:12:47,314:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:12:47,315:INFO:Preparing preprocessing pipeline...
2023-08-18 15:12:47,318:INFO:Set up label encoding.
2023-08-18 15:12:47,318:INFO:Set up simple imputation.
2023-08-18 15:12:47,356:INFO:Set up encoding of ordinal features.
2023-08-18 15:12:47,407:INFO:Set up encoding of categorical features.
2023-08-18 15:12:47,407:INFO:Set up removing outliers.
2023-08-18 15:12:47,408:INFO:Set up imbalanced handling.
2023-08-18 15:12:47,408:INFO:Set up feature normalization.
2023-08-18 15:12:47,410:INFO:Set up column name cleaning.
2023-08-18 15:13:02,126:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:13:02,167:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:13:02,168:INFO:Creating final display dataframe.
2023-08-18 15:13:15,984:INFO:Setup _display_container:            Description                Value      
0                    Session id               559
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (425485, 42)
6   Transformed train set shape      (342094, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU              True
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              90fc
2023-08-18 15:13:15,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,014:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,029:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:13:16,168:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:13:16,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,200:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:13:16,218:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:13:16,329:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:13:16,330:INFO:setup() successfully completed in 30.68s...............
2023-08-18 15:13:37,238:INFO:PyCaret ClassificationExperiment
2023-08-18 15:13:37,238:INFO:Logging name: clf-default-name
2023-08-18 15:13:37,238:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:13:37,238:INFO:version 3.0.4
2023-08-18 15:13:37,238:INFO:Initializing setup()
2023-08-18 15:13:37,238:INFO:self.USI: 8c2f
2023-08-18 15:13:37,238:INFO:self._variable_keys: {'_ml_usecase', 'data', 'y_test', 'X_test', 'y_train', 'seed', 'USI', 'fold_generator', 'memory', 'gpu_n_jobs_param', 'X', 'is_multiclass', 'target_param', 'fix_imbalance', 'html_param', 'exp_id', 'gpu_param', '_available_plots', 'logging_param', 'fold_groups_param', 'y', 'n_jobs_param', 'pipeline', 'X_train', 'idx', 'log_plots_param', 'fold_shuffle_param', 'exp_name_log'}
2023-08-18 15:13:37,238:INFO:Checking environment
2023-08-18 15:13:37,238:INFO:python_version: 3.10.12
2023-08-18 15:13:37,238:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:13:37,238:INFO:machine: AMD64
2023-08-18 15:13:37,239:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:13:37,242:INFO:Memory: svmem(total=68448301056, available=49852141568, percent=27.2, used=18596159488, free=49852141568)
2023-08-18 15:13:37,242:INFO:Physical Core: 12
2023-08-18 15:13:37,242:INFO:Logical Core: 20
2023-08-18 15:13:37,242:INFO:Checking libraries
2023-08-18 15:13:37,242:INFO:System:
2023-08-18 15:13:37,242:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:13:37,242:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:13:37,242:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:13:37,242:INFO:PyCaret required dependencies:
2023-08-18 15:13:37,243:INFO:                 pip: 23.2.1
2023-08-18 15:13:37,243:INFO:          setuptools: 68.0.0
2023-08-18 15:13:37,243:INFO:             pycaret: 3.0.4
2023-08-18 15:13:37,243:INFO:             IPython: 7.34.0
2023-08-18 15:13:37,243:INFO:          ipywidgets: 7.8.0
2023-08-18 15:13:37,243:INFO:                tqdm: 4.66.1
2023-08-18 15:13:37,243:INFO:               numpy: 1.23.5
2023-08-18 15:13:37,243:INFO:              pandas: 1.5.3
2023-08-18 15:13:37,243:INFO:              jinja2: 3.1.2
2023-08-18 15:13:37,243:INFO:               scipy: 1.10.1
2023-08-18 15:13:37,243:INFO:              joblib: 1.3.2
2023-08-18 15:13:37,243:INFO:             sklearn: 1.2.2
2023-08-18 15:13:37,243:INFO:                pyod: 1.1.0
2023-08-18 15:13:37,243:INFO:            imblearn: 0.11.0
2023-08-18 15:13:37,243:INFO:   category_encoders: 2.6.2
2023-08-18 15:13:37,243:INFO:            lightgbm: 4.0.0
2023-08-18 15:13:37,243:INFO:               numba: 0.57.1
2023-08-18 15:13:37,243:INFO:            requests: 2.31.0
2023-08-18 15:13:37,243:INFO:          matplotlib: 3.7.2
2023-08-18 15:13:37,243:INFO:          scikitplot: 0.3.7
2023-08-18 15:13:37,243:INFO:         yellowbrick: 1.5
2023-08-18 15:13:37,243:INFO:              plotly: 5.16.1
2023-08-18 15:13:37,243:INFO:    plotly-resampler: Not installed
2023-08-18 15:13:37,243:INFO:             kaleido: 0.2.1
2023-08-18 15:13:37,243:INFO:           schemdraw: 0.15
2023-08-18 15:13:37,243:INFO:         statsmodels: 0.14.0
2023-08-18 15:13:37,243:INFO:              sktime: 0.21.0
2023-08-18 15:13:37,243:INFO:               tbats: 1.1.3
2023-08-18 15:13:37,243:INFO:            pmdarima: 2.0.3
2023-08-18 15:13:37,243:INFO:              psutil: 5.9.5
2023-08-18 15:13:37,243:INFO:          markupsafe: 2.1.3
2023-08-18 15:13:37,243:INFO:             pickle5: Not installed
2023-08-18 15:13:37,243:INFO:         cloudpickle: 2.2.1
2023-08-18 15:13:37,243:INFO:         deprecation: 2.1.0
2023-08-18 15:13:37,243:INFO:              xxhash: 3.3.0
2023-08-18 15:13:37,243:INFO:           wurlitzer: 3.0.3
2023-08-18 15:13:37,243:INFO:PyCaret optional dependencies:
2023-08-18 15:13:37,243:INFO:                shap: 0.42.1
2023-08-18 15:13:37,243:INFO:           interpret: 0.4.3
2023-08-18 15:13:37,243:INFO:                umap: 0.5.3
2023-08-18 15:13:37,243:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:13:37,243:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:13:37,243:INFO:             autoviz: 0.1.730
2023-08-18 15:13:37,244:INFO:           fairlearn: 0.7.0
2023-08-18 15:13:37,244:INFO:          deepchecks: 0.17.4
2023-08-18 15:13:37,244:INFO:             xgboost: 1.7.6
2023-08-18 15:13:37,244:INFO:            catboost: 1.2
2023-08-18 15:13:37,244:INFO:              kmodes: 0.12.2
2023-08-18 15:13:37,244:INFO:             mlxtend: 0.22.0
2023-08-18 15:13:37,244:INFO:       statsforecast: 1.5.0
2023-08-18 15:13:37,244:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:13:37,244:INFO:                 ray: 2.6.3
2023-08-18 15:13:37,244:INFO:            hyperopt: 0.2.7
2023-08-18 15:13:37,244:INFO:              optuna: 3.3.0
2023-08-18 15:13:37,244:INFO:               skopt: 0.9.0
2023-08-18 15:13:37,244:INFO:              mlflow: 1.30.1
2023-08-18 15:13:37,244:INFO:              gradio: 3.40.1
2023-08-18 15:13:37,244:INFO:             fastapi: 0.101.1
2023-08-18 15:13:37,244:INFO:             uvicorn: 0.23.2
2023-08-18 15:13:37,244:INFO:              m2cgen: 0.10.0
2023-08-18 15:13:37,244:INFO:           evidently: 0.2.8
2023-08-18 15:13:37,244:INFO:               fugue: 0.8.6
2023-08-18 15:13:37,244:INFO:           streamlit: 1.25.0
2023-08-18 15:13:37,244:INFO:             prophet: 1.1.4
2023-08-18 15:13:37,244:INFO:None
2023-08-18 15:13:37,244:INFO:Set up data.
2023-08-18 15:13:37,434:INFO:Set up train/test split.
2023-08-18 15:13:37,585:INFO:Set up index.
2023-08-18 15:13:37,590:INFO:Set up folding strategy.
2023-08-18 15:13:37,590:INFO:Assigning column types.
2023-08-18 15:13:37,608:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:13:37,634:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:13:37,634:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:13:37,650:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:13:37,652:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:13:37,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:13:37,678:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:13:37,695:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:13:37,697:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:13:37,698:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:13:37,723:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:13:37,740:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:13:37,741:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:13:37,768:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:13:37,783:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:13:37,785:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:13:37,785:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:13:37,826:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:13:37,828:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:13:37,869:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:13:37,870:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:13:37,871:INFO:Preparing preprocessing pipeline...
2023-08-18 15:13:37,875:INFO:Set up label encoding.
2023-08-18 15:13:37,875:INFO:Set up simple imputation.
2023-08-18 15:13:37,909:INFO:Set up encoding of ordinal features.
2023-08-18 15:13:37,952:INFO:Set up encoding of categorical features.
2023-08-18 15:13:37,952:INFO:Set up removing outliers.
2023-08-18 15:13:37,952:INFO:Set up imbalanced handling.
2023-08-18 15:13:37,952:INFO:Set up feature normalization.
2023-08-18 15:13:37,955:INFO:Set up column name cleaning.
2023-08-18 15:13:52,279:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:13:52,319:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:13:52,319:INFO:Creating final display dataframe.
2023-08-18 15:14:06,055:INFO:Setup _display_container:            Description                Value      
0                    Session id              4656
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (425229, 42)
6   Transformed train set shape      (341838, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              8c2f
2023-08-18 15:14:06,099:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:14:06,101:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:14:06,143:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:14:06,145:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:14:06,145:INFO:setup() successfully completed in 29.16s...............
2023-08-18 15:23:24,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:23:24,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:23:24,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:23:24,487:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:23:25,213:INFO:PyCaret ClassificationExperiment
2023-08-18 15:23:25,214:INFO:Logging name: clf-default-name
2023-08-18 15:23:25,214:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:23:25,214:INFO:version 3.0.4
2023-08-18 15:23:25,214:INFO:Initializing setup()
2023-08-18 15:23:25,214:INFO:self.USI: 822e
2023-08-18 15:23:25,214:INFO:self._variable_keys: {'idx', 'exp_name_log', 'exp_id', 'X_test', '_available_plots', 'target_param', 'n_jobs_param', 'X', 'fix_imbalance', 'fold_groups_param', 'USI', 'logging_param', 'memory', 'seed', 'X_train', 'y_test', 'gpu_n_jobs_param', '_ml_usecase', 'is_multiclass', 'gpu_param', 'data', 'fold_generator', 'y_train', 'y', 'pipeline', 'fold_shuffle_param', 'log_plots_param', 'html_param'}
2023-08-18 15:23:25,214:INFO:Checking environment
2023-08-18 15:23:25,214:INFO:python_version: 3.10.12
2023-08-18 15:23:25,214:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:23:25,214:INFO:machine: AMD64
2023-08-18 15:23:25,214:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:23:25,217:INFO:Memory: svmem(total=68448301056, available=50275061760, percent=26.6, used=18173239296, free=50275061760)
2023-08-18 15:23:25,218:INFO:Physical Core: 12
2023-08-18 15:23:25,218:INFO:Logical Core: 20
2023-08-18 15:23:25,218:INFO:Checking libraries
2023-08-18 15:23:25,218:INFO:System:
2023-08-18 15:23:25,218:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:23:25,218:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:23:25,218:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:23:25,218:INFO:PyCaret required dependencies:
2023-08-18 15:23:25,555:INFO:                 pip: 23.2.1
2023-08-18 15:23:25,555:INFO:          setuptools: 68.0.0
2023-08-18 15:23:25,555:INFO:             pycaret: 3.0.4
2023-08-18 15:23:25,555:INFO:             IPython: 7.34.0
2023-08-18 15:23:25,555:INFO:          ipywidgets: 7.8.0
2023-08-18 15:23:25,555:INFO:                tqdm: 4.66.1
2023-08-18 15:23:25,555:INFO:               numpy: 1.23.5
2023-08-18 15:23:25,555:INFO:              pandas: 1.5.3
2023-08-18 15:23:25,556:INFO:              jinja2: 3.1.2
2023-08-18 15:23:25,556:INFO:               scipy: 1.10.1
2023-08-18 15:23:25,556:INFO:              joblib: 1.3.2
2023-08-18 15:23:25,556:INFO:             sklearn: 1.2.2
2023-08-18 15:23:25,556:INFO:                pyod: 1.1.0
2023-08-18 15:23:25,556:INFO:            imblearn: 0.11.0
2023-08-18 15:23:25,556:INFO:   category_encoders: 2.6.2
2023-08-18 15:23:25,556:INFO:            lightgbm: 4.0.0
2023-08-18 15:23:25,556:INFO:               numba: 0.57.1
2023-08-18 15:23:25,556:INFO:            requests: 2.31.0
2023-08-18 15:23:25,556:INFO:          matplotlib: 3.7.2
2023-08-18 15:23:25,556:INFO:          scikitplot: 0.3.7
2023-08-18 15:23:25,556:INFO:         yellowbrick: 1.5
2023-08-18 15:23:25,556:INFO:              plotly: 5.16.1
2023-08-18 15:23:25,556:INFO:    plotly-resampler: Not installed
2023-08-18 15:23:25,556:INFO:             kaleido: 0.2.1
2023-08-18 15:23:25,556:INFO:           schemdraw: 0.15
2023-08-18 15:23:25,556:INFO:         statsmodels: 0.14.0
2023-08-18 15:23:25,556:INFO:              sktime: 0.21.0
2023-08-18 15:23:25,556:INFO:               tbats: 1.1.3
2023-08-18 15:23:25,556:INFO:            pmdarima: 2.0.3
2023-08-18 15:23:25,556:INFO:              psutil: 5.9.5
2023-08-18 15:23:25,556:INFO:          markupsafe: 2.1.3
2023-08-18 15:23:25,556:INFO:             pickle5: Not installed
2023-08-18 15:23:25,556:INFO:         cloudpickle: 2.2.1
2023-08-18 15:23:25,556:INFO:         deprecation: 2.1.0
2023-08-18 15:23:25,556:INFO:              xxhash: 3.3.0
2023-08-18 15:23:25,556:INFO:           wurlitzer: 3.0.3
2023-08-18 15:23:25,556:INFO:PyCaret optional dependencies:
2023-08-18 15:23:26,661:INFO:                shap: 0.42.1
2023-08-18 15:23:26,661:INFO:           interpret: 0.4.3
2023-08-18 15:23:26,661:INFO:                umap: 0.5.3
2023-08-18 15:23:26,661:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:23:26,661:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:23:26,661:INFO:             autoviz: 0.1.730
2023-08-18 15:23:26,661:INFO:           fairlearn: 0.7.0
2023-08-18 15:23:26,662:INFO:          deepchecks: 0.17.4
2023-08-18 15:23:26,662:INFO:             xgboost: 1.7.6
2023-08-18 15:23:26,662:INFO:            catboost: 1.2
2023-08-18 15:23:26,662:INFO:              kmodes: 0.12.2
2023-08-18 15:23:26,662:INFO:             mlxtend: 0.22.0
2023-08-18 15:23:26,662:INFO:       statsforecast: 1.5.0
2023-08-18 15:23:26,662:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:23:26,662:INFO:                 ray: 2.6.3
2023-08-18 15:23:26,662:INFO:            hyperopt: 0.2.7
2023-08-18 15:23:26,662:INFO:              optuna: 3.3.0
2023-08-18 15:23:26,662:INFO:               skopt: 0.9.0
2023-08-18 15:23:26,662:INFO:              mlflow: 1.30.1
2023-08-18 15:23:26,662:INFO:              gradio: 3.40.1
2023-08-18 15:23:26,662:INFO:             fastapi: 0.101.1
2023-08-18 15:23:26,662:INFO:             uvicorn: 0.23.2
2023-08-18 15:23:26,662:INFO:              m2cgen: 0.10.0
2023-08-18 15:23:26,663:INFO:           evidently: 0.2.8
2023-08-18 15:23:26,663:INFO:               fugue: 0.8.6
2023-08-18 15:23:26,663:INFO:           streamlit: 1.25.0
2023-08-18 15:23:26,663:INFO:             prophet: 1.1.4
2023-08-18 15:23:26,663:INFO:None
2023-08-18 15:23:26,663:INFO:Set up data.
2023-08-18 15:23:26,861:INFO:Set up train/test split.
2023-08-18 15:23:27,002:INFO:Set up index.
2023-08-18 15:23:27,006:INFO:Set up folding strategy.
2023-08-18 15:23:27,006:INFO:Assigning column types.
2023-08-18 15:23:27,021:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:23:27,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:23:27,046:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:23:27,066:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:23:27,067:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:23:27,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:23:27,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:23:27,121:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:23:27,122:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:23:27,123:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:23:27,148:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:23:27,164:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:23:27,166:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:23:27,191:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:23:27,206:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:23:27,207:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:23:27,208:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:23:27,248:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:23:27,250:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:23:27,290:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:23:27,291:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:23:27,293:INFO:Preparing preprocessing pipeline...
2023-08-18 15:23:27,296:INFO:Set up label encoding.
2023-08-18 15:23:27,296:INFO:Set up simple imputation.
2023-08-18 15:23:27,327:INFO:Set up encoding of ordinal features.
2023-08-18 15:23:27,360:INFO:Set up encoding of categorical features.
2023-08-18 15:23:27,361:INFO:Set up removing outliers.
2023-08-18 15:23:27,361:INFO:Set up imbalanced handling.
2023-08-18 15:23:27,361:INFO:Set up feature normalization.
2023-08-18 15:23:27,363:INFO:Set up column name cleaning.
2023-08-18 15:23:29,247:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:23:29,286:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:23:29,286:INFO:Creating final display dataframe.
2023-08-18 15:23:30,818:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (426079, 42)
6   Transformed train set shape      (342688, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              822e
2023-08-18 15:23:30,862:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:23:30,864:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:23:30,907:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:23:30,908:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:23:30,909:INFO:setup() successfully completed in 5.98s...............
2023-08-18 15:26:41,142:INFO:PyCaret ClassificationExperiment
2023-08-18 15:26:41,142:INFO:Logging name: clf-default-name
2023-08-18 15:26:41,142:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:26:41,142:INFO:version 3.0.4
2023-08-18 15:26:41,142:INFO:Initializing setup()
2023-08-18 15:26:41,142:INFO:self.USI: a437
2023-08-18 15:26:41,142:INFO:self._variable_keys: {'idx', 'exp_name_log', 'exp_id', 'X_test', '_available_plots', 'target_param', 'n_jobs_param', 'X', 'fix_imbalance', 'fold_groups_param', 'USI', 'logging_param', 'memory', 'seed', 'X_train', 'y_test', 'gpu_n_jobs_param', '_ml_usecase', 'is_multiclass', 'gpu_param', 'data', 'fold_generator', 'y_train', 'y', 'pipeline', 'fold_shuffle_param', 'log_plots_param', 'html_param'}
2023-08-18 15:26:41,142:INFO:Checking environment
2023-08-18 15:26:41,143:INFO:python_version: 3.10.12
2023-08-18 15:26:41,143:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:26:41,143:INFO:machine: AMD64
2023-08-18 15:26:41,143:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:26:41,146:INFO:Memory: svmem(total=68448301056, available=50165886976, percent=26.7, used=18282414080, free=50165886976)
2023-08-18 15:26:41,147:INFO:Physical Core: 12
2023-08-18 15:26:41,147:INFO:Logical Core: 20
2023-08-18 15:26:41,147:INFO:Checking libraries
2023-08-18 15:26:41,147:INFO:System:
2023-08-18 15:26:41,147:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:26:41,147:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:26:41,147:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:26:41,147:INFO:PyCaret required dependencies:
2023-08-18 15:26:41,147:INFO:                 pip: 23.2.1
2023-08-18 15:26:41,147:INFO:          setuptools: 68.0.0
2023-08-18 15:26:41,147:INFO:             pycaret: 3.0.4
2023-08-18 15:26:41,147:INFO:             IPython: 7.34.0
2023-08-18 15:26:41,147:INFO:          ipywidgets: 7.8.0
2023-08-18 15:26:41,147:INFO:                tqdm: 4.66.1
2023-08-18 15:26:41,147:INFO:               numpy: 1.23.5
2023-08-18 15:26:41,147:INFO:              pandas: 1.5.3
2023-08-18 15:26:41,147:INFO:              jinja2: 3.1.2
2023-08-18 15:26:41,147:INFO:               scipy: 1.10.1
2023-08-18 15:26:41,147:INFO:              joblib: 1.3.2
2023-08-18 15:26:41,147:INFO:             sklearn: 1.2.2
2023-08-18 15:26:41,147:INFO:                pyod: 1.1.0
2023-08-18 15:26:41,147:INFO:            imblearn: 0.11.0
2023-08-18 15:26:41,147:INFO:   category_encoders: 2.6.2
2023-08-18 15:26:41,147:INFO:            lightgbm: 4.0.0
2023-08-18 15:26:41,147:INFO:               numba: 0.57.1
2023-08-18 15:26:41,147:INFO:            requests: 2.31.0
2023-08-18 15:26:41,147:INFO:          matplotlib: 3.7.2
2023-08-18 15:26:41,147:INFO:          scikitplot: 0.3.7
2023-08-18 15:26:41,147:INFO:         yellowbrick: 1.5
2023-08-18 15:26:41,147:INFO:              plotly: 5.16.1
2023-08-18 15:26:41,147:INFO:    plotly-resampler: Not installed
2023-08-18 15:26:41,147:INFO:             kaleido: 0.2.1
2023-08-18 15:26:41,147:INFO:           schemdraw: 0.15
2023-08-18 15:26:41,147:INFO:         statsmodels: 0.14.0
2023-08-18 15:26:41,147:INFO:              sktime: 0.21.0
2023-08-18 15:26:41,147:INFO:               tbats: 1.1.3
2023-08-18 15:26:41,147:INFO:            pmdarima: 2.0.3
2023-08-18 15:26:41,147:INFO:              psutil: 5.9.5
2023-08-18 15:26:41,147:INFO:          markupsafe: 2.1.3
2023-08-18 15:26:41,147:INFO:             pickle5: Not installed
2023-08-18 15:26:41,147:INFO:         cloudpickle: 2.2.1
2023-08-18 15:26:41,147:INFO:         deprecation: 2.1.0
2023-08-18 15:26:41,147:INFO:              xxhash: 3.3.0
2023-08-18 15:26:41,147:INFO:           wurlitzer: 3.0.3
2023-08-18 15:26:41,147:INFO:PyCaret optional dependencies:
2023-08-18 15:26:41,148:INFO:                shap: 0.42.1
2023-08-18 15:26:41,148:INFO:           interpret: 0.4.3
2023-08-18 15:26:41,148:INFO:                umap: 0.5.3
2023-08-18 15:26:41,148:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:26:41,148:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:26:41,148:INFO:             autoviz: 0.1.730
2023-08-18 15:26:41,148:INFO:           fairlearn: 0.7.0
2023-08-18 15:26:41,148:INFO:          deepchecks: 0.17.4
2023-08-18 15:26:41,148:INFO:             xgboost: 1.7.6
2023-08-18 15:26:41,148:INFO:            catboost: 1.2
2023-08-18 15:26:41,148:INFO:              kmodes: 0.12.2
2023-08-18 15:26:41,148:INFO:             mlxtend: 0.22.0
2023-08-18 15:26:41,148:INFO:       statsforecast: 1.5.0
2023-08-18 15:26:41,148:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:26:41,148:INFO:                 ray: 2.6.3
2023-08-18 15:26:41,148:INFO:            hyperopt: 0.2.7
2023-08-18 15:26:41,148:INFO:              optuna: 3.3.0
2023-08-18 15:26:41,148:INFO:               skopt: 0.9.0
2023-08-18 15:26:41,148:INFO:              mlflow: 1.30.1
2023-08-18 15:26:41,148:INFO:              gradio: 3.40.1
2023-08-18 15:26:41,148:INFO:             fastapi: 0.101.1
2023-08-18 15:26:41,148:INFO:             uvicorn: 0.23.2
2023-08-18 15:26:41,148:INFO:              m2cgen: 0.10.0
2023-08-18 15:26:41,148:INFO:           evidently: 0.2.8
2023-08-18 15:26:41,148:INFO:               fugue: 0.8.6
2023-08-18 15:26:41,148:INFO:           streamlit: 1.25.0
2023-08-18 15:26:41,148:INFO:             prophet: 1.1.4
2023-08-18 15:26:41,148:INFO:None
2023-08-18 15:26:41,148:INFO:Set up data.
2023-08-18 15:26:41,330:INFO:Set up train/test split.
2023-08-18 15:26:41,481:INFO:Set up index.
2023-08-18 15:26:41,487:INFO:Set up folding strategy.
2023-08-18 15:26:41,487:INFO:Assigning column types.
2023-08-18 15:26:41,507:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:26:41,531:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:26:41,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:26:41,547:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:26:41,549:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:26:41,574:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:26:41,575:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:26:41,593:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:26:41,597:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:26:41,598:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:26:41,626:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:26:41,642:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:26:41,643:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:26:41,669:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:26:41,686:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:26:41,689:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:26:41,690:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:26:41,735:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:26:41,736:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:26:41,778:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:26:41,779:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:26:41,781:INFO:Preparing preprocessing pipeline...
2023-08-18 15:26:41,785:INFO:Set up label encoding.
2023-08-18 15:26:41,785:INFO:Set up simple imputation.
2023-08-18 15:26:41,840:INFO:Set up encoding of ordinal features.
2023-08-18 15:26:41,890:INFO:Set up encoding of categorical features.
2023-08-18 15:26:41,890:INFO:Set up removing outliers.
2023-08-18 15:26:41,890:INFO:Set up imbalanced handling.
2023-08-18 15:26:41,890:INFO:Set up feature normalization.
2023-08-18 15:26:41,893:INFO:Set up column name cleaning.
2023-08-18 15:26:43,973:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:26:44,025:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:26:44,026:INFO:Creating final display dataframe.
2023-08-18 15:26:45,540:INFO:Setup _display_container:            Description                Value      
0                    Session id               559
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (425485, 42)
6   Transformed train set shape      (342094, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              a437
2023-08-18 15:26:45,583:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:26:45,585:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:26:45,630:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:26:45,631:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:26:45,633:INFO:setup() successfully completed in 4.77s...............
2023-08-18 15:28:37,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:28:37,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:28:37,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:28:37,940:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:28:38,837:INFO:PyCaret ClassificationExperiment
2023-08-18 15:28:38,837:INFO:Logging name: clf-default-name
2023-08-18 15:28:38,837:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:28:38,837:INFO:version 3.0.4
2023-08-18 15:28:38,837:INFO:Initializing setup()
2023-08-18 15:28:38,838:INFO:self.USI: aaa5
2023-08-18 15:28:38,838:INFO:self._variable_keys: {'_ml_usecase', 'html_param', 'X_test', 'exp_id', 'log_plots_param', 'y_test', 'n_jobs_param', 'fold_generator', 'pipeline', 'fold_shuffle_param', 'data', 'USI', 'exp_name_log', 'y', 'gpu_n_jobs_param', 'idx', 'fold_groups_param', 'gpu_param', 'target_param', 'fix_imbalance', 'X_train', 'y_train', 'X', 'logging_param', 'seed', 'memory', 'is_multiclass', '_available_plots'}
2023-08-18 15:28:38,838:INFO:Checking environment
2023-08-18 15:28:38,838:INFO:python_version: 3.10.12
2023-08-18 15:28:38,838:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:28:38,838:INFO:machine: AMD64
2023-08-18 15:28:38,838:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:28:38,842:INFO:Memory: svmem(total=68448301056, available=50607763456, percent=26.1, used=17840537600, free=50607763456)
2023-08-18 15:28:38,842:INFO:Physical Core: 12
2023-08-18 15:28:38,842:INFO:Logical Core: 20
2023-08-18 15:28:38,842:INFO:Checking libraries
2023-08-18 15:28:38,842:INFO:System:
2023-08-18 15:28:38,842:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:28:38,842:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:28:38,842:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:28:38,842:INFO:PyCaret required dependencies:
2023-08-18 15:28:39,201:INFO:                 pip: 23.2.1
2023-08-18 15:28:39,201:INFO:          setuptools: 68.0.0
2023-08-18 15:28:39,201:INFO:             pycaret: 3.0.4
2023-08-18 15:28:39,201:INFO:             IPython: 7.34.0
2023-08-18 15:28:39,201:INFO:          ipywidgets: 7.8.0
2023-08-18 15:28:39,201:INFO:                tqdm: 4.66.1
2023-08-18 15:28:39,201:INFO:               numpy: 1.23.5
2023-08-18 15:28:39,201:INFO:              pandas: 1.5.3
2023-08-18 15:28:39,201:INFO:              jinja2: 3.1.2
2023-08-18 15:28:39,201:INFO:               scipy: 1.10.1
2023-08-18 15:28:39,201:INFO:              joblib: 1.3.2
2023-08-18 15:28:39,201:INFO:             sklearn: 1.2.2
2023-08-18 15:28:39,201:INFO:                pyod: 1.1.0
2023-08-18 15:28:39,201:INFO:            imblearn: 0.11.0
2023-08-18 15:28:39,201:INFO:   category_encoders: 2.6.2
2023-08-18 15:28:39,201:INFO:            lightgbm: 4.0.0
2023-08-18 15:28:39,201:INFO:               numba: 0.57.1
2023-08-18 15:28:39,201:INFO:            requests: 2.31.0
2023-08-18 15:28:39,201:INFO:          matplotlib: 3.7.2
2023-08-18 15:28:39,201:INFO:          scikitplot: 0.3.7
2023-08-18 15:28:39,201:INFO:         yellowbrick: 1.5
2023-08-18 15:28:39,201:INFO:              plotly: 5.16.1
2023-08-18 15:28:39,201:INFO:    plotly-resampler: Not installed
2023-08-18 15:28:39,201:INFO:             kaleido: 0.2.1
2023-08-18 15:28:39,201:INFO:           schemdraw: 0.15
2023-08-18 15:28:39,201:INFO:         statsmodels: 0.14.0
2023-08-18 15:28:39,201:INFO:              sktime: 0.21.0
2023-08-18 15:28:39,201:INFO:               tbats: 1.1.3
2023-08-18 15:28:39,202:INFO:            pmdarima: 2.0.3
2023-08-18 15:28:39,202:INFO:              psutil: 5.9.5
2023-08-18 15:28:39,202:INFO:          markupsafe: 2.1.3
2023-08-18 15:28:39,202:INFO:             pickle5: Not installed
2023-08-18 15:28:39,202:INFO:         cloudpickle: 2.2.1
2023-08-18 15:28:39,202:INFO:         deprecation: 2.1.0
2023-08-18 15:28:39,202:INFO:              xxhash: 3.3.0
2023-08-18 15:28:39,202:INFO:           wurlitzer: 3.0.3
2023-08-18 15:28:39,202:INFO:PyCaret optional dependencies:
2023-08-18 15:28:40,333:INFO:                shap: 0.42.1
2023-08-18 15:28:40,333:INFO:           interpret: 0.4.3
2023-08-18 15:28:40,333:INFO:                umap: 0.5.3
2023-08-18 15:28:40,333:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:28:40,333:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:28:40,333:INFO:             autoviz: 0.1.730
2023-08-18 15:28:40,333:INFO:           fairlearn: 0.7.0
2023-08-18 15:28:40,333:INFO:          deepchecks: 0.17.4
2023-08-18 15:28:40,333:INFO:             xgboost: 1.7.6
2023-08-18 15:28:40,333:INFO:            catboost: 1.2
2023-08-18 15:28:40,333:INFO:              kmodes: 0.12.2
2023-08-18 15:28:40,333:INFO:             mlxtend: 0.22.0
2023-08-18 15:28:40,333:INFO:       statsforecast: 1.5.0
2023-08-18 15:28:40,333:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:28:40,333:INFO:                 ray: 2.6.3
2023-08-18 15:28:40,333:INFO:            hyperopt: 0.2.7
2023-08-18 15:28:40,333:INFO:              optuna: 3.3.0
2023-08-18 15:28:40,333:INFO:               skopt: 0.9.0
2023-08-18 15:28:40,333:INFO:              mlflow: 1.30.1
2023-08-18 15:28:40,333:INFO:              gradio: 3.40.1
2023-08-18 15:28:40,333:INFO:             fastapi: 0.101.1
2023-08-18 15:28:40,333:INFO:             uvicorn: 0.23.2
2023-08-18 15:28:40,333:INFO:              m2cgen: 0.10.0
2023-08-18 15:28:40,333:INFO:           evidently: 0.2.8
2023-08-18 15:28:40,333:INFO:               fugue: 0.8.6
2023-08-18 15:28:40,333:INFO:           streamlit: 1.25.0
2023-08-18 15:28:40,333:INFO:             prophet: 1.1.4
2023-08-18 15:28:40,333:INFO:None
2023-08-18 15:28:40,333:INFO:Set up data.
2023-08-18 15:28:40,505:INFO:Set up train/test split.
2023-08-18 15:28:40,649:INFO:Set up index.
2023-08-18 15:28:40,653:INFO:Set up folding strategy.
2023-08-18 15:28:40,653:INFO:Assigning column types.
2023-08-18 15:28:40,670:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:28:40,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:28:40,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:28:40,714:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:28:40,716:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:28:40,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:28:40,755:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:28:40,773:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:28:40,776:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:28:40,776:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:28:40,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:28:40,818:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:28:40,819:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:28:40,845:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:28:40,860:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:28:40,862:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:28:40,863:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:28:40,902:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:28:40,905:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:28:40,944:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:28:40,946:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:28:40,948:INFO:Preparing preprocessing pipeline...
2023-08-18 15:28:40,951:INFO:Set up label encoding.
2023-08-18 15:28:40,951:INFO:Set up simple imputation.
2023-08-18 15:28:40,983:INFO:Set up encoding of ordinal features.
2023-08-18 15:28:41,018:INFO:Set up encoding of categorical features.
2023-08-18 15:28:41,019:INFO:Set up removing outliers.
2023-08-18 15:28:41,019:INFO:Set up imbalanced handling.
2023-08-18 15:28:41,019:INFO:Set up feature normalization.
2023-08-18 15:28:41,021:INFO:Set up column name cleaning.
2023-08-18 15:28:41,762:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:28:41,803:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:28:41,803:INFO:Creating final display dataframe.
2023-08-18 15:28:43,317:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (426079, 42)
6   Transformed train set shape      (342688, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              aaa5
2023-08-18 15:28:43,363:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:28:43,365:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:28:43,405:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:28:43,407:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:28:43,407:INFO:setup() successfully completed in 4.97s...............
2023-08-18 15:35:24,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:35:24,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:35:24,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:35:24,362:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:35:25,063:INFO:PyCaret ClassificationExperiment
2023-08-18 15:35:25,063:INFO:Logging name: clf-default-name
2023-08-18 15:35:25,064:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:35:25,064:INFO:version 3.0.4
2023-08-18 15:35:25,064:INFO:Initializing setup()
2023-08-18 15:35:25,064:INFO:self.USI: e9ac
2023-08-18 15:35:25,064:INFO:self._variable_keys: {'idx', 'fold_groups_param', 'USI', 'exp_id', 'memory', 'y_test', '_available_plots', '_ml_usecase', 'pipeline', 'X_test', 'target_param', 'n_jobs_param', 'seed', 'y_train', 'exp_name_log', 'is_multiclass', 'fold_shuffle_param', 'y', 'html_param', 'fix_imbalance', 'fold_generator', 'gpu_param', 'X', 'logging_param', 'X_train', 'log_plots_param', 'data', 'gpu_n_jobs_param'}
2023-08-18 15:35:25,064:INFO:Checking environment
2023-08-18 15:35:25,064:INFO:python_version: 3.10.12
2023-08-18 15:35:25,064:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:35:25,064:INFO:machine: AMD64
2023-08-18 15:35:25,064:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:35:25,072:INFO:Memory: svmem(total=68448301056, available=50339319808, percent=26.5, used=18108981248, free=50339319808)
2023-08-18 15:35:25,072:INFO:Physical Core: 12
2023-08-18 15:35:25,072:INFO:Logical Core: 20
2023-08-18 15:35:25,072:INFO:Checking libraries
2023-08-18 15:35:25,072:INFO:System:
2023-08-18 15:35:25,072:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:35:25,072:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:35:25,072:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:35:25,072:INFO:PyCaret required dependencies:
2023-08-18 15:35:25,417:INFO:                 pip: 23.2.1
2023-08-18 15:35:25,417:INFO:          setuptools: 68.0.0
2023-08-18 15:35:25,417:INFO:             pycaret: 3.0.4
2023-08-18 15:35:25,417:INFO:             IPython: 7.34.0
2023-08-18 15:35:25,417:INFO:          ipywidgets: 7.8.0
2023-08-18 15:35:25,417:INFO:                tqdm: 4.66.1
2023-08-18 15:35:25,417:INFO:               numpy: 1.23.5
2023-08-18 15:35:25,417:INFO:              pandas: 1.5.3
2023-08-18 15:35:25,417:INFO:              jinja2: 3.1.2
2023-08-18 15:35:25,417:INFO:               scipy: 1.10.1
2023-08-18 15:35:25,417:INFO:              joblib: 1.3.2
2023-08-18 15:35:25,417:INFO:             sklearn: 1.2.2
2023-08-18 15:35:25,417:INFO:                pyod: 1.1.0
2023-08-18 15:35:25,417:INFO:            imblearn: 0.11.0
2023-08-18 15:35:25,417:INFO:   category_encoders: 2.6.2
2023-08-18 15:35:25,417:INFO:            lightgbm: 4.0.0
2023-08-18 15:35:25,417:INFO:               numba: 0.57.1
2023-08-18 15:35:25,417:INFO:            requests: 2.31.0
2023-08-18 15:35:25,417:INFO:          matplotlib: 3.7.2
2023-08-18 15:35:25,417:INFO:          scikitplot: 0.3.7
2023-08-18 15:35:25,417:INFO:         yellowbrick: 1.5
2023-08-18 15:35:25,417:INFO:              plotly: 5.16.1
2023-08-18 15:35:25,417:INFO:    plotly-resampler: Not installed
2023-08-18 15:35:25,417:INFO:             kaleido: 0.2.1
2023-08-18 15:35:25,417:INFO:           schemdraw: 0.15
2023-08-18 15:35:25,417:INFO:         statsmodels: 0.14.0
2023-08-18 15:35:25,418:INFO:              sktime: 0.21.0
2023-08-18 15:35:25,418:INFO:               tbats: 1.1.3
2023-08-18 15:35:25,418:INFO:            pmdarima: 2.0.3
2023-08-18 15:35:25,418:INFO:              psutil: 5.9.5
2023-08-18 15:35:25,418:INFO:          markupsafe: 2.1.3
2023-08-18 15:35:25,418:INFO:             pickle5: Not installed
2023-08-18 15:35:25,418:INFO:         cloudpickle: 2.2.1
2023-08-18 15:35:25,418:INFO:         deprecation: 2.1.0
2023-08-18 15:35:25,418:INFO:              xxhash: 3.3.0
2023-08-18 15:35:25,418:INFO:           wurlitzer: 3.0.3
2023-08-18 15:35:25,418:INFO:PyCaret optional dependencies:
2023-08-18 15:35:26,543:INFO:                shap: 0.42.1
2023-08-18 15:35:26,543:INFO:           interpret: 0.4.3
2023-08-18 15:35:26,543:INFO:                umap: 0.5.3
2023-08-18 15:35:26,543:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:35:26,543:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:35:26,543:INFO:             autoviz: 0.1.730
2023-08-18 15:35:26,543:INFO:           fairlearn: 0.7.0
2023-08-18 15:35:26,543:INFO:          deepchecks: 0.17.4
2023-08-18 15:35:26,543:INFO:             xgboost: 1.7.6
2023-08-18 15:35:26,543:INFO:            catboost: 1.2
2023-08-18 15:35:26,543:INFO:              kmodes: 0.12.2
2023-08-18 15:35:26,543:INFO:             mlxtend: 0.22.0
2023-08-18 15:35:26,543:INFO:       statsforecast: 1.5.0
2023-08-18 15:35:26,543:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:35:26,543:INFO:                 ray: 2.6.3
2023-08-18 15:35:26,543:INFO:            hyperopt: 0.2.7
2023-08-18 15:35:26,543:INFO:              optuna: 3.3.0
2023-08-18 15:35:26,543:INFO:               skopt: 0.9.0
2023-08-18 15:35:26,543:INFO:              mlflow: 1.30.1
2023-08-18 15:35:26,543:INFO:              gradio: 3.40.1
2023-08-18 15:35:26,543:INFO:             fastapi: 0.101.1
2023-08-18 15:35:26,543:INFO:             uvicorn: 0.23.2
2023-08-18 15:35:26,543:INFO:              m2cgen: 0.10.0
2023-08-18 15:35:26,543:INFO:           evidently: 0.2.8
2023-08-18 15:35:26,543:INFO:               fugue: 0.8.6
2023-08-18 15:35:26,543:INFO:           streamlit: 1.25.0
2023-08-18 15:35:26,543:INFO:             prophet: 1.1.4
2023-08-18 15:35:26,543:INFO:None
2023-08-18 15:35:26,543:INFO:Set up data.
2023-08-18 15:35:26,720:INFO:Set up train/test split.
2023-08-18 15:35:26,888:INFO:Set up index.
2023-08-18 15:35:26,892:INFO:Set up folding strategy.
2023-08-18 15:35:26,893:INFO:Assigning column types.
2023-08-18 15:35:26,908:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:35:26,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:35:26,933:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:35:26,953:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:35:26,955:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:35:26,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:35:26,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:35:27,009:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:35:27,010:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:35:27,011:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:35:27,036:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:35:27,051:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:35:27,052:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:35:27,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:35:27,093:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:35:27,094:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:35:27,095:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:35:27,134:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:35:27,136:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:35:27,175:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:35:27,177:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:35:27,178:INFO:Preparing preprocessing pipeline...
2023-08-18 15:35:27,182:INFO:Set up label encoding.
2023-08-18 15:35:27,182:INFO:Set up simple imputation.
2023-08-18 15:35:27,214:INFO:Set up encoding of ordinal features.
2023-08-18 15:35:27,249:INFO:Set up encoding of categorical features.
2023-08-18 15:35:27,249:INFO:Set up removing outliers.
2023-08-18 15:35:27,249:INFO:Set up imbalanced handling.
2023-08-18 15:35:27,249:INFO:Set up feature normalization.
2023-08-18 15:35:27,251:INFO:Set up column name cleaning.
2023-08-18 15:35:27,990:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:35:28,031:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:35:28,031:INFO:Creating final display dataframe.
2023-08-18 15:35:28,397:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (426079, 42)
6   Transformed train set shape      (342688, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              e9ac
2023-08-18 15:35:28,443:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:35:28,445:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:35:28,486:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:35:28,487:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:35:28,488:INFO:setup() successfully completed in 3.69s...............
2023-08-18 15:36:16,579:INFO:PyCaret ClassificationExperiment
2023-08-18 15:36:16,579:INFO:Logging name: clf-default-name
2023-08-18 15:36:16,579:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:36:16,579:INFO:version 3.0.4
2023-08-18 15:36:16,579:INFO:Initializing setup()
2023-08-18 15:36:16,579:INFO:self.USI: 2d14
2023-08-18 15:36:16,579:INFO:self._variable_keys: {'idx', 'fold_groups_param', 'USI', 'exp_id', 'memory', 'y_test', '_available_plots', '_ml_usecase', 'pipeline', 'X_test', 'target_param', 'n_jobs_param', 'seed', 'y_train', 'exp_name_log', 'is_multiclass', 'fold_shuffle_param', 'y', 'html_param', 'fix_imbalance', 'fold_generator', 'gpu_param', 'X', 'logging_param', 'X_train', 'log_plots_param', 'data', 'gpu_n_jobs_param'}
2023-08-18 15:36:16,579:INFO:Checking environment
2023-08-18 15:36:16,579:INFO:python_version: 3.10.12
2023-08-18 15:36:16,579:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:36:16,579:INFO:machine: AMD64
2023-08-18 15:36:16,579:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:36:16,583:INFO:Memory: svmem(total=68448301056, available=50257154048, percent=26.6, used=18191147008, free=50257154048)
2023-08-18 15:36:16,583:INFO:Physical Core: 12
2023-08-18 15:36:16,583:INFO:Logical Core: 20
2023-08-18 15:36:16,583:INFO:Checking libraries
2023-08-18 15:36:16,583:INFO:System:
2023-08-18 15:36:16,583:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:36:16,583:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:36:16,583:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:36:16,583:INFO:PyCaret required dependencies:
2023-08-18 15:36:16,583:INFO:                 pip: 23.2.1
2023-08-18 15:36:16,583:INFO:          setuptools: 68.0.0
2023-08-18 15:36:16,583:INFO:             pycaret: 3.0.4
2023-08-18 15:36:16,583:INFO:             IPython: 7.34.0
2023-08-18 15:36:16,583:INFO:          ipywidgets: 7.8.0
2023-08-18 15:36:16,583:INFO:                tqdm: 4.66.1
2023-08-18 15:36:16,583:INFO:               numpy: 1.23.5
2023-08-18 15:36:16,583:INFO:              pandas: 1.5.3
2023-08-18 15:36:16,583:INFO:              jinja2: 3.1.2
2023-08-18 15:36:16,583:INFO:               scipy: 1.10.1
2023-08-18 15:36:16,583:INFO:              joblib: 1.3.2
2023-08-18 15:36:16,583:INFO:             sklearn: 1.2.2
2023-08-18 15:36:16,583:INFO:                pyod: 1.1.0
2023-08-18 15:36:16,583:INFO:            imblearn: 0.11.0
2023-08-18 15:36:16,583:INFO:   category_encoders: 2.6.2
2023-08-18 15:36:16,583:INFO:            lightgbm: 4.0.0
2023-08-18 15:36:16,583:INFO:               numba: 0.57.1
2023-08-18 15:36:16,583:INFO:            requests: 2.31.0
2023-08-18 15:36:16,583:INFO:          matplotlib: 3.7.2
2023-08-18 15:36:16,583:INFO:          scikitplot: 0.3.7
2023-08-18 15:36:16,583:INFO:         yellowbrick: 1.5
2023-08-18 15:36:16,583:INFO:              plotly: 5.16.1
2023-08-18 15:36:16,583:INFO:    plotly-resampler: Not installed
2023-08-18 15:36:16,583:INFO:             kaleido: 0.2.1
2023-08-18 15:36:16,584:INFO:           schemdraw: 0.15
2023-08-18 15:36:16,584:INFO:         statsmodels: 0.14.0
2023-08-18 15:36:16,584:INFO:              sktime: 0.21.0
2023-08-18 15:36:16,584:INFO:               tbats: 1.1.3
2023-08-18 15:36:16,584:INFO:            pmdarima: 2.0.3
2023-08-18 15:36:16,584:INFO:              psutil: 5.9.5
2023-08-18 15:36:16,584:INFO:          markupsafe: 2.1.3
2023-08-18 15:36:16,584:INFO:             pickle5: Not installed
2023-08-18 15:36:16,584:INFO:         cloudpickle: 2.2.1
2023-08-18 15:36:16,584:INFO:         deprecation: 2.1.0
2023-08-18 15:36:16,584:INFO:              xxhash: 3.3.0
2023-08-18 15:36:16,584:INFO:           wurlitzer: 3.0.3
2023-08-18 15:36:16,584:INFO:PyCaret optional dependencies:
2023-08-18 15:36:16,584:INFO:                shap: 0.42.1
2023-08-18 15:36:16,584:INFO:           interpret: 0.4.3
2023-08-18 15:36:16,584:INFO:                umap: 0.5.3
2023-08-18 15:36:16,584:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:36:16,584:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:36:16,584:INFO:             autoviz: 0.1.730
2023-08-18 15:36:16,584:INFO:           fairlearn: 0.7.0
2023-08-18 15:36:16,584:INFO:          deepchecks: 0.17.4
2023-08-18 15:36:16,584:INFO:             xgboost: 1.7.6
2023-08-18 15:36:16,584:INFO:            catboost: 1.2
2023-08-18 15:36:16,584:INFO:              kmodes: 0.12.2
2023-08-18 15:36:16,584:INFO:             mlxtend: 0.22.0
2023-08-18 15:36:16,584:INFO:       statsforecast: 1.5.0
2023-08-18 15:36:16,584:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:36:16,584:INFO:                 ray: 2.6.3
2023-08-18 15:36:16,584:INFO:            hyperopt: 0.2.7
2023-08-18 15:36:16,584:INFO:              optuna: 3.3.0
2023-08-18 15:36:16,584:INFO:               skopt: 0.9.0
2023-08-18 15:36:16,584:INFO:              mlflow: 1.30.1
2023-08-18 15:36:16,584:INFO:              gradio: 3.40.1
2023-08-18 15:36:16,584:INFO:             fastapi: 0.101.1
2023-08-18 15:36:16,584:INFO:             uvicorn: 0.23.2
2023-08-18 15:36:16,584:INFO:              m2cgen: 0.10.0
2023-08-18 15:36:16,584:INFO:           evidently: 0.2.8
2023-08-18 15:36:16,584:INFO:               fugue: 0.8.6
2023-08-18 15:36:16,584:INFO:           streamlit: 1.25.0
2023-08-18 15:36:16,584:INFO:             prophet: 1.1.4
2023-08-18 15:36:16,584:INFO:None
2023-08-18 15:36:16,584:INFO:Set up data.
2023-08-18 15:36:16,764:INFO:Set up train/test split.
2023-08-18 15:36:16,908:INFO:Set up index.
2023-08-18 15:36:16,913:INFO:Set up folding strategy.
2023-08-18 15:36:16,913:INFO:Assigning column types.
2023-08-18 15:36:16,933:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:36:16,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:36:16,957:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:36:16,973:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:36:16,974:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:36:16,998:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:36:16,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:36:17,014:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:36:17,016:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:36:17,016:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:36:17,041:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:36:17,057:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:36:17,058:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:36:17,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:36:17,099:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:36:17,101:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:36:17,101:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:36:17,142:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:36:17,143:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:36:17,183:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:36:17,185:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:36:17,186:INFO:Preparing preprocessing pipeline...
2023-08-18 15:36:17,189:INFO:Set up label encoding.
2023-08-18 15:36:17,189:INFO:Set up simple imputation.
2023-08-18 15:36:17,221:INFO:Set up encoding of ordinal features.
2023-08-18 15:36:17,257:INFO:Set up encoding of categorical features.
2023-08-18 15:36:17,257:INFO:Set up removing outliers.
2023-08-18 15:36:17,257:INFO:Set up imbalanced handling.
2023-08-18 15:36:17,257:INFO:Set up feature normalization.
2023-08-18 15:36:17,259:INFO:Set up column name cleaning.
2023-08-18 15:36:18,031:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:36:18,071:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:36:18,071:INFO:Creating final display dataframe.
2023-08-18 15:36:19,625:INFO:Setup _display_container:            Description                Value      
0                    Session id               559
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (425485, 42)
6   Transformed train set shape      (342094, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              2d14
2023-08-18 15:36:19,671:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:36:19,672:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:36:19,714:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:36:19,716:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:36:19,717:INFO:setup() successfully completed in 3.4s...............
2023-08-18 15:40:18,744:INFO:PyCaret ClassificationExperiment
2023-08-18 15:40:18,744:INFO:Logging name: clf-default-name
2023-08-18 15:40:18,744:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:40:18,744:INFO:version 3.0.4
2023-08-18 15:40:18,744:INFO:Initializing setup()
2023-08-18 15:40:18,744:INFO:self.USI: 056c
2023-08-18 15:40:18,744:INFO:self._variable_keys: {'idx', 'fold_groups_param', 'USI', 'exp_id', 'memory', 'y_test', '_available_plots', '_ml_usecase', 'pipeline', 'X_test', 'target_param', 'n_jobs_param', 'seed', 'y_train', 'exp_name_log', 'is_multiclass', 'fold_shuffle_param', 'y', 'html_param', 'fix_imbalance', 'fold_generator', 'gpu_param', 'X', 'logging_param', 'X_train', 'log_plots_param', 'data', 'gpu_n_jobs_param'}
2023-08-18 15:40:18,744:INFO:Checking environment
2023-08-18 15:40:18,744:INFO:python_version: 3.10.12
2023-08-18 15:40:18,745:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:40:18,745:INFO:machine: AMD64
2023-08-18 15:40:18,745:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:40:18,748:INFO:Memory: svmem(total=68448301056, available=49783996416, percent=27.3, used=18664304640, free=49783996416)
2023-08-18 15:40:18,748:INFO:Physical Core: 12
2023-08-18 15:40:18,748:INFO:Logical Core: 20
2023-08-18 15:40:18,748:INFO:Checking libraries
2023-08-18 15:40:18,748:INFO:System:
2023-08-18 15:40:18,748:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:40:18,748:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:40:18,748:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:40:18,748:INFO:PyCaret required dependencies:
2023-08-18 15:40:18,749:INFO:                 pip: 23.2.1
2023-08-18 15:40:18,749:INFO:          setuptools: 68.0.0
2023-08-18 15:40:18,749:INFO:             pycaret: 3.0.4
2023-08-18 15:40:18,749:INFO:             IPython: 7.34.0
2023-08-18 15:40:18,749:INFO:          ipywidgets: 7.8.0
2023-08-18 15:40:18,749:INFO:                tqdm: 4.66.1
2023-08-18 15:40:18,749:INFO:               numpy: 1.23.5
2023-08-18 15:40:18,749:INFO:              pandas: 1.5.3
2023-08-18 15:40:18,749:INFO:              jinja2: 3.1.2
2023-08-18 15:40:18,749:INFO:               scipy: 1.10.1
2023-08-18 15:40:18,749:INFO:              joblib: 1.3.2
2023-08-18 15:40:18,749:INFO:             sklearn: 1.2.2
2023-08-18 15:40:18,749:INFO:                pyod: 1.1.0
2023-08-18 15:40:18,749:INFO:            imblearn: 0.11.0
2023-08-18 15:40:18,749:INFO:   category_encoders: 2.6.2
2023-08-18 15:40:18,749:INFO:            lightgbm: 4.0.0
2023-08-18 15:40:18,749:INFO:               numba: 0.57.1
2023-08-18 15:40:18,749:INFO:            requests: 2.31.0
2023-08-18 15:40:18,749:INFO:          matplotlib: 3.7.2
2023-08-18 15:40:18,749:INFO:          scikitplot: 0.3.7
2023-08-18 15:40:18,749:INFO:         yellowbrick: 1.5
2023-08-18 15:40:18,749:INFO:              plotly: 5.16.1
2023-08-18 15:40:18,749:INFO:    plotly-resampler: Not installed
2023-08-18 15:40:18,749:INFO:             kaleido: 0.2.1
2023-08-18 15:40:18,749:INFO:           schemdraw: 0.15
2023-08-18 15:40:18,749:INFO:         statsmodels: 0.14.0
2023-08-18 15:40:18,749:INFO:              sktime: 0.21.0
2023-08-18 15:40:18,749:INFO:               tbats: 1.1.3
2023-08-18 15:40:18,749:INFO:            pmdarima: 2.0.3
2023-08-18 15:40:18,749:INFO:              psutil: 5.9.5
2023-08-18 15:40:18,749:INFO:          markupsafe: 2.1.3
2023-08-18 15:40:18,749:INFO:             pickle5: Not installed
2023-08-18 15:40:18,749:INFO:         cloudpickle: 2.2.1
2023-08-18 15:40:18,749:INFO:         deprecation: 2.1.0
2023-08-18 15:40:18,749:INFO:              xxhash: 3.3.0
2023-08-18 15:40:18,749:INFO:           wurlitzer: 3.0.3
2023-08-18 15:40:18,749:INFO:PyCaret optional dependencies:
2023-08-18 15:40:18,749:INFO:                shap: 0.42.1
2023-08-18 15:40:18,749:INFO:           interpret: 0.4.3
2023-08-18 15:40:18,749:INFO:                umap: 0.5.3
2023-08-18 15:40:18,749:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:40:18,749:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:40:18,749:INFO:             autoviz: 0.1.730
2023-08-18 15:40:18,749:INFO:           fairlearn: 0.7.0
2023-08-18 15:40:18,749:INFO:          deepchecks: 0.17.4
2023-08-18 15:40:18,749:INFO:             xgboost: 1.7.6
2023-08-18 15:40:18,749:INFO:            catboost: 1.2
2023-08-18 15:40:18,749:INFO:              kmodes: 0.12.2
2023-08-18 15:40:18,750:INFO:             mlxtend: 0.22.0
2023-08-18 15:40:18,750:INFO:       statsforecast: 1.5.0
2023-08-18 15:40:18,750:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:40:18,750:INFO:                 ray: 2.6.3
2023-08-18 15:40:18,750:INFO:            hyperopt: 0.2.7
2023-08-18 15:40:18,750:INFO:              optuna: 3.3.0
2023-08-18 15:40:18,750:INFO:               skopt: 0.9.0
2023-08-18 15:40:18,750:INFO:              mlflow: 1.30.1
2023-08-18 15:40:18,750:INFO:              gradio: 3.40.1
2023-08-18 15:40:18,750:INFO:             fastapi: 0.101.1
2023-08-18 15:40:18,750:INFO:             uvicorn: 0.23.2
2023-08-18 15:40:18,750:INFO:              m2cgen: 0.10.0
2023-08-18 15:40:18,750:INFO:           evidently: 0.2.8
2023-08-18 15:40:18,750:INFO:               fugue: 0.8.6
2023-08-18 15:40:18,750:INFO:           streamlit: 1.25.0
2023-08-18 15:40:18,750:INFO:             prophet: 1.1.4
2023-08-18 15:40:18,750:INFO:None
2023-08-18 15:40:18,750:INFO:Set up data.
2023-08-18 15:40:18,927:INFO:Set up train/test split.
2023-08-18 15:40:19,064:INFO:Set up index.
2023-08-18 15:40:19,068:INFO:Set up folding strategy.
2023-08-18 15:40:19,068:INFO:Assigning column types.
2023-08-18 15:40:19,079:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:40:19,103:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:40:19,103:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:40:19,118:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:40:19,120:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:40:19,144:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:40:19,145:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:40:19,160:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:40:19,161:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:40:19,162:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:40:19,188:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:40:19,204:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:40:19,205:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:40:19,231:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:40:19,246:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:40:19,248:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:40:19,248:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:40:19,290:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:40:19,291:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:40:19,332:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:40:19,334:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:40:19,335:INFO:Preparing preprocessing pipeline...
2023-08-18 15:40:19,338:INFO:Set up label encoding.
2023-08-18 15:40:19,338:INFO:Set up simple imputation.
2023-08-18 15:40:19,369:INFO:Set up encoding of ordinal features.
2023-08-18 15:40:19,404:INFO:Set up encoding of categorical features.
2023-08-18 15:40:19,404:INFO:Set up removing outliers.
2023-08-18 15:40:19,404:INFO:Set up feature normalization.
2023-08-18 15:40:19,406:INFO:Set up column name cleaning.
2023-08-18 15:40:32,108:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:40:32,151:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=4656,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:40:32,151:INFO:Creating final display dataframe.
2023-08-18 15:40:44,038:INFO:Setup _display_container:            Description                Value      
0                    Session id              4656
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 17)
5        Transformed data shape      (268239, 33)
6   Transformed train set shape      (184848, 33)
7    Transformed test set shape       (83391, 33)
8              Ordinal features                 8
9              Numeric features                 6
10         Categorical features                10
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              056c
2023-08-18 15:40:44,091:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:40:44,095:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:40:44,146:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:40:44,147:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:40:44,149:INFO:setup() successfully completed in 25.67s...............
2023-08-18 15:41:05,519:INFO:Initializing compare_models()
2023-08-18 15:41:05,519:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-18 15:41:05,519:INFO:Checking exceptions
2023-08-18 15:41:05,539:INFO:Preparing display monitor
2023-08-18 15:41:05,558:INFO:Initializing Logistic Regression
2023-08-18 15:41:05,558:INFO:Total runtime is 0.0 minutes
2023-08-18 15:41:05,560:INFO:SubProcess create_model() called ==================================
2023-08-18 15:41:05,560:INFO:Initializing create_model()
2023-08-18 15:41:05,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:41:05,561:INFO:Checking exceptions
2023-08-18 15:41:05,561:INFO:Importing libraries
2023-08-18 15:41:05,561:INFO:Copying training dataset
2023-08-18 15:41:05,603:INFO:Defining folds
2023-08-18 15:41:05,604:INFO:Declaring metric variables
2023-08-18 15:41:05,606:INFO:Importing untrained model
2023-08-18 15:41:05,609:INFO:Logistic Regression Imported successfully
2023-08-18 15:41:05,612:INFO:Starting cross validation
2023-08-18 15:41:05,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:41:15,303:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:15,356:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:15,364:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:15,418:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:15,423:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:15,444:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:15,503:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:15,507:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:15,571:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 15:41:49,217:INFO:Calculating mean and std
2023-08-18 15:41:49,218:INFO:Creating metrics dataframe
2023-08-18 15:41:49,658:INFO:Uploading results into container
2023-08-18 15:41:49,659:INFO:Uploading model into container now
2023-08-18 15:41:49,660:INFO:_master_model_container: 1
2023-08-18 15:41:49,660:INFO:_display_container: 2
2023-08-18 15:41:49,660:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4656, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-18 15:41:49,660:INFO:create_model() successfully completed......................................
2023-08-18 15:41:49,885:INFO:SubProcess create_model() end ==================================
2023-08-18 15:41:49,885:INFO:Creating metrics dataframe
2023-08-18 15:41:49,891:INFO:Initializing K Neighbors Classifier
2023-08-18 15:41:49,891:INFO:Total runtime is 0.7388701876004536 minutes
2023-08-18 15:41:49,893:INFO:SubProcess create_model() called ==================================
2023-08-18 15:41:49,893:INFO:Initializing create_model()
2023-08-18 15:41:49,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:41:49,894:INFO:Checking exceptions
2023-08-18 15:41:49,894:INFO:Importing libraries
2023-08-18 15:41:49,894:INFO:Copying training dataset
2023-08-18 15:41:49,953:INFO:Defining folds
2023-08-18 15:41:49,953:INFO:Declaring metric variables
2023-08-18 15:41:49,956:INFO:Importing untrained model
2023-08-18 15:41:49,959:INFO:K Neighbors Classifier Imported successfully
2023-08-18 15:41:49,965:INFO:Starting cross validation
2023-08-18 15:41:49,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:42:29,493:INFO:Calculating mean and std
2023-08-18 15:42:29,494:INFO:Creating metrics dataframe
2023-08-18 15:42:29,890:INFO:Uploading results into container
2023-08-18 15:42:29,891:INFO:Uploading model into container now
2023-08-18 15:42:29,891:INFO:_master_model_container: 2
2023-08-18 15:42:29,891:INFO:_display_container: 2
2023-08-18 15:42:29,892:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-18 15:42:29,892:INFO:create_model() successfully completed......................................
2023-08-18 15:42:30,008:INFO:SubProcess create_model() end ==================================
2023-08-18 15:42:30,008:INFO:Creating metrics dataframe
2023-08-18 15:42:30,014:INFO:Initializing Naive Bayes
2023-08-18 15:42:30,014:INFO:Total runtime is 1.4075912555058796 minutes
2023-08-18 15:42:30,016:INFO:SubProcess create_model() called ==================================
2023-08-18 15:42:30,016:INFO:Initializing create_model()
2023-08-18 15:42:30,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:42:30,017:INFO:Checking exceptions
2023-08-18 15:42:30,017:INFO:Importing libraries
2023-08-18 15:42:30,017:INFO:Copying training dataset
2023-08-18 15:42:30,054:INFO:Defining folds
2023-08-18 15:42:30,054:INFO:Declaring metric variables
2023-08-18 15:42:30,057:INFO:Importing untrained model
2023-08-18 15:42:30,060:INFO:Naive Bayes Imported successfully
2023-08-18 15:42:30,065:INFO:Starting cross validation
2023-08-18 15:42:30,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:42:35,369:INFO:Calculating mean and std
2023-08-18 15:42:35,370:INFO:Creating metrics dataframe
2023-08-18 15:42:35,757:INFO:Uploading results into container
2023-08-18 15:42:35,758:INFO:Uploading model into container now
2023-08-18 15:42:35,758:INFO:_master_model_container: 3
2023-08-18 15:42:35,758:INFO:_display_container: 2
2023-08-18 15:42:35,758:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-18 15:42:35,758:INFO:create_model() successfully completed......................................
2023-08-18 15:42:35,870:INFO:SubProcess create_model() end ==================================
2023-08-18 15:42:35,870:INFO:Creating metrics dataframe
2023-08-18 15:42:35,876:INFO:Initializing Decision Tree Classifier
2023-08-18 15:42:35,876:INFO:Total runtime is 1.5052997271219888 minutes
2023-08-18 15:42:35,879:INFO:SubProcess create_model() called ==================================
2023-08-18 15:42:35,879:INFO:Initializing create_model()
2023-08-18 15:42:35,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:42:35,879:INFO:Checking exceptions
2023-08-18 15:42:35,879:INFO:Importing libraries
2023-08-18 15:42:35,879:INFO:Copying training dataset
2023-08-18 15:42:35,914:INFO:Defining folds
2023-08-18 15:42:35,914:INFO:Declaring metric variables
2023-08-18 15:42:35,917:INFO:Importing untrained model
2023-08-18 15:42:35,919:INFO:Decision Tree Classifier Imported successfully
2023-08-18 15:42:35,924:INFO:Starting cross validation
2023-08-18 15:42:35,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:42:42,185:INFO:Calculating mean and std
2023-08-18 15:42:42,186:INFO:Creating metrics dataframe
2023-08-18 15:42:42,603:INFO:Uploading results into container
2023-08-18 15:42:42,604:INFO:Uploading model into container now
2023-08-18 15:42:42,604:INFO:_master_model_container: 4
2023-08-18 15:42:42,604:INFO:_display_container: 2
2023-08-18 15:42:42,604:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4656, splitter='best')
2023-08-18 15:42:42,604:INFO:create_model() successfully completed......................................
2023-08-18 15:42:42,716:INFO:SubProcess create_model() end ==================================
2023-08-18 15:42:42,716:INFO:Creating metrics dataframe
2023-08-18 15:42:42,723:INFO:Initializing SVM - Linear Kernel
2023-08-18 15:42:42,723:INFO:Total runtime is 1.6194117506345111 minutes
2023-08-18 15:42:42,725:INFO:SubProcess create_model() called ==================================
2023-08-18 15:42:42,725:INFO:Initializing create_model()
2023-08-18 15:42:42,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:42:42,726:INFO:Checking exceptions
2023-08-18 15:42:42,726:INFO:Importing libraries
2023-08-18 15:42:42,726:INFO:Copying training dataset
2023-08-18 15:42:42,765:INFO:Defining folds
2023-08-18 15:42:42,765:INFO:Declaring metric variables
2023-08-18 15:42:42,767:INFO:Importing untrained model
2023-08-18 15:42:42,770:INFO:SVM - Linear Kernel Imported successfully
2023-08-18 15:42:42,775:INFO:Starting cross validation
2023-08-18 15:42:42,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:42:45,403:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,450:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,459:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,476:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,502:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,510:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,549:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,555:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,570:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 15:42:45,625:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:45,674:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:45,688:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:45,700:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:45,713:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:45,741:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:45,768:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:45,781:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:45,790:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:48,685:INFO:Calculating mean and std
2023-08-18 15:42:48,686:INFO:Creating metrics dataframe
2023-08-18 15:42:49,092:INFO:Uploading results into container
2023-08-18 15:42:49,093:INFO:Uploading model into container now
2023-08-18 15:42:49,093:INFO:_master_model_container: 5
2023-08-18 15:42:49,093:INFO:_display_container: 2
2023-08-18 15:42:49,093:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4656, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-18 15:42:49,093:INFO:create_model() successfully completed......................................
2023-08-18 15:42:49,205:INFO:SubProcess create_model() end ==================================
2023-08-18 15:42:49,205:INFO:Creating metrics dataframe
2023-08-18 15:42:49,211:INFO:Initializing Ridge Classifier
2023-08-18 15:42:49,211:INFO:Total runtime is 1.7275404055913288 minutes
2023-08-18 15:42:49,214:INFO:SubProcess create_model() called ==================================
2023-08-18 15:42:49,214:INFO:Initializing create_model()
2023-08-18 15:42:49,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:42:49,214:INFO:Checking exceptions
2023-08-18 15:42:49,214:INFO:Importing libraries
2023-08-18 15:42:49,214:INFO:Copying training dataset
2023-08-18 15:42:49,253:INFO:Defining folds
2023-08-18 15:42:49,254:INFO:Declaring metric variables
2023-08-18 15:42:49,256:INFO:Importing untrained model
2023-08-18 15:42:49,259:INFO:Ridge Classifier Imported successfully
2023-08-18 15:42:49,263:INFO:Starting cross validation
2023-08-18 15:42:49,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:42:51,267:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,292:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,357:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,366:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,383:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,396:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,424:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,427:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,478:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,487:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,502:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 15:42:51,526:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,587:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,590:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,613:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,614:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,643:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,655:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,712:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:51,733:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:42:54,544:INFO:Calculating mean and std
2023-08-18 15:42:54,545:INFO:Creating metrics dataframe
2023-08-18 15:42:54,942:INFO:Uploading results into container
2023-08-18 15:42:54,942:INFO:Uploading model into container now
2023-08-18 15:42:54,943:INFO:_master_model_container: 6
2023-08-18 15:42:54,943:INFO:_display_container: 2
2023-08-18 15:42:54,943:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4656, solver='auto',
                tol=0.0001)
2023-08-18 15:42:54,943:INFO:create_model() successfully completed......................................
2023-08-18 15:42:55,055:INFO:SubProcess create_model() end ==================================
2023-08-18 15:42:55,055:INFO:Creating metrics dataframe
2023-08-18 15:42:55,062:INFO:Initializing Random Forest Classifier
2023-08-18 15:42:55,062:INFO:Total runtime is 1.825063637892405 minutes
2023-08-18 15:42:55,065:INFO:SubProcess create_model() called ==================================
2023-08-18 15:42:55,065:INFO:Initializing create_model()
2023-08-18 15:42:55,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:42:55,065:INFO:Checking exceptions
2023-08-18 15:42:55,065:INFO:Importing libraries
2023-08-18 15:42:55,065:INFO:Copying training dataset
2023-08-18 15:42:55,104:INFO:Defining folds
2023-08-18 15:42:55,104:INFO:Declaring metric variables
2023-08-18 15:42:55,107:INFO:Importing untrained model
2023-08-18 15:42:55,109:INFO:Random Forest Classifier Imported successfully
2023-08-18 15:42:55,114:INFO:Starting cross validation
2023-08-18 15:42:55,121:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:43:21,146:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.05s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-18 15:43:23,688:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-18 15:43:28,765:INFO:Calculating mean and std
2023-08-18 15:43:28,766:INFO:Creating metrics dataframe
2023-08-18 15:43:29,092:INFO:Uploading results into container
2023-08-18 15:43:29,093:INFO:Uploading model into container now
2023-08-18 15:43:29,093:INFO:_master_model_container: 7
2023-08-18 15:43:29,093:INFO:_display_container: 2
2023-08-18 15:43:29,094:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=4656, verbose=0, warm_start=False)
2023-08-18 15:43:29,094:INFO:create_model() successfully completed......................................
2023-08-18 15:43:29,210:INFO:SubProcess create_model() end ==================================
2023-08-18 15:43:29,210:INFO:Creating metrics dataframe
2023-08-18 15:43:29,218:INFO:Initializing Quadratic Discriminant Analysis
2023-08-18 15:43:29,218:INFO:Total runtime is 2.394325530529022 minutes
2023-08-18 15:43:29,221:INFO:SubProcess create_model() called ==================================
2023-08-18 15:43:29,221:INFO:Initializing create_model()
2023-08-18 15:43:29,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:43:29,221:INFO:Checking exceptions
2023-08-18 15:43:29,221:INFO:Importing libraries
2023-08-18 15:43:29,221:INFO:Copying training dataset
2023-08-18 15:43:29,264:INFO:Defining folds
2023-08-18 15:43:29,264:INFO:Declaring metric variables
2023-08-18 15:43:29,267:INFO:Importing untrained model
2023-08-18 15:43:29,270:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-18 15:43:29,275:INFO:Starting cross validation
2023-08-18 15:43:29,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:43:32,345:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,356:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,413:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,451:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,481:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,513:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,565:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,568:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,620:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:32,626:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:43:36,003:INFO:Calculating mean and std
2023-08-18 15:43:36,004:INFO:Creating metrics dataframe
2023-08-18 15:43:36,397:INFO:Uploading results into container
2023-08-18 15:43:36,398:INFO:Uploading model into container now
2023-08-18 15:43:36,399:INFO:_master_model_container: 8
2023-08-18 15:43:36,399:INFO:_display_container: 2
2023-08-18 15:43:36,399:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-18 15:43:36,399:INFO:create_model() successfully completed......................................
2023-08-18 15:43:36,517:INFO:SubProcess create_model() end ==================================
2023-08-18 15:43:36,518:INFO:Creating metrics dataframe
2023-08-18 15:43:36,526:INFO:Initializing Ada Boost Classifier
2023-08-18 15:43:36,526:INFO:Total runtime is 2.516124808788299 minutes
2023-08-18 15:43:36,529:INFO:SubProcess create_model() called ==================================
2023-08-18 15:43:36,529:INFO:Initializing create_model()
2023-08-18 15:43:36,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:43:36,529:INFO:Checking exceptions
2023-08-18 15:43:36,529:INFO:Importing libraries
2023-08-18 15:43:36,529:INFO:Copying training dataset
2023-08-18 15:43:36,571:INFO:Defining folds
2023-08-18 15:43:36,571:INFO:Declaring metric variables
2023-08-18 15:43:36,574:INFO:Importing untrained model
2023-08-18 15:43:36,576:INFO:Ada Boost Classifier Imported successfully
2023-08-18 15:43:36,580:INFO:Starting cross validation
2023-08-18 15:43:36,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:43:54,808:INFO:Calculating mean and std
2023-08-18 15:43:54,809:INFO:Creating metrics dataframe
2023-08-18 15:43:55,148:INFO:Uploading results into container
2023-08-18 15:43:55,148:INFO:Uploading model into container now
2023-08-18 15:43:55,149:INFO:_master_model_container: 9
2023-08-18 15:43:55,149:INFO:_display_container: 2
2023-08-18 15:43:55,149:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=4656)
2023-08-18 15:43:55,149:INFO:create_model() successfully completed......................................
2023-08-18 15:43:55,262:INFO:SubProcess create_model() end ==================================
2023-08-18 15:43:55,262:INFO:Creating metrics dataframe
2023-08-18 15:43:55,270:INFO:Initializing Gradient Boosting Classifier
2023-08-18 15:43:55,270:INFO:Total runtime is 2.828532707691192 minutes
2023-08-18 15:43:55,272:INFO:SubProcess create_model() called ==================================
2023-08-18 15:43:55,273:INFO:Initializing create_model()
2023-08-18 15:43:55,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:43:55,273:INFO:Checking exceptions
2023-08-18 15:43:55,273:INFO:Importing libraries
2023-08-18 15:43:55,273:INFO:Copying training dataset
2023-08-18 15:43:55,308:INFO:Defining folds
2023-08-18 15:43:55,309:INFO:Declaring metric variables
2023-08-18 15:43:55,311:INFO:Importing untrained model
2023-08-18 15:43:55,313:INFO:Gradient Boosting Classifier Imported successfully
2023-08-18 15:43:55,318:INFO:Starting cross validation
2023-08-18 15:43:55,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:44:37,773:INFO:Calculating mean and std
2023-08-18 15:44:37,774:INFO:Creating metrics dataframe
2023-08-18 15:44:38,111:INFO:Uploading results into container
2023-08-18 15:44:38,111:INFO:Uploading model into container now
2023-08-18 15:44:38,112:INFO:_master_model_container: 10
2023-08-18 15:44:38,112:INFO:_display_container: 2
2023-08-18 15:44:38,112:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4656, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-18 15:44:38,112:INFO:create_model() successfully completed......................................
2023-08-18 15:44:38,232:INFO:SubProcess create_model() end ==================================
2023-08-18 15:44:38,232:INFO:Creating metrics dataframe
2023-08-18 15:44:38,240:INFO:Initializing Linear Discriminant Analysis
2023-08-18 15:44:38,241:INFO:Total runtime is 3.54470549027125 minutes
2023-08-18 15:44:38,243:INFO:SubProcess create_model() called ==================================
2023-08-18 15:44:38,243:INFO:Initializing create_model()
2023-08-18 15:44:38,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:44:38,243:INFO:Checking exceptions
2023-08-18 15:44:38,243:INFO:Importing libraries
2023-08-18 15:44:38,243:INFO:Copying training dataset
2023-08-18 15:44:38,288:INFO:Defining folds
2023-08-18 15:44:38,288:INFO:Declaring metric variables
2023-08-18 15:44:38,291:INFO:Importing untrained model
2023-08-18 15:44:38,293:INFO:Linear Discriminant Analysis Imported successfully
2023-08-18 15:44:38,298:INFO:Starting cross validation
2023-08-18 15:44:38,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:44:45,060:INFO:Calculating mean and std
2023-08-18 15:44:45,061:INFO:Creating metrics dataframe
2023-08-18 15:44:45,408:INFO:Uploading results into container
2023-08-18 15:44:45,409:INFO:Uploading model into container now
2023-08-18 15:44:45,410:INFO:_master_model_container: 11
2023-08-18 15:44:45,410:INFO:_display_container: 2
2023-08-18 15:44:45,410:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-18 15:44:45,410:INFO:create_model() successfully completed......................................
2023-08-18 15:44:45,526:INFO:SubProcess create_model() end ==================================
2023-08-18 15:44:45,526:INFO:Creating metrics dataframe
2023-08-18 15:44:45,535:INFO:Initializing Extra Trees Classifier
2023-08-18 15:44:45,535:INFO:Total runtime is 3.6662845094998673 minutes
2023-08-18 15:44:45,537:INFO:SubProcess create_model() called ==================================
2023-08-18 15:44:45,537:INFO:Initializing create_model()
2023-08-18 15:44:45,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:44:45,538:INFO:Checking exceptions
2023-08-18 15:44:45,538:INFO:Importing libraries
2023-08-18 15:44:45,538:INFO:Copying training dataset
2023-08-18 15:44:45,576:INFO:Defining folds
2023-08-18 15:44:45,576:INFO:Declaring metric variables
2023-08-18 15:44:45,579:INFO:Importing untrained model
2023-08-18 15:44:45,581:INFO:Extra Trees Classifier Imported successfully
2023-08-18 15:44:45,586:INFO:Starting cross validation
2023-08-18 15:44:45,591:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:45:18,647:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-18 15:45:18,789:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-18 15:45:20,283:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 15:45:22,694:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 15:45:22,830:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 15:45:22,890:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 15:45:23,050:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 15:45:25,542:INFO:Calculating mean and std
2023-08-18 15:45:25,544:INFO:Creating metrics dataframe
2023-08-18 15:45:25,866:INFO:Uploading results into container
2023-08-18 15:45:25,867:INFO:Uploading model into container now
2023-08-18 15:45:25,867:INFO:_master_model_container: 12
2023-08-18 15:45:25,867:INFO:_display_container: 2
2023-08-18 15:45:25,868:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4656, verbose=0, warm_start=False)
2023-08-18 15:45:25,868:INFO:create_model() successfully completed......................................
2023-08-18 15:45:25,980:INFO:SubProcess create_model() end ==================================
2023-08-18 15:45:25,981:INFO:Creating metrics dataframe
2023-08-18 15:45:25,988:INFO:Initializing Extreme Gradient Boosting
2023-08-18 15:45:25,988:INFO:Total runtime is 4.340497040748596 minutes
2023-08-18 15:45:25,990:INFO:SubProcess create_model() called ==================================
2023-08-18 15:45:25,991:INFO:Initializing create_model()
2023-08-18 15:45:25,991:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:45:25,991:INFO:Checking exceptions
2023-08-18 15:45:25,991:INFO:Importing libraries
2023-08-18 15:45:25,991:INFO:Copying training dataset
2023-08-18 15:45:26,054:INFO:Defining folds
2023-08-18 15:45:26,054:INFO:Declaring metric variables
2023-08-18 15:45:26,056:INFO:Importing untrained model
2023-08-18 15:45:26,059:INFO:Extreme Gradient Boosting Imported successfully
2023-08-18 15:45:26,063:INFO:Starting cross validation
2023-08-18 15:45:26,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:45:49,342:INFO:Calculating mean and std
2023-08-18 15:45:49,343:INFO:Creating metrics dataframe
2023-08-18 15:45:49,658:INFO:Uploading results into container
2023-08-18 15:45:49,659:INFO:Uploading model into container now
2023-08-18 15:45:49,659:INFO:_master_model_container: 13
2023-08-18 15:45:49,659:INFO:_display_container: 2
2023-08-18 15:45:49,660:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-18 15:45:49,660:INFO:create_model() successfully completed......................................
2023-08-18 15:45:49,777:INFO:SubProcess create_model() end ==================================
2023-08-18 15:45:49,777:INFO:Creating metrics dataframe
2023-08-18 15:45:49,787:INFO:Initializing Light Gradient Boosting Machine
2023-08-18 15:45:49,787:INFO:Total runtime is 4.737146914005279 minutes
2023-08-18 15:45:49,789:INFO:SubProcess create_model() called ==================================
2023-08-18 15:45:49,790:INFO:Initializing create_model()
2023-08-18 15:45:49,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:45:49,790:INFO:Checking exceptions
2023-08-18 15:45:49,790:INFO:Importing libraries
2023-08-18 15:45:49,790:INFO:Copying training dataset
2023-08-18 15:45:49,827:INFO:Defining folds
2023-08-18 15:45:49,827:INFO:Declaring metric variables
2023-08-18 15:45:49,830:INFO:Importing untrained model
2023-08-18 15:45:49,833:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-18 15:45:49,840:INFO:Starting cross validation
2023-08-18 15:45:49,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:45:57,954:INFO:Calculating mean and std
2023-08-18 15:45:57,955:INFO:Creating metrics dataframe
2023-08-18 15:45:58,283:INFO:Uploading results into container
2023-08-18 15:45:58,283:INFO:Uploading model into container now
2023-08-18 15:45:58,284:INFO:_master_model_container: 14
2023-08-18 15:45:58,284:INFO:_display_container: 2
2023-08-18 15:45:58,284:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4656, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-18 15:45:58,284:INFO:create_model() successfully completed......................................
2023-08-18 15:45:58,395:INFO:SubProcess create_model() end ==================================
2023-08-18 15:45:58,395:INFO:Creating metrics dataframe
2023-08-18 15:45:58,404:INFO:Initializing CatBoost Classifier
2023-08-18 15:45:58,405:INFO:Total runtime is 4.880773595968881 minutes
2023-08-18 15:45:58,407:INFO:SubProcess create_model() called ==================================
2023-08-18 15:45:58,407:INFO:Initializing create_model()
2023-08-18 15:45:58,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:45:58,407:INFO:Checking exceptions
2023-08-18 15:45:58,407:INFO:Importing libraries
2023-08-18 15:45:58,407:INFO:Copying training dataset
2023-08-18 15:45:58,442:INFO:Defining folds
2023-08-18 15:45:58,442:INFO:Declaring metric variables
2023-08-18 15:45:58,447:INFO:Importing untrained model
2023-08-18 15:45:58,451:INFO:CatBoost Classifier Imported successfully
2023-08-18 15:45:58,456:INFO:Starting cross validation
2023-08-18 15:45:58,462:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:47:36,946:INFO:Calculating mean and std
2023-08-18 15:47:36,947:INFO:Creating metrics dataframe
2023-08-18 15:47:37,266:INFO:Uploading results into container
2023-08-18 15:47:37,267:INFO:Uploading model into container now
2023-08-18 15:47:37,267:INFO:_master_model_container: 15
2023-08-18 15:47:37,267:INFO:_display_container: 2
2023-08-18 15:47:37,268:INFO:<catboost.core.CatBoostClassifier object at 0x00000224DA17AA40>
2023-08-18 15:47:37,268:INFO:create_model() successfully completed......................................
2023-08-18 15:47:37,383:INFO:SubProcess create_model() end ==================================
2023-08-18 15:47:37,383:INFO:Creating metrics dataframe
2023-08-18 15:47:37,391:INFO:Initializing Dummy Classifier
2023-08-18 15:47:37,391:INFO:Total runtime is 6.530535483360289 minutes
2023-08-18 15:47:37,393:INFO:SubProcess create_model() called ==================================
2023-08-18 15:47:37,394:INFO:Initializing create_model()
2023-08-18 15:47:37,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224E0196380>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:47:37,394:INFO:Checking exceptions
2023-08-18 15:47:37,394:INFO:Importing libraries
2023-08-18 15:47:37,394:INFO:Copying training dataset
2023-08-18 15:47:37,432:INFO:Defining folds
2023-08-18 15:47:37,433:INFO:Declaring metric variables
2023-08-18 15:47:37,435:INFO:Importing untrained model
2023-08-18 15:47:37,438:INFO:Dummy Classifier Imported successfully
2023-08-18 15:47:37,442:INFO:Starting cross validation
2023-08-18 15:47:37,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:47:39,202:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,249:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,289:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,299:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,329:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,409:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,442:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,447:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,452:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:39,479:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 15:47:41,756:INFO:Calculating mean and std
2023-08-18 15:47:41,757:INFO:Creating metrics dataframe
2023-08-18 15:47:42,066:INFO:Uploading results into container
2023-08-18 15:47:42,067:INFO:Uploading model into container now
2023-08-18 15:47:42,068:INFO:_master_model_container: 16
2023-08-18 15:47:42,068:INFO:_display_container: 2
2023-08-18 15:47:42,068:INFO:DummyClassifier(constant=None, random_state=4656, strategy='prior')
2023-08-18 15:47:42,068:INFO:create_model() successfully completed......................................
2023-08-18 15:47:42,178:INFO:SubProcess create_model() end ==================================
2023-08-18 15:47:42,178:INFO:Creating metrics dataframe
2023-08-18 15:47:42,193:INFO:Initializing create_model()
2023-08-18 15:47:42,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4656, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:47:42,193:INFO:Checking exceptions
2023-08-18 15:47:42,194:INFO:Importing libraries
2023-08-18 15:47:42,194:INFO:Copying training dataset
2023-08-18 15:47:42,235:INFO:Defining folds
2023-08-18 15:47:42,235:INFO:Declaring metric variables
2023-08-18 15:47:42,235:INFO:Importing untrained model
2023-08-18 15:47:42,235:INFO:Declaring custom model
2023-08-18 15:47:42,235:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-18 15:47:42,241:INFO:Cross validation set to False
2023-08-18 15:47:42,241:INFO:Fitting Model
2023-08-18 15:47:54,046:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-18 15:47:54,046:INFO:[LightGBM] [Info] Number of positive: 13155, number of negative: 171693
2023-08-18 15:47:54,067:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006854 seconds.
2023-08-18 15:47:54,067:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-18 15:47:54,067:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-18 15:47:54,067:INFO:[LightGBM] [Info] Total Bins 467
2023-08-18 15:47:54,067:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 32
2023-08-18 15:47:54,068:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.071167 -> initscore=-2.568906
2023-08-18 15:47:54,068:INFO:[LightGBM] [Info] Start training from score -2.568906
2023-08-18 15:47:54,600:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4656, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-18 15:47:54,600:INFO:create_model() successfully completed......................................
2023-08-18 15:47:54,733:INFO:_master_model_container: 16
2023-08-18 15:47:54,734:INFO:_display_container: 2
2023-08-18 15:47:54,734:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4656, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-18 15:47:54,734:INFO:compare_models() successfully completed......................................
2023-08-18 15:48:57,514:INFO:Initializing create_model()
2023-08-18 15:48:57,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:48:57,514:INFO:Checking exceptions
2023-08-18 15:48:57,524:INFO:Importing libraries
2023-08-18 15:48:57,524:INFO:Copying training dataset
2023-08-18 15:48:57,567:INFO:Defining folds
2023-08-18 15:48:57,567:INFO:Declaring metric variables
2023-08-18 15:48:57,570:INFO:Importing untrained model
2023-08-18 15:48:57,573:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-18 15:48:57,578:INFO:Starting cross validation
2023-08-18 15:48:57,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:49:01,735:INFO:Calculating mean and std
2023-08-18 15:49:01,736:INFO:Creating metrics dataframe
2023-08-18 15:49:01,740:INFO:Finalizing model
2023-08-18 15:49:03,364:INFO:Uploading results into container
2023-08-18 15:49:03,364:INFO:Uploading model into container now
2023-08-18 15:49:03,370:INFO:_master_model_container: 17
2023-08-18 15:49:03,371:INFO:_display_container: 3
2023-08-18 15:49:03,371:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4656, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-18 15:49:03,371:INFO:create_model() successfully completed......................................
2023-08-18 15:49:03,533:INFO:Initializing create_model()
2023-08-18 15:49:03,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:49:03,533:INFO:Checking exceptions
2023-08-18 15:49:03,543:INFO:Importing libraries
2023-08-18 15:49:03,543:INFO:Copying training dataset
2023-08-18 15:49:03,581:INFO:Defining folds
2023-08-18 15:49:03,581:INFO:Declaring metric variables
2023-08-18 15:49:03,585:INFO:Importing untrained model
2023-08-18 15:49:03,587:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-18 15:49:03,592:INFO:Starting cross validation
2023-08-18 15:49:03,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:49:07,989:INFO:Calculating mean and std
2023-08-18 15:49:07,990:INFO:Creating metrics dataframe
2023-08-18 15:49:07,994:INFO:Finalizing model
2023-08-18 15:49:09,905:INFO:Uploading results into container
2023-08-18 15:49:09,906:INFO:Uploading model into container now
2023-08-18 15:49:09,913:INFO:_master_model_container: 18
2023-08-18 15:49:09,913:INFO:_display_container: 4
2023-08-18 15:49:09,914:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-18 15:49:09,914:INFO:create_model() successfully completed......................................
2023-08-18 15:49:10,040:INFO:Initializing create_model()
2023-08-18 15:49:10,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:49:10,040:INFO:Checking exceptions
2023-08-18 15:49:10,049:INFO:Importing libraries
2023-08-18 15:49:10,049:INFO:Copying training dataset
2023-08-18 15:49:10,091:INFO:Defining folds
2023-08-18 15:49:10,092:INFO:Declaring metric variables
2023-08-18 15:49:10,094:INFO:Importing untrained model
2023-08-18 15:49:10,096:INFO:Naive Bayes Imported successfully
2023-08-18 15:49:10,100:INFO:Starting cross validation
2023-08-18 15:49:10,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:49:14,949:INFO:Calculating mean and std
2023-08-18 15:49:14,950:INFO:Creating metrics dataframe
2023-08-18 15:49:14,954:INFO:Finalizing model
2023-08-18 15:49:15,920:INFO:Uploading results into container
2023-08-18 15:49:15,921:INFO:Uploading model into container now
2023-08-18 15:49:15,927:INFO:_master_model_container: 19
2023-08-18 15:49:15,927:INFO:_display_container: 5
2023-08-18 15:49:15,927:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-18 15:49:15,927:INFO:create_model() successfully completed......................................
2023-08-18 15:49:16,057:INFO:Initializing blend_models()
2023-08-18 15:49:16,057:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4656, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-18 15:49:16,057:INFO:Checking exceptions
2023-08-18 15:49:16,076:INFO:Importing libraries
2023-08-18 15:49:16,077:INFO:Copying training dataset
2023-08-18 15:49:16,079:INFO:Getting model names
2023-08-18 15:49:16,081:INFO:SubProcess create_model() called ==================================
2023-08-18 15:49:16,083:INFO:Initializing create_model()
2023-08-18 15:49:16,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000224DA865CC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 15:49:16,083:INFO:Checking exceptions
2023-08-18 15:49:16,084:INFO:Importing libraries
2023-08-18 15:49:16,084:INFO:Copying training dataset
2023-08-18 15:49:16,124:INFO:Defining folds
2023-08-18 15:49:16,124:INFO:Declaring metric variables
2023-08-18 15:49:16,127:INFO:Importing untrained model
2023-08-18 15:49:16,127:INFO:Declaring custom model
2023-08-18 15:49:16,130:INFO:Voting Classifier Imported successfully
2023-08-18 15:49:16,134:INFO:Starting cross validation
2023-08-18 15:49:16,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 15:49:19,308:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:19,581:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:19,908:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:19,922:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:19,926:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:20,250:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:20,344:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:20,519:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:20,538:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:26,557:INFO:Calculating mean and std
2023-08-18 15:49:26,558:INFO:Creating metrics dataframe
2023-08-18 15:49:26,562:INFO:Finalizing model
2023-08-18 15:49:27,677:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 15:49:28,152:INFO:Uploading results into container
2023-08-18 15:49:28,153:INFO:Uploading model into container now
2023-08-18 15:49:28,153:INFO:_master_model_container: 20
2023-08-18 15:49:28,154:INFO:_display_container: 6
2023-08-18 15:49:28,155:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-18 15:49:28,155:INFO:create_model() successfully completed......................................
2023-08-18 15:49:28,270:INFO:SubProcess create_model() end ==================================
2023-08-18 15:49:28,275:INFO:_master_model_container: 20
2023-08-18 15:49:28,276:INFO:_display_container: 6
2023-08-18 15:49:28,277:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-18 15:49:28,277:INFO:blend_models() successfully completed......................................
2023-08-18 15:50:04,435:INFO:Initializing evaluate_model()
2023-08-18 15:50:04,435:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-18 15:50:04,458:INFO:Initializing plot_model()
2023-08-18 15:50:04,458:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, system=True)
2023-08-18 15:50:04,458:INFO:Checking exceptions
2023-08-18 15:50:04,470:INFO:Preloading libraries
2023-08-18 15:50:04,475:INFO:Copying training dataset
2023-08-18 15:50:04,475:INFO:Plot type: pipeline
2023-08-18 15:50:04,704:INFO:Visual Rendered Successfully
2023-08-18 15:50:04,822:INFO:plot_model() successfully completed......................................
2023-08-18 15:50:13,014:INFO:Initializing tune_model()
2023-08-18 15:50:13,014:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4656, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Recall, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>)
2023-08-18 15:50:13,014:INFO:Checking exceptions
2023-08-18 15:50:13,037:INFO:Copying training dataset
2023-08-18 15:50:13,065:INFO:Checking base model
2023-08-18 15:50:13,065:INFO:Base model : Light Gradient Boosting Machine
2023-08-18 15:50:13,068:INFO:Declaring metric variables
2023-08-18 15:50:13,070:INFO:Defining Hyperparameters
2023-08-18 15:50:13,213:INFO:Tuning with n_jobs=-1
2023-08-18 15:50:13,213:INFO:Initializing RandomizedSearchCV
2023-08-18 15:50:46,884:INFO:Initializing finalize_model()
2023-08-18 15:50:46,884:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-18 15:50:46,886:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-18 15:50:46,896:INFO:Initializing create_model()
2023-08-18 15:50:46,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-18 15:50:46,897:INFO:Checking exceptions
2023-08-18 15:50:46,898:INFO:Importing libraries
2023-08-18 15:50:46,898:INFO:Copying training dataset
2023-08-18 15:50:46,900:INFO:Defining folds
2023-08-18 15:50:46,900:INFO:Declaring metric variables
2023-08-18 15:50:46,900:INFO:Importing untrained model
2023-08-18 15:50:46,901:INFO:Declaring custom model
2023-08-18 15:50:46,901:INFO:Voting Classifier Imported successfully
2023-08-18 15:50:46,907:INFO:Cross validation set to False
2023-08-18 15:50:46,908:INFO:Fitting Model
2023-08-18 15:51:06,628:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-18 15:51:06,628:INFO:create_model() successfully completed......................................
2023-08-18 15:51:06,751:INFO:_master_model_container: 20
2023-08-18 15:51:06,751:INFO:_display_container: 6
2023-08-18 15:51:06,801:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-18 15:51:06,801:INFO:finalize_model() successfully completed......................................
2023-08-18 15:51:24,602:INFO:Initializing save_model()
2023-08-18 15:51:24,602:INFO:save_model(model=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=4656, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), model_name=final_blended_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=4656,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-08-18 15:51:24,602:INFO:Adding model into prep_pipe
2023-08-18 15:51:24,647:INFO:final_blended_model.pkl saved in current working directory
2023-08-18 15:51:24,710:INFO:Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-18 15:51:24,710:INFO:save_model() successfully completed......................................
2023-08-18 15:51:31,479:INFO:Initializing load_model()
2023-08-18 15:51:31,479:INFO:load_model(model_name=final_blended_model, platform=None, authentication=None, verbose=True)
2023-08-18 15:51:31,570:INFO:Initializing predict_model()
2023-08-18 15:51:31,570:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000224E00ECAC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0)),
                                              ('Quadratic Discriminant '
                                               'Analysis',
                                               QuadraticDiscriminantAnalysis(priors=None,
                                                                             reg_param=0.0,
                                                                             store_covariance=False,
                                                                             tol=0.0001)),
                                              ('Naive Bayes',
                                               GaussianNB(priors=None,
                                                          var_smoothing=1e-09))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000224D979FE20>)
2023-08-18 15:51:31,570:INFO:Checking exceptions
2023-08-18 15:51:31,570:INFO:Preloading libraries
2023-08-18 15:51:31,572:INFO:Set up data.
2023-08-18 15:51:31,626:INFO:Set up index.
2023-08-18 15:55:39,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:55:39,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:55:39,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:55:39,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:55:40,673:INFO:PyCaret ClassificationExperiment
2023-08-18 15:55:40,673:INFO:Logging name: clf-default-name
2023-08-18 15:55:40,673:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:55:40,673:INFO:version 3.0.4
2023-08-18 15:55:40,673:INFO:Initializing setup()
2023-08-18 15:55:40,673:INFO:self.USI: d139
2023-08-18 15:55:40,673:INFO:self._variable_keys: {'log_plots_param', 'gpu_param', 'memory', 'USI', 'logging_param', 'y_test', 'target_param', 'n_jobs_param', '_available_plots', 'y', 'fold_groups_param', 'exp_name_log', 'y_train', 'X_test', 'exp_id', 'seed', 'fold_shuffle_param', 'fix_imbalance', 'X_train', 'X', 'html_param', 'gpu_n_jobs_param', 'data', 'pipeline', 'is_multiclass', 'idx', 'fold_generator', '_ml_usecase'}
2023-08-18 15:55:40,673:INFO:Checking environment
2023-08-18 15:55:40,673:INFO:python_version: 3.10.12
2023-08-18 15:55:40,673:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:55:40,673:INFO:machine: AMD64
2023-08-18 15:55:40,673:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:55:40,678:INFO:Memory: svmem(total=68448301056, available=49912705024, percent=27.1, used=18535596032, free=49912705024)
2023-08-18 15:55:40,678:INFO:Physical Core: 12
2023-08-18 15:55:40,678:INFO:Logical Core: 20
2023-08-18 15:55:40,678:INFO:Checking libraries
2023-08-18 15:55:40,678:INFO:System:
2023-08-18 15:55:40,678:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:55:40,678:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:55:40,678:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:55:40,678:INFO:PyCaret required dependencies:
2023-08-18 15:55:41,068:INFO:                 pip: 23.2.1
2023-08-18 15:55:41,068:INFO:          setuptools: 68.0.0
2023-08-18 15:55:41,068:INFO:             pycaret: 3.0.4
2023-08-18 15:55:41,068:INFO:             IPython: 7.34.0
2023-08-18 15:55:41,068:INFO:          ipywidgets: 7.8.0
2023-08-18 15:55:41,068:INFO:                tqdm: 4.66.1
2023-08-18 15:55:41,068:INFO:               numpy: 1.23.5
2023-08-18 15:55:41,068:INFO:              pandas: 1.5.3
2023-08-18 15:55:41,068:INFO:              jinja2: 3.1.2
2023-08-18 15:55:41,068:INFO:               scipy: 1.10.1
2023-08-18 15:55:41,068:INFO:              joblib: 1.3.2
2023-08-18 15:55:41,068:INFO:             sklearn: 1.2.2
2023-08-18 15:55:41,068:INFO:                pyod: 1.1.0
2023-08-18 15:55:41,068:INFO:            imblearn: 0.11.0
2023-08-18 15:55:41,069:INFO:   category_encoders: 2.6.2
2023-08-18 15:55:41,069:INFO:            lightgbm: 4.0.0
2023-08-18 15:55:41,069:INFO:               numba: 0.57.1
2023-08-18 15:55:41,069:INFO:            requests: 2.31.0
2023-08-18 15:55:41,069:INFO:          matplotlib: 3.7.2
2023-08-18 15:55:41,069:INFO:          scikitplot: 0.3.7
2023-08-18 15:55:41,069:INFO:         yellowbrick: 1.5
2023-08-18 15:55:41,069:INFO:              plotly: 5.16.1
2023-08-18 15:55:41,069:INFO:    plotly-resampler: Not installed
2023-08-18 15:55:41,069:INFO:             kaleido: 0.2.1
2023-08-18 15:55:41,069:INFO:           schemdraw: 0.15
2023-08-18 15:55:41,069:INFO:         statsmodels: 0.14.0
2023-08-18 15:55:41,069:INFO:              sktime: 0.21.0
2023-08-18 15:55:41,069:INFO:               tbats: 1.1.3
2023-08-18 15:55:41,069:INFO:            pmdarima: 2.0.3
2023-08-18 15:55:41,069:INFO:              psutil: 5.9.5
2023-08-18 15:55:41,069:INFO:          markupsafe: 2.1.3
2023-08-18 15:55:41,069:INFO:             pickle5: Not installed
2023-08-18 15:55:41,069:INFO:         cloudpickle: 2.2.1
2023-08-18 15:55:41,069:INFO:         deprecation: 2.1.0
2023-08-18 15:55:41,069:INFO:              xxhash: 3.3.0
2023-08-18 15:55:41,069:INFO:           wurlitzer: 3.0.3
2023-08-18 15:55:41,069:INFO:PyCaret optional dependencies:
2023-08-18 15:55:42,301:INFO:                shap: 0.42.1
2023-08-18 15:55:42,301:INFO:           interpret: 0.4.3
2023-08-18 15:55:42,301:INFO:                umap: 0.5.3
2023-08-18 15:55:42,301:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:55:42,301:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:55:42,301:INFO:             autoviz: 0.1.730
2023-08-18 15:55:42,301:INFO:           fairlearn: 0.7.0
2023-08-18 15:55:42,301:INFO:          deepchecks: 0.17.4
2023-08-18 15:55:42,301:INFO:             xgboost: 1.7.6
2023-08-18 15:55:42,301:INFO:            catboost: 1.2
2023-08-18 15:55:42,301:INFO:              kmodes: 0.12.2
2023-08-18 15:55:42,301:INFO:             mlxtend: 0.22.0
2023-08-18 15:55:42,301:INFO:       statsforecast: 1.5.0
2023-08-18 15:55:42,301:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:55:42,301:INFO:                 ray: 2.6.3
2023-08-18 15:55:42,301:INFO:            hyperopt: 0.2.7
2023-08-18 15:55:42,301:INFO:              optuna: 3.3.0
2023-08-18 15:55:42,301:INFO:               skopt: 0.9.0
2023-08-18 15:55:42,301:INFO:              mlflow: 1.30.1
2023-08-18 15:55:42,301:INFO:              gradio: 3.40.1
2023-08-18 15:55:42,301:INFO:             fastapi: 0.101.1
2023-08-18 15:55:42,301:INFO:             uvicorn: 0.23.2
2023-08-18 15:55:42,301:INFO:              m2cgen: 0.10.0
2023-08-18 15:55:42,301:INFO:           evidently: 0.2.8
2023-08-18 15:55:42,301:INFO:               fugue: 0.8.6
2023-08-18 15:55:42,301:INFO:           streamlit: 1.25.0
2023-08-18 15:55:42,301:INFO:             prophet: 1.1.4
2023-08-18 15:55:42,302:INFO:None
2023-08-18 15:55:42,302:INFO:Set up data.
2023-08-18 15:55:42,475:INFO:Set up train/test split.
2023-08-18 15:55:42,622:INFO:Set up index.
2023-08-18 15:55:42,628:INFO:Set up folding strategy.
2023-08-18 15:55:42,628:INFO:Assigning column types.
2023-08-18 15:55:42,645:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:55:42,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:55:42,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:55:42,689:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:55:42,690:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:55:42,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:55:42,730:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:55:42,745:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:55:42,746:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:55:42,747:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:55:42,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:55:42,786:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:55:42,787:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:55:42,812:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:55:42,827:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:55:42,829:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:55:42,830:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:55:42,867:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:55:42,869:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:55:42,906:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:55:42,908:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:55:42,909:INFO:Preparing preprocessing pipeline...
2023-08-18 15:55:42,913:INFO:Set up label encoding.
2023-08-18 15:55:42,913:INFO:Set up simple imputation.
2023-08-18 15:55:42,945:INFO:Set up encoding of ordinal features.
2023-08-18 15:55:42,979:INFO:Set up encoding of categorical features.
2023-08-18 15:55:42,980:INFO:Set up removing outliers.
2023-08-18 15:55:42,980:INFO:Set up imbalanced handling.
2023-08-18 15:55:42,980:INFO:Set up feature normalization.
2023-08-18 15:55:42,982:INFO:Set up column name cleaning.
2023-08-18 15:55:56,696:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:55:56,735:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:55:56,735:INFO:Creating final display dataframe.
2023-08-18 15:56:09,791:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (426079, 42)
6   Transformed train set shape      (342688, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              d139
2023-08-18 15:56:09,836:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:56:09,838:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:56:09,878:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:56:09,880:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:56:09,881:INFO:setup() successfully completed in 29.54s...............
2023-08-18 15:57:38,309:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:57:38,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:57:38,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:57:38,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 15:57:39,040:INFO:PyCaret ClassificationExperiment
2023-08-18 15:57:39,040:INFO:Logging name: clf-default-name
2023-08-18 15:57:39,040:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 15:57:39,040:INFO:version 3.0.4
2023-08-18 15:57:39,040:INFO:Initializing setup()
2023-08-18 15:57:39,040:INFO:self.USI: e1c2
2023-08-18 15:57:39,040:INFO:self._variable_keys: {'logging_param', 'pipeline', 'y_test', 'fix_imbalance', 'gpu_n_jobs_param', 'USI', 'gpu_param', 'exp_id', 'exp_name_log', 'html_param', 'log_plots_param', 'data', '_ml_usecase', 'idx', 'X_train', 'fold_shuffle_param', 'y', 'n_jobs_param', 'seed', 'fold_generator', 'X_test', 'target_param', '_available_plots', 'y_train', 'memory', 'is_multiclass', 'X', 'fold_groups_param'}
2023-08-18 15:57:39,040:INFO:Checking environment
2023-08-18 15:57:39,041:INFO:python_version: 3.10.12
2023-08-18 15:57:39,041:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 15:57:39,041:INFO:machine: AMD64
2023-08-18 15:57:39,041:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 15:57:39,044:INFO:Memory: svmem(total=68448301056, available=50026897408, percent=26.9, used=18421403648, free=50026897408)
2023-08-18 15:57:39,045:INFO:Physical Core: 12
2023-08-18 15:57:39,045:INFO:Logical Core: 20
2023-08-18 15:57:39,045:INFO:Checking libraries
2023-08-18 15:57:39,045:INFO:System:
2023-08-18 15:57:39,045:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 15:57:39,045:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 15:57:39,045:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 15:57:39,045:INFO:PyCaret required dependencies:
2023-08-18 15:57:39,383:INFO:                 pip: 23.2.1
2023-08-18 15:57:39,383:INFO:          setuptools: 68.0.0
2023-08-18 15:57:39,383:INFO:             pycaret: 3.0.4
2023-08-18 15:57:39,383:INFO:             IPython: 7.34.0
2023-08-18 15:57:39,383:INFO:          ipywidgets: 7.8.0
2023-08-18 15:57:39,383:INFO:                tqdm: 4.66.1
2023-08-18 15:57:39,383:INFO:               numpy: 1.23.5
2023-08-18 15:57:39,383:INFO:              pandas: 1.5.3
2023-08-18 15:57:39,383:INFO:              jinja2: 3.1.2
2023-08-18 15:57:39,384:INFO:               scipy: 1.10.1
2023-08-18 15:57:39,384:INFO:              joblib: 1.3.2
2023-08-18 15:57:39,384:INFO:             sklearn: 1.2.2
2023-08-18 15:57:39,384:INFO:                pyod: 1.1.0
2023-08-18 15:57:39,384:INFO:            imblearn: 0.11.0
2023-08-18 15:57:39,384:INFO:   category_encoders: 2.6.2
2023-08-18 15:57:39,384:INFO:            lightgbm: 4.0.0
2023-08-18 15:57:39,384:INFO:               numba: 0.57.1
2023-08-18 15:57:39,384:INFO:            requests: 2.31.0
2023-08-18 15:57:39,384:INFO:          matplotlib: 3.7.2
2023-08-18 15:57:39,384:INFO:          scikitplot: 0.3.7
2023-08-18 15:57:39,384:INFO:         yellowbrick: 1.5
2023-08-18 15:57:39,384:INFO:              plotly: 5.16.1
2023-08-18 15:57:39,384:INFO:    plotly-resampler: Not installed
2023-08-18 15:57:39,384:INFO:             kaleido: 0.2.1
2023-08-18 15:57:39,384:INFO:           schemdraw: 0.15
2023-08-18 15:57:39,384:INFO:         statsmodels: 0.14.0
2023-08-18 15:57:39,384:INFO:              sktime: 0.21.0
2023-08-18 15:57:39,384:INFO:               tbats: 1.1.3
2023-08-18 15:57:39,384:INFO:            pmdarima: 2.0.3
2023-08-18 15:57:39,384:INFO:              psutil: 5.9.5
2023-08-18 15:57:39,384:INFO:          markupsafe: 2.1.3
2023-08-18 15:57:39,384:INFO:             pickle5: Not installed
2023-08-18 15:57:39,384:INFO:         cloudpickle: 2.2.1
2023-08-18 15:57:39,384:INFO:         deprecation: 2.1.0
2023-08-18 15:57:39,384:INFO:              xxhash: 3.3.0
2023-08-18 15:57:39,384:INFO:           wurlitzer: 3.0.3
2023-08-18 15:57:39,384:INFO:PyCaret optional dependencies:
2023-08-18 15:57:40,566:INFO:                shap: 0.42.1
2023-08-18 15:57:40,567:INFO:           interpret: 0.4.3
2023-08-18 15:57:40,567:INFO:                umap: 0.5.3
2023-08-18 15:57:40,567:INFO:    pandas_profiling: 4.5.1
2023-08-18 15:57:40,567:INFO:  explainerdashboard: 0.4.3
2023-08-18 15:57:40,567:INFO:             autoviz: 0.1.730
2023-08-18 15:57:40,567:INFO:           fairlearn: 0.7.0
2023-08-18 15:57:40,567:INFO:          deepchecks: 0.17.4
2023-08-18 15:57:40,567:INFO:             xgboost: 1.7.6
2023-08-18 15:57:40,567:INFO:            catboost: 1.2
2023-08-18 15:57:40,567:INFO:              kmodes: 0.12.2
2023-08-18 15:57:40,567:INFO:             mlxtend: 0.22.0
2023-08-18 15:57:40,567:INFO:       statsforecast: 1.5.0
2023-08-18 15:57:40,567:INFO:        tune_sklearn: 0.4.6
2023-08-18 15:57:40,567:INFO:                 ray: 2.6.3
2023-08-18 15:57:40,567:INFO:            hyperopt: 0.2.7
2023-08-18 15:57:40,567:INFO:              optuna: 3.3.0
2023-08-18 15:57:40,567:INFO:               skopt: 0.9.0
2023-08-18 15:57:40,567:INFO:              mlflow: 1.30.1
2023-08-18 15:57:40,567:INFO:              gradio: 3.40.1
2023-08-18 15:57:40,567:INFO:             fastapi: 0.101.1
2023-08-18 15:57:40,567:INFO:             uvicorn: 0.23.2
2023-08-18 15:57:40,567:INFO:              m2cgen: 0.10.0
2023-08-18 15:57:40,567:INFO:           evidently: 0.2.8
2023-08-18 15:57:40,567:INFO:               fugue: 0.8.6
2023-08-18 15:57:40,567:INFO:           streamlit: 1.25.0
2023-08-18 15:57:40,567:INFO:             prophet: 1.1.4
2023-08-18 15:57:40,567:INFO:None
2023-08-18 15:57:40,567:INFO:Set up data.
2023-08-18 15:57:40,743:INFO:Set up train/test split.
2023-08-18 15:57:40,890:INFO:Set up index.
2023-08-18 15:57:40,896:INFO:Set up folding strategy.
2023-08-18 15:57:40,896:INFO:Assigning column types.
2023-08-18 15:57:40,912:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 15:57:40,935:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:57:40,937:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:57:40,954:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:57:40,956:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:57:40,994:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 15:57:40,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:57:41,009:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:57:41,010:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:57:41,011:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 15:57:41,034:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:57:41,049:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:57:41,050:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:57:41,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 15:57:41,090:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:57:41,092:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:57:41,092:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 15:57:41,130:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:57:41,132:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:57:41,170:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:57:41,172:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:57:41,173:INFO:Preparing preprocessing pipeline...
2023-08-18 15:57:41,176:INFO:Set up label encoding.
2023-08-18 15:57:41,177:INFO:Set up simple imputation.
2023-08-18 15:57:41,208:INFO:Set up encoding of ordinal features.
2023-08-18 15:57:41,244:INFO:Set up encoding of categorical features.
2023-08-18 15:57:41,244:INFO:Set up removing outliers.
2023-08-18 15:57:41,244:INFO:Set up imbalanced handling.
2023-08-18 15:57:41,244:INFO:Set up feature normalization.
2023-08-18 15:57:41,247:INFO:Set up column name cleaning.
2023-08-18 15:57:43,076:INFO:Finished creating preprocessing pipeline.
2023-08-18 15:57:43,115:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 15:57:43,115:INFO:Creating final display dataframe.
2023-08-18 15:57:44,589:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (426079, 42)
6   Transformed train set shape      (342688, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              e1c2
2023-08-18 15:57:44,634:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:57:44,636:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:57:44,676:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 15:57:44,678:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 15:57:44,679:INFO:setup() successfully completed in 5.93s...............
2023-08-18 16:00:58,504:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 16:00:58,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 16:00:58,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 16:00:58,505:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 16:00:59,230:INFO:PyCaret ClassificationExperiment
2023-08-18 16:00:59,230:INFO:Logging name: clf-default-name
2023-08-18 16:00:59,230:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 16:00:59,230:INFO:version 3.0.4
2023-08-18 16:00:59,230:INFO:Initializing setup()
2023-08-18 16:00:59,230:INFO:self.USI: a5f8
2023-08-18 16:00:59,230:INFO:self._variable_keys: {'gpu_param', 'X_test', 'n_jobs_param', 'fold_groups_param', 'target_param', 'pipeline', 'logging_param', 'USI', 'seed', 'idx', 'exp_name_log', 'X', 'y_test', 'memory', 'y', '_available_plots', 'data', 'y_train', 'fix_imbalance', '_ml_usecase', 'exp_id', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'html_param', 'fold_shuffle_param'}
2023-08-18 16:00:59,230:INFO:Checking environment
2023-08-18 16:00:59,231:INFO:python_version: 3.10.12
2023-08-18 16:00:59,231:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 16:00:59,231:INFO:machine: AMD64
2023-08-18 16:00:59,231:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 16:00:59,235:INFO:Memory: svmem(total=68448301056, available=49856139264, percent=27.2, used=18592161792, free=49856139264)
2023-08-18 16:00:59,235:INFO:Physical Core: 12
2023-08-18 16:00:59,235:INFO:Logical Core: 20
2023-08-18 16:00:59,235:INFO:Checking libraries
2023-08-18 16:00:59,235:INFO:System:
2023-08-18 16:00:59,235:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 16:00:59,235:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 16:00:59,235:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 16:00:59,235:INFO:PyCaret required dependencies:
2023-08-18 16:00:59,595:INFO:                 pip: 23.2.1
2023-08-18 16:00:59,595:INFO:          setuptools: 68.0.0
2023-08-18 16:00:59,595:INFO:             pycaret: 3.0.4
2023-08-18 16:00:59,595:INFO:             IPython: 7.34.0
2023-08-18 16:00:59,595:INFO:          ipywidgets: 7.8.0
2023-08-18 16:00:59,595:INFO:                tqdm: 4.66.1
2023-08-18 16:00:59,595:INFO:               numpy: 1.23.5
2023-08-18 16:00:59,595:INFO:              pandas: 1.5.3
2023-08-18 16:00:59,595:INFO:              jinja2: 3.1.2
2023-08-18 16:00:59,595:INFO:               scipy: 1.10.1
2023-08-18 16:00:59,595:INFO:              joblib: 1.3.2
2023-08-18 16:00:59,595:INFO:             sklearn: 1.2.2
2023-08-18 16:00:59,595:INFO:                pyod: 1.1.0
2023-08-18 16:00:59,595:INFO:            imblearn: 0.11.0
2023-08-18 16:00:59,595:INFO:   category_encoders: 2.6.2
2023-08-18 16:00:59,595:INFO:            lightgbm: 4.0.0
2023-08-18 16:00:59,595:INFO:               numba: 0.57.1
2023-08-18 16:00:59,595:INFO:            requests: 2.31.0
2023-08-18 16:00:59,595:INFO:          matplotlib: 3.7.2
2023-08-18 16:00:59,596:INFO:          scikitplot: 0.3.7
2023-08-18 16:00:59,596:INFO:         yellowbrick: 1.5
2023-08-18 16:00:59,596:INFO:              plotly: 5.16.1
2023-08-18 16:00:59,596:INFO:    plotly-resampler: Not installed
2023-08-18 16:00:59,596:INFO:             kaleido: 0.2.1
2023-08-18 16:00:59,596:INFO:           schemdraw: 0.15
2023-08-18 16:00:59,596:INFO:         statsmodels: 0.14.0
2023-08-18 16:00:59,596:INFO:              sktime: 0.21.0
2023-08-18 16:00:59,596:INFO:               tbats: 1.1.3
2023-08-18 16:00:59,596:INFO:            pmdarima: 2.0.3
2023-08-18 16:00:59,596:INFO:              psutil: 5.9.5
2023-08-18 16:00:59,596:INFO:          markupsafe: 2.1.3
2023-08-18 16:00:59,596:INFO:             pickle5: Not installed
2023-08-18 16:00:59,596:INFO:         cloudpickle: 2.2.1
2023-08-18 16:00:59,596:INFO:         deprecation: 2.1.0
2023-08-18 16:00:59,596:INFO:              xxhash: 3.3.0
2023-08-18 16:00:59,596:INFO:           wurlitzer: 3.0.3
2023-08-18 16:00:59,596:INFO:PyCaret optional dependencies:
2023-08-18 16:01:00,786:INFO:                shap: 0.42.1
2023-08-18 16:01:00,787:INFO:           interpret: 0.4.3
2023-08-18 16:01:00,787:INFO:                umap: 0.5.3
2023-08-18 16:01:00,787:INFO:    pandas_profiling: 4.5.1
2023-08-18 16:01:00,787:INFO:  explainerdashboard: 0.4.3
2023-08-18 16:01:00,787:INFO:             autoviz: 0.1.730
2023-08-18 16:01:00,787:INFO:           fairlearn: 0.7.0
2023-08-18 16:01:00,787:INFO:          deepchecks: 0.17.4
2023-08-18 16:01:00,787:INFO:             xgboost: 1.7.6
2023-08-18 16:01:00,787:INFO:            catboost: 1.2
2023-08-18 16:01:00,787:INFO:              kmodes: 0.12.2
2023-08-18 16:01:00,787:INFO:             mlxtend: 0.22.0
2023-08-18 16:01:00,787:INFO:       statsforecast: 1.5.0
2023-08-18 16:01:00,787:INFO:        tune_sklearn: 0.4.6
2023-08-18 16:01:00,787:INFO:                 ray: 2.6.3
2023-08-18 16:01:00,787:INFO:            hyperopt: 0.2.7
2023-08-18 16:01:00,787:INFO:              optuna: 3.3.0
2023-08-18 16:01:00,787:INFO:               skopt: 0.9.0
2023-08-18 16:01:00,787:INFO:              mlflow: 1.30.1
2023-08-18 16:01:00,787:INFO:              gradio: 3.40.1
2023-08-18 16:01:00,787:INFO:             fastapi: 0.101.1
2023-08-18 16:01:00,787:INFO:             uvicorn: 0.23.2
2023-08-18 16:01:00,787:INFO:              m2cgen: 0.10.0
2023-08-18 16:01:00,787:INFO:           evidently: 0.2.8
2023-08-18 16:01:00,787:INFO:               fugue: 0.8.6
2023-08-18 16:01:00,787:INFO:           streamlit: 1.25.0
2023-08-18 16:01:00,787:INFO:             prophet: 1.1.4
2023-08-18 16:01:00,787:INFO:None
2023-08-18 16:01:00,787:INFO:Set up data.
2023-08-18 16:01:00,960:INFO:Set up train/test split.
2023-08-18 16:01:01,103:INFO:Set up index.
2023-08-18 16:01:01,108:INFO:Set up folding strategy.
2023-08-18 16:01:01,108:INFO:Assigning column types.
2023-08-18 16:01:01,124:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 16:01:01,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 16:01:01,150:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:01:01,170:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:01:01,171:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:01:01,210:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 16:01:01,211:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:01:01,226:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:01:01,227:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:01:01,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 16:01:01,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:01:01,267:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:01:01,268:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:01:01,293:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:01:01,308:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:01:01,310:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:01:01,310:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 16:01:01,351:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:01:01,353:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:01:01,393:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:01:01,394:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:01:01,396:INFO:Preparing preprocessing pipeline...
2023-08-18 16:01:01,399:INFO:Set up label encoding.
2023-08-18 16:01:01,399:INFO:Set up simple imputation.
2023-08-18 16:01:01,433:INFO:Set up encoding of ordinal features.
2023-08-18 16:01:01,470:INFO:Set up encoding of categorical features.
2023-08-18 16:01:01,470:INFO:Set up removing outliers.
2023-08-18 16:01:01,470:INFO:Set up imbalanced handling.
2023-08-18 16:01:01,470:INFO:Set up feature normalization.
2023-08-18 16:01:01,472:INFO:Set up column name cleaning.
2023-08-18 16:01:02,195:INFO:Finished creating preprocessing pipeline.
2023-08-18 16:01:02,236:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 16:01:02,236:INFO:Creating final display dataframe.
2023-08-18 16:01:03,691:INFO:Setup _display_container:            Description                Value      
0                    Session id              1974
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (426079, 42)
6   Transformed train set shape      (342688, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              a5f8
2023-08-18 16:01:03,736:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:01:03,738:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:01:03,779:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:01:03,781:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:01:03,782:INFO:setup() successfully completed in 4.83s...............
2023-08-18 16:04:34,680:INFO:PyCaret ClassificationExperiment
2023-08-18 16:04:34,680:INFO:Logging name: clf-default-name
2023-08-18 16:04:34,680:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 16:04:34,680:INFO:version 3.0.4
2023-08-18 16:04:34,680:INFO:Initializing setup()
2023-08-18 16:04:34,680:INFO:self.USI: 344d
2023-08-18 16:04:34,680:INFO:self._variable_keys: {'gpu_param', 'X_test', 'n_jobs_param', 'fold_groups_param', 'target_param', 'pipeline', 'logging_param', 'USI', 'seed', 'idx', 'exp_name_log', 'X', 'y_test', 'memory', 'y', '_available_plots', 'data', 'y_train', 'fix_imbalance', '_ml_usecase', 'exp_id', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'is_multiclass', 'fold_generator', 'html_param', 'fold_shuffle_param'}
2023-08-18 16:04:34,680:INFO:Checking environment
2023-08-18 16:04:34,680:INFO:python_version: 3.10.12
2023-08-18 16:04:34,680:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 16:04:34,680:INFO:machine: AMD64
2023-08-18 16:04:34,681:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 16:04:34,684:INFO:Memory: svmem(total=68448301056, available=49549033472, percent=27.6, used=18899267584, free=49549033472)
2023-08-18 16:04:34,684:INFO:Physical Core: 12
2023-08-18 16:04:34,684:INFO:Logical Core: 20
2023-08-18 16:04:34,684:INFO:Checking libraries
2023-08-18 16:04:34,684:INFO:System:
2023-08-18 16:04:34,684:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 16:04:34,684:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 16:04:34,684:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 16:04:34,684:INFO:PyCaret required dependencies:
2023-08-18 16:04:34,684:INFO:                 pip: 23.2.1
2023-08-18 16:04:34,684:INFO:          setuptools: 68.0.0
2023-08-18 16:04:34,684:INFO:             pycaret: 3.0.4
2023-08-18 16:04:34,684:INFO:             IPython: 7.34.0
2023-08-18 16:04:34,684:INFO:          ipywidgets: 7.8.0
2023-08-18 16:04:34,684:INFO:                tqdm: 4.66.1
2023-08-18 16:04:34,684:INFO:               numpy: 1.23.5
2023-08-18 16:04:34,684:INFO:              pandas: 1.5.3
2023-08-18 16:04:34,685:INFO:              jinja2: 3.1.2
2023-08-18 16:04:34,685:INFO:               scipy: 1.10.1
2023-08-18 16:04:34,685:INFO:              joblib: 1.3.2
2023-08-18 16:04:34,685:INFO:             sklearn: 1.2.2
2023-08-18 16:04:34,685:INFO:                pyod: 1.1.0
2023-08-18 16:04:34,685:INFO:            imblearn: 0.11.0
2023-08-18 16:04:34,685:INFO:   category_encoders: 2.6.2
2023-08-18 16:04:34,685:INFO:            lightgbm: 4.0.0
2023-08-18 16:04:34,685:INFO:               numba: 0.57.1
2023-08-18 16:04:34,685:INFO:            requests: 2.31.0
2023-08-18 16:04:34,685:INFO:          matplotlib: 3.7.2
2023-08-18 16:04:34,685:INFO:          scikitplot: 0.3.7
2023-08-18 16:04:34,685:INFO:         yellowbrick: 1.5
2023-08-18 16:04:34,685:INFO:              plotly: 5.16.1
2023-08-18 16:04:34,685:INFO:    plotly-resampler: Not installed
2023-08-18 16:04:34,685:INFO:             kaleido: 0.2.1
2023-08-18 16:04:34,685:INFO:           schemdraw: 0.15
2023-08-18 16:04:34,685:INFO:         statsmodels: 0.14.0
2023-08-18 16:04:34,685:INFO:              sktime: 0.21.0
2023-08-18 16:04:34,685:INFO:               tbats: 1.1.3
2023-08-18 16:04:34,685:INFO:            pmdarima: 2.0.3
2023-08-18 16:04:34,685:INFO:              psutil: 5.9.5
2023-08-18 16:04:34,685:INFO:          markupsafe: 2.1.3
2023-08-18 16:04:34,685:INFO:             pickle5: Not installed
2023-08-18 16:04:34,685:INFO:         cloudpickle: 2.2.1
2023-08-18 16:04:34,686:INFO:         deprecation: 2.1.0
2023-08-18 16:04:34,686:INFO:              xxhash: 3.3.0
2023-08-18 16:04:34,686:INFO:           wurlitzer: 3.0.3
2023-08-18 16:04:34,686:INFO:PyCaret optional dependencies:
2023-08-18 16:04:34,686:INFO:                shap: 0.42.1
2023-08-18 16:04:34,686:INFO:           interpret: 0.4.3
2023-08-18 16:04:34,686:INFO:                umap: 0.5.3
2023-08-18 16:04:34,686:INFO:    pandas_profiling: 4.5.1
2023-08-18 16:04:34,686:INFO:  explainerdashboard: 0.4.3
2023-08-18 16:04:34,686:INFO:             autoviz: 0.1.730
2023-08-18 16:04:34,686:INFO:           fairlearn: 0.7.0
2023-08-18 16:04:34,686:INFO:          deepchecks: 0.17.4
2023-08-18 16:04:34,686:INFO:             xgboost: 1.7.6
2023-08-18 16:04:34,686:INFO:            catboost: 1.2
2023-08-18 16:04:34,686:INFO:              kmodes: 0.12.2
2023-08-18 16:04:34,686:INFO:             mlxtend: 0.22.0
2023-08-18 16:04:34,686:INFO:       statsforecast: 1.5.0
2023-08-18 16:04:34,686:INFO:        tune_sklearn: 0.4.6
2023-08-18 16:04:34,686:INFO:                 ray: 2.6.3
2023-08-18 16:04:34,686:INFO:            hyperopt: 0.2.7
2023-08-18 16:04:34,686:INFO:              optuna: 3.3.0
2023-08-18 16:04:34,686:INFO:               skopt: 0.9.0
2023-08-18 16:04:34,686:INFO:              mlflow: 1.30.1
2023-08-18 16:04:34,686:INFO:              gradio: 3.40.1
2023-08-18 16:04:34,686:INFO:             fastapi: 0.101.1
2023-08-18 16:04:34,686:INFO:             uvicorn: 0.23.2
2023-08-18 16:04:34,686:INFO:              m2cgen: 0.10.0
2023-08-18 16:04:34,686:INFO:           evidently: 0.2.8
2023-08-18 16:04:34,686:INFO:               fugue: 0.8.6
2023-08-18 16:04:34,686:INFO:           streamlit: 1.25.0
2023-08-18 16:04:34,686:INFO:             prophet: 1.1.4
2023-08-18 16:04:34,686:INFO:None
2023-08-18 16:04:34,686:INFO:Set up data.
2023-08-18 16:04:34,852:INFO:Set up train/test split.
2023-08-18 16:04:34,983:INFO:Set up index.
2023-08-18 16:04:34,987:INFO:Set up folding strategy.
2023-08-18 16:04:34,987:INFO:Assigning column types.
2023-08-18 16:04:34,997:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 16:04:35,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 16:04:35,021:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:04:35,035:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:04:35,037:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:04:35,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 16:04:35,062:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:04:35,077:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:04:35,079:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:04:35,079:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 16:04:35,103:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:04:35,119:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:04:35,120:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:04:35,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:04:35,161:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:04:35,163:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:04:35,163:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 16:04:35,203:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:04:35,204:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:04:35,243:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:04:35,244:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:04:35,246:INFO:Preparing preprocessing pipeline...
2023-08-18 16:04:35,248:INFO:Set up label encoding.
2023-08-18 16:04:35,248:INFO:Set up simple imputation.
2023-08-18 16:04:35,279:INFO:Set up encoding of ordinal features.
2023-08-18 16:04:35,309:INFO:Set up encoding of categorical features.
2023-08-18 16:04:35,310:INFO:Set up removing outliers.
2023-08-18 16:04:35,310:INFO:Set up feature normalization.
2023-08-18 16:04:35,311:INFO:Set up column name cleaning.
2023-08-18 16:04:47,009:INFO:Finished creating preprocessing pipeline.
2023-08-18 16:04:47,054:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=559,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 16:04:47,054:INFO:Creating final display dataframe.
2023-08-18 16:04:58,423:INFO:Setup _display_container:            Description                Value      
0                    Session id               559
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 17)
5        Transformed data shape      (268239, 33)
6   Transformed train set shape      (184848, 33)
7    Transformed test set shape       (83391, 33)
8              Ordinal features                 8
9              Numeric features                 6
10         Categorical features                10
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              344d
2023-08-18 16:04:58,467:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:04:58,469:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:04:58,510:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:04:58,512:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:04:58,512:INFO:setup() successfully completed in 24.08s...............
2023-08-18 16:06:39,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 16:06:39,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 16:06:39,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 16:06:39,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-18 16:06:40,417:INFO:PyCaret ClassificationExperiment
2023-08-18 16:06:40,417:INFO:Logging name: clf-default-name
2023-08-18 16:06:40,417:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 16:06:40,417:INFO:version 3.0.4
2023-08-18 16:06:40,417:INFO:Initializing setup()
2023-08-18 16:06:40,417:INFO:self.USI: c323
2023-08-18 16:06:40,417:INFO:self._variable_keys: {'log_plots_param', 'gpu_n_jobs_param', '_available_plots', 'X', 'memory', 'idx', 'fix_imbalance', 'html_param', 'logging_param', 'y_train', 'y', 'is_multiclass', 'gpu_param', 'exp_name_log', 'X_test', 'seed', 'pipeline', 'n_jobs_param', 'data', '_ml_usecase', 'exp_id', 'USI', 'X_train', 'fold_shuffle_param', 'fold_groups_param', 'target_param', 'y_test', 'fold_generator'}
2023-08-18 16:06:40,417:INFO:Checking environment
2023-08-18 16:06:40,417:INFO:python_version: 3.10.12
2023-08-18 16:06:40,417:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 16:06:40,417:INFO:machine: AMD64
2023-08-18 16:06:40,417:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 16:06:40,421:INFO:Memory: svmem(total=68448301056, available=50023772160, percent=26.9, used=18424528896, free=50023772160)
2023-08-18 16:06:40,421:INFO:Physical Core: 12
2023-08-18 16:06:40,421:INFO:Logical Core: 20
2023-08-18 16:06:40,421:INFO:Checking libraries
2023-08-18 16:06:40,421:INFO:System:
2023-08-18 16:06:40,421:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 16:06:40,421:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 16:06:40,421:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 16:06:40,421:INFO:PyCaret required dependencies:
2023-08-18 16:06:40,830:INFO:                 pip: 23.2.1
2023-08-18 16:06:40,830:INFO:          setuptools: 68.0.0
2023-08-18 16:06:40,830:INFO:             pycaret: 3.0.4
2023-08-18 16:06:40,830:INFO:             IPython: 7.34.0
2023-08-18 16:06:40,830:INFO:          ipywidgets: 7.8.0
2023-08-18 16:06:40,830:INFO:                tqdm: 4.66.1
2023-08-18 16:06:40,830:INFO:               numpy: 1.23.5
2023-08-18 16:06:40,830:INFO:              pandas: 1.5.3
2023-08-18 16:06:40,830:INFO:              jinja2: 3.1.2
2023-08-18 16:06:40,830:INFO:               scipy: 1.10.1
2023-08-18 16:06:40,830:INFO:              joblib: 1.3.2
2023-08-18 16:06:40,830:INFO:             sklearn: 1.2.2
2023-08-18 16:06:40,830:INFO:                pyod: 1.1.0
2023-08-18 16:06:40,830:INFO:            imblearn: 0.11.0
2023-08-18 16:06:40,830:INFO:   category_encoders: 2.6.2
2023-08-18 16:06:40,830:INFO:            lightgbm: 4.0.0
2023-08-18 16:06:40,830:INFO:               numba: 0.57.1
2023-08-18 16:06:40,830:INFO:            requests: 2.31.0
2023-08-18 16:06:40,830:INFO:          matplotlib: 3.7.2
2023-08-18 16:06:40,830:INFO:          scikitplot: 0.3.7
2023-08-18 16:06:40,830:INFO:         yellowbrick: 1.5
2023-08-18 16:06:40,830:INFO:              plotly: 5.16.1
2023-08-18 16:06:40,830:INFO:    plotly-resampler: Not installed
2023-08-18 16:06:40,830:INFO:             kaleido: 0.2.1
2023-08-18 16:06:40,830:INFO:           schemdraw: 0.15
2023-08-18 16:06:40,830:INFO:         statsmodels: 0.14.0
2023-08-18 16:06:40,830:INFO:              sktime: 0.21.0
2023-08-18 16:06:40,830:INFO:               tbats: 1.1.3
2023-08-18 16:06:40,830:INFO:            pmdarima: 2.0.3
2023-08-18 16:06:40,830:INFO:              psutil: 5.9.5
2023-08-18 16:06:40,830:INFO:          markupsafe: 2.1.3
2023-08-18 16:06:40,830:INFO:             pickle5: Not installed
2023-08-18 16:06:40,830:INFO:         cloudpickle: 2.2.1
2023-08-18 16:06:40,831:INFO:         deprecation: 2.1.0
2023-08-18 16:06:40,831:INFO:              xxhash: 3.3.0
2023-08-18 16:06:40,831:INFO:           wurlitzer: 3.0.3
2023-08-18 16:06:40,831:INFO:PyCaret optional dependencies:
2023-08-18 16:06:42,056:INFO:                shap: 0.42.1
2023-08-18 16:06:42,056:INFO:           interpret: 0.4.3
2023-08-18 16:06:42,056:INFO:                umap: 0.5.3
2023-08-18 16:06:42,056:INFO:    pandas_profiling: 4.5.1
2023-08-18 16:06:42,056:INFO:  explainerdashboard: 0.4.3
2023-08-18 16:06:42,056:INFO:             autoviz: 0.1.730
2023-08-18 16:06:42,056:INFO:           fairlearn: 0.7.0
2023-08-18 16:06:42,056:INFO:          deepchecks: 0.17.4
2023-08-18 16:06:42,056:INFO:             xgboost: 1.7.6
2023-08-18 16:06:42,056:INFO:            catboost: 1.2
2023-08-18 16:06:42,056:INFO:              kmodes: 0.12.2
2023-08-18 16:06:42,056:INFO:             mlxtend: 0.22.0
2023-08-18 16:06:42,056:INFO:       statsforecast: 1.5.0
2023-08-18 16:06:42,056:INFO:        tune_sklearn: 0.4.6
2023-08-18 16:06:42,056:INFO:                 ray: 2.6.3
2023-08-18 16:06:42,056:INFO:            hyperopt: 0.2.7
2023-08-18 16:06:42,056:INFO:              optuna: 3.3.0
2023-08-18 16:06:42,057:INFO:               skopt: 0.9.0
2023-08-18 16:06:42,057:INFO:              mlflow: 1.30.1
2023-08-18 16:06:42,057:INFO:              gradio: 3.40.1
2023-08-18 16:06:42,057:INFO:             fastapi: 0.101.1
2023-08-18 16:06:42,057:INFO:             uvicorn: 0.23.2
2023-08-18 16:06:42,057:INFO:              m2cgen: 0.10.0
2023-08-18 16:06:42,057:INFO:           evidently: 0.2.8
2023-08-18 16:06:42,057:INFO:               fugue: 0.8.6
2023-08-18 16:06:42,057:INFO:           streamlit: 1.25.0
2023-08-18 16:06:42,057:INFO:             prophet: 1.1.4
2023-08-18 16:06:42,057:INFO:None
2023-08-18 16:06:42,057:INFO:Set up data.
2023-08-18 16:06:42,234:INFO:Set up train/test split.
2023-08-18 16:06:42,380:INFO:Set up index.
2023-08-18 16:06:42,385:INFO:Set up folding strategy.
2023-08-18 16:06:42,385:INFO:Assigning column types.
2023-08-18 16:06:42,401:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 16:06:42,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 16:06:42,427:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:06:42,446:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:06:42,447:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:06:42,488:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 16:06:42,489:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:06:42,505:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:06:42,507:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:06:42,507:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 16:06:42,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:06:42,547:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:06:42,549:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:06:42,574:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:06:42,589:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:06:42,590:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:06:42,591:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 16:06:42,630:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:06:42,632:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:06:42,674:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:06:42,676:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:06:42,677:INFO:Preparing preprocessing pipeline...
2023-08-18 16:06:42,681:INFO:Set up label encoding.
2023-08-18 16:06:42,681:INFO:Set up simple imputation.
2023-08-18 16:06:42,716:INFO:Set up encoding of ordinal features.
2023-08-18 16:06:42,757:INFO:Set up encoding of categorical features.
2023-08-18 16:06:42,757:INFO:Set up removing outliers.
2023-08-18 16:06:42,757:INFO:Set up imbalanced handling.
2023-08-18 16:06:42,757:INFO:Set up feature normalization.
2023-08-18 16:06:42,759:INFO:Set up column name cleaning.
2023-08-18 16:06:56,556:INFO:Finished creating preprocessing pipeline.
2023-08-18 16:06:56,597:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'BMI', 'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consum...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 16:06:56,597:INFO:Creating final display dataframe.
2023-08-18 16:07:09,591:INFO:Setup _display_container:            Description                Value      
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 19)
5        Transformed data shape      (424819, 42)
6   Transformed train set shape      (341428, 42)
7    Transformed test set shape       (83391, 42)
8              Ordinal features                 7
9              Numeric features                 7
10         Categorical features                11
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            zscore
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              c323
2023-08-18 16:07:09,639:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:07:09,641:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:07:09,684:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:07:09,686:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:07:09,687:INFO:setup() successfully completed in 29.54s...............
2023-08-18 16:07:59,412:INFO:PyCaret ClassificationExperiment
2023-08-18 16:07:59,412:INFO:Logging name: clf-default-name
2023-08-18 16:07:59,412:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-18 16:07:59,412:INFO:version 3.0.4
2023-08-18 16:07:59,412:INFO:Initializing setup()
2023-08-18 16:07:59,412:INFO:self.USI: e515
2023-08-18 16:07:59,412:INFO:self._variable_keys: {'log_plots_param', 'gpu_n_jobs_param', '_available_plots', 'X', 'memory', 'idx', 'fix_imbalance', 'html_param', 'logging_param', 'y_train', 'y', 'is_multiclass', 'gpu_param', 'exp_name_log', 'X_test', 'seed', 'pipeline', 'n_jobs_param', 'data', '_ml_usecase', 'exp_id', 'USI', 'X_train', 'fold_shuffle_param', 'fold_groups_param', 'target_param', 'y_test', 'fold_generator'}
2023-08-18 16:07:59,412:INFO:Checking environment
2023-08-18 16:07:59,413:INFO:python_version: 3.10.12
2023-08-18 16:07:59,413:INFO:python_build: ('main', 'Jun 23 2023 22:34:57')
2023-08-18 16:07:59,413:INFO:machine: AMD64
2023-08-18 16:07:59,413:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-18 16:07:59,416:INFO:Memory: svmem(total=68448301056, available=49641021440, percent=27.5, used=18807279616, free=49641021440)
2023-08-18 16:07:59,416:INFO:Physical Core: 12
2023-08-18 16:07:59,416:INFO:Logical Core: 20
2023-08-18 16:07:59,417:INFO:Checking libraries
2023-08-18 16:07:59,417:INFO:System:
2023-08-18 16:07:59,417:INFO:    python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]
2023-08-18 16:07:59,417:INFO:executable: c:\Users\Ramon\miniforge3\envs\PyCaretEnv\python.exe
2023-08-18 16:07:59,417:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-18 16:07:59,417:INFO:PyCaret required dependencies:
2023-08-18 16:07:59,417:INFO:                 pip: 23.2.1
2023-08-18 16:07:59,417:INFO:          setuptools: 68.0.0
2023-08-18 16:07:59,417:INFO:             pycaret: 3.0.4
2023-08-18 16:07:59,417:INFO:             IPython: 7.34.0
2023-08-18 16:07:59,417:INFO:          ipywidgets: 7.8.0
2023-08-18 16:07:59,417:INFO:                tqdm: 4.66.1
2023-08-18 16:07:59,417:INFO:               numpy: 1.23.5
2023-08-18 16:07:59,417:INFO:              pandas: 1.5.3
2023-08-18 16:07:59,417:INFO:              jinja2: 3.1.2
2023-08-18 16:07:59,417:INFO:               scipy: 1.10.1
2023-08-18 16:07:59,417:INFO:              joblib: 1.3.2
2023-08-18 16:07:59,417:INFO:             sklearn: 1.2.2
2023-08-18 16:07:59,417:INFO:                pyod: 1.1.0
2023-08-18 16:07:59,417:INFO:            imblearn: 0.11.0
2023-08-18 16:07:59,417:INFO:   category_encoders: 2.6.2
2023-08-18 16:07:59,417:INFO:            lightgbm: 4.0.0
2023-08-18 16:07:59,417:INFO:               numba: 0.57.1
2023-08-18 16:07:59,417:INFO:            requests: 2.31.0
2023-08-18 16:07:59,417:INFO:          matplotlib: 3.7.2
2023-08-18 16:07:59,417:INFO:          scikitplot: 0.3.7
2023-08-18 16:07:59,417:INFO:         yellowbrick: 1.5
2023-08-18 16:07:59,417:INFO:              plotly: 5.16.1
2023-08-18 16:07:59,417:INFO:    plotly-resampler: Not installed
2023-08-18 16:07:59,417:INFO:             kaleido: 0.2.1
2023-08-18 16:07:59,417:INFO:           schemdraw: 0.15
2023-08-18 16:07:59,417:INFO:         statsmodels: 0.14.0
2023-08-18 16:07:59,417:INFO:              sktime: 0.21.0
2023-08-18 16:07:59,417:INFO:               tbats: 1.1.3
2023-08-18 16:07:59,417:INFO:            pmdarima: 2.0.3
2023-08-18 16:07:59,417:INFO:              psutil: 5.9.5
2023-08-18 16:07:59,417:INFO:          markupsafe: 2.1.3
2023-08-18 16:07:59,417:INFO:             pickle5: Not installed
2023-08-18 16:07:59,417:INFO:         cloudpickle: 2.2.1
2023-08-18 16:07:59,417:INFO:         deprecation: 2.1.0
2023-08-18 16:07:59,417:INFO:              xxhash: 3.3.0
2023-08-18 16:07:59,417:INFO:           wurlitzer: 3.0.3
2023-08-18 16:07:59,417:INFO:PyCaret optional dependencies:
2023-08-18 16:07:59,417:INFO:                shap: 0.42.1
2023-08-18 16:07:59,417:INFO:           interpret: 0.4.3
2023-08-18 16:07:59,417:INFO:                umap: 0.5.3
2023-08-18 16:07:59,417:INFO:    pandas_profiling: 4.5.1
2023-08-18 16:07:59,417:INFO:  explainerdashboard: 0.4.3
2023-08-18 16:07:59,418:INFO:             autoviz: 0.1.730
2023-08-18 16:07:59,418:INFO:           fairlearn: 0.7.0
2023-08-18 16:07:59,418:INFO:          deepchecks: 0.17.4
2023-08-18 16:07:59,418:INFO:             xgboost: 1.7.6
2023-08-18 16:07:59,418:INFO:            catboost: 1.2
2023-08-18 16:07:59,418:INFO:              kmodes: 0.12.2
2023-08-18 16:07:59,418:INFO:             mlxtend: 0.22.0
2023-08-18 16:07:59,418:INFO:       statsforecast: 1.5.0
2023-08-18 16:07:59,418:INFO:        tune_sklearn: 0.4.6
2023-08-18 16:07:59,418:INFO:                 ray: 2.6.3
2023-08-18 16:07:59,418:INFO:            hyperopt: 0.2.7
2023-08-18 16:07:59,418:INFO:              optuna: 3.3.0
2023-08-18 16:07:59,418:INFO:               skopt: 0.9.0
2023-08-18 16:07:59,418:INFO:              mlflow: 1.30.1
2023-08-18 16:07:59,418:INFO:              gradio: 3.40.1
2023-08-18 16:07:59,418:INFO:             fastapi: 0.101.1
2023-08-18 16:07:59,418:INFO:             uvicorn: 0.23.2
2023-08-18 16:07:59,418:INFO:              m2cgen: 0.10.0
2023-08-18 16:07:59,418:INFO:           evidently: 0.2.8
2023-08-18 16:07:59,418:INFO:               fugue: 0.8.6
2023-08-18 16:07:59,418:INFO:           streamlit: 1.25.0
2023-08-18 16:07:59,418:INFO:             prophet: 1.1.4
2023-08-18 16:07:59,418:INFO:None
2023-08-18 16:07:59,418:INFO:Set up data.
2023-08-18 16:07:59,594:INFO:Set up train/test split.
2023-08-18 16:07:59,729:INFO:Set up index.
2023-08-18 16:07:59,733:INFO:Set up folding strategy.
2023-08-18 16:07:59,733:INFO:Assigning column types.
2023-08-18 16:07:59,744:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-18 16:07:59,768:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 16:07:59,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:07:59,785:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:07:59,786:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:07:59,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-18 16:07:59,812:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:07:59,827:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:07:59,829:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:07:59,829:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-18 16:07:59,854:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:07:59,869:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:07:59,870:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:07:59,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-18 16:07:59,911:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:07:59,913:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:07:59,913:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-18 16:07:59,953:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:07:59,954:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:07:59,994:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:07:59,996:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:07:59,997:INFO:Preparing preprocessing pipeline...
2023-08-18 16:07:59,999:INFO:Set up label encoding.
2023-08-18 16:07:59,999:INFO:Set up simple imputation.
2023-08-18 16:08:00,031:INFO:Set up encoding of ordinal features.
2023-08-18 16:08:00,062:INFO:Set up encoding of categorical features.
2023-08-18 16:08:00,062:INFO:Set up removing outliers.
2023-08-18 16:08:00,063:INFO:Set up feature normalization.
2023-08-18 16:08:00,064:INFO:Set up column name cleaning.
2023-08-18 16:08:11,769:INFO:Finished creating preprocessing pipeline.
2023-08-18 16:08:11,812:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Ramon\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Height_(cm)', 'Weight_(kg)',
                                             'Alcohol_Consumption',
                                             'Fruit_Consumption',
                                             'Green_Vegetables_Consumption'...
                                    transformer=RemoveOutliers(method='iforest',
                                                               n_jobs=1,
                                                               random_state=123,
                                                               threshold=0.05))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-18 16:08:11,812:INFO:Creating final display dataframe.
2023-08-18 16:08:23,275:INFO:Setup _display_container:            Description                Value      
0                    Session id               123
1                        Target     Heart_Disease
2                   Target type            Binary
3                Target mapping     No: 0, Yes: 1
4           Original data shape      (277968, 17)
5        Transformed data shape      (268239, 33)
6   Transformed train set shape      (184848, 33)
7    Transformed test set shape       (83391, 33)
8              Ordinal features                 8
9              Numeric features                 6
10         Categorical features                10
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold              0.05
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              e515
2023-08-18 16:08:23,319:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:08:23,321:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:08:23,360:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-18 16:08:23,362:INFO:Soft dependency imported: catboost: 1.2
2023-08-18 16:08:23,363:INFO:setup() successfully completed in 24.29s...............
2023-08-18 16:08:46,483:INFO:Initializing compare_models()
2023-08-18 16:08:46,483:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-18 16:08:46,483:INFO:Checking exceptions
2023-08-18 16:08:46,503:INFO:Preparing display monitor
2023-08-18 16:08:46,517:INFO:Initializing Logistic Regression
2023-08-18 16:08:46,517:INFO:Total runtime is 0.0 minutes
2023-08-18 16:08:46,519:INFO:SubProcess create_model() called ==================================
2023-08-18 16:08:46,519:INFO:Initializing create_model()
2023-08-18 16:08:46,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:08:46,519:INFO:Checking exceptions
2023-08-18 16:08:46,520:INFO:Importing libraries
2023-08-18 16:08:46,520:INFO:Copying training dataset
2023-08-18 16:08:46,565:INFO:Defining folds
2023-08-18 16:08:46,566:INFO:Declaring metric variables
2023-08-18 16:08:46,570:INFO:Importing untrained model
2023-08-18 16:08:46,573:INFO:Logistic Regression Imported successfully
2023-08-18 16:08:46,578:INFO:Starting cross validation
2023-08-18 16:08:46,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:08:54,453:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,485:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,542:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,546:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,573:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,574:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,626:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,633:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,639:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:08:54,658:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-08-18 16:09:26,134:INFO:Calculating mean and std
2023-08-18 16:09:26,134:INFO:Creating metrics dataframe
2023-08-18 16:09:26,481:INFO:Uploading results into container
2023-08-18 16:09:26,482:INFO:Uploading model into container now
2023-08-18 16:09:26,482:INFO:_master_model_container: 1
2023-08-18 16:09:26,482:INFO:_display_container: 2
2023-08-18 16:09:26,483:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-18 16:09:26,483:INFO:create_model() successfully completed......................................
2023-08-18 16:09:26,629:INFO:SubProcess create_model() end ==================================
2023-08-18 16:09:26,629:INFO:Creating metrics dataframe
2023-08-18 16:09:26,636:INFO:Initializing K Neighbors Classifier
2023-08-18 16:09:26,636:INFO:Total runtime is 0.6686415831247966 minutes
2023-08-18 16:09:26,638:INFO:SubProcess create_model() called ==================================
2023-08-18 16:09:26,639:INFO:Initializing create_model()
2023-08-18 16:09:26,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:09:26,639:INFO:Checking exceptions
2023-08-18 16:09:26,639:INFO:Importing libraries
2023-08-18 16:09:26,639:INFO:Copying training dataset
2023-08-18 16:09:26,675:INFO:Defining folds
2023-08-18 16:09:26,675:INFO:Declaring metric variables
2023-08-18 16:09:26,677:INFO:Importing untrained model
2023-08-18 16:09:26,680:INFO:K Neighbors Classifier Imported successfully
2023-08-18 16:09:26,684:INFO:Starting cross validation
2023-08-18 16:09:26,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:10:02,879:INFO:Calculating mean and std
2023-08-18 16:10:02,880:INFO:Creating metrics dataframe
2023-08-18 16:10:03,247:INFO:Uploading results into container
2023-08-18 16:10:03,248:INFO:Uploading model into container now
2023-08-18 16:10:03,248:INFO:_master_model_container: 2
2023-08-18 16:10:03,249:INFO:_display_container: 2
2023-08-18 16:10:03,249:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-18 16:10:03,249:INFO:create_model() successfully completed......................................
2023-08-18 16:10:03,354:INFO:SubProcess create_model() end ==================================
2023-08-18 16:10:03,354:INFO:Creating metrics dataframe
2023-08-18 16:10:03,361:INFO:Initializing Naive Bayes
2023-08-18 16:10:03,361:INFO:Total runtime is 1.2807205359141034 minutes
2023-08-18 16:10:03,363:INFO:SubProcess create_model() called ==================================
2023-08-18 16:10:03,364:INFO:Initializing create_model()
2023-08-18 16:10:03,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:10:03,364:INFO:Checking exceptions
2023-08-18 16:10:03,364:INFO:Importing libraries
2023-08-18 16:10:03,364:INFO:Copying training dataset
2023-08-18 16:10:03,395:INFO:Defining folds
2023-08-18 16:10:03,395:INFO:Declaring metric variables
2023-08-18 16:10:03,399:INFO:Importing untrained model
2023-08-18 16:10:03,402:INFO:Naive Bayes Imported successfully
2023-08-18 16:10:03,407:INFO:Starting cross validation
2023-08-18 16:10:03,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:10:08,321:INFO:Calculating mean and std
2023-08-18 16:10:08,322:INFO:Creating metrics dataframe
2023-08-18 16:10:08,674:INFO:Uploading results into container
2023-08-18 16:10:08,675:INFO:Uploading model into container now
2023-08-18 16:10:08,675:INFO:_master_model_container: 3
2023-08-18 16:10:08,675:INFO:_display_container: 2
2023-08-18 16:10:08,675:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-18 16:10:08,675:INFO:create_model() successfully completed......................................
2023-08-18 16:10:08,780:INFO:SubProcess create_model() end ==================================
2023-08-18 16:10:08,780:INFO:Creating metrics dataframe
2023-08-18 16:10:08,787:INFO:Initializing Decision Tree Classifier
2023-08-18 16:10:08,787:INFO:Total runtime is 1.3711539189020794 minutes
2023-08-18 16:10:08,789:INFO:SubProcess create_model() called ==================================
2023-08-18 16:10:08,790:INFO:Initializing create_model()
2023-08-18 16:10:08,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:10:08,790:INFO:Checking exceptions
2023-08-18 16:10:08,790:INFO:Importing libraries
2023-08-18 16:10:08,790:INFO:Copying training dataset
2023-08-18 16:10:08,826:INFO:Defining folds
2023-08-18 16:10:08,826:INFO:Declaring metric variables
2023-08-18 16:10:08,829:INFO:Importing untrained model
2023-08-18 16:10:08,831:INFO:Decision Tree Classifier Imported successfully
2023-08-18 16:10:08,836:INFO:Starting cross validation
2023-08-18 16:10:08,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:10:14,683:INFO:Calculating mean and std
2023-08-18 16:10:14,684:INFO:Creating metrics dataframe
2023-08-18 16:10:15,051:INFO:Uploading results into container
2023-08-18 16:10:15,051:INFO:Uploading model into container now
2023-08-18 16:10:15,052:INFO:_master_model_container: 4
2023-08-18 16:10:15,052:INFO:_display_container: 2
2023-08-18 16:10:15,052:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-18 16:10:15,052:INFO:create_model() successfully completed......................................
2023-08-18 16:10:15,156:INFO:SubProcess create_model() end ==================================
2023-08-18 16:10:15,157:INFO:Creating metrics dataframe
2023-08-18 16:10:15,165:INFO:Initializing SVM - Linear Kernel
2023-08-18 16:10:15,165:INFO:Total runtime is 1.4774548292160035 minutes
2023-08-18 16:10:15,168:INFO:SubProcess create_model() called ==================================
2023-08-18 16:10:15,168:INFO:Initializing create_model()
2023-08-18 16:10:15,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:10:15,168:INFO:Checking exceptions
2023-08-18 16:10:15,168:INFO:Importing libraries
2023-08-18 16:10:15,168:INFO:Copying training dataset
2023-08-18 16:10:15,200:INFO:Defining folds
2023-08-18 16:10:15,201:INFO:Declaring metric variables
2023-08-18 16:10:15,204:INFO:Importing untrained model
2023-08-18 16:10:15,208:INFO:SVM - Linear Kernel Imported successfully
2023-08-18 16:10:15,212:INFO:Starting cross validation
2023-08-18 16:10:15,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:10:17,780:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,832:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,832:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,833:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,846:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,856:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,877:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,881:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,883:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,914:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-18 16:10:17,987:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:18,021:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:18,034:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:18,044:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:18,069:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:18,071:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:18,083:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:18,100:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:18,131:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:20,902:INFO:Calculating mean and std
2023-08-18 16:10:20,903:INFO:Creating metrics dataframe
2023-08-18 16:10:21,291:INFO:Uploading results into container
2023-08-18 16:10:21,292:INFO:Uploading model into container now
2023-08-18 16:10:21,292:INFO:_master_model_container: 5
2023-08-18 16:10:21,292:INFO:_display_container: 2
2023-08-18 16:10:21,292:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-18 16:10:21,293:INFO:create_model() successfully completed......................................
2023-08-18 16:10:21,397:INFO:SubProcess create_model() end ==================================
2023-08-18 16:10:21,397:INFO:Creating metrics dataframe
2023-08-18 16:10:21,405:INFO:Initializing Ridge Classifier
2023-08-18 16:10:21,405:INFO:Total runtime is 1.5814656893412273 minutes
2023-08-18 16:10:21,407:INFO:SubProcess create_model() called ==================================
2023-08-18 16:10:21,407:INFO:Initializing create_model()
2023-08-18 16:10:21,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:10:21,407:INFO:Checking exceptions
2023-08-18 16:10:21,407:INFO:Importing libraries
2023-08-18 16:10:21,407:INFO:Copying training dataset
2023-08-18 16:10:21,452:INFO:Defining folds
2023-08-18 16:10:21,452:INFO:Declaring metric variables
2023-08-18 16:10:21,455:INFO:Importing untrained model
2023-08-18 16:10:21,458:INFO:Ridge Classifier Imported successfully
2023-08-18 16:10:21,462:INFO:Starting cross validation
2023-08-18 16:10:21,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:10:23,493:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,522:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,558:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,578:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,593:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,599:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,607:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,663:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,664:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,691:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-18 16:10:23,699:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,742:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,765:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,806:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,813:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,819:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,826:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,865:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,873:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:23,922:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:10:26,509:INFO:Calculating mean and std
2023-08-18 16:10:26,510:INFO:Creating metrics dataframe
2023-08-18 16:10:26,881:INFO:Uploading results into container
2023-08-18 16:10:26,882:INFO:Uploading model into container now
2023-08-18 16:10:26,882:INFO:_master_model_container: 6
2023-08-18 16:10:26,882:INFO:_display_container: 2
2023-08-18 16:10:26,882:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-18 16:10:26,882:INFO:create_model() successfully completed......................................
2023-08-18 16:10:26,984:INFO:SubProcess create_model() end ==================================
2023-08-18 16:10:26,985:INFO:Creating metrics dataframe
2023-08-18 16:10:26,992:INFO:Initializing Random Forest Classifier
2023-08-18 16:10:26,992:INFO:Total runtime is 1.6745708624521893 minutes
2023-08-18 16:10:26,994:INFO:SubProcess create_model() called ==================================
2023-08-18 16:10:26,994:INFO:Initializing create_model()
2023-08-18 16:10:26,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:10:26,994:INFO:Checking exceptions
2023-08-18 16:10:26,995:INFO:Importing libraries
2023-08-18 16:10:26,995:INFO:Copying training dataset
2023-08-18 16:10:27,025:INFO:Defining folds
2023-08-18 16:10:27,025:INFO:Declaring metric variables
2023-08-18 16:10:27,028:INFO:Importing untrained model
2023-08-18 16:10:27,030:INFO:Random Forest Classifier Imported successfully
2023-08-18 16:10:27,037:INFO:Starting cross validation
2023-08-18 16:10:27,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:10:45,275:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.84s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-18 16:10:45,523:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-18 16:10:48,083:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-18 16:10:48,689:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-18 16:10:49,822:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-18 16:10:50,326:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.77s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-18 16:10:52,724:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.08s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 16:10:54,259:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 16:10:54,589:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 16:10:58,770:INFO:Calculating mean and std
2023-08-18 16:10:58,771:INFO:Creating metrics dataframe
2023-08-18 16:10:59,128:INFO:Uploading results into container
2023-08-18 16:10:59,128:INFO:Uploading model into container now
2023-08-18 16:10:59,129:INFO:_master_model_container: 7
2023-08-18 16:10:59,129:INFO:_display_container: 2
2023-08-18 16:10:59,129:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-18 16:10:59,129:INFO:create_model() successfully completed......................................
2023-08-18 16:10:59,232:INFO:SubProcess create_model() end ==================================
2023-08-18 16:10:59,232:INFO:Creating metrics dataframe
2023-08-18 16:10:59,240:INFO:Initializing Quadratic Discriminant Analysis
2023-08-18 16:10:59,240:INFO:Total runtime is 2.2120413382848105 minutes
2023-08-18 16:10:59,242:INFO:SubProcess create_model() called ==================================
2023-08-18 16:10:59,242:INFO:Initializing create_model()
2023-08-18 16:10:59,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:10:59,242:INFO:Checking exceptions
2023-08-18 16:10:59,242:INFO:Importing libraries
2023-08-18 16:10:59,243:INFO:Copying training dataset
2023-08-18 16:10:59,277:INFO:Defining folds
2023-08-18 16:10:59,277:INFO:Declaring metric variables
2023-08-18 16:10:59,281:INFO:Importing untrained model
2023-08-18 16:10:59,284:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-18 16:10:59,288:INFO:Starting cross validation
2023-08-18 16:10:59,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:11:02,327:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,350:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,350:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,387:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,438:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,450:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,512:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,552:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,553:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:02,593:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:11:05,817:INFO:Calculating mean and std
2023-08-18 16:11:05,818:INFO:Creating metrics dataframe
2023-08-18 16:11:06,173:INFO:Uploading results into container
2023-08-18 16:11:06,173:INFO:Uploading model into container now
2023-08-18 16:11:06,173:INFO:_master_model_container: 8
2023-08-18 16:11:06,174:INFO:_display_container: 2
2023-08-18 16:11:06,174:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-18 16:11:06,174:INFO:create_model() successfully completed......................................
2023-08-18 16:11:06,280:INFO:SubProcess create_model() end ==================================
2023-08-18 16:11:06,280:INFO:Creating metrics dataframe
2023-08-18 16:11:06,287:INFO:Initializing Ada Boost Classifier
2023-08-18 16:11:06,287:INFO:Total runtime is 2.329499693711599 minutes
2023-08-18 16:11:06,289:INFO:SubProcess create_model() called ==================================
2023-08-18 16:11:06,289:INFO:Initializing create_model()
2023-08-18 16:11:06,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:11:06,289:INFO:Checking exceptions
2023-08-18 16:11:06,289:INFO:Importing libraries
2023-08-18 16:11:06,289:INFO:Copying training dataset
2023-08-18 16:11:06,319:INFO:Defining folds
2023-08-18 16:11:06,320:INFO:Declaring metric variables
2023-08-18 16:11:06,323:INFO:Importing untrained model
2023-08-18 16:11:06,326:INFO:Ada Boost Classifier Imported successfully
2023-08-18 16:11:06,331:INFO:Starting cross validation
2023-08-18 16:11:06,337:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:11:22,443:INFO:Calculating mean and std
2023-08-18 16:11:22,444:INFO:Creating metrics dataframe
2023-08-18 16:11:22,818:INFO:Uploading results into container
2023-08-18 16:11:22,819:INFO:Uploading model into container now
2023-08-18 16:11:22,819:INFO:_master_model_container: 9
2023-08-18 16:11:22,819:INFO:_display_container: 2
2023-08-18 16:11:22,820:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-18 16:11:22,820:INFO:create_model() successfully completed......................................
2023-08-18 16:11:22,925:INFO:SubProcess create_model() end ==================================
2023-08-18 16:11:22,925:INFO:Creating metrics dataframe
2023-08-18 16:11:22,933:INFO:Initializing Gradient Boosting Classifier
2023-08-18 16:11:22,933:INFO:Total runtime is 2.6069239854812625 minutes
2023-08-18 16:11:22,936:INFO:SubProcess create_model() called ==================================
2023-08-18 16:11:22,936:INFO:Initializing create_model()
2023-08-18 16:11:22,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:11:22,936:INFO:Checking exceptions
2023-08-18 16:11:22,936:INFO:Importing libraries
2023-08-18 16:11:22,936:INFO:Copying training dataset
2023-08-18 16:11:22,974:INFO:Defining folds
2023-08-18 16:11:22,974:INFO:Declaring metric variables
2023-08-18 16:11:22,977:INFO:Importing untrained model
2023-08-18 16:11:22,980:INFO:Gradient Boosting Classifier Imported successfully
2023-08-18 16:11:22,984:INFO:Starting cross validation
2023-08-18 16:11:22,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:12:00,932:INFO:Calculating mean and std
2023-08-18 16:12:00,933:INFO:Creating metrics dataframe
2023-08-18 16:12:01,284:INFO:Uploading results into container
2023-08-18 16:12:01,285:INFO:Uploading model into container now
2023-08-18 16:12:01,285:INFO:_master_model_container: 10
2023-08-18 16:12:01,285:INFO:_display_container: 2
2023-08-18 16:12:01,286:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-18 16:12:01,286:INFO:create_model() successfully completed......................................
2023-08-18 16:12:01,386:INFO:SubProcess create_model() end ==================================
2023-08-18 16:12:01,386:INFO:Creating metrics dataframe
2023-08-18 16:12:01,394:INFO:Initializing Linear Discriminant Analysis
2023-08-18 16:12:01,394:INFO:Total runtime is 3.2479425350824993 minutes
2023-08-18 16:12:01,396:INFO:SubProcess create_model() called ==================================
2023-08-18 16:12:01,396:INFO:Initializing create_model()
2023-08-18 16:12:01,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:12:01,396:INFO:Checking exceptions
2023-08-18 16:12:01,396:INFO:Importing libraries
2023-08-18 16:12:01,396:INFO:Copying training dataset
2023-08-18 16:12:01,434:INFO:Defining folds
2023-08-18 16:12:01,434:INFO:Declaring metric variables
2023-08-18 16:12:01,437:INFO:Importing untrained model
2023-08-18 16:12:01,439:INFO:Linear Discriminant Analysis Imported successfully
2023-08-18 16:12:01,444:INFO:Starting cross validation
2023-08-18 16:12:01,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:12:08,059:INFO:Calculating mean and std
2023-08-18 16:12:08,060:INFO:Creating metrics dataframe
2023-08-18 16:12:08,421:INFO:Uploading results into container
2023-08-18 16:12:08,421:INFO:Uploading model into container now
2023-08-18 16:12:08,422:INFO:_master_model_container: 11
2023-08-18 16:12:08,422:INFO:_display_container: 2
2023-08-18 16:12:08,422:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-18 16:12:08,422:INFO:create_model() successfully completed......................................
2023-08-18 16:12:08,523:INFO:SubProcess create_model() end ==================================
2023-08-18 16:12:08,524:INFO:Creating metrics dataframe
2023-08-18 16:12:08,532:INFO:Initializing Extra Trees Classifier
2023-08-18 16:12:08,532:INFO:Total runtime is 3.3669100801150007 minutes
2023-08-18 16:12:08,534:INFO:SubProcess create_model() called ==================================
2023-08-18 16:12:08,534:INFO:Initializing create_model()
2023-08-18 16:12:08,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:12:08,535:INFO:Checking exceptions
2023-08-18 16:12:08,535:INFO:Importing libraries
2023-08-18 16:12:08,535:INFO:Copying training dataset
2023-08-18 16:12:08,572:INFO:Defining folds
2023-08-18 16:12:08,572:INFO:Declaring metric variables
2023-08-18 16:12:08,575:INFO:Importing untrained model
2023-08-18 16:12:08,577:INFO:Extra Trees Classifier Imported successfully
2023-08-18 16:12:08,582:INFO:Starting cross validation
2023-08-18 16:12:08,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:12:43,060:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 16:12:43,144:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 16:12:43,242:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-18 16:12:46,379:INFO:Calculating mean and std
2023-08-18 16:12:46,380:INFO:Creating metrics dataframe
2023-08-18 16:12:46,717:INFO:Uploading results into container
2023-08-18 16:12:46,718:INFO:Uploading model into container now
2023-08-18 16:12:46,719:INFO:_master_model_container: 12
2023-08-18 16:12:46,719:INFO:_display_container: 2
2023-08-18 16:12:46,719:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-18 16:12:46,719:INFO:create_model() successfully completed......................................
2023-08-18 16:12:46,840:INFO:SubProcess create_model() end ==================================
2023-08-18 16:12:46,840:INFO:Creating metrics dataframe
2023-08-18 16:12:46,849:INFO:Initializing Extreme Gradient Boosting
2023-08-18 16:12:46,849:INFO:Total runtime is 4.005526741345724 minutes
2023-08-18 16:12:46,852:INFO:SubProcess create_model() called ==================================
2023-08-18 16:12:46,852:INFO:Initializing create_model()
2023-08-18 16:12:46,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:12:46,852:INFO:Checking exceptions
2023-08-18 16:12:46,852:INFO:Importing libraries
2023-08-18 16:12:46,852:INFO:Copying training dataset
2023-08-18 16:12:46,891:INFO:Defining folds
2023-08-18 16:12:46,891:INFO:Declaring metric variables
2023-08-18 16:12:46,894:INFO:Importing untrained model
2023-08-18 16:12:46,896:INFO:Extreme Gradient Boosting Imported successfully
2023-08-18 16:12:46,901:INFO:Starting cross validation
2023-08-18 16:12:46,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:13:08,166:INFO:Calculating mean and std
2023-08-18 16:13:08,167:INFO:Creating metrics dataframe
2023-08-18 16:13:08,491:INFO:Uploading results into container
2023-08-18 16:13:08,492:INFO:Uploading model into container now
2023-08-18 16:13:08,492:INFO:_master_model_container: 13
2023-08-18 16:13:08,492:INFO:_display_container: 2
2023-08-18 16:13:08,493:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-18 16:13:08,493:INFO:create_model() successfully completed......................................
2023-08-18 16:13:08,598:INFO:SubProcess create_model() end ==================================
2023-08-18 16:13:08,598:INFO:Creating metrics dataframe
2023-08-18 16:13:08,607:INFO:Initializing Light Gradient Boosting Machine
2023-08-18 16:13:08,607:INFO:Total runtime is 4.368151183923086 minutes
2023-08-18 16:13:08,609:INFO:SubProcess create_model() called ==================================
2023-08-18 16:13:08,609:INFO:Initializing create_model()
2023-08-18 16:13:08,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:13:08,609:INFO:Checking exceptions
2023-08-18 16:13:08,609:INFO:Importing libraries
2023-08-18 16:13:08,609:INFO:Copying training dataset
2023-08-18 16:13:08,644:INFO:Defining folds
2023-08-18 16:13:08,644:INFO:Declaring metric variables
2023-08-18 16:13:08,648:INFO:Importing untrained model
2023-08-18 16:13:08,651:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-18 16:13:08,655:INFO:Starting cross validation
2023-08-18 16:13:08,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:13:16,257:INFO:Calculating mean and std
2023-08-18 16:13:16,258:INFO:Creating metrics dataframe
2023-08-18 16:13:16,602:INFO:Uploading results into container
2023-08-18 16:13:16,602:INFO:Uploading model into container now
2023-08-18 16:13:16,602:INFO:_master_model_container: 14
2023-08-18 16:13:16,602:INFO:_display_container: 2
2023-08-18 16:13:16,604:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-18 16:13:16,604:INFO:create_model() successfully completed......................................
2023-08-18 16:13:16,707:INFO:SubProcess create_model() end ==================================
2023-08-18 16:13:16,707:INFO:Creating metrics dataframe
2023-08-18 16:13:16,715:INFO:Initializing CatBoost Classifier
2023-08-18 16:13:16,715:INFO:Total runtime is 4.5032880465189615 minutes
2023-08-18 16:13:16,717:INFO:SubProcess create_model() called ==================================
2023-08-18 16:13:16,718:INFO:Initializing create_model()
2023-08-18 16:13:16,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:13:16,718:INFO:Checking exceptions
2023-08-18 16:13:16,718:INFO:Importing libraries
2023-08-18 16:13:16,718:INFO:Copying training dataset
2023-08-18 16:13:16,755:INFO:Defining folds
2023-08-18 16:13:16,755:INFO:Declaring metric variables
2023-08-18 16:13:16,758:INFO:Importing untrained model
2023-08-18 16:13:16,760:INFO:CatBoost Classifier Imported successfully
2023-08-18 16:13:16,764:INFO:Starting cross validation
2023-08-18 16:13:16,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:14:51,664:INFO:Calculating mean and std
2023-08-18 16:14:51,665:INFO:Creating metrics dataframe
2023-08-18 16:14:52,011:INFO:Uploading results into container
2023-08-18 16:14:52,012:INFO:Uploading model into container now
2023-08-18 16:14:52,012:INFO:_master_model_container: 15
2023-08-18 16:14:52,012:INFO:_display_container: 2
2023-08-18 16:14:52,012:INFO:<catboost.core.CatBoostClassifier object at 0x0000018F2D5B38B0>
2023-08-18 16:14:52,012:INFO:create_model() successfully completed......................................
2023-08-18 16:14:52,122:INFO:SubProcess create_model() end ==================================
2023-08-18 16:14:52,122:INFO:Creating metrics dataframe
2023-08-18 16:14:52,130:INFO:Initializing Dummy Classifier
2023-08-18 16:14:52,130:INFO:Total runtime is 6.093535526593526 minutes
2023-08-18 16:14:52,132:INFO:SubProcess create_model() called ==================================
2023-08-18 16:14:52,132:INFO:Initializing create_model()
2023-08-18 16:14:52,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F2DB82440>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:14:52,132:INFO:Checking exceptions
2023-08-18 16:14:52,132:INFO:Importing libraries
2023-08-18 16:14:52,132:INFO:Copying training dataset
2023-08-18 16:14:52,167:INFO:Defining folds
2023-08-18 16:14:52,167:INFO:Declaring metric variables
2023-08-18 16:14:52,170:INFO:Importing untrained model
2023-08-18 16:14:52,173:INFO:Dummy Classifier Imported successfully
2023-08-18 16:14:52,178:INFO:Starting cross validation
2023-08-18 16:14:52,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:14:53,943:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:53,946:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:53,949:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:54,083:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:54,123:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:54,140:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:54,171:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:54,194:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:54,195:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:54,246:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-18 16:14:56,708:INFO:Calculating mean and std
2023-08-18 16:14:56,709:INFO:Creating metrics dataframe
2023-08-18 16:14:57,076:INFO:Uploading results into container
2023-08-18 16:14:57,077:INFO:Uploading model into container now
2023-08-18 16:14:57,077:INFO:_master_model_container: 16
2023-08-18 16:14:57,077:INFO:_display_container: 2
2023-08-18 16:14:57,077:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-18 16:14:57,078:INFO:create_model() successfully completed......................................
2023-08-18 16:14:57,192:INFO:SubProcess create_model() end ==================================
2023-08-18 16:14:57,192:INFO:Creating metrics dataframe
2023-08-18 16:14:57,208:INFO:Initializing create_model()
2023-08-18 16:14:57,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:14:57,208:INFO:Checking exceptions
2023-08-18 16:14:57,210:INFO:Importing libraries
2023-08-18 16:14:57,210:INFO:Copying training dataset
2023-08-18 16:14:57,250:INFO:Defining folds
2023-08-18 16:14:57,250:INFO:Declaring metric variables
2023-08-18 16:14:57,250:INFO:Importing untrained model
2023-08-18 16:14:57,250:INFO:Declaring custom model
2023-08-18 16:14:57,251:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-18 16:14:57,256:INFO:Cross validation set to False
2023-08-18 16:14:57,256:INFO:Fitting Model
2023-08-18 16:15:09,332:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-18 16:15:09,333:INFO:[LightGBM] [Info] Number of positive: 13203, number of negative: 171645
2023-08-18 16:15:09,352:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006754 seconds.
2023-08-18 16:15:09,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-18 16:15:09,352:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-18 16:15:09,352:INFO:[LightGBM] [Info] Total Bins 467
2023-08-18 16:15:09,352:INFO:[LightGBM] [Info] Number of data points in the train set: 184848, number of used features: 32
2023-08-18 16:15:09,353:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.071426 -> initscore=-2.564984
2023-08-18 16:15:09,353:INFO:[LightGBM] [Info] Start training from score -2.564984
2023-08-18 16:15:09,902:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-18 16:15:09,902:INFO:create_model() successfully completed......................................
2023-08-18 16:15:10,032:INFO:_master_model_container: 16
2023-08-18 16:15:10,032:INFO:_display_container: 2
2023-08-18 16:15:10,032:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-18 16:15:10,032:INFO:compare_models() successfully completed......................................
2023-08-18 16:17:34,222:INFO:Initializing create_model()
2023-08-18 16:17:34,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:17:34,222:INFO:Checking exceptions
2023-08-18 16:17:34,231:INFO:Importing libraries
2023-08-18 16:17:34,231:INFO:Copying training dataset
2023-08-18 16:17:34,275:INFO:Defining folds
2023-08-18 16:17:34,275:INFO:Declaring metric variables
2023-08-18 16:17:34,278:INFO:Importing untrained model
2023-08-18 16:17:34,280:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-18 16:17:34,285:INFO:Starting cross validation
2023-08-18 16:17:34,291:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:17:38,878:INFO:Calculating mean and std
2023-08-18 16:17:38,879:INFO:Creating metrics dataframe
2023-08-18 16:17:38,884:INFO:Finalizing model
2023-08-18 16:17:41,055:INFO:Uploading results into container
2023-08-18 16:17:41,055:INFO:Uploading model into container now
2023-08-18 16:17:41,063:INFO:_master_model_container: 17
2023-08-18 16:17:41,064:INFO:_display_container: 3
2023-08-18 16:17:41,064:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-18 16:17:41,064:INFO:create_model() successfully completed......................................
2023-08-18 16:17:41,201:INFO:Initializing create_model()
2023-08-18 16:17:41,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=qda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:17:41,201:INFO:Checking exceptions
2023-08-18 16:17:41,210:INFO:Importing libraries
2023-08-18 16:17:41,210:INFO:Copying training dataset
2023-08-18 16:17:41,251:INFO:Defining folds
2023-08-18 16:17:41,252:INFO:Declaring metric variables
2023-08-18 16:17:41,254:INFO:Importing untrained model
2023-08-18 16:17:41,257:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-18 16:17:41,261:INFO:Starting cross validation
2023-08-18 16:17:41,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:17:45,656:INFO:Calculating mean and std
2023-08-18 16:17:45,657:INFO:Creating metrics dataframe
2023-08-18 16:17:45,661:INFO:Finalizing model
2023-08-18 16:17:46,787:INFO:Uploading results into container
2023-08-18 16:17:46,788:INFO:Uploading model into container now
2023-08-18 16:17:46,798:INFO:_master_model_container: 18
2023-08-18 16:17:46,799:INFO:_display_container: 4
2023-08-18 16:17:46,799:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-18 16:17:46,799:INFO:create_model() successfully completed......................................
2023-08-18 16:17:46,947:INFO:Initializing create_model()
2023-08-18 16:17:46,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=nb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:17:46,947:INFO:Checking exceptions
2023-08-18 16:17:46,956:INFO:Importing libraries
2023-08-18 16:17:46,957:INFO:Copying training dataset
2023-08-18 16:17:46,993:INFO:Defining folds
2023-08-18 16:17:46,994:INFO:Declaring metric variables
2023-08-18 16:17:46,996:INFO:Importing untrained model
2023-08-18 16:17:46,999:INFO:Naive Bayes Imported successfully
2023-08-18 16:17:47,004:INFO:Starting cross validation
2023-08-18 16:17:47,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:17:51,962:INFO:Calculating mean and std
2023-08-18 16:17:51,963:INFO:Creating metrics dataframe
2023-08-18 16:17:51,968:INFO:Finalizing model
2023-08-18 16:17:52,893:INFO:Uploading results into container
2023-08-18 16:17:52,893:INFO:Uploading model into container now
2023-08-18 16:17:52,900:INFO:_master_model_container: 19
2023-08-18 16:17:52,901:INFO:_display_container: 5
2023-08-18 16:17:52,901:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-18 16:17:52,901:INFO:create_model() successfully completed......................................
2023-08-18 16:17:53,017:INFO:Initializing blend_models()
2023-08-18 16:17:53,017:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-18 16:17:53,018:INFO:Checking exceptions
2023-08-18 16:17:53,048:INFO:Importing libraries
2023-08-18 16:17:53,048:INFO:Copying training dataset
2023-08-18 16:17:53,050:INFO:Getting model names
2023-08-18 16:17:53,053:INFO:SubProcess create_model() called ==================================
2023-08-18 16:17:53,055:INFO:Initializing create_model()
2023-08-18 16:17:53,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F248ABAF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:17:53,056:INFO:Checking exceptions
2023-08-18 16:17:53,056:INFO:Importing libraries
2023-08-18 16:17:53,056:INFO:Copying training dataset
2023-08-18 16:17:53,111:INFO:Defining folds
2023-08-18 16:17:53,111:INFO:Declaring metric variables
2023-08-18 16:17:53,113:INFO:Importing untrained model
2023-08-18 16:17:53,114:INFO:Declaring custom model
2023-08-18 16:17:53,117:INFO:Voting Classifier Imported successfully
2023-08-18 16:17:53,121:INFO:Starting cross validation
2023-08-18 16:17:53,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:17:56,363:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:56,440:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:56,496:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:56,800:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:56,851:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:57,145:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:57,164:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:57,173:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:57,175:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:17:57,228:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:03,529:INFO:Calculating mean and std
2023-08-18 16:18:03,530:INFO:Creating metrics dataframe
2023-08-18 16:18:03,534:INFO:Finalizing model
2023-08-18 16:18:04,661:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:05,153:INFO:Uploading results into container
2023-08-18 16:18:05,154:INFO:Uploading model into container now
2023-08-18 16:18:05,154:INFO:_master_model_container: 20
2023-08-18 16:18:05,154:INFO:_display_container: 6
2023-08-18 16:18:05,156:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-18 16:18:05,156:INFO:create_model() successfully completed......................................
2023-08-18 16:18:05,268:INFO:SubProcess create_model() end ==================================
2023-08-18 16:18:05,274:INFO:_master_model_container: 20
2023-08-18 16:18:05,275:INFO:_display_container: 6
2023-08-18 16:18:05,276:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-18 16:18:05,276:INFO:blend_models() successfully completed......................................
2023-08-18 16:18:05,388:INFO:Initializing blend_models()
2023-08-18 16:18:05,388:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=soft, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-18 16:18:05,388:INFO:Checking exceptions
2023-08-18 16:18:05,408:INFO:Importing libraries
2023-08-18 16:18:05,409:INFO:Copying training dataset
2023-08-18 16:18:05,411:INFO:Getting model names
2023-08-18 16:18:05,414:INFO:SubProcess create_model() called ==================================
2023-08-18 16:18:05,416:INFO:Initializing create_model()
2023-08-18 16:18:05,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018F1DE5FA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-18 16:18:05,416:INFO:Checking exceptions
2023-08-18 16:18:05,416:INFO:Importing libraries
2023-08-18 16:18:05,416:INFO:Copying training dataset
2023-08-18 16:18:05,458:INFO:Defining folds
2023-08-18 16:18:05,458:INFO:Declaring metric variables
2023-08-18 16:18:05,460:INFO:Importing untrained model
2023-08-18 16:18:05,460:INFO:Declaring custom model
2023-08-18 16:18:05,464:INFO:Voting Classifier Imported successfully
2023-08-18 16:18:05,468:INFO:Starting cross validation
2023-08-18 16:18:05,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-18 16:18:08,348:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:08,616:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:08,783:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:08,874:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:08,879:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:08,949:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:09,056:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:09,063:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:09,147:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:09,155:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:15,798:INFO:Calculating mean and std
2023-08-18 16:18:15,799:INFO:Creating metrics dataframe
2023-08-18 16:18:15,803:INFO:Finalizing model
2023-08-18 16:18:16,863:WARNING:c:\Users\Ramon\miniforge3\envs\PyCaretEnv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-18 16:18:17,483:INFO:Uploading results into container
2023-08-18 16:18:17,484:INFO:Uploading model into container now
2023-08-18 16:18:17,485:INFO:_master_model_container: 21
2023-08-18 16:18:17,485:INFO:_display_container: 7
2023-08-18 16:18:17,486:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-18 16:18:17,486:INFO:create_model() successfully completed......................................
2023-08-18 16:18:17,603:INFO:SubProcess create_model() end ==================================
2023-08-18 16:18:17,609:INFO:_master_model_container: 21
2023-08-18 16:18:17,609:INFO:_display_container: 7
2023-08-18 16:18:17,611:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-18 16:18:17,611:INFO:blend_models() successfully completed......................................
2023-08-18 16:22:15,873:INFO:Initializing evaluate_model()
2023-08-18 16:22:15,873:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-18 16:22:15,897:INFO:Initializing plot_model()
2023-08-18 16:22:15,897:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001)),
                             ('Naive Bayes',
                              GaussianNB(priors=None, var_smoothing=1e-09))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, system=True)
2023-08-18 16:22:15,897:INFO:Checking exceptions
2023-08-18 16:22:15,909:INFO:Preloading libraries
2023-08-18 16:22:15,913:INFO:Copying training dataset
2023-08-18 16:22:15,913:INFO:Plot type: pipeline
2023-08-18 16:22:16,131:INFO:Visual Rendered Successfully
2023-08-18 16:22:16,251:INFO:plot_model() successfully completed......................................
2023-08-18 16:22:16,253:INFO:Initializing evaluate_model()
2023-08-18 16:22:16,254:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-18 16:22:16,293:INFO:Initializing plot_model()
2023-08-18 16:22:16,293:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0)),
                             ('Quadratic Discriminant Analysis',
                              QuadraticDiscriminantAnalysis(priors=None,
                                                            reg_param=0.0,
                                                            store_covariance=False,
                                                            tol=0.0001))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018F1DAC6E00>, system=True)
2023-08-18 16:22:16,293:INFO:Checking exceptions
2023-08-18 16:22:16,306:INFO:Preloading libraries
2023-08-18 16:22:16,311:INFO:Copying training dataset
2023-08-18 16:22:16,311:INFO:Plot type: pipeline
2023-08-18 16:22:16,500:INFO:Visual Rendered Successfully
2023-08-18 16:22:16,615:INFO:plot_model() successfully completed......................................
